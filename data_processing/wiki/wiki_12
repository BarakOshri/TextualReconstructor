<doc id="2078" url="http://en.wikipedia.org/wiki?curid=2078" title="Acorn Electron">
Acorn Electron

The Acorn Electron is a budget version of the BBC Micro educational/home computer made by Acorn Computers Ltd. It has 32 kilobytes of RAM, and its ROM includes BBC BASIC v2 along with its operating system.
The Electron was able to save and load programs onto audio cassette via a supplied converter cable that connected it to any standard tape recorder that had the correct sockets. It was capable of basic graphics, and could display onto either a television set, a colour (RGB) monitor or a "green screen" monitor.
At its peak, the Electron was the third best selling micro in the United Kingdom, and total lifetime game sales for the Electron exceeded those of the BBC Micro.
History.
The Electron was developed during 1983 as a cheap sibling for the BBC Micro with the intention of capturing the low-cost Christmas sales market for that year. Although Acorn were able to shrink substantially the same functionality as the BBC into just one chip, manufacturing problems meant that despite pre orders of 300,000, only 30,000 machines were available for the Christmas period — to the extent that some shops reported eight presales for every delivered machine, there were even press reports of fights in places such as Rumbelows over the slim shipments of machines, as parents could not get an Electron, they turned to other readily available machines such as the ZX Spectrum and Commodore 64.
Unfortunately for Acorn, in the months after Christmas, the firm was tied to accepting delivery of the remaining pre order machines, and there was a warehouse in Wellingborough with unsold machines piled up to the ceiling.
This was a blow from which the machine never fully recovered, although games sales for it would ultimately outstrip those of the BBC Micro. Following Olivetti's 1985 cash injection into Acorn the machine was effectively sidelined.
With hindsight, the machine lacked the RAM (a typical program would need to fit in only around 20 kB once display memory is subtracted) and processing power to take on the prevailing Sinclair ZX Spectrum and Commodore 64. Despite this, several features that would later be associated with BBC Master and Archimedes were first features of Electron expansion units, including ROM cartridge slots and the Advanced Disc Filing System — a hierarchical improvement to the BBC's original Disc Filing System.
While it may not have been as popular as the Spectrum, Commodore 64 or Amstrad CPC, it did sell in sufficient numbers to ensure that new software was being produced right up until the early 1990s. This meant the Electron had a lifespan not much shorter than those more popular micros and much longer than competitors such as the Oric-1 and Dragon 32.
Popular upgrades.
Acorn Plus 1.
The Acorn Plus 1 added two ROM cartridge slots, an analogue interface (supporting two channels) and a Centronics parallel port. The analogue interface was normally used for joysticks, the parallel for a printer. The ROM slots could be booted from via the "Shift+BREAK" key-combination. (The slot at the front of the interface took priority if both were populated).
Access to ROM memory occurred at 2 MHz regardless of graphics mode so theoretically programs released on ROM could run at least twice as fast as those released on tape or disc. Despite this all of the games released on ROM were packaged as "serial ROMS", from which the micro would load programs into main memory in exactly the same way as if it were loading from tape. This meant that programs did not need to be modified for their new memory location but gave no execution speed benefits.
The Cartridge-port ROM-slots provided additional control lines, (compared to the lines available via the Edge-connector on the rear of the Electron), such as ROMSTBY, SNDIN, ROMQA, and some additional Voltage sources (+16V) etc. The total number of lines exposed via the Cartridge port almost matched those from the 1 MHz bus of the BBC.
Additional peripheral cartridge-holders by companies such as P.R.E.S. (via their products) allowed 'Sideways ROM' capability, that allowed the standard Acorn ROM space to be programmatically mapped out for alternative EPROMs, either physically via ZIF Sockets, or 'virtually' via ROM-images loaded into (battery-backed) RAM in the same ROM memory space. This enabled the Electron to achieve the same functionality as that provided by the Expansion-ROM slots under the keyboard and on the bottom-left of the BBC Micro B keyboard.
The addition of the Plus 1 added a number of new *FX and OSBYTE calls that allowed the OS to read the values from the analogue and parallel interfaces.
Compatibility.
The Plus 1 needed memory page &D for its workspace, and some games used this space. To disable the Plus 1, after pressing BREAK, the following commands could be issued:
 *FX163,128,1<br>
 ?&212=&D6<br>
 ?&213=&F1<br>
 ?&2AC=0
Acorn Plus 2.
Per a News article on Page #9 of the October 1984 issue of Acorn User, the Acorn 'Plus 2' interface was due to provide Econet capability. This interface did not make it to market.
Acorn Plus 3.
The Acorn Plus 3 was a hardware module that connected independently of the Plus 1 and provided a double-density 3½" disc drive connected through a WD1770 drive controller and an ADFS ROM. There were two versions of the Plus 3 produced: A Single-sided and a Double-sided drive version. Because the WD1770 is capable of single density mode and uses the same IBM360 derived floppy disc format as the Intel 8271 found in the BBC Micro, it was also possible to run a DFS filing system with an alternate ROM, such as the P.R.E.S AP4 interface.
The Plus 3 reset PAGE to &1D00, reducing the amount of free RAM available to user. The ADFS system could be temporarily disabled (and PAGE reset to &E00) via the *NOADFS command. Alternative WD1770-based DFS and ADFS interfaces such as the P.R.E.S AP4 and 'ADFS E00' products left PAGE at &E00, and did not require the presence of the ZYSYSHELP file (see below)
Disks had to be manually mounted and dismounted using the *MOUNT / *DISMOUNT commands, or using the CTRL-A+BREAK key combination. Disks could also be booted from via the standard "Shift+BREAK" key-combination, if the !BOOT file was present on the disk. This behaviour was the same as on the BBC Micro.
The Plus 3 included an uprated square black power supply unit with mains cord, manufactured by STC, designed and manufactured in England to BS 415 and BS 5850, that was designed to power the Plus 3, in addition to the Electron and the Plus 1 interface as well. This replaced the original cream-coloured "wall wart" style power supply, designed to BS 415 and manufactured in Hong Kong.
The original Electron Edge-connector was repeated on the back of the Plus3, in addition to a secondary smaller edge-connector, that enabled additional drives to be connected (Shugart-compatible connection). These required their own power-supply. The secondary edge-connector could not power external drives.
Repair note: If the internal power-supply connector, used to power the existing internal 3.5" drive is damaged, and requires replacement, then the original AMP 800-930 4-pin connector, which was already in short supply during the original production run, may be replaced with a Molex 5264 50-37-5043 "Mini-SPOX" connector as an alternative.
If using the Plus3 in screen modes 0-3, the pseudo-variable TIME would be thrown off, as the interrupts were disabled during disk access in these modes.
Per a News article on page 9 of the October 1984 issue of Acorn User, the Plus 3 was originally destined to have used the Intel 8272 disk controller, (and not 8271, which were in short supply at the time).
ADFS quirks.
The ADFS file format used the bytes Hugo to delimit the directory names on the disc, named after ADFS inventor Hugo Tyson. Another quirk was the presence of the file ZYSYSHELP which was required by the system, and created during formatting. This was a kludge. Acorn's v1.0 ADFS implementation on the Electron was unreliable when writing to the first few tracks of a disc, so this was a "fix" and simply involved writing a file full of garbage to the suspect part. The ADFS would then skip it. Disc corruption could also occur if attempting to use the *COMPACT command without disabling the blinking cursor with the following command:
 This was due to the fact that the *COMPACT command used screen memory as working space during the operation, and the blinking cursor corrupted that memory space.
Disc formatting was done via the *EFORM command, vs the more familiar *FORM40/*FORM80 DFS commands. Note additionally that the *EFORM command differs from the equivalent *AFORM command for the 1770 ADFS on the BBC Microcomputer. This is possibly as a result of needing to create the ZYSYSHELP file on the Electron. The *EFORM command was only supplied on the Welcome disc that was shipped with the Plus3, and was not included in the ROM.
First Byte Joystick Interface.
As a games machine the Electron shared the same failing as the Sinclair Spectrum in not having a joystick port. This was quickly remedied by First Byte Computers who developed an interface and software which allowed a "switched" joystick to be used with the majority of software titles. This interface became very popular and was sold by W.H. Smiths, Boots, Comet and hundreds of independent computer dealers.
P.R.E.S. Advanced Plus 3.
The Advanced Plus 3 was very similar to the Acorn Plus 3 but packaged as an ADFS ROM cartridge for the Plus 1 with a disc drive connector at the head. This made it possible to connect a 5¼" floppy disc drive as used by BBC Micro owners or a more common 3½" drive.
P.R.E.S. Advanced Plus 5.
 Provided User Port (all lines), 1 MHz bus and 'Tube' bus capability, enabling second processor usage.
For the PRES5, and other similar interfaces, the User Port is usually implemented via a 6522 VIA chip.
Slogger/Elektuur Turbo Board.
The Slogger and Elektuur Turbo Boards were born out of a hack initially devised at Acorn. By moving the lowest 8 kB of RAM outside of reach of the ULA, the CPU could always access it at 2 MHz. The tradeoff was that the screen could not be located in that 8 kB. In practice the operating system ROMs always put the screen into the top 24 kB and as a result this probably only broke compatibility with around 2% of software.
The Slogger Turbo Board was a professionally fitted upgrade whereas the Elektuur modification was described in an article in Dutch Electronics magazine Elektuur and intended for users to perform at home.
Speeding up the low portion of memory is particularly useful on 6502 derived machines because that processor has a faster addressing mode for the first 256 bytes and so it is common for software to put any variables involved in time critical sections of program into that region.
If Acorn had thought to include this small modification in the original Electron design it is likely the machine would have had a much greater impact as it would have nearly doubled the amount of motion possible in games and saved modes 0–3 (including the only 16 colour mode) from being nearly useless due to contended memory timings.
Slogger Master RAM Board.
A development of the Turbo Board, the Master RAM Board duplicated the Turbo Board functionality and added a further option of running the micro with 32 kB of shadow RAM in addition to the ordinary 32 kB — giving 64 kB total. Some clever program counter catches meant that the ordinary system ROMs and any software using the OS calls could function without significant modification, making substantially more memory available for BASIC, View, Viewsheet and almost every other business application. By providing extra storage this modification also allowed some games and applications intended for the BBC Micro to function on the Electron despite the lack of a native Mode 7.
Applications could not directly address video memory in this mode without modification, so it was incompatible with most games, although there is no inherent reason why a game could not be written to function in shadow mode.
During its decline, Master RAM Boards were added to every Electron in an attempt to increase sales.
Jafa Systems Mode 7 Display Unit.
Of the capabilities present in the BBC Micro but absent from the Electron, the teletext-style "mode 7" was particularly conspicuous because of the very low memory usage in that mode (just less than 1 kB) and the high number of BBC programs that used it. provided a number of solutions to redress this deficiency. (Note - the Jafa interface did not provide Teletext interface itself, but it did work in conjunction with specific CEEFAX/Teletext/Prestel adaptors from other manufacturers such as Morley)
The most basic solution was a pure software system supplied on a ROM cartridge that drew a low resolution approximation of the mode 7 display in a graphics mode. Although cheap and effective in enabling use of some software that only used official ROM entry points for text output, this solution proved very slow because the Electron had to be placed into an 80-byte-pitch display to be able to get anywhere near to reproducing mode 7 and the CPU spent a lot of time drawing approximations of mode 7 characters and graphics that in a hardware solution would be achieved without any CPU processing. It also used up 20 kB of RAM for the graphics display rather than the 1 kB of a hardware mode 7.
Two solutions with additional hardware were provided. The first used the same graphics processor as the BBC Micro in mode 7 — the SAA5050 — but used software to ensure that it was fed with the correct graphics data. A software ROM would put the machine into an ordinary 40-byte-pitch display. While the ULA would read the display from memory in the usual fashion, the SAA5050 would listen to the data it was reading and produce a mode 7 interpretation of the same information. When necessary the hardware would switch between the graphics output being produced by the micro and that being produced by the add-on.
The disadvantage to this system is that while the SAA5050 would expect to be repeatedly fed the same 40 bytes of data for every display scanline of each character row, the ULA would read a different set of 40 bytes for every display scanline in order to produce a full graphics display. A software ROM worked around this by duplicating the data intended for a mode 7 display in memory. Although this produced a mode 7 that barely impacted upon CPU performance and gave the same visual quality as the BBC Micro, it remained compatible only with software that used the ROM routines for outputting text and graphics and still used 10 kB of memory for the display.
A second version of the hardware add-on corrected these problems. By adding a CRTC6845 to the package, a full hardware solution was created that did not reduce CPU performance and only used 1 kB of memory for the display. A software ROM was still supplied, but this did no more than expand the hardware ROM so that it knew mode 7 now existed and was able to switch into it.
Electron Second Processor.
During the latter years, PMS produced a specifically for the Electron. This provided an alternative to buying the combination of the P.R.E.S. Advanced Plus 5 and Acorn 6502 2nd Processor.
Merlin M2105.
An unusual variant of the Electron was sold by British Telecom Business Systems as the BT Merlin M2105 Communications Terminal. This consisted of a de-badged Electron plus a large expansion unit containing 32 kB of RAM, 48 kB of ROM, a Centronics printer port and a modem. The ROM firmware provided dial-up communications facilities. These were used by the Interflora florists network in the UK for over a decade.
Technical information.
The hardware of the BBC Micro was emulated by a single customized ULA chip designed by Acorn in conjunction with Ferranti. It had feature limitations such as the inability to provide teletext mode and being unable to output more than one channel of sound. By contrast, the BBC Micro was capable of three-way polyphony (plus one noise channel).
The edge-connector on the rear of the Electron exposed almost all the Bus lines, but not all. (The BBC Micro, courtesy of all its ports, exposed all lines.)
For Issue 1-4 motherboards, the ULA had an issue similar to those experienced by other socketed CPU's. Over time, the thermal heating and cooling could cause the ULA to rise slightly out of its socket just enough to cause the machine to start exhibiting 'hanging' or other startup-failure issues, such as a continuous 'startup beep'. This was despite a metal cover, and locking-bar mechanism designed to prevent this from occurring. Pushing down on the metal cover to reseat the ULA was normally sufficient to rectify these issues. Issue 5 and 6 boards utilized a different epoxy resin covering directly over the ULA, which resolved this issue.
The keyboard included a form of single-key keyword input, similar to that used on the Sinclair Spectrum, via the 'func' key. However, unlike the Spectrum, the single-keypress keyword-entry was optional, and keywords could be entered manually if preferred.
The ULA controlled memory access and was able to provide 32K × 8 bits of addressable RAM using 4 × 64K × 1-bit RAM chips (4164). Due to needing two accesses to each chip instead of one, and the complications of the video hardware also needing access, reading or writing RAM was much slower than on the BBC Micro. This meant that although ROM applications ran at the same speed, there was a substantial speed decrease on applications running from RAM.
Quirks.
Like the BBC Micro, the Electron was constrained by limited memory resources. Of the 32 kB RAM, 3½ kB was allocated to the OS at startup and at least 10 kB was taken up by the display buffer in contiguous display modes.
Due to the timing of interrupts it was possible to disable either the top 100 or bottom 156 lines of the display with palette changes. Many games took advantage of this, gaining storage by leaving non-graphical data in the disabled area.
Other games would load non-graphical data into the display, leaving it visible as regions of apparently randomly coloured pixels.
Although page flipping was a hardware possibility, the limited memory forced most applications to do all their drawing directly to the visible screen, often resulting in graphical flicker or visible redraw. A notable exception is Players' "Joe Blade" series.
Tricks.
FireTrack: smooth vertical scrolling.
Although programs can alter the position of the screen in memory, the non-linear format of the display means that vertical scrolling can only be done in blocks of 8 pixels without further work.
"FireTrack" exploits a division in the way the Electron handles its display — of the seven available graphics modes, two are configured so that the final two of every ten scanlines are blank and are not based on the contents of RAM. If 16 scanlines of continuous graphical data are written to a character-block-aligned portion of the screen then they will appear as a continuous block in most modes but in the two non-continuous modes they will be displayed as two blocks of eight scanlines, separated in the middle by two blank scanlines.
In order to keep track of its position within the display, the Electron maintains an internal display address counter. The same counter is used in both the continuous and non-continuous graphics modes and switching modes mid-frame does not cause any adjustment to the counter.
"FireTrack" switches from a non-continuous to a continuous graphics mode part way down the display. By using the palette to mask the top area of the display and taking care about when it changes mode it can shift the continuous graphics at the bottom of the display down in two pixel increments because the internal display counter is not incremented on blank scanlines during non-continuous graphics modes.
Exile: sampled speech.
"Exile" turns the Electron's one channel output into a digital speaker for PCM output.
The speaker can be programmatically switched on or off at any time but is permanently attached to a hardware counter so is normally only able to output a square wave. But if set to a frequency outside the human audible range then the ear can't perceive the square wave, only the difference between the speaker being switched on and off. This gives the effect of a simple toggle speaker similar to that seen in the 48 kB Sinclair ZX Spectrum. "Exile" uses this to output 1-bit audio samples.
Frak! and Zalaga: Polyphonic music.
Aardvark Software's "Frak!" and "Zalaga" As part of the copy protection, illegal copies of the games would cause a pseudo-polyphonic rendition of Trumpet Hornpipe, the Captain Pugwash theme tune, to play endlessly rather than loading the game properly (Pugwash being a pirate). On the Electron version of Frak!, the tune was the main theme from "Benny Hill" (Boots Randolph's "Yakety Sax"). The polyphony was achieved via fast note-switching to achieve the necessary chords.
Popular games.
Although not as well supported by the biggest software publishers as rivals like the Commodore 64 and Sinclair ZX Spectrum, a good range of games were available for the Electron. The traditional BBC Micro publishers such as Acornsoft, Superior Software and Micro Power offered the widest support. Notable popular games particularly associated with the Electron include:
There were also many popular games officially converted to the Electron from arcade machines (including "Crystal Castles", "Tempest", "Commando", "Paperboy" and "Yie Ar Kung-Fu") or other home computer systems (including "Impossible Mission", "Jet Set Willy", "The Way of the Exploding Fist", "Tetris", "The Last Ninja", "Barbarian" and "SimCity").
Despite Acorn themselves effectively shelving the Electron in 1985, games continued to be developed and released by professional software houses until 1991. There were around 1,400 games released for the Acorn Electron, several thousand extra public domain titles were released on disc through Public Domain libraries. Notable enterprises which produced discs of such software are BBC PD, Electron User Group and HeadFirst PD.
Emulation.
Three emulators of the machine exist, ElectrEm for Windows/Linux/OS X, Elkulator for Windows/DOS, ElkJS is a browser based (Javascript/HTML5) Emulator and the Multi-system emulator MESS. Electron software is predominantly archived in the UEF file format.
Design team.
The operating system ROM locations 0xFC00-0xFDFF contain the following text, which is different from the 'thanks' list in the original BBC Model B:
codice_1
Additionally, the last bytes of both the BASIC ROM and 'Plus 3 Interface' ADFS v1.0 ROM include the word "Roger", thought to be a reference to Roger Wilson.
The case was designed by industrial designer Allen Boothroyd of Cambridge Product Design Ltd.

</doc>
<doc id="2080" url="http://en.wikipedia.org/wiki?curid=2080" title="A Fire Upon the Deep">
A Fire Upon the Deep

A Fire Upon the Deep is a science fiction novel by American writer Vernor Vinge, a space opera involving superhuman intelligences, aliens, variable physics, space battles, love, betrayal, genocide, and a conversation medium resembling Usenet. "A Fire Upon the Deep" won the Hugo Award in 1993 (tied with "Doomsday Book" by Connie Willis).
Besides the normal print book editions, the novel was also included on a CD-ROM sold by ClariNet Communications along with the other nominees for the 1993 Hugo awards. The CD-ROM edition included numerous annotations by Vinge on his thoughts and intentions about different parts of the book.
Setting.
The novel is set in various locations in the Milky Way. The galaxy is divided into four concentric volumes called the "Zones of Thought"; it is not clear to the novel's characters if this is a natural phenomenon or an artificially-produced one, but it seems to roughly correspond with galactic-scale stellar density. The Zones reflect fundamental differences in basic physical laws, and one of the main consequences is their effect on intelligence, both biological and artificial. Artificial intelligence and automation is most directly affected, in that advanced hardware and software from the Beyond or the Transcend will work less and less well as a ship "descends" towards the Unthinking Depths. But even biological intelligence is affected to a lesser degree. The four zones are spoken of in terms of "low" to "high" as follows:
Plot.
An expedition from Straumli Realm, an ambitious young human civilization in the Beyond just inside the Transcend border, investigates a five-billion-year-old data archive in the Transcend that offers the possibility of unimaginable riches. The expedition's facility, called High Lab, is gradually compromised by a dormant super-intelligent entity (actually encoded within the archive) later known as the Blight. The Blight rapidly learns how to infiltrate and control the computer systems of High Lab, and even develops the ability to possess and control the living humans. The novel starts with an imaginative description of the evolution of this superintelligence through exponentially accelerating developmental stages, culminating in a transcendent, nigh-omnipotent power that is unfathomable to mere humans. Shortly before its final "flowering", the changes in a single minute of the Blight's life are said to exceed those of 10,000 years of human civilization.
Recognizing the danger of what they have awakened, the researchers at High Lab attempt to flee in two ships. Suspicious, the Blight discovers that one of the ships contains a data storage device in its cargo manifest; assuming it contains information that could harm it, the Blight destroys the ship. The second ship is allowed to escape, unharmed, as the Blight assumes that it is no threat; but later realizes that it actually held a "countermeasure", one of the few things in the universe that the Blight fears.
The ship lands on a distant planet with a medieval-level civilization of dog-like creatures dubbed "Tines", who live in packs as group minds. The ship is revealed to be a sleeper ship, carrying most of High Lab's children in "coldsleep boxes". The boxes are rapidly failing and the surviving adults begin unloading them, but are killed when one of two rival forces of Tines seize the ship. The faction that initially contacts the humans, led by a Tine known as Steel, kills the adults and destroys many of the coldsleep boxes. They also capture a boy named Jefri Olsndot, whom Steel intended on killing but eventually exploits in order to develop advanced technology (such as cannon and radio communication). Jefri's older sister, Johanna, is rescued by Pilgrim and Scriber, wandering Tines who bring her to the rival faction, led by Woodcarver. She is asked to help develop technology that could gain the upper hand in the impending war.
A distress signal from the sleeper ship eventually reaches "Relay", a major node in the galactic communications network. A benign transcendent entity (known as a "Power") named "Old One" contacts Relay, seeking information about the Blight and the humans who released it. Old One constructs a seemingly human man, Pham Nuwen, to act as its agent. Pham and Ravna Bergsndot – a human employee of Relay's owners, the wealthy Vrinimi Organization – trace the sleeper ship's signal to the Tines world. Vrinimi Org helps modify a vessel, the "Out of Band II", to reach the Tines world and to investigate what the ship carried with it from the High Lab.
The Blight attacks Relay and Old One. Old One has given Pham the information necessary to activate the Blight Countermeasure subconsciously, a process known as "godshatter" (which will result in his death). Pham and Ravna escape Relay's destruction in the "Out of Band II". After arriving at the Tines homeworld and allying with Woodcarver to defeat Steel, Pham initiates the Countermeasure, which extends the Slow Zone by thousands of light-years to enclose the Blight. This ends the threat of the Blight at the cost of wrecking thousands of uninvolved civilizations, causing trillions of deaths and potentially the extinction of several galactic races. The process strands the other humans on the Tines world, now in the depths of the "Slow Zone" where rescue by an advanced civilization is impossible.
Just before Pham dies, he realises that although his body is a reconstruction, the memories implanted by Old One are real. Vinge expands on Pham's backstory in "A Deepness in the Sky".
Intelligent Species.
A race of humanoids with colorful butterfly-like wings who attempt to use the chaos of the Blight to reestablish their waning hegemony. Despite their attractive, delicate appearance and initial demeanor, the Aprahanti are revealed to be an extremely fearsome and vicious species.
A representative being of a dormant super-intelligent entity group. Such super-intelligences can rapidly infiltrate and control the computer systems of less technologically advanced species, and even develop the ability to possess and control biological beings. Such super-intelligences are effectively immortal, nigh-omnipotent and transcendent.
Older race of inward dreamers, original inhabitants of Sjandra Kei.
All humans in the novel (except Pham) are descended from Nyjoran stock. Their ancestors were "Tuvo-Norsk" asteroid miners from Old Earth's solar system, which is noted as being on the other side of the galaxy in the Slow Zone. ("Nyjora" sounds similar to New Norwegian "New Earth".) One of the major human habitations is Sjandra Kei, three systems comprising roughly 28 billion individuals. Their main language is Samnorsk, the Norwegian term for a hypothetical unification of the Bokmål and Nynorsk forms of the language. (Vinge indicates in the book's dedication that several key ideas in it came to him while at a conference in Tromsø, Norway.)
A sessile race of trees with fronds that are used for expression. 5 billion years ago, the Blight gave them wheeled mechanical constructs (skrodes) to move and as short-term memory, and the destruction of the Blight survived as their founding myth. The Blight is able to corrupt and operate the Riders via their Skrodes.
A canid race, each 'person' comprising a group mind of 4-8 individuals, connected by ultrasonic waves. Each 'soul' will last as long as it has enough members, potentially hundreds of years.
Related works.
Vinge first used the concepts of "Zones of Thought" in a 1988 novella, "The Blabber", which occurs after "Fire". Vinge's novel, "A Deepness in the Sky" (1999), is a prequel to "A Fire Upon the Deep" set 20,000 years earlier and featuring Pham Nuwen. Vinge's "The Children of the Sky", "a near-term sequel to "A Fire Upon the Deep"", set ten years later, was released in October 2011.
Vinge's former wife, Joan D. Vinge, has also written stories in the Zones of Thought universe, based on his notes. These include "The Outcasts of Heaven Belt", "Legacy", and a planned novel featuring Pham Nuwen.
Title.
Vinge's original title for the novel was "Among the Tines"; its actual title was suggested by his editors.
Awards and nominations.
"A Fire Upon the Deep" shared the 1993 Hugo Award for Best Novel with "Doomsday Book", by Connie Willis. The book was nominated for the 1992 Nebula Award for Best Novel, the 1993 John W. Campbell Memorial Award for Best Science Fiction Novel, and the 1993 Locus Award for Best Science Fiction Novel.
Critical reactions.
Jo Walton wrote: "Any one of the ideas in "A Fire Upon the Deep" would have kept an ordinary writer going for years. For me it’s the book that does everything right, the example of what science fiction does when it works. ... "A Fire Upon the Deep" remains a favourite and a delight to re-read, absorbing even when I know exactly what’s coming."

</doc>
<doc id="2082" url="http://en.wikipedia.org/wiki?curid=2082" title="Aeronautics">
Aeronautics

Aeronautics (from the ancient Greek words ὰήρ "āēr", which means "air", and ναυτική "nautikē" which means "navigation", i.e. "navigation of the air") is the science or art involved with the study, design, and manufacturing of airflight-capable machines, and the techniques of operating aircraft and rockets within the atmosphere. The British Royal Aeronautical Society identifies the aspects of "aeronautical Art, Science and Engineering" and "the profession of Aeronautics (which expression includes Astronautics)." 
While the term—literally meaning "sailing the air"—originally referred solely to the science of "operating" the aircraft, it has since been expanded to include technology, business and other aspects related to aircraft. 
The term "aviation" is sometimes used interchangeably with aeronautics, although "aeronautics" includes lighter-than-air craft such as airships, and includes ballistic vehicles while "aviation" technically does not.
A significant part of aeronautical science is a branch of dynamics called aerodynamics, which deals with the motion of air and the way that it interacts with objects in motion, such as an aircraft.
History.
Early ideas.
Attempts to fly without any real aeronautical understanding have been made from the earliest times, typically by constructing wings and jumping from a tower with crippling or lethal results.
Wiser investigators sought to gain some rational understanding through the study of bird flight. An early example appears in ancient Egyptian texts. Later medieval Islamic scientists also made such studies. The founders of modern aeronautics, Leonardo da Vinci in the Renaissance and Cayley around 1800, both began their investigations with studies of bird flight.
Man-carrying kites are believed to have been used extensively in ancient China. In 1282 the European explorer Marco Polo described the Chinese techniques then current. The Chinese also constructed small hot air balloons, or lanterns, and rotary-wing toys.
An early European to provide any scientific discussion of flight was Roger Bacon, who described principles of operation for the lighter-than-air balloon and the flapping-wing ornithopter, which he envisaged would be constructed in the future. The lifting medium for his balloon would be an "aether" whose composition he did not know.
In the late fifteenth century, Leonardo da Vinci followed up his study of birds with designs for some of the earliest flying machines, including the flapping-wing ornithopter and the rotating-wing helicopter. Although his designs were rational, they were not based on particularly good science. Many of his designs, such as a four-person screw-type helicopter, have severe flaws. He did at least understand that "An object offers as much resistance to the air as the air does to the object." (Newton would not publish the Third law of motion until 1687.) His analysis led to the realisation that manpower alone was not sufficient for sustained flight, and his later designs included a mechanical power source such as a spring. Da Vinci's work was lost after his death and did not reappear until it had been overtaken by the work of George Cayley.
Balloon flight.
The modern era of lighter-than-air flight began early in the 17th century with Galileo's experiments in which he showed that air has weight. Around 1650 Cyrano de Bergerac wrote some fantasy novels in which he described the principle of ascent using a substance (dew) he supposed to be lighter than air, and descending by releasing a controlled amount of the substance. Francesco Lana de Terzi measured the pressure of air at sea level and in 1670 proposed the first scientifically credible lifting medium in the form of hollow metal spheres from which all the air had been pumped out. These would be lighter than the displaced air and able to lift an airship. His proposed methods of controlling height are still in use today; by carrying ballast which may be dropped overboard to gain height, and by venting the lifting containers to lose height. In practice de Terzi's spheres would have collapsed under air pressure, and further developments had to wait for more practicable lifting gases.
From the mid-18th century the Montgolfier brothers in France began experimenting with balloons. Their balloons were made of paper, and early experiments using steam as the lifting gas were short-lived due to its effect on the paper as it condensed. Mistaking smoke for a kind of steam, they began filling their balloons with hot smoky air which they called "electric smoke" and, despite not fully understanding the principles at work, made some successful launches and in 1783 were invited to give a demonstration to the French Academie des Sciences.
Meanwhile the discovery of hydrogen led Joseph Black in c. 1780 to propose its use as a lifting gas, though practical demonstration awaited a gastight balloon material. On hearing of the Montgolfier Brothers' invitation, the French Academy member Jacques Charles offered a similar demonstration of a hydrogen balloon. Charles and two craftsmen, the Robert brothers, developed a gastight material of rubberised silk for the envelope. The hydrogen gas was to be generated by chemical reaction during the filling process.
The Montgolfier designs had several shortcomings, not least the need for dry weather and a tendency for sparks from the fire to set light to the paper balloon. The manned design had a gallery around the base of the balloon rather than the hanging basket of the first, unmanned design, which brought the paper closer to the fire. On their free flight, De Rozier and d'Arlandes took buckets of water and sponges to douse these fires as they arose. On the other hand, the manned design of Charles was essentially modern. As a result of these exploits, the hot-air ballon became known as the "Montgolfière" type and the hydrogen balloon the "Charlière".
Charles and the Robert brothers' next balloon, "La Caroline", was a Charlière that followed Jean Baptiste Meusnier's proposals for an elongated dirigible balloon, and was notable for having an outer envelope with the gas contained in a second, inner ballonet. On 19 September 1784, it completed the first flight of over 100 km, between Paris and Beuvry, despite the man-powered propulsive devices proving useless.
In an attempt the next year to provide both endurance and controllability, de Rozier developed a balloon having both hot air and hydrogen gas bags, a design which was soon named after him as the "Rozière." The principle was to use the hydrogen section for constant lift and to navigate vertically by heating and allowing to cool the hot air section, in order to catch the most favourable wind at whatever altitude it was blowing. The balloon envelope was made of goldbeaters skin. The first flight ended in disaster and the approach has seldom been used since.
Cayley and the foundation of modern aeronautics.
Sir George Cayley (1773-1857) is widely acknowledged as the founder of modern aeronautics. He was first called the "father of the aeroplane" in 1846 and Henson called him the "father of aerial navigation." He was the first true scientific aerial investigator to publish his work, which included for the first time the underlying principles and forces of flight.
In 1809 he began the publication of a landmark three-part treatise titled "On Aerial Navigation" (1809–1810). In it he wrote the first scientific statement of the problem, "The whole problem is confined within these limits, viz. to make a surface support a given weight by the application of power to the resistance of air." He identified the four vector forces that influence an aircraft: "thrust", "lift", "drag" and "weight" and distinguished stability and control in his designs.
He developed the modern conventional form of the fixed-wing aeroplane having a stabilising tail with both horizontal and vertical surfaces, flying gliders both unmanned and manned.
He introduced the use of the whirling arm test rig to investigate the aerodynamics of flight, using it to discover the benefits of the curved or cambered aerofoil over the flat wing he had used for his first glider. He also identified and described the importance of dihedral, diagonal bracing and drag reduction, and contributed to the understanding and design of ornithopters and parachutes.
Another significant invention was the tension-spoked wheel, which he devised in order to create a light, strong wheel for aircraft undercarriage.
The 19th century.
During the 19th century Cayley's ideas were refined, proved and expanded on. Important investigators included Otto Lilienthal and Horatio Phillips.
Branches.
Aeronautics may be divided into three main branches comprising Aviation, Aeronautical science and Aeronautical engineering.
Aviation.
Aviation is the art or practice of aeronautics. Historically aviation meant only heavier-than-air flight, but nowadays it includes flying in balloons and airships.
Aeronautical science.
Aeronautical science covers the practical theory of aeronautics and aviation, including operations, navigation, air safety and human factors.
A candidate pilot is likely to study for a qualification in aeronautical science.
Aeronautical engineering.
Aeronautical engineering covers the design and construction of aircraft, including how they are powered, how they are used and how they are controlled for safe operation.
A major part of aeronautical engineering is aerodynamics, the science of passage through the air.
With the increasing activity in spaceflight, nowadays aeronautics and astronautics are often combined as aerospace engineering.
Aerodynamics.
The science of aerodynamics deals with the motion of air and the way that it interacts with objects in motion, such as an aircraft.
The study of aerodynamics falls broadly into three areas:
"Incompressible flow" occurs where the air simply moves to avoid objects, typically at subsonic speeds below that of sound (Mach 1).
"Compressible flow" occurs where shock waves appear at points where the air becomes compressed, typically at speeds above Mach 1.
"Transonic flow" occurs in the intermediate speed range around Mach 1, where the airflow over an object may be locally subsonic at one point and locally supersonic at another.
Rocketry.
A rocket or rocket vehicle is a missile, spacecraft, aircraft or other vehicle which obtains thrust from a rocket engine. In all rockets, the exhaust is formed entirely from propellants carried within the rocket before use. Rocket engines work by action and reaction. Rocket engines push rockets forwards simply by throwing their exhaust backwards extremely fast.
Rockets for military and recreational uses date back to at least 13th century China. Significant scientific, interplanetary and industrial use did not occur until the 20th century, when rocketry was the enabling technology of the Space Age, including setting foot on the moon.
Rockets are used for fireworks, weaponry, ejection seats, launch vehicles for artificial satellites, human spaceflight and exploration of other planets. While comparatively inefficient for low speed use, they are very lightweight and powerful, capable of generating large accelerations and of attaining extremely high speeds with reasonable efficiency.
Chemical rockets are the most common type of rocket and they typically create their exhaust by the combustion of rocket propellant. Chemical rockets store a large amount of energy in an easily released form, and can be very dangerous. However, careful design, testing, construction and use minimizes risks.

</doc>
<doc id="2083" url="http://en.wikipedia.org/wiki?curid=2083" title="Auguste and Louis Lumière">
Auguste and Louis Lumière

The Lumière () brothers, Auguste Marie Louis Nicolas (19 October 1862, Besançon, France – 10 April 1954, Lyon) and Louis Jean (5 October 1864, Besançon, France – 6 June 1948, Bandol), are credited to be the first filmmakers in history. They patented the cinematograph, which contrary to Edison's "peepshow" kinetoscope, the former allowed viewing by multiple parties at once, like current cinema. Their first film, Sortie de l'usine Lumière de Lyon, shot in 1894, is considered the first real motion picture in history. Curiously, their surname, "Lumière", is French for 
"light".
History.
The Lumière brothers were born in Besançon, France and moved to Lyon in 1870, where both attended La Martiniere, the largest technical school in Lyon. Their father, Claude-Antoine Lumière (1840–1911), ran a photographic firm where both brothers worked for him: Louis as a physicist and Auguste as a manager. Louis had made some improvements to the still-photograph process, the most notable being the dry-plate process, which was a major step towards moving images.
It was not until their father retired in 1892 that the brothers began to create moving pictures. They patented a number of significant processes leading up to their film camera, most notably film perforations (originally implemented by Emile Reynaud) as a means of advancing the film through the camera and projector. The original cinématographe had been patented by Léon Guillaume Bouly on 12 February 1892. The brothers patented their own version on 13 February 1895. The first footage ever to be recorded using it was recorded on March 19, 1895. This first film shows workers leaving the Lumière factory.
First film screenings.
The Lumières held their first private screening of projected motion pictures in 1895. Their first public screening of films at which admission was charged was held on December 28, 1895, at Salon Indien du Grand Café in Paris. This history-making presentation featured ten short films, including their first film, "Sortie des Usines Lumière à Lyon" ("Workers Leaving the Lumière Factory"). Each film is 17 meters long, which, when hand cranked through a projector, runs approximately 50 seconds.
 It is believed their first film was actually recorded that same year (1895) with Léon Bouly's cinématographe device, which was patented the previous year. The cinématographe — a three-in-one device that could record, develop, and project motion pictures — was further developed by the Lumières.
The public debut at the Grand Café came a few months later and consisted of the following ten short films (in order of presentation):
The Lumières went on tour with the cinématographe in 1896, visiting Bombay, London, Montreal, New York and Buenos Aires.
The moving images had an immediate and significant influence on popular culture with "L'Arrivée d'un Train en Gare de la Ciotat" (literally, "the arrival of a train at La Ciotat", but more commonly known as "Arrival of a Train at a Station") and "Carmaux, défournage du coke" (Drawing out the coke). Their actuality films, or "actualités", are often cited as the first, primitive documentaries. They also made the first steps towards comedy film with the slapstick of "L'Arroseur Arrosé".
Early color photography.
The brothers stated that "the cinema is an invention without any future" and declined to sell their camera to other filmmakers such as Georges Méliès. This made many film makers upset. Consequently, their role in the history of film was exceedingly brief. They turned their attentions to colour photography and in 1903 they patented a colour photography process, the "Autochrome Lumière", launched on the market in 1907. Throughout much of the 20th century, the Lumière company was a major producer of photographic products in Europe, but the brand name, Lumière, disappeared from the marketplace following merger with Ilford(ref .
Other early cinematographers.
The Lumière Brothers were not the only ones to claim the title of the first cinematographers. The scientific chronophotography devices developed by Eadweard Muybridge, Étienne-Jules Marey and Ottomar Anschütz in the 1880s were able to produce moving photographs, as was William Friese-Greene's 'chronophotographic' system, demonstrated in 1890, and Thomas Edison's Kinetoscope (developed by W K-L Dickson), premiered in 1891. Since 1892, the projected drawings of Émile Reynaud's Théâtre Optique were attracting Paris crowds to the Museé Grevin. Louis Le Prince and Claude Mechant had been shooting moving picture sequences on paper film as soon as 1888, but had never performed a public demonstration. Polish inventor, Kazimierz Prószyński had built his camera and projecting device, called Pleograph, in 1894. Max and Emil Skladanowsky, inventors of the Bioscop, had offered projected moving images to a paying public one month earlier (November 1, 1895, in Berlin). Nevertheless, film historians consider the Grand Café screening to be the true birth of the cinema as a commercial medium, because the Skladanowsky brothers' screening used an extremely impractical dual system motion picture projector that was immediately supplanted by the Lumiere cinematographe.
Although the Lumière brothers were not the first inventors to develop techniques to create motion pictures, they are often credited as among the first inventors of the technology for Cinema as a mass medium, and are among the first who understood how to use it.

</doc>
<doc id="2084" url="http://en.wikipedia.org/wiki?curid=2084" title="Acts of the Apostles">
Acts of the Apostles

The Acts of the Apostles (, "Práxeis tôn Apostólōn"; ), often referred to simply as Acts, is the fifth book of the New Testament; it tells of the founding of the Christian church and the spread of its message to the Roman empire.
Acts is the second half of a two-part work by the same anonymous author, Luke-Acts, usually dated to around 80-90 CE. The first part, the gospel of Luke, tells how God fulfilled his plan for the world's salvation through the life, death and resurrection of Jesus of Nazareth, the promised Messiah. Acts tells the story of the Early Christian church. The early chapters, set in Jerusalem, describe the Day of Pentecost (the coming of the Holy Spirit) and the growth of the church in Jerusalem. Initially the Jews are receptive to the Christian message, but soon they turn against the followers of the Messiah. Rejected by the Jews, under the guidance of the Apostle Peter the message is taken to the Gentiles. The later chapters tell of Paul's conversion, his mission in Asia Minor and the Aegean, and finally his imprisonment in Rome, where, as the book ends, he awaits trial.
Luke-Acts is an attempt to answer a theological problem, namely how the Messiah of the Jews came to have an overwhelmingly non-Jewish church; the answer it provides, and its central theme, is that the message of Christ was sent to the Gentiles because the Jews rejected it.
Composition and setting.
Title, unity of Luke-Acts, authorship and date.
The title "Acts of the Apostles" (Greek "Praxeis Apostolon") was first used by Irenaeus in the late 2nd century. It is not known whether this was an existing title or one invented by Irenaeus; it does seem clear, however, that it was not given by the author.
The gospel of Luke and Acts make up a two-volume work which scholars call Luke-Acts. Together they account for 27.5% of the New Testament, the largest contribution by a single author, providing the framework for both the Church's liturgical calendar and the historical outline into which later generations have fitted their idea of the story of Jesus and the early church.
The author is not named in either volume. According to a Church tradition dating from the 2nd century, he was the "Luke" named as a companion of the apostle Paul in three of the letters attributed to Paul himself; this view is still sometimes advanced, but "a critical consensus emphasizes the countless contradictions between the account in Acts and the authentic Pauline letters." (An example can be seen by comparing Acts' accounts of Paul's conversion (Acts 9:1-31, 22:6-21, and 26:9-23) with Paul's own statement that he remained unknown to Christians in Judea after that event (Galatians 1:17-24).) He admired Paul, but his theology was significantly different from Paul's on key points and he does not (in Acts) represent Paul's views accurately.
He was educated, a man of means, probably urban, and someone who respected manual work, although not a worker himself; this is significant, because more high-brow writers of the time looked down on the artisans and small business-people who made up the early church of Paul and were presumably Luke's audience.
Most experts date the composition of Luke-Acts to around 80-90 CE, although some suggest 90-110. The eclipse of the traditional attribution to Luke the companion of Paul has meant that an early date for the gospel is now rarely put forward.
Genre, sources and historicity of Acts.
Luke describes his work, Luke-Acts, as a "narrative" ("diegesis"). Acts, the second part, is widely thought of as a history, but it lacks exact analogies in Hellenistic or Jewish literature. The title "Acts of the Apostles" ("Praxeis Apostolon") would seem to identify it with the genre telling of the deeds and achievements of great men ("praxeis"), but it was not the title given by the author.
Luke seems to have taken as his model the works of two respected Classical authors, Dionysius of Halicarnassus, who wrote a well-known history of Rome, and the Jewish historian Josephus, author of a history of the Jews. Like them he anchors his history by dating the birth of the founder (Romulus and Moses for Dionysius and Josephus, Jesus for Luke) and like them he tells how the founder is born from God, taught authoritatively, and appeared to witnesses after death before ascending to heaven.
Luke would have had the same sources available for Acts as he used in writing his gospel: the Septuagint (a Greek translation of the Jewish scriptures), the gospel of Mark and the collection of "sayings of Jesus" called the Q source. By and large, however, the sources for Acts can only be guessed at. Luke transposed a few incidents from Mark's gospel to the time of the Apostles – for example, the material about "clean" and "unclean" foods in Mark 7 is used in Acts 10, and Mark's account of the accusation that Jesus has attacked the Temple (Mark 14:58) is used in a story about Stephen (Acts 6:14).) There are also points of contacts (meaning suggestive parallels but something less than clear evidence) with 1 Peter, Hebrews, and 1 Clement, as well as with the writings of the Jewish historian Josephus. (A knowledge of Josephus would incidentally push the date of composition for Acts to later than 93 CE). Other sources can only be inferred from internal evidence – the three "we" passages, for example, might point to such a source, and the traditional explanation is that they represent eye-witness accounts. The search for such inferred sources was popular in the 19th century, but by the mid-20th it had largely been abandoned.
Acts was read as a reliable history of the early church well into the post-Reformation era. By the 17th century, however, biblical scholars began to notice that it was incomplete and tendentious – its picture of a harmonious church is quite at odds with that given by Paul's letters, and it omits important events such as the deaths of both Peter and Paul. The mid-19th century scholar Ferdinand Bauer suggested that Luke had re-written history to present a united Peter and Paul and advance a single orthodoxy against the Marconites. (Marcon was a 2nd-century heretic who wished to cut Christianity off entirely from the Jews). Bauer continues to have enormous influence, but today there is less interest in determining Luke's historical accuracy (although this has never died out) than in understanding his theological program.
Audience and authorial intent.
Luke was written to be read aloud to a group of Jesus-followers gathered in a house to share the Lord's supper. The author assumes an educated Greek-speaking audience, but directs his attention to specifically Christian concerns rather than to the Greco-Roman world at large. He begins his gospel with a preface addressed to "Theophilus", informing him of his intention to provide an "ordered account" of events which will lead his reader to "certainty". He did not write in order to provide Theophilus with historical justification – "did it happen?" – but to encourage faith – "what happened, and what does it all mean?"
Acts (or Luke-Acts) is intended as a work of "edification." Edification means "the empirical demonstration that virtue is superior to vice," but is not all of Luke's purpose. He also engages with the question of a Christian's proper relationship with the Roman Empire, the civil power of the day: could a Christian obey God and also Caesar? The answer is ambiguous. The Romans never move against Jesus or his followers unless provoked by the Jews, in the trial scenes the Christian missionaries are always cleared of charges of violating Roman laws, and Acts ends with Paul in Rome proclaiming the Christian message under Roman protection; at the same time, Luke makes clear that the Romans, like all earthly rulers, receive their authority from Satan, while Christ is ruler of the kingdom of God. 
Luke-Acts can be also seen as a defense of (or "apology" for) the Jesus movement addressed to the Jews: the bulk of the speeches and sermons in Acts are addressed to Jewish audiences, with the Romans featuring as external arbiters on disputes concerning Jewish customs and law. On the one hand Luke portrays the Christians as a sect of the Jews, and therefore entitled to legal protection as a recognised religion; on the other, Luke seems unclear as to the future God intends for Jews and Christians, celebrating the Jewishness of Jesus and his immediate followers while also stressing how the Jews had rejected God's promised Messiah.
Manuscripts.
There are two major textual variants of Luke-Acts, the Western text-type and the Alexandrian. The oldest complete Alexandrian manuscripts date from the 4th century and the oldest Western ones from the 6th, with fragments and citations going back to the 3rd. Western texts of Acts are 10% longer than Alexandrian texts, the additions tending to enhance the Jewish rejection of the Messiah and the role of the Holy Spirit, in ways that are stylistically different from the rest of Acts. These conflicts suggest that Luke-Acts was still being substantially revised well into the 2nd century. The majority of scholars prefer the Alexandrian (shorter) text-type over the Western as the more authentic, but this same argument would favour the Western over the Alexandrian for the gospel of Luke, as in that case the Western version is the shorter. The debate therefore continues.
Structure and content.
Structure.
Acts has two key structural principles. The first is the geographic movement from Jerusalem, centre of God's Covenantal people the Jews, to Rome, centre of the Gentile world. This structure reaches back to the author's preceding work, the Gospel of Luke, and is signaled by parallel scenes such as Paul's utterance in Acts 19:21, which echoes Jesus' words 9:51 (Paul has Rome as his destination, as Jesus had Jerusalem). The second key element is the roles of Peter and Paul, the first representing the Jewish Christian church, the second the mission to the Gentiles.
Content.
The gospel of Luke began with a prologue addressed to Theophilus; Acts likewise opens with an address to Theophilus and refers to "my earlier book", almost certainly the gospel.
The apostles and other followers of Jesus meet and elect Matthias to replace Judas as a member of The Twelve. On Pentecost, the Holy Spirit descends and confers God's power on them, and Peter, along with John, preaches to many in Jerusalem, and performs Christ-like healings, casting out of evil spirits, and raising of the dead. At first many Jews follow Christ and are baptized, but the Christians begin to be increasingly persecuted by the Jews. Stephen is arrested for blasphemy, and after a trial, is found guilty and stoned by the Jews. Stephen's death marks a major turning point: the Jews have rejected the message, and henceforth it will be taken to the Gentiles.
The message is taken to the Samaritans, a people rejected by Jews, and to the Gentiles. Saul of Tarsus, one of the Jews who persecuted the Christians, is converted by a vision to become a follower of Christ (an event which Luke regards as so important that he relates it three times). Peter, directed by a series of visions, preaches to Cornelius the Centurion, a Gentile God-fearer, who becomes a follower of Christ. The Holy Spirit descends on Peter and Cornelius, thus confirming that the message of eternal life in Christ is for all mankind. The Gentile church is established in Antioch (north-western Syria, the third-largest city of the empire), and here Christ's followers are first called Christians.
The mission to the Gentiles is promoted from Antioch and confirmed at meeting in Jerusalem between Paul and the leadership of the Jerusalem church. Paul spends the next few years traveling through western Asia Minor and the Aegean,preaching, converting Gentiles, and founding new churches. On a visit to Jerusalem he is set on by a Jewish mob. Saved by the Roman commander, he is accused by the Jews accused of being a revolutionary, the "ringleader of the sect of the Nazarenes", and imprisoned. Paul asserts his right as a Roman citizen, to be tried in Rome and is sent by sea to Rome, where he spends another two years under house arrest, proclaiming the Kingdom of God and teaching the "Lord Jesus Christ". Acts ends abruptly without recording the outcome of Paul's legal troubles.
Theology.
Prior to the 1950s Luke-Acts was seen as a historical work, written to defend Christianity before the Romans or Paul against his detractors; since then, however, the tendency has been to see the work as primarily theological. Luke's theology is expressed primarily through his overarching plot, the way scenes, themes and characters combine to construct his specific worldview. His "salvation history" stretches from the Creation to the present time of his readers, in three ages: first, the time of "the Law and the Prophets" (Luke 16:16), the period beginning with Genesis and ending with the appearance of John the Baptist (Luke 1:5-3:1); second, the epoch of Jesus, in which the Kingdom of God was preached (Luke 3:2-24:51); and finally the period of the Church, which began when the risen Christ was taken into Heaven, and would end with his second coming.
Luke-Acts is an attempt to answer a theological problem, namely how the Messiah promised to the Jews came to have an overwhelmingly non-Jewish church; the answer it provides, and its central theme, is that the message of Christ was sent to the Gentiles because the Jews rejected it. This theme is introduced at the opening of the gospel of Luke, when Jesus, rejected in Nazareth, recalls that the prophets were rejected by Israel and accepted by Gentiles; at the end of the gospel he commands his disciples to preach his message to all nations, "beginning from Jerusalem." He repeats the command in Acts, telling them to preach "in Jerusalem, in all Judea and Samaria, and to the end of the Earth." They then proceed to do so, in the order outlined: first Jerusalem, then Judea, then Samaria, then the entire (Roman) world.
For Luke, the Holy Spirit is the driving force behind the spread of the Christian message, and he places more emphasis on it than do any of the other evangelists. The Spirit is "poured out" at Pentecost, on the first Samaritan and Gentile believers, and on disciples who had been baptised only by John the Baptist, each time as a sign of God's approval. The Holy Spirit represents God's power (At his ascension, Jesus tells his followers, "You shall receive power when the Holy Spirit has come upon you"): through it the disciples are given speech to convert thousands in Jerusalem, forming the first church (the term is used for the first time in Acts 5).
Prayer is a major motif in both the Gospel of Luke and Acts. The Gospel of Luke depicts prayer as a certain feature in Jesus's life. Examples of prayer which are unique to Luke include Jesus's prayers at the time of his baptism (), his praying all night before choosing the twelve (), and praying for the transfiguration (). Acts also features an emphasis on prayer and includes a number of notable prayers such as the "Believers' Prayer" (), Stephen's death prayer (), and Simon Magus' prayer request ().
Comparison with other writings.
Gospel of Luke.
As the second part of the two-part work Luke-Acts, Acts has significant links to the gospel of Luke. Major turning points in the structure of Acts, for example, find parallels in Luke: the presentation of the child Jesus in the Temple parallels the opening of Acts in the Temple, Jesus' forty days of testing in the wilderness prior to his mission parallel the forty days prior to his Ascension in Acts, the miission of Jesus in Samaria and the Decapolis (the lands of the Samaritans and Gentiles) parallels the missions of the Apostles in Samaria and the Gentile lands, and so on (see Gospel of Luke). These parallels continue through both books.
There are also differences between Luke and Acts, amounting at times to outright contradiction. For example, the gospel seems to place the Ascension on Easter Sunday, immediately after the Resurrection, while Acts 1 puts it forty days later. There are similar conflicts over the theology. While not seriously questioning the single authorship of Luke-Acts, these differences do suggest the need for caution in seeking too much consistency in books written in essence as popular literature.
Pauline epistles.
Acts agrees with Paul's letters on the major outline of Paul's career: as Saul he is converted and becomes Paul the Christian missionary and apostle, establishing new churches in Asia Minor and the Aegean and struggling to free Gentile Christians from the Jewish Law. There are also agreements on many incidents, such as Paul's escape from Damascus, where he is lowered down the walls in a basket. But details of these same incidents are frequently contradictory: for example, according to Paul it was a pagan king who was trying to arrest him in Damascus, but according to Luke it was, characteristically, the Jews (2 Corinthians 11:33 and Acts 9:24). Many of the disagreements are not so immediately obvious: Acts speaks of "Christians" and "disciples", but Paul never uses either term, and there are striking differences in the accounts of Paul's relationship with the Jerusalem church and its leaders (Acts 9-15 vs. Galatians 1-2). Acts omits much from the letters, notably Paul's problems with his congregations (internal difficulties are said to be the fault of the Jews instead), and his apparent final rejection by the church leaders in Jerusalem (Acts has Paul and Barnabas deliver an offering that is accepted, a trip that has no mention in the letters). There are also major differences between Acts on Paul on Christology (the understanding of Christ's nature), eschatology (understanding of the "last things"), and apostleship.

</doc>
<doc id="2085" url="http://en.wikipedia.org/wiki?curid=2085" title="Assyria">
Assyria

Assyria (𒀸𒋗𒁺 𐎹 Aššūrāyu) was a major Mesopotamian East Semitic kingdom, and often empire, of the Ancient Near East, existing as an independent state for a period of approximately nineteen centuries from c. 2500 BC to 605 BC, spanning the Early Bronze Age through to the late Iron Age. For a further thirteen centuries, from the end of the 7th century BC to the mid-7th century AD, it survived as a geo-political entity, for the most part ruled by foreign powers, although a number of small Neo-Assyrian states arose at different times between the 1st century BC and late 3rd century AD.
Centered on the Upper Tigris river, in northern Mesopotamia (northern Iraq, northeast Syria and southeastern Turkey), the Assyrians came to rule powerful empires at several times, the last of which grew to be the largest and most powerful empire the world had yet seen.
As a substantial part of the greater Mesopotamian "cradle of civilization" which included Sumer, Akkad and later Babylonia, Assyria was at the height of technological, scientific and cultural achievements for its time. At its peak, the Assyrian empire stretched from Cyprus in the Mediterranean Sea to Persia (Iran), and from the Caucasus Mountains (Armenia, Georgia, Azerbaijan) to the Arabian Peninsula and Egypt.
Assyria is named for its original capital, the ancient city of Aššur (a.k.a. Ashur) which dates to c. 2600 BC (located in what is now the Saladin Province of northern Iraq), originally one of a number of Akkadian city states in Mesopotamia. In the late 24th century BC, Assyrian kings were regional leaders only, and subject to Sargon of Akkad, who united all the Akkadian Semites and Sumerian-speaking peoples of Mesopotamia under the Akkadian Empire, which lasted from c. 2334 BC to 2154 BC. Following the fall of the Akkadian Empire c. 2154 BC, and the short lived succeeding Sumerian Third Dynasty of Ur which ruled southern Assyria, Assyria regained full independence.
The history of Assyria proper is roughly divided into three periods, known as Old Assyrian, Middle Assyrian and Neo-Assyrian. These terms are in wide use in Assyrology and roughly correspond to the Middle Bronze Age, Late Bronze Age and Early Iron Age, respectively. In the Old Assyrian period, Assyria established colonies in Asia Minor and the Levant and, under king Ilushuma, it asserted itself over southern Mesopotamia. From the late 19th century BC, Assyria came into conflict with the newly created state of Babylonia, which eventually eclipsed the older Sumero-Akkadian states in the south, such as Ur, Isin, Larsa and Kish.
Assyria experienced fluctuating fortunes in the Middle Assyrian period. Assyria had a period of empire under Shamshi-Adad I and Ishme-Dagan in the 19th and 18th centuries BC. Following this, it found itself under Babylonian and Mitanni-Hurrian domination for short periods in the 18th and 15th centuries BC respectively, and another period of great power occurred with the rise of the Middle Assyrian Empire (from 1365 BC to 1056 BC), which included the reigns of great kings, such as Ashur-uballit I, Arik-den-ili, Tukulti-Ninurta I and Tiglath-Pileser I. During this period, Assyria overthrew Mitanni and eclipsed both the Hittite Empire and Egyptian Empire in the Near East.
Beginning with the campaigns of Adad-nirari II from 911 BC, it again became a great power over the next three centuries, overthrowing the Twenty-fifth dynasty of Egypt and conquering Egypt, Babylonia, Elam, Urartu/Armenia, Media, Persia, Mannea, Gutium, Phoenicia/Canaan, Aramea (Syria), Arabia, Israel, Judah, Edom, Moab, Samarra, Cilicia, Cyprus, Chaldea, Nabatea, Commagene, Dilmun, the Hurrians, Sutu and Neo-Hittites, driving the Ethiopians and Nubians from Egypt, defeating the Cimmerians and Scythians and exacting tribute from Phrygia, Magan and Punt among others.
After its fall (between 612 BC and 605 BC), Assyria remained a province and geo-political entity under the Babylonian, Median, Achaemenid, Seleucid, Parthian, Roman and Sassanid empires until the Arab Islamic dominance of Mesopotamia in the mid-7th century, when it was finally dissolved, after which the remnants of the Assyrian people (by now Christians) gradually became a minority in their homeland.
Names.
Assyria was also sometimes known as Subartu prior to the rise of the city state of Ashur after which it was 𒀸𒋗𒁺 𐎹 Aššūrāyu, and after its fall, from 605 BC through to the late 7th century AD variously as Athura and also referenced as Atouria according to Strabo, "Syria" (Greek), "Assyria" (Latin) and Assuristan. The term "Assyria" can also refer to the geographic region or heartland where Assyria, its empires and the Assyrian people were (and still are) centered. The modern Assyrian Christian (AKA Chaldo-Assyrian) ethnic minority in northern Iraq, north east Syria, south east Turkey and north west Iran are the descendants of the ancient Assyrians (see Assyrian continuity).
Pre-history of Assyria.
In prehistoric times, the region that was to become known as Assyria (and Subartu) was home to a Neanderthal culture such as has been found at the Shanidar Cave. The earliest Neolithic sites in Assyria were the Jarmo culture c. 7100 BC and Tell Hassuna, the centre of the "Hassuna culture", c. 6000 BC.
During the 3rd millennium BC, a very intimate cultural symbiosis developed between the Sumerians and the Semitic Akkadians throughout Mesopotamia, which included widespread bilingualism. The influence of Sumerian (a language isolate, i.e. not related to any other language) on Akkadian (and vice versa) is evident in all areas, from lexical borrowing on a massive scale, to syntactic, morphological, and phonological convergence. This has prompted scholars to refer to Sumerian and Akkadian in the 3rd millennium BC as a "sprachbund".
Akkadian gradually replaced Sumerian as the spoken language of Mesopotamia somewhere after the turn of the 3rd and the 2nd millennium BC (the exact dating being a matter of debate), but Sumerian continued to be used as a sacred, ceremonial, literary and scientific language in Mesopotamia until the 1st century AD.
The cities of Assur (also spelled Ashur or Aššur) and Nineveh, together with a number of other towns and cities, existed since at least before the middle of the 3rd millennium BC (c. 2600 BC), although they appear to have been Sumerian-ruled administrative centres at this time, rather than independent states.
According to some Judaeo-Christian writers , the city of Ashur was founded by Ashur the son of Shem, who was deified by later generations as the city's patron god . However, it is not among the cities said to have been founded by him in Genesis 10:11–12, and the far older Assyrian annals make no mention of the later Judeo-Christian figures of Shem and Ashur.
Assyrian tradition lists an early Assyrian king named Ushpia as having dedicated the first temple to the god Ashur in the city in the 21st century BC. It is highly likely that the city was named in honour of its patron Assyrian god with the same name.
Classical dating.
George Syncellus in his "Chronographia" quotes a fragment from Julius Africanus which dates the founding of Assyria to 2284 BC. The Roman historian Velleius Paterculus citing Aemilius Sura states that Assyria was founded 1995 years before Philip V was defeated in 197 BC (at the Battle of Cynoscephalae) by the Romans. The sum therefore 197 + 1995 = 2192 BC for the foundation of Assyria. Diodorus Siculus recorded another tradition from Ctesias, that dates Assyria 1,306 years before 883 BC (the starting date of the reign of Ashurnasirpal II) and so the sum 883 + 1306 = 2189 BC. The "Chronicle" of Eusebius provides yet another date for the founding of Assyria, with the accession of Ninus, dating to 2057 BC, but the Armenian translation of the "Chronicle" puts this figure back slightly to 2116 BC. Another classical dating tradition found in the "Excerpta Latina Barbari" dates the foundation of Assyria, under Belus, to 2206 BC.
Early Assyria, 2600–2335 BC.
The city of Ashur, together with a number of other Assyrian cities, seem to have been established by 2600 BC, however it is likely that they were initially Sumerian dominated administrative centres. In c. the late 26th century BC, Eannatum of Lagash, then the dominant Sumerian ruler in Mesopotamia, mentions "smiting Subartu" (Subartu being the Sumerian name for Assyria). Similarly, in c. the early 25th century BC, Lugal-Anne-Mundu the king of the Sumerian state of Adab lists Subartu as paying tribute to him.
Of the early history of the kingdom of Assyria, little is positively known. In the Assyrian King List, the earliest king recorded was Tudiya. In archaeological reports from Ebla, it appeared that Tudiya's activities were confirmed with the discovery of a tablet where he concluded a treaty for the operation of a "karum" (trading colony) in Eblaite territory, with "king" Ibrium of Ebla (who is now known to have been the vizier of Ebla for king Ishar-Damu). This entire reading is now questionable, as several scholars have more recently argued that the treaty in question was not with king Tudiya of Assyria, but rather with the unnamed king of an uncertain location called "Abarsal".
Tudiya was succeeded on the list by Adamu and then a further thirteen rulers (Yangi, Shuhlamu, Harharu, Mandaru, Imshu, Harshu, Didanu, Hanu, Zuabu, Nuabu, Abazu, Belu and Azarah). Nothing concrete is yet known about these names, although it has been noted that a much later Babylonian tablet listing the ancestral lineage of Hammurabi, the Amorite king of Babylon, seems to include the same names from Tudiya through Nuabu, though in a heavily corrupted form.
The earliest kings, such as Tudiya, who are recorded as "kings who lived in tents", may have been independent Akkadian semi-nomadic pastoralist rulers. These kings at some point became fully urbanised and founded the "city state" of Ashur.
Assyria in the Akkadian Empire and Neo-Sumerian Empires.
During the Akkadian Empire (2334–2154 BC) the Assyrians, like all the Akkadian Semites (and also the Sumerians), became subject to the dynasty of the city state of Akkad, centered in central Mesopotamia. The Akkadian Empire founded by Sargon the Great, claimed to encompass the surrounding "four quarters". The region of Assyria, north of the seat of the empire in central Mesopotamia had also been known as Subartu by the Sumerians, and the name Azuhinum in Akkadian records also seems to refer to Assyria proper.
Assyrian rulers were subject to Sargon and his successors, and the city of Ashur became a regional administrative center of the Empire, implicated by the Nuzi tablets.
During this period, the Akkadian-speaking Semites of Mesopotamia came to rule an empire encompassing not only Mesopotamia itself but large swathes of Asia Minor, ancient Iran, Elam, the Arabian Peninsula, Canaan and Syria.
Assyria seems to have already been firmly involved in trade in Asia Minor by this time; the earliest known reference to Anatolian "karum"s in Hatti, was found on later cuneiform tablets describing the early period of the Akkadian Empire (c. 2350 BC). On those tablets, Assyrian traders in Burushanda implored the help of their ruler, Sargon the Great, and this appellation continued to exist throughout the Assyrian Empire for about 1,700 years. The name "Hatti" itself even appears in later accounts of his grandson, Naram-Sin, campaigning in Anatolia.
Assyrian and Akkadian traders spread the use of writing in the form of the Mesopotamian cuneiform script to Asia Minor and The Levant.
However, towards the end of the reign of Sargon the Great, the Assyrian faction rebelled against him; "the tribes of Assyria of the upper country—in their turn attacked, but they submitted to his arms, and Sargon settled their habitations, and he smote them grievously".
The Akkadian Empire was destroyed by economic decline and internal civil war, followed by attacks from barbarian Gutian people in 2154 BC.
The rulers of Assyria during the period between c. 2154 BC and 2112 BC once again became fully independent, as the Gutians are only known to have administered southern Mesopotamia. However, the king list is the only information from Assyria for this period.
Most of Assyria briefly became part of the Neo-Sumerian Empire (or 3rd dynasty of Ur) founded in c. 2112 BC. Sumerian domination extended as far as the city of Ashur, but appears not to have reached Nineveh and the far north of Assyria. One local ruler ("shakkanakku") named Zāriqum (who does not appear on any Assyrian king list) is listed as paying tribute to Amar-Sin of Ur. Ashur's rulers appear to have remained largely under Sumerian domination until the mid-21st century BC (c. 2050 BC); the king list names Assyrian rulers for this period and several are known from other references to have also borne the title of "shakkanakka" or vassal governors for the neo-Sumerians.
Old Assyrian Kingdom.
The first written inscriptions by 'urbanised' Assyrian kings appear in the mid-21st century BC, after they had shrugged off Sumerian domination. The land of Assyria as a whole then consisted of a number of city states and small Semitic Akkadian kingdoms, some of which were initially independent of Assyria. The foundation of the first major temple in the city of Ashur was traditionally ascribed to king Ushpia who reigned c. 2050 BC, possibly a contemporary of Ishbi-Erra of Isin and Naplanum of Larsa. He was reputedly succeeded by kings named Apiashal, Sulili, Kikkiya and Akiya (died c. 2026 BC), of whom little is known, apart from much later mentions of Kikkiya conducting fortifications on the city walls, and building work on temples in Ashur.
The main rivals, neighbours or trading partners to early Assyrian kings during the 22nd, 21st and 20th centuries BC would have been the Hattians and Hurrians to the north in Asia Minor, the Gutians and Turukku to the east in the Zagros Mountains of northwest Iran, the Elamites to the southeast in what is now south central Iran, the Amorites to the west in what is today Syria, and their fellow Sumero-Akkadian city-states of southern Mesopotamia such as Isin, Kish, Ur and Larsa.
Like many city-states in Mesopotamian history, Ashur was, to a great extent, an oligarchy rather than a monarchy. Authority was considered to lie with "the City", and the polity had three main centres of power—an assembly of elders, a hereditary ruler, and an eponym. The ruler presided over the assembly and carried out its decisions. He was not referred to with the usual Akkadian term for "king", "šarrum"; that was instead reserved for the city's patron deity Assur, of whom the ruler was the high priest. The ruler himself was only designated as "the steward of Assur" ("iššiak Assur"), where the term for steward is a borrowing from Sumerian "ensi(k)". The third centre of power was the eponym ("limmum"), who gave the year his name, similarly to the later archons and consuls of Classical Antiquity. He was annually elected by lot and was responsible for the economic administration of the city, which included the power to detain people and confiscate property. The institution of the eponym as well as the formula "iššiak Assur" lingered on as ceremonial vestiges of this early system throughout the history of the Assyrian monarchy.
Dynasty of Puzur-Ashur I, 2025–1809 BC, Old Assyrian Empire.
In approximately 2025 BC (long chronology), Puzur-Ashur I (perhaps a contemporary of Shu-ilishu of Larsa and Samium of Isin) is speculated (on the basis of his name being Akkadian rather than Hurrian) to have overthrown Kikkiya and founded a new dynasty which was to survive for 216 years. His descendants left inscriptions mentioning him regarding the building of temples to gods such as Ashur, Adad and Ishtar in Assyria. The length of his reign is unknown.
Shalim-ahum (died c. 2009 BC) succeeded the throne at a currently unknown date. He left inscriptions in archaic Old Assyrian regarding the construction of a temple dedicated to the god Ashur, and the placement of beer vats within it.
Ilushuma (c. 2008–1975 BC) took the throne in c. 2008 BC, and is known from his inscription (extant in several copies) where he claims to have "washed the copper" and "established liberty" for the Akkadians in Sumerian city-states as far as the Persian Gulf. This has been taken by some scholars to imply that he made military campaigns into Southern Mesopotamia to relieve his fellow Mesopotamians from Amorite and Elamite invasions, however some recent scholars have taken the view that the inscription means he supplied these areas with copper from Hatti, and that the word used for "liberty" ("adduraru") is usually in the context of his exempting the southern Mesopotamian kings from tariffs.
"The freedom of the Akkadians and their children I established. I purified their copper. I established their freedom from the border of the marshes and Ur and Nippur, Awal, and Kish, Der of the goddess Ishtar, as far as the City of (Ashur)."
Assyria had long held extensive contact with Hattian, Hittite and Hurrian cities on the Anatolian plateau in Asia Minor. The Assyrians who had for centuries traded in the region, and possibly ruled small areas bordering Assyria, now established significant colonies in Cappadocia (e.g., at Kanesh (modern Kültepe) from 2008 BC to 1740 BC). These colonies, called "karum", from the Akkadian word for 'port', were attached to Hattian cities in Anatolia, but physically separate, and had special tax status. They must have arisen from a long tradition of trade between Assyria and the Anatolian cities, but no archaeological or written records show this. The trade consisted of metals (copper or tin and perhaps iron; the terminology is not entirely clear) being traded for textiles from Assyria.
Erishum I (c. 1974–1935 BC) vigorously expanded Assyrian colonies in Asia Minor during his long reign, the major ones appearing to be at Kanesh, Ḫattuša (Boğazköy) (the future capital of the Hittite Empire) and Amkuwa (Alisar Höyük), together with a further eighteen smaller colonies. He created some of the earliest examples of Written Law, conducted extensive building work in the form of fortifying the walls of major Assyrian cities and the erection of temples dedicated to Ashur and Ishtar. It is from his reign that the continuous "limmum" lists are known, however there are references to the eponym-books for his predecessors having been destroyed at some point.
Ikunum (c. 1934–1921 BC) built a major temple for the god Ningal. He further strengthened the fortifications of the city of Assur and maintained Assyria's colonies in Asia Minor.
Sargon I (c. 1920–1881 BC) succeeded him in c. 1920 BC, and had an unusually long reign of 39 years. It is likely he was named after his illustrious predecessor Sargon of Akkad. He is known to have refortified the defences of major Assyrian cities, and maintained Assyrian colonies in Asia Minor during his reign. Apart from this, little has yet been unearthed about him. At some point he appears to have withdrawn Assyrian aid to southern Mesopotamia. It was during his reign in Assyria that the initially minor city-state of Babylon was founded in 1894 BC by an Amorite "Malka" (prince) named Sumuabum.
Puzur-Ashur II (c. 1881–1873 BC) came to the throne as an already older man due to his fathers long reign. Little is known about his rule, but it appears to have been uneventful.
Naram-Suen (c. 1872–1818 BC) ascended to the throne in 1872 BC, and is likely named after his predecessor Naram-Sin of the Akkadian Empire. Assyria continued to be wealthy during his 54 year long reign (one of the longest in the ancient Near East), and he defeated the future usurper king Shamshi-Adad I who attempted to take his throne.
Erishum II (c. 1818–1809 BC) was to be the last king of the dynasty of Puzur-Ashur I, founded c. 2025 BC. After only eight or nine years in power he was overthrown by Shamshi-Adad I, the Amorite usurper who had previously been defeated in an attempt to unseat Naram-Suen, and who claimed legitimacy by asserting descent from the mid 21st century BC Assyrian king, Ushpia.
Amorite Period in Assyria, 1809–1750 BC.
The Amorites were successfully repelled by the Assyrian kings of the 20th and 19th centuries BC.
However, in 1809 BC the native Akkadian king of Assyria Erishum II was deposed, and the throne of Assyria was usurped by Shamshi-Adad I (c. 1809 – 1776 BC) in the expansion of Semitic Amorite tribes from the Khabur River delta.
Although regarded as an Amorite by later Assyrian tradition, Shamshi-Adad's descent is suggested to be from the same line as the native Akkadian speaking ruler Ushpia in the Assyrian King List. He put his son Ishme-Dagan on the throne of a nearby Assyrian city, Ekallatum, and maintained Assyria's Anatolian colonies. Shamshi-Adad I then went on to conquer the kingdom of Mari (in modern Syria) on the Euphrates putting another of his sons, Yasmah-Adad on the throne there. Shamshi-Adad's Assyria now encompassed the whole of northern Mesopotamia and included territory in central Mesopotamia, Asia Minor and northern Syria. Shamshi-Adad I mentions conducting raids on the Canaanite coasts of the far off Mediterranean, where he erected stelae to commemorate his victories. He himself resided in a new capital city founded in the Khabur valley in northern Mesopotamia, called Shubat-Enlil.
Ishme-Dagan I (1774–1763 BC) inherited Assyria, but Yasmah-Adad was overthrown by a new king called Zimrilim in Mari. The new king of Mari allied himself with the Amorite king Hammurabi of Babylon, who had made the recently created, and originally minor state of Babylon into a major power. It was from the reign of Hammurabi onwards that southern Mesopotamia came to be known as Babylonia.
Assyria now faced the rising power of Babylon in the south. Ishme-Dagan responded by making an alliance with the enemies of Babylon, and the power struggle continued without resolution for decades. Ishme-Dagan, like his father was a great warrior, and in addition to repelling Babylonian attacks, campaigned successfully against the Turukku and Lullubi of the Zagros Mountains (in modern Iran) who had attacked the Assyrian city of Ekallatum, and against Dadusha, king of Eshnunna, and the state of Iamhad (modern Aleppo).
Assyria under Babylonian domination, 1750–1732 BC.
Hammurabi, after first conquering Mari, Larsa, and Eshnunna, eventually prevailed over Ishme-Dagan's successor Mut-Ashkur (1750–1740 BC), and subjected him to Babylon c. 1750 BC. With Hammurabi, the various "karum" colonies in Anatolia ceased trade activity—probably because the goods of Assyria were now being traded with the Babylonians. The Assyrian monarchy survived, however the three Amorite kings succeeding Ishme-Dagan, Mut-Ashkur (who was the son of Ishme-Dagan and married to a Hurrian queen), Rimush (1739–1733 BC) and Asinum (1732 BC), were vassals, dependent on the Babylonians during the reign of Hammurabi, and for a short time, of his successor Samsu-iluna.
Assyrian Adaside dynasty, 1732–1451 BC.
The short lived Babylonian Empire quickly began to unravel upon the death of Hammurabi, and Babylonia lost control over Assyria during the reign of Hammurabi's successor Samsu-iluna (1750–1712 BC). A period of civil war ensued after Asinum (a grandson of Shamshi-Adad I and the last Amorite ruler of Assyria) was deposed in approximately 1732 BC by a powerful native Akkadian-Assyrian vice regent named Puzur-Sin, who regarded Asinum as both a foreigner and a former lackey of Babylon. 
A native king named Ashur-dugul seized the throne in 1732 BC, probably with the help of Puzur-Sin. However, he was unable to retain control for long, and was soon deposed by a rival claimant, Ashur-apla-idi. Internal instability ensued with four further kings (Nasir-Sin, Sin-namir, Ipqi-Ishtar and Adad-salulu) all reigning in quick succession over a period of approximately six years between 1732 and 1727 BC. Babylonia seems to have been too powerless to intervene or take advantage of this situation.
Finally, a king named Adasi (1726–1701 BC) came to the fore c. 1726 BC and managed to quell the civil unrest and stabilise the situation in Assyria. Adasi completely drove the Babylonians and Amorites from the Assyrian sphere of influence during his reign, and Babylonian power began to quickly wane in Mesopotamia as a whole, also losing the far south of Mesopotamia to the Sealand Dynasty, although the Amorites would retain control over a much reduced and weak Babylonia itself until 1595 BC, when they were overthrown by the Kassites, a people from the Zagros Mountains who spoke a language isolate and were neither Semites nor Indo-Europeans.
Adasi was succeeded by Bel-bani (1700–1691 BC) who is credited in Assyrian annals with inflicting further defeats on the Babylonians and Amorites, and further strengthening and stabilising the kingdom.
Little is currently known of many of the kings that followed such as; Libaya (1690–1674 BC), Sharma-Adad I (1673–1662 BC), Iptar-Sin (1661–1650 BC), Bazaya (1649–1622 BC) (a contemporary of Peshgaldaramesh of the Sealand Dynasty), Lullaya (1621–1618 BC) (who usurperped the throne from Bazaya), Shu-Ninua (1615–1602 BC) and Sharma-Adad II (1601–1599 BC). However, Assyria seems to have been a relatively strong and stable nation, existing undisturbed by its neighbours such as the Hatti, Hittites, Hurrians, Amorites, Babylonians, Elamites or Mitanni during this period.
Assyria appears to have remained strong and secure; when Babylon was sacked by the Hittites and subsequently fell to the Kassites in 1595 BC, both powers were unable to make any inroads into Assyria, and there seems to have been no trouble between the first Kassite ruler of Babylon, Agum II, and Erishum III (1598–1586 BC) of Assyria, and a mutually beneficial treaty was signed between the two rulers.
Shamshi-Adad II (1585–1580 BC), Ishme-Dagan II (1579–1562 BC) and Shamshi-Adad III (1562–1548 BC) seem also to have had peaceful tenures, although few records have thus far been discovered about their reigns. Similarly, Ashur-nirari I (1547–1522 BC) seems not to have been troubled by the newly founded Mitanni Empire in Asia Minor, the Hittite empire, or Babylon during his 25-year reign. He is known to have been an active king, improving the infrastructure, dedicating temples and conducting various building projects throughout the kingdom.
Puzur-Ashur III (1521–1498 BC) proved to be a strong and energetic ruler. He undertook much rebuilding work in Assur, the city was refortified and the southern quarters incorporated into the main city defences. Temples to the moon god Sin (Nanna) and the sun god Shamash were erected during his reign. He signed a treaty with Burna-Buriash I the Kassite king of Babylon, defining the borders of the two nations in the late 16th century BC. He was succeeded by Enlil-nasir I (1497–1483 BC) who appears to have had a peaceful an uneventful reign, as does his successor Nur-ili (1482–1471 BC).
The son of Nur-ili, Ashur-shaduni (1470 BC) was deposed by his uncle Ashur-rabi I (1470–1451 BC) in his first year of rule. Little is known about his nineteen-year reign, but it appears to have been largely uneventful.
Assyria in decline, 1450–1393 BC.
The emergence of the Mitanni Empire in the 16th century BC did eventually lead to a short period of sporadic Mitanni-Hurrian domination in the latter half of the 15th century. The Indo-European speaking Mitanni are thought to have conquered and formed the ruling class over the indigenous Hurrians of eastern Anatolia. The Hurrians spoke a language isolate, i.e. neither Semitic nor Indo-European.
Ashur-nadin-ahhe I (1450–1431 BC) was courted by the Egyptians, who were rivals of the Mitanni, and attempting to gain a foothold in the Near East. Amenhotep II sent the Assyrian king a tribute of gold to seal an alliance against the Hurri-Mitanni empire. It is likely that this alliance prompted Saushtatar, the Mitanni emperor, to invade Assyria, and sack the city of Ashur, after which Assyria became a sometime vassal state, with Ashur-nadin-ahhe I being forced to pay tribute to Saushtatar. He was deposed by his own brother Enlil-nasir II (1430–1425 BC) in 1430 BC, possibly with the aid of the Mitanni, who received tribute from the new king. Ashur-nirari II (1424–1418 BC) had an uneventful reign, and appears to have also paid tribute to the Mitanni Empire.
The Assyrian monarchy survived, and the Mitanni influence appears to have been sporadic. They appear not to have been always willing or able to interfere in Assyrian internal and international affairs.
Ashur-bel-nisheshu (1417–1409 BC) seems to have been independent of Mitanni influence, as evidenced by his signing a mutually beneficial treaty with Karaindash, the Kassite king of Babylonia in the late 15th century. He also undertook extensive rebuilding work in Ashur itself, and Assyria appears to have redeveloped its former highly sophisticated financial and economic systems during his reign.
Ashur-rim-nisheshu (1408–1401 BC) also undertook building work, strengthening the city walls of the capital.
Ashur-nadin-ahhe II (1400–1393 BC) also received a tribute of gold and diplomatic overtures from Egypt, probably in an attempt to gain Assyrian military support against Egypt's Mitanni and Hittite rivals in the region. However, the Assyrian king appears not to have been in a strong enough position to challenge the Mitanni.
Eriba-Adad I (1392–1366 BC), a son of Ashur-bel-nisheshu, ascended the throne in 1392 BC and finally broke the ties to the Mitanni Empire.
There are dozens of Mesopotamian cuneiform texts from this period, with precise observations of solar and lunar eclipses, that have been used as 'anchors' in the various attempts to define the chronology of Babylonia and Assyria for the early 2nd millennium BC (i.e., the "high", "middle", and "low" chronologies.)
Middle Assyrian Empire, 1392–1056 BC.
Scholars variously date the beginning of the "Middle Assyrian period" to either the fall of the Old Assyrian kingdom of Shamshi-Adad I, or to the ascension of Ashur-uballit I to the throne of Assyria.
Assyrian expansion and empire, 1392–1056 BC.
By the reign of Eriba-Adad I (1392–1366 BC) Mitanni influence over Assyria was on the wane. Eriba-Adad I became involved in a dynastic battle between Tushratta and his brother Artatama II and after this his son Shuttarna II, who called himself king of the Hurri while seeking support from the Assyrians. A pro-Assyria faction appeared at the royal Mitanni court. Eriba-Adad I had thus finally broken Mitanni influence over Assyria, and in turn had now made Assyria an influence over Mitanni affairs.
Ashur-uballit I (1365–1330 BC) succeeded the throne of Assyria in 1365 BC, and proved to be a fierce, ambitious and powerful ruler. Assyrian pressure from the southeast and Hittite pressure from the north-west, enabled Ashur-uballit I to break Mitanni power. He met and decisively defeated Shuttarna II the Mitanni king in battle, making Assyria once more an imperial power at the expense of not only the Mitanni themselves, but also Kassite Babylonia, the Hurrians and the Hittites; and a time came when the Kassite king in Babylon was glad to marry Muballiṭat-Šērūa, the daughter of Ashur-uballit, whose letters to Akhenaten of Egypt form part of the Amarna letters.
This marriage led to disastrous results for Babylonia, as the Kassite faction at court murdered the half Assyrian Babylonian king and placed a pretender on the throne. Assur-uballit I promptly invaded Babylonia to avenge his son-in-law, entering Babylon, deposing the king and installing Kurigalzu II of the royal line king there.
Ashur-uballit I then attacked and defeated Mattiwaza the Mitanni king despite attempts by the Hittite king Suppiluliumas, now fearful of growing Assyrian power, to help the Mitanni. The lands of the Mitanni and Hurrians were duly appropriated by Assyria, making it a large and powerful empire.
Enlil-nirari (1329–1308 BC) succeeded Ashur-uballit I. He described himself as a "Great-King" ("Sharru rabû") in letters to the Hittite kings. He was immediately attacked by Kurigalzu II of Babylon who had been installed by his father, but succeeded in defeating him, repelling Babylonian attempts to invade Assyria, counterattacking and appropriating Babylonian territory in the process, thus further expanding Assyria.
The successor of Enlil-nirari, Arik-den-ili (c. 1307–1296 BC), consolidated Assyrian power, and successfully campaigned in the Zagros Mountains to the east, subjugating the Lullubi and Gutians. In Syria, he defeated Semitic tribes of the so-called Ahlamu group, who were possibly predecessors of the Arameans or an Aramean tribe.
He was followed by Adad-nirari I (1295–1275 BC) who made Kalhu (Biblical Calah/Nimrud) his capital, and continued expansion to the northwest, mainly at the expense of the Hittites and Hurrians, conquering Hittite territories such as Carchemish and beyond. Adad-nirari I made further gains to the south, annexing Babylonian territory and forcing the Kassite rulers of Babylon into accepting a new frontier agreement in Assyria's favour.
Adad-nirari's inscriptions are more detailed than any of his predecessors. He declares that the gods of Mesopotamia called him to war, a statement used by most subsequent Assyrian kings. He referred to himself again as "Sharru Rabi" (meaning "The Great King" in the Akkadian language) and conducted extensive building projects in Ashur and the provinces.
In 1274 BC Shalmaneser I (1274–1244 BC) ascended the throne. He proved to be a great warrior king. During his reign he conquered the Hurrian kingdom of Urartu that would have encompassed most of Eastern Anatolia and the Caucasus Mountains in the 9th century BC, and the fierce Gutians of the Zagros. He then attacked the Mitanni-Hurrians, defeating both King Shattuara and his Hittite and Aramaean allies, finally completely destroying the Hurri-Mitanni kingdom in the process.
During the campaign against the Hittites, Shattuara cut off the Assyrian army from their supply of food and water, but the Assyrians broke free in a desperate battle, counterattacked, and conquered and annexed what remained of the Mitanni kingdom. Shalmaneser I installed an Assyrian prince, Ilu-ippada as ruler of Mitanni, with Assyrian governors such as Meli-sah, installed to rule individual cities.
The Hittites, having failed to save Mitanni, allied with Babylon in an unsuccessful economic war against Assyria for many years. Assyria was now a large and powerful empire, and a major threat to Egyptian and Hittite interests in the region, and was perhaps the reason that these two powers, fearful of Assyrian might, made peace with one another. Like his father, Shalmaneser was a great builder and he further expanded the city of Kalhu at the juncture of the Tigris and Zab Rivers.
Shalmaneser's son and successor, Tukulti-Ninurta I (1244–1207 BC), won a major victory against the Hittites and their king Tudhaliya IV at the Battle of Nihriya and took thousands of prisoners. He then conquered Babylonia, taking Kashtiliash IV as a captive and ruled there himself as king for seven years, taking on the old title "King of Sumer and Akkad" first used by Sargon of Akkad. Tukulti-Ninurta I thus became the first Akkadian speaking native Mesopotamian to rule the state of Babylonia, its founders having been foreign Amorites, succeeded by equally foreign Kassites. Tukulti-Ninurta petitioned the god Shamash before beginning his counter offensive. Kashtiliash IV was captured, single-handed by Tukulti-Ninurta according to "his" account, who "trod with my feet upon his lordly neck as though it were a footstool" and deported him ignominiously in chains to Assyria. The victorious Assyrian demolished the walls of Babylon, massacred many of the inhabitants, pillaged and plundered his way across the city to the Esagila temple, where he made off with the statue of Marduk. He then proclaimed himself "king of Karduniash, king of Sumer and Akkad, king of Sippar and Babylon, king of Tilmun and Meluhha." Middle Assyrian texts recovered at ancient Dūr-Katlimmu, include a letter from Tukulti-Ninurta to his "sukkal rabi'u", or grand vizier, Ashur-iddin advising him of the approach of his general Shulman-mushabshu escorting the captive Kashtiliash, his wife, and his retinue which incorporated a large number of women, on his way to exile after his defeat. In the process he defeated the Elamites, who had themselves coveted Babylon. He also wrote an epic poem documenting his wars against Babylon and Elam. After a Babylonian revolt, he raided and plundered the temples in Babylon, regarded as an act of sacrilege. As relations with the priesthood in Ashur began deteriorating, Tukulti-Ninurta built a new capital city; Kar-Tukulti-Ninurta.
A number of historians, including Julian Jaynes, identify Tukulti-Ninurta I and his deeds as the historical origin for the fictional biblical character Nimrod in the Old Testament.
However, Tukulti-Ninurta's sons rebelled and besieged the ageing king in his capital. He was murdered and then succeeded by Ashur-nadin-apli (1206–1203 BC) who left the running of his empire to Assyrian regional governors such as Adad-bēl-gabbe. Another unstable period for Assyria followed, it was riven by periods of internal strife and the new king only made token and unsuccessful attempts to recapture Babylon, whose Kassite kings had taken advantage of the upheavals in Assyria and freed themselves from Assyrian rule. However, Assyria itself was not threatened by foreign powers during the reigns of Ashur-nirari III (1202–1197 BC), Enlil-kudurri-usur (1196–1193 BC) and Ninurta-apal-Ekur (1192–1180 BC), although Ninurta-apal-Ekur usurped the throne from Enlil-kudurri-usur.
Ashur-Dan I (1179–1133 BC) stabilised the internal unrest in Assyria during his unusually long reign, quelling instability. During the twilight years of the Kassite dynasty in Babylonia, he records that he seized northern Babylonia, including the cities of Zaban, Irriya and Ugar-sallu during the reigns of Marduk-apla-iddina I and Zababa-shuma-iddin, plundering them and "taking their vast booty to Assyria." However, the conquest of northern Babylonia brought Assyria into direct conflict with Elam which had taken the remainder of Babylonia. The powerful Elamites, under king Shutruk-Nahhunte, fresh from sacking Babylon, entered into a protracted war with Assyria, they briefly took the Assyrian city of Arrapkha, which Ashur-Dan I then retook, eventually defeating the Elamites and forcing a treaty upon them in the process.
Another very brief period of internal upheaval followed the death of Ashur-Dan I when his son and successor Ninurta-tukulti-Ashur (1133 BC) was deposed in his first year of rule by his own brother Mutakkil-Nusku and forced to flee to Babylonia. Mutakkil-Nusku himself died in the same year (1133 BC).
A third brother, Ashur-resh-ishi I (1133–1116 BC) took the throne. This was to lead to a renewed period of Assyrian expansion and empire. As the Hittite empire collapsed from the onslaught of the Indo-European Phrygians (called Mushki in Assyrian annals), Babylon and Assyria began to vie for Aramaean regions (in modern Syria), formerly under firm Hittite control. When their forces encountered one another in this region, the Assyrian king Ashur-resh-ishi I met and defeated Nebuchadnezzar I of Babylon on a number of occasions. Assyria then invaded and annexed Hittite-controlled lands in Asia Minor, Aram (Syria), and Gutians and Kassite regions in the Zagros, marking an upsurge in imperian expansion.
Tiglath-Pileser I (1115–1077 BC), vies with Shamshi-Adad I and Ashur-uballit I among historians as being regarded as the founder of the first Assyrian empire. The son of Ashur-resh-ishi I, he ascended to the throne upon his father's death, and became one of the greatest of Assyrian conquerors during his 38-year reign.
His first campaign in 1112 BC was against the Phrygians who had attempted to occupy certain Assyrian districts in the Upper Euphrates region of Asia Minor; after defeating and driving out the Phrygians he then overran the Luwian kingdoms of Commagene, Cilicia and Cappadocia in western Asia Minor, and drove the Neo-Hittites from the Assyrian province of Subartu, northeast of Malatia.
In a subsequent campaign, the Assyrian forces penetrated Urartu, into the mountains south of Lake Van and then turned westward to receive the submission of Malatia. In his fifth year, Tiglath-Pileser again attacked Commagene, Cilicia and Cappadocia, and placed a record of his victories engraved on copper plates in a fortress he built to secure his Anatolian conquests.
The Aramaeans of northern and central Syria were the next targets of the Assyrian king, who made his way as far as the sources of the Tigris. The control of the high road to the Mediterranean was secured by the possession of the Hittite town of Pitru at the junction between the Euphrates and Sajur; thence he proceeded to conquer the Canaanite/Phoenician city-states of Byblos, Tyre, Sidon, Simyra, Berytus (Beirut), Aradus and finally Arvad where he embarked onto a ship to sail the Mediterranean, on which he killed a "nahiru" or "sea-horse" (which A. Leo Oppenheim translates as a narwhal) in the sea. He was passionately fond of hunting and was also a great builder. The general view is that the restoration of the temple of the gods Ashur and Hadad at the Assyrian capital of Assur (Ashur) was one of his initiatives.
He also invaded and defeated Babylon twice, assuming the old title "King of Sumer and Akkad", forcing tribute from Babylon, although he did not actually depose the actual king in Babylonia, where the old "Kassite Dynasty" had now succumbed to an Elamite one.
He was succeeded by Asharid-apal-Ekur (1076–1074 BC) who reigned for just two years. His reign marked the elevation of the office of "ummânu" (royal scribe) in importance.
Ashur-bel-kala (1073–1056 BC) kept the vast empire together, campaigning successfully against Urartu and Phrygia to the north and the Arameans to the west. He maintained friendly relations with Marduk-shapik-zeri of Babylon, however upon the death of that king, he invaded Babylonia and deposed the new ruler Kadašman-Buriaš, appointing Adad-apla-iddina as his vassal in Babylon. He built some of the earliest examples of both Zoological Gardens and Botanical Gardens in Ashur, collecting all manner of animals and plants from his empire, and receiving a collection of exotic animals as tributes from Egypt.
He was also a great hunter, describing his exploits "at the city of Araziqu which is before the land of Hatti and at the foot of Mount Lebanon." These locations show that well into his reign Assyria still controlled a vast empire.
Late in his reign, the Middle Assyrian Empire erupted into civil war, when a rebellion was orchestrated by Tukulti-Mer, a pretender to the throne of Assyria. Ashur-bel-kala eventually crushed Tukulti-Mer and his allies, however the civil war in Assyria had allowed hordes of Arameans to take advantage of the situation, and press in on Assyrian controlled territory from the west. Ashur-bel-kala counterattacked them, and conquered as far as Carchemish and the source of the Khabur river, but by the end of his reign many of the areas of Syria and Phoenicia-Canaan to the west of these regions as far as the Mediterranean, previously under firm Assyrian control, were eventually lost to the Assyrian Empire.
Assyria in the Ancient Dark Ages, 1055–936 BC.
The period from 1200 BC to 900 BC was a dark age for the entire Near East, North Africa, Caucasus, Mediterranean and Balkan regions, with great upheavals and mass movements of people.
Assyria and its empire were not unduly affected by these tumultuous events for some 150 years, perhaps the only ancient power that was not. However, upon the death of Ashur-bel-kala in 1056 BC, Assyria went into a "comparative" decline for the next 100 or so years. The empire shrank significantly, and by 1020 BC Assyria appears to have controlled only areas close to Assyria itself, essential to keeping trade routes open in eastern Syria, south eastern Asia Minor central Mesopotamia and north western Iran.
New West Semitic peoples such as the Arameans, Chaldeans and Suteans moved into areas to the west and south of Assyria, including overrunning much of Babylonia to the south, Indo-European speaking Iranic peoples such as the Medes, Persians and Parthians moved into the lands to the east of Assyria, displacing the native Gutians and pressuring Elam and Mannea (which were all ancient non Indo-European civilisations of Iran), and to the north the Phrygians overran the Hittites, a new Hurrian state named Urartu arose in the Caucasus, and Cimmerians, Colchians (Georgians) and Scythians around the Black Sea and Caucasus. Egypt was divided and in disarray, and Israelites were battling with other fellow Semitic Canaanite peoples such as the Amalekites, Moabites, Edomites and Ammonites and the non-Semitic Peleset/Philistines (who were probably one of the so-called Sea Peoples) for the control of southern Canaan.
Despite the apparent weakness of Assyria in comparison to its former might, at heart it in fact remained a solid, well defended nation whose warriors were the best in the world. Assyria, with its stable monarchy, powerful army and secure borders was in a stronger position during this time than potential rivals such as Egypt, Babylonia, Elam, Phrygia, Urartu, Persia and Media Kings such as Ashur-bel-kala, Eriba-Adad II, Ashur-rabi II, Ashurnasirpal I, Tiglath-Pileser II and Ashur-Dan II successfully defended Assyria's borders and upheld stability during this tumultuous time.
Assyrian kings during this period appear to have adopted a policy of maintaining and defending a compact, secure nation and satellite colonies immediately surrounding it, and interspersed this with sporadic punitive raids and invasions of neighbouring territories when the need arose.
Eriba-Adad II ruled for only two years, and in that time continued to campaign against the Arameans and neo-Hittites before he was deposed by his elderly uncle Shamshi-Adad IV (1053–1050 BC) who appears to have had an uneventful reign. Ashurnasirpal I (1049–1031 BC) succeeded him, and during his reign he continued to campaign endlessly against the Arameans to the west. Assyria was also afflicted by famine during this period. Shalmaneser II (1030–1019 BC) appears to have lost territory in the Levant to the Arameans, who also appear to have also occupied Nairi in southeast Asia Minor, hitherto an Assyrian colony.
Ashur-nirari IV took the throne in 1018 BC, and captured the Babylonian city of Atlila from Simbar-Shipak and continued Assyrian campaigns against the Arameans. He was eventually deposed by his uncle Ashur-rabi II in 1013 BC.
During the reign of Ashur-rabi II (1013–972 BC) Aramaean tribes took the cities of Pitru and Mutkinu (which had been taken and colonized by Tiglath Pileser I.) This event showed how far Assyria could assert itself militarily when the need arose. The Assyrian king attacked the Arameans, forced his way to the far off Mediterranean and constructed a stele in the area of Mount Atalur.
Ashur-resh-ishi II (971–968 BC) in all likelihood a fairly elderly man due to the length of his father's reign, had a largely uneventful period of rule, concerning himself with defending Assyria's borders and conducting various rebuilding projects within Assyria.
Tiglath-Pileser II (967–936 BC) succeeded him, and reigned for 28 years. He maintained the policies of his recent predecessors, but appears to have had an uneventful reign.
Society in the Middle Assyrian period.
Assyria had difficulties with keeping the trade routes open. Unlike the situation in the Old Assyrian period, the Anatolian metal trade was effectively dominated by the Hittites and the Hurrians. These people now controlled the Mediterranean ports, while the Kassites controlled the river route south to the Persian Gulf.
The Middle Assyrian kingdom was well organized, and in the firm control of the king, who also functioned as the High Priest of Ashur, the state god. He had certain obligations to fulfill in the cult, and had to provide resources for the temples. The priesthood became a major power in Assyrian society. Conflicts with the priesthood are thought to have been behind the murder of king Tukulti-Ninurta I.
The main Assyrian cities of the middle period were Ashur, Kalhu (Nimrud) and Nineveh, all situated in the Tigris River valley. At the end of the Bronze Age, Nineveh was much smaller than Babylon, but still one of the world's major cities (population c. 33,000). By the end of the Neo-Assyrian period, it had grown to a population of some 120,000, and was possibly the largest city in the world at that time. All free male citizens were obliged to serve in the army for a time, a system which was called the "ilku"-service. A legal code was produced during the 14th and 13th centuries which, among other things, clearly shows that the social position of women in Assyria was lower than that of neighbouring societies. Men were permitted to divorce their wives with no compensation paid to the latter. If a woman committed adultery, she could be beaten or put to death. It's not certain if these laws were seriously enforced, but they appear to be a backlash against some older documents that granted things like equal compensation to both partners in divorce. The women of the king's harem and their servants were also subject to harsh punishments, such as beatings, mutilation, and death. Assyria, in general, had much harsher laws than most of the region. Executions were not uncommon, nor were whippings followed by forced labour. Some offenses allowed the accused a trial under torture/duress. One tablet that covers property rights has brutal penalties for violators. A creditor could force debtors to work for him, but not sell them.
The Middle Assyrian Period is marked by the long wars fought during this period that helped build Assyria into a warrior society. The king depended on both the citizen class and priests in his capital, and the landed nobility who supplied the horses needed by Assyria's military. Documents and letters illustrate the importance of the latter to Assyrian society. Assyria needed less artificial irrigation than Babylon, and horse-breeding was extensive. Portions of elaborate texts about the care and training of them have been found. Trade was carried out in all directions. The mountain country to the north and west of Assyria was a major source of metal ore, as well as lumber. Economic factors were a common "casus belli".
Assyrian architecture, like that of Babylonia, was influenced by Sumero-Akkadian styles (and to some degree Mitanni), but early on developed its own distinctive style. Palaces sported colourful wall decorations, and seal-cutting (an art learned from Mittani) developed apace. Schools for scribes taught both the Babylonian and Assyrian dialects of Akkadian, and Sumerian and Akkadian literary works were often copied with an Assyrian flavour. The Assyrian dialect of Akkadian was used in legal, official, religious, and practical texts such as medicine or instructions on manufacturing items. During the 13th to 10th centuries, picture tales appeared as a new art form: a continuous series of images carved on square stone steles. Somewhat reminiscent of a comic book, these show events such as warfare or hunting, placed in order from the upper left to the lower right corner of the stele with captions written underneath them. These and the excellent cut seals show that Assyrian art was beginning to surpass that of Babylon. Architecture saw the introduction of a new style of ziggurat, with two towers and colorful enameled tiles.
Neo-Assyrian Empire, 911–627 BC.
Ashur-Dan II (935–912 BC) oversaw a marked economic and organisational upturn in the fortunes of Assyria, laying the platform for it to once again forge an empire. He is recorded as having made successful punitive raids outside the borders of Assyria to clear Aramean and other tribal peoples from the regions surrounding Assyria in all directions. He concentrated on rebuilding Assyria within its natural borders, from Tur Abdin to Arrapha (Kirkuk), he built government offices in all provinces, and created a major economic boost by providing ploughs throughout the land, which yielded record grain production.
The Neo-Assyrian Empire is usually considered to have begun with the accession of Adad-nirari II, in 911 BC, lasting until the fall of Nineveh at the hands of the Babylonians, Chaldeans, Medes/Persians, Scythians and Cimmerians in 612 BC.
Expansion, 911–627 BC.
When the ancient Dark Ages (which for Assyria lasted from 1050 to 936 BC) finally lifted, the world had changed dramatically. Ancient kingdoms such as Assyria, Babylonia, Elam and Egypt still endured, the Hittites did also, in the form of smaller Neo-Hittite states. A number of new states had arisen during the tumultuous time between 1200 and 936 BC, such as; Persia, Media, Parthia, Mannea, Israel, Urartu, Phrygia, Lydia, the Aramean and Phoenician states of the Levant, Doric Greece, Putria (Libya), Colchia, Tabal, Nubia/Kush. In addition, other nations and peoples; such as Chaldea, Judah, Scythia, Cimmeria, Samarra, Ethiopia, Nabatea, Armenia and the Arabs were to emerge in the following centuries.
However, it was the ancient state of Assyria which would once more rise to prominence, and Assyria was to meet and defeat these new peoples, together with old foes, over the coming three centuries.
Beginning with the campaigns of Adad-nirari II (911-892 BC), Assyria once more became a great power, growing to be the greatest empire the world had yet seen. The new king firmly subjugated the areas that were previously only under nominal Assyrian vassalage, conquering and deporting troublesome Aramean, Neo-Hittite and Hurrian populations in the north to far-off places. Adad-nirari II then twice attacked and defeated Shamash-mudammiq of Babylonia, annexing a large area of land north of the Diyala River and the towns of Hīt and Zanqu in mid Mesopotamia. Later in his reign, he made further gains against King Nabu-shuma-ukin I of Babylonia. He then conquered Kadmuh and Nisibin from the Arameans, and secured the Khabur region.
His successor, Tukulti-Ninurta II (891–884 BC) consolidated Assyria's gains and expanded into the Zagros Mountains in modern Iran, subjugating the newly arrived Persians, Parthians and Medes as well as pushing into central Asia Minor.
Ashurnasirpal II (883–859 BC) was a fierce and ruthless ruler who advanced without opposition through Aram and Canaan (modern Syria, Lebannon, Jordan and Israel) and Asia Minor as far as the Mediterranean and conquered and exacted tribute from Aramea, Phrygia and Phoenicia among others. Ashurnasirpal II also repressed revolts among the Medes and Persians in the Zagros Mountains, and moved his capital to the city of Kalhu (Calah/Nimrud). The palaces, temples and other buildings raised by him bear witness to a considerable development of wealth, science, architecture and art. He also built a number of new heavily fortified towns, such as Imgur-Enlil (Balawat), Tushhan, Kar-Ashurnasirpal and Nibarti-Ashur. Ashurnasirpal II also had a keen interest in Botany and Zoology; collecting all manner of plants, seeds and animals to be displayed in Assyria.
Shalmaneser III (858–823 BC) had his authority challenged by a large alliance of a dozen nations, some of which were vassals, including; Babylonia, Egypt, Elam, Israel, Hamath, Phoenicia, the Arabs, Arameans, Suteans and neo Hittites among others, fighting them to a standstill at the Battle of Qarqar. 
Subsequent to this, Shalmaneser III attacked and reduced Babylonia to vassalage, including subjugating the Chaldean, Aramean and Sutean tribes settled within it. He then defeated Aramea, Israel, Moab, Edom, Urartu, Phoenicia, the Neo-Hittite states and the desert dwelling Arabs of the Arabian Peninsula, forcing all of these to pay tribute to Assyria. 
It is in Assyrian accounts of the 850's BC, recorded during the reign of Shalmaneser III, that the Arabs and Chaldeans first enter the pages of written history.
His armies penetrated to The Caucasus, Lake Van and the Taurus Mountains; the Hittites around Carchemish were compelled to pay tribute, and the kingdoms of Hamath and Aram Damascus were subdued. In 831 BC, he received the submission of the Georgian kingdom of Tabal. He consolidated Assyrian control over the regions conquered by his predecessors and, by the end of his 27-year reign, Assyria was master of Mesopotamia, The Levant, western Iran, Israel, Jordan and much of Asia Minor. Due to old age, in the last 6 years of his reign he passed command of his armies to the "Turtanu" (General) Dayyan-Assur.
However, his successor, Shamshi-Adad V (822-811 BC) (also known as Shamshi-Ramman II), inherited an empire beset by civil war in Assyria itself. The first years of his reign saw a serious struggle for the succession of the aged Shalmaneser III. The revolt, which had broken out by 826 BC, was led by Shamshi-Adad's brother Assur-danin-pal. The rebellious brother, according to Shamshi-Adad's own inscriptions, succeeded in bringing to his side 27 important cities, including Nineveh and Babylon. The rebellion lasted until 820 BC, preventing Assyria expanding its empire further until it was quelled. 
Later in his reign, Shamshi-Adad V successfully campaigned against both Babylonia and Elam, and forced a treaty in Assyria's favour on the Babylonian king Marduk-zakir-shumi I. In 814 BCE, he won the battle of Dur-Papsukkal against the new Babylonian king Murduk-balassu-iqbi, and went on to subjugate the immigrant tribes of Chaldeans, Arameans, and Suteans who had recently settled in parts of Babylonia.
He was succeeded by Adad-nirari III (810–782 BC), who was merely a boy. The Empire was thus ruled by his mother, the famed queen Semiramis (Shammuramat), until 806 BC. Semiramis held the empire together, and appears to have campaigned successfully in subjugating the Persians, Parthians and Medes during her regency, leading to the later Iranian myths and legends surrounding her.
In 806 BC, Adad-nirari III took the reins of power from Semiramis. He invaded the Levant and subjugated the Arameans, Phoenicians, Philistines, Israelites, Neo-Hittites, Moabites and Edomites. He entered Damascus and forced tribute upon its Aramean king Ben-Hadad III. He next turned eastward to Iran, and subjugated the Persians, Medes and the pre Iranian Manneans, penetrating as far north east as the Caspian Sea. He then turned south, forcing Babylonia to pay tribute. His next targets were the migrant Aramean, Chaldean and Sutu tribes, who had settled in the far south eastern corner of Mesopotamia, whom he conquered and reduced to vassalage. Then the Arabs in the deserts of the Arabian Peninsula to the south of Mesopotamia were invaded, vanquished and forced to pay tribute also.
Adad-nirari III died prematurely in 782 BC, which led to a temporary period of stagnation within the empire. Assyria continued its military dominance, however Shalmaneser IV (782 - 773 BC) himself seems to have wielded little personal authority, and a victory over Argishti I, king of Urartu at Til Barsip is accredited to an Assyrian General ('Turtanu') named Shamshi-ilu, who does not even bother to mention his king. Shamshi-ilu also scored victories over the Arameans and Neo-Hittites, and again, takes personal credit at the expense of his king.
Ashur-dan III ascended the throne in 772 BC. He proved to be a largely ineffectual ruler who was beset by internal rebellions in the cities of Ashur, Arrapkha and Guzana; and his personal authority was checked by powerful generals, such as Shamshi-ilu. He failed to make any further gains in Babylonia, Canaan and Aram. His reign was also marred by Plague and an ominous Solar Eclipse and, as with his predecessor, military victories were credited to Shamshi-ilu.
Ashur-nirari V became king in 754 BC, the early part of his reign seems to have been one of permanent internal revolution, and he apprears to have barely left his palace in Nineveh. However later in his reign he led a number of successful campaigns in Asia Minor and the Levant. He was deposed by Tiglath-pileser III in 745 BC bringing a resurgence to Assyrian expansion.
Tiglath-Pileser III (745–727 BC) initiated a renewed period of Assyrian expansion; Urartu, Persia, Media, Mannea, Babylonia, Arabia, Phoenicia, Israel, Judah, Samaria, Nabatea, Chaldea, Cyprus, Moab, Edom and the Neo-Hittites were subjugated, Tiglath-Pileser III was declared king in Babylon and the Assyrian empire was now stretched from the Caucasus Mountains to Arabia and from the Caspian Sea to Cyprus. Tiglath-Pileser III had reorganised the Assyrian army into the first professional fighting force in history, and greatly improved the civil administration of his empire, setting the template for all future ancient empires
Tiglath-Pileser III introduced Mesopotamian Eastern Aramaic as the "Lingua Franca" of Assyria and its vast empire, whose Akkadian infused descendant dialects survive among the modern Assyrian Christian people to this day.
Shalmaneser V (726–723 BC) consolidated Assyrian power during his short reign, and repressed Egyptian attempts to gain a foothold in the near east, defeating and driving out Pharaoh Piye from the region. He is mentioned in Biblical sources as having conquered the Samaritans, and being responsible for deporting the Ten Lost Tribes of Israel to Assyria.
Sargon II (722–705 BC) maintained the empire, driving the Cimmerians and Scythians from Iran, where they had invaded and attacked the Persians and Medes, who were vassals of Assyria. Deioces, king of the Medes and Persians was then forced to pay tribute. Mannea, Cilicia Cappadocia and Commagene were conquered, Urartu was ravaged, and Babylon, Aram, Phoenicia, Israel, Arabia, Cyprus, and the famed Midas (king of Phrygia) were forced to pay tribute. His "stele" has been found as far west as Larnaca in Cyprus. Sargon II conquered Gurgum, Milid, the Georgian state of Tabal, and all of the Hittite kingdoms of the Taurus Mountains. Egypt once again attempted to gain ground in the region by supporting Israel's rebellion against the empire but Sargon II crushed the uprising, and Piye was once more routed and driven back over the Sinai. Sargon II was killed in 705 BC while on a punitive raid against the Cimmerians, and was succeeded by Sennacherib.
Sennacherib (705-681 BC), a ruthless ruler, defeated the Greeks who were attempting to gain a foothold in Cilicia, and then defeated and drove the Nubian ruled Egyptians from the Near East where the Nubian Pharaoh Taharqa had fomented revolt against Assyria. 
Sennacherib was forced to contend with a major revolt within his empire, which included a large alliance of subject peoples, including Babylonians, Persians, Medes, Chaldeans, Elamites, Parthians, Manneans and Arameans. The prime movers in this rebellion were Mushezib-Marduk of Babylonia, Achaemenes of Persia, Khumban-umena III of Elam, and Deioces of Media. The Battle of Halule was fought in 691 BC between Sennacherib and his enemies, in which this vast alliance failed to overthrow Sennacherib. The Assyrian king was then able to subjugate these nations individually, Babylon was sacked and largely destroyed by Sennacherib. 
He sacked Israel, subjugated the Samaritans and laid siege to Judah, forcing tribute upon it. He installed his own son Ashur-nadin-shumi as king in Babylonia. He maintained Assyrian domination over the Medes, Manneans and Persians to the east, Asia Minor and the southern Caucasus to the north and north west, and the Levant, Phonecia and Aram in the west. Sennacherib's palace and garden at Nineveh have been proposed as the archetype of the Hanging Garden of Babylon. Sennacherib was murdered by his own sons (according to the Bible the sons were named Adrammelech, Abimelech and Sharezer) in a palace revolt, apparently in revenge for the destruction of Babylon, a city sacred to all Mesopotamians, including the Assyrians.
Esarhaddon (680–669 BC) expanded Assyria still further, campaigning deep into the Caucasus Mountains in the north, breaking Urartu completely in the process. Tiring of Egyptian interference in the Assyrian Empire, Esarhaddon decided to conquer Egypt. He crossed the Sinai Desert, and invaded and took Egypt with surprising ease and speed, driving its foreign Nubian/Kushite and Ethiopian rulers out and destroying the Kushite Empire in the process. He expanded the empire as far south as Arabia and Dilmun (modern Bahrain or Qatar).
Esarhaddon also completely rebuilt Babylon during his reign, bringing peace to Mesopotamia as a whole. The Babylonians, Egyptians, Elamites, Cimmerians, Scythians, Persians, Medes, Manneans, Arameans, Chaldeans, Israelites, Phoenicians and Urartians were vanquished and regarded as vassals and Assyria's empire was kept secure. 
He imposed a so-called "Vassal Treaty" upon his Persian and Median subjects, forcing Teispes of Persia and Deioces of Media to submit both to himself, and in advance to his chosen successor, Ashurbanipal. Esarhaddon died whilst preparing to leave for Egypt to once more eject the Nubians, who were attempting to encroach on the southern part of the country. This task was successfully completed by his successor, Ashurbanipal.
Under Ashurbanipal (669–627 BC), Assyrian domination spanned from the Caucasus Mountains in the north to Nubia, Egypt and Arabia in the south, and from Cyprus and Antioch in the west to Persia in the east.
He was an unusually educated man for his time, being able to read and write in Akkadian, Aramaic and Sumerian, and having a proficient understanding of Astronomy and Mathematics, as well as military, civil and political aptitude. He built the famed Library of Ashurbanipal which contained a multitude of ancient texts from all over Mesopotamia, and was the first library in history to classify works in order of genre.
Ashurbanipal began his rule by easily crushing the Nubian/Cushite king Taharqa, who had attempted to invade the southern part of Assyrian-controlled Egypt. Memphis was sacked, and Taharqa was chased back into Nubia (modern Sudan) by a pursuing Assyrian army, and was never again to pose a threat. Ashurbanipal then put down a series of rebellions by the native Egyptians themselves, installing Necho I as a puppet Pharaoh. However in 664 BC, the new Nubian-Kushite king Tantamani once more attempted to invade Egypt, however he was savagely crushed, Thebes was sacked and looted, and he fled to Nubia, bringing to an end, once and for all, Nubian designs on Egypt.
Phraortes, the king of the Medes and Persians, also rebelled against Assyria, and attempted to attack Assyria itself in 653 BC, however he met with defeat at the hands of Ashurbanipal, and was killed. The succeeding Median kings, Madius and then Cyaxares the Great, were both in turn subjugated by Ashurbanipal.
At around this time, Gyges king of Lydia in western Asia Minor, offered his submission to Ashurbanipal.
In 652 BC, just one year after his victory over Phraortes, his own brother Shamash-shum-ukin, the Assyrian king of Babylon who had spent seventeen years peacefully subject to his sibling, became infused with Babylonian nationalism, declaring that Babylon and not Nineveh should be the seat of empire. Shamash-shum-ukin raised a powerful coalition of peoples resentful of being subject to Assyria, including- Babylonians, Chaldeans, Persians, Arameans, Suteans, Arabs, Elamites, Scythians, Cimmerians, and even some Assyrians. War raged between the two brothers for five years, until in 648 BC, Babylon was sacked, and Shamash-shum-ukin slain. Ashurbanipal then wrought savage revenge, Elam was utterly destroyed, the Aramean, Chaldean, Sutean tribes were brutally punished, Arabia was ravaged by the Assyrian army, and its rebellious shiekhs put to death. Cyrus I of Persia (grandfather of Cyrus the Great) was forced into submission, as a part of this defeated alliance.
Late in his reign, Ashurbanipal was forced to contend with renewed attempts on his empire by the Scythians and Cimmerians. The Scythians were able to once more ravage Assyria's Median and Persian colonies in Ancient Iran before being finally subdued, and the last decade or so of his reign seems to have been peaceful.
He built vast libraries and initiated a surge in the building of temples and palaces. After the crushing of the Babylonian revolt, Ashurbanipal appeared master of all he surveyed. To the east, Elam was devastated and prostrate before Assyria, the Manneans and the Iranian Persians and Medes were vassals. To the south, Babylonia was occupied, the Chaldeans, Arabs, Sutu and Nabateans subjugated, the Nubian empire destroyed, and Egypt paid tribute. To the north, the Scythians and Cimmerians had been vanquished and driven from Assyrian territory, Urartu (Armenia), Phrygia, Corduene and the neo Hittites were in vassalage, and Lydia pleading for Assyrian protection. To the west, Aramea (Syria), the Phoenicians, Israel, Judah, Samarra and Cyprus were subjugated, and the Hellenised inhabitants of Caria, Cilicia, Cappadocia and Commagene paid tribute to Assyria.
Assyria conquered the 25th dynasty Egypt (expelling its Nubian/Kushite dynasty) as well as Babylonia, Chaldea, Elam, Media, Persia, Urartu, Armenia, Phoenicia, Aramea/Syria, Phrygia, the Neo-Hittite States, the Hurrian lands, Arabia, Gutium, Israel, Judah, Samarra, Moab, Edom, Corduene, Cilicia, Mannea and parts of Ancient Greece (such as Cyprus), and defeated and/or exacted tribute from Scythia, Cimmeria, Lydia, Nubia, Ethiopia and others.
At its height, the Empire encompassed the whole of the modern nations of Iraq, Syria, Egypt, Lebanon, Israel, Jordan, Kuwait, Bahrain, Palestine and Cyprus, together with large swathes of Iran, Saudi Arabia, Turkey, Sudan, Libya, Armenia, Georgia and Azerbaijan.
Assyria now appeared stronger than ever. However, the long struggles pacifying the Babylonians, Chaldeans, Arameans and Elamites, the exertions undertaken in keeping the Medes, Scythians, Persians, Urartians and Cimmerians subjugated, and the constant campaigning over three centuries to control and expand its vast empire in all directions, had left Assyria exhausted. 
It had been drained of wealth and manpower; the devastated provinces could yield nothing to supply the needs of the imperial exchequer, it was difficult to find sufficient troops to garrison and effectively control the huge empire, and after the death of Ashurbanipal severe civil unrest broke out in Assyria itself, and the empire began to unravel.
Downfall, 626–605 BC.
The Assyrian Empire was severely crippled following the death of Ashurbanipal in 627 BC—the nation and its empire descending into a prolonged and brutal series of civil wars involving three rival kings, Ashur-etil-ilani, Sin-shumu-lishir and Sin-shar-ishkun. Egypt's 26th Dynasty, which had been installed by the Assyrians as vassals, quietly detached itself from Assyria, although it was careful to retain friendly relations.
Ashur-etil-ilani came to the throne in 626 BC, and was immediately beset by a series of internal civil wars. He was deposed in 623 BC, after four years of bitter fighting by Sin-shumu-lishir, an Assyrian "Turtanu" (General) who also occupied and claimed the throne of Babylon in that year. In turn, Sin-shumu-lishir was deposed as ruler of Assyria and Babylonia after a year of warfare by Sin-shar-ishkun (622–612 BC)—who was then himself faced with constant violent rebellion in the Assyrian homeland.
This situation led to wholesale revolution in Babylonia, and during the reign of Sin-shar-ishkun many Assyrian colonies to the west, east and north similarly took advantage and ceased to pay tribute to Assyria, most significantly the Medes, Persians, Scythians, Cimmerians, Babylonians, Chaldeans and Arameans.
The Scythians and Cimmerians took advantage of the bitter fighting among the Assyrians to raid Assyrian colonies, with hordes of horse borne marauders ravaging parts of Asia Minor and the Caucasus, where the vassal kings of Urartu and Lydia begged their Assyrian overlord for help in vain. They also raided the Levant, Israel and Judah (where Ashkalon was sacked by the Scythians) and all the way into Egypt whose coasts were ravaged and looted.
The Iranic peoples (the Medes, Persians and Parthians), aided by the previous Assyrian destruction of the hitherto dominant Elamites of Ancient Iran, also took advantage of the upheavals in Assyria to coalesce into a powerful Median dominated force which destroyed the "pre-Iranic" Assyrian vassal kingdom of Mannea and absorbed the remnants of the pre-Iranic Elamites of southern Iran, and the equally pre-Iranic Gutians, Manneans and Kassites of the Zagros Mountains and the Caspian Sea.
In Aram (modern Syria), Phoenicia and southern Canaan (modern Israel, Jordan, Sinai and Palestine), the various Aramean, Phoenician and Jewish states quietly reasserted their independence, and in western Asia Minor and eastern Mediterranean, the Lydians, Greeks, Cilicians, Carians, Cappadocian and Luwian states did the same. Armenians, Sarmatians and Colchians (Georgians) also began to establish themselves in parts of the Caucasus.
By 620 BC, Nabopolassar, (a previously unknown "Malka" of the Chaldean tribes who had settled the far southeast of Mesopotamia circa 900 BC) had claimed the city of Babylon and swathes of Babylonia in the confusion. Sin-shar-ishkun amassed a large army to eject Nabopolassar from Babylon; however, yet another massive revolt broke out in Assyria proper, forcing the bulk of his army to turn back, where they promptly joined the rebels in Nineveh. Similarly, Nabopolassar was unable to gain control over all of Babylonia, and could not make any inroads into Assyria despite its weakened state, being repelled at every attempt. The next four years saw bitter fighting in the heart of Babylonia itself, as the Assyrians tried to wrest back control.
However, Nabopolassar entered into an alliance with the Median king Cyaxares the Great, who had taken advantage of the upheavals in Assyria to free the Iranian peoples from Assyrian vassalage and unite the Iranian Medes, Persians and Parthians, together with the remnants of the pre-Iranian Elamites, Gutians and Manneans, into a powerful Median-dominated force. Previous mass alliances against Assyria during the reigns of Shalmaneser III, Sargon II, Sennacherib and Ashurbanipal had failed, Assyria being at the height of its power. However the nation at this time was in a severely depleted state, ravaged by civil war, disunity, instability and battle fatigue, and the forces ranged against it from all sides proved too much. 
The Babylonians, Chaldeans, Medes and Persians, together with the Scythians and Cimmerians to the north, attacked Assyria in 615 BC, sacking the cities of Kalhu (Biblical Calah/Nimrud) and Arrapha (Kirkuk). In 614 BC Assur, Guzana and Arbela (Irbil) fell. However, during 613 Sin-shar-ishkun rallied against the odds, defeating attacks by the Medes, Babylonians and Scythians.
A concerted and combined attack was launched against Assyria the following year, Nineveh itself was finally sacked in mid 612 BC, after a prolonged siege followed by house to house fighting. Sin-shar-ishkun was killed defending his capital.
Despite the loss of almost all of its major cities, and in the face of overwhelming odds, Assyrian resistance continued. Ashur-uballit II (612- 605? BC) took the throne amid the street by street fighting in Nineveh, and refused a request to bow in vassalage to Nabopolassar, Cyaxares and their allies. He managed to break out of Nineveh and successfully fight his way to the northern Assyrian city of Harran, he took the city and founded it as a new capital. Ashur-uballit II somehow managed to keep control of a now greatly reduced Assyria for five years, repelling attacks by his enemies. However, Harran too was eventually besieged and taken by the Medes, Babylonians and Scythians in 608 BC, with Ashur-uballit II once more managing to break free of the siege.
Egypt, itself a former Assyrian colony whose current dynasty had been installed as puppet rulers by the Assyrians, then came to Assyria's aid, possibly in fear that without Assyrian protection they would be next to succumb.
Ashur-uballit II and Necho of Egypt made a failed attempt to recapture Harran in 608 BC. The next three years saw the remnants of the Assyrian army and their Egyptian allies vainly attempting to eject the invaders from Assyria. In 605 BC, the Babylonians and Medes defeated the Assyrians and Egyptians at Carchemish, bringing an end to Assyria as an independent political entity, although it was to launch major rebellions against the Achaemenid Empire in 546 BC and 520 BC, and remained a geo-political region and colonised province until the late 7th century AD.
The fate of Ashur-uballit II remains unknown, his Limmu Lists end after the fall of Harran, and it is possible he was either killed at this time, at the battle of Carshemish in 605 BC, or simply disappeared into obscurity.
Assyria after the empire.
Achaemenid Assyria, Athura, Assuristan, Assyria province, Adiabene, Osroene and Hatra.
Most of Assyria was ruled by Babylon from 605 BC until 539 BC, the northern reaches being ruled first by the Medes and then from 549 BC by their successors, the Persians. In a twist of fate, Nabonidus the last king of Babylon was himself an Assyrian from Harran; however, apart from plans to dedicate religious temples in that city, Nabonidus showed little interest in rebuilding Assyria. Nineveh and Kalhu remained in ruins, conversely a number of towns and cities such as Arrapkha, Guzana and Harran remained intact, and Assur and Arbela were not completely destroyed, as is attested by their later revival. However, Assyria spent much of this period in a degree of devastation following its fall.
Achaemenid Assyria (549–330 BC).
After this, it was ruled by the Persian Achaemenid Empire (as Athura) from 549 BC to 330 BC (see Achaemenid Assyria). Between 546 and 545 BC, Assyria rebelled against the new Persian Dynasty, which had usurped the previous Median dynasty. The rebellion was eventually quashed by Cyrus the Great.
Assyria seems to have recovered dramatically, and flourished during this period. It became a major agricultural and administrative centre of the Achaemenid Empire, and its soldiers were a mainstay of the Persian Army. In fact, Assyria even became powerful enough to raise another full-scale revolt against the Persian empire in 520–519 BC.
The Persians had spent centuries under Assyrian domination, and Assyrian influence can be seen in Achaemenid art, infrastructure and administration. Early Persian rulers saw themselves as successors to Ashurbanipal, and Mesopotamian Aramaic was retained as the "lingua franca" of the empire for over two hundred years. Nineveh was never rebuilt however, and 200 years after it was sacked Xenophon reported only small numbers of Assyrians living amongst its ruins.
Seleucid Assyria.
In 330 BC, Assyria fell to Alexander the Great, the Macedonian Emperor from Greece; it thereafter became part of the Seleucid Empire and was renamed Syria, a Hurrian, Luwian and Greek corruption of Assyria. It is from this period that the later "Syria" Vs "Assyria" naming controversy arises, the Seleucids applied the name not only to Assyria itself, but also to the lands to the west (Aram modern Syria), which had been part of the Assyrian empire. When they lost control of Assyria, the name "Syria" survived and was applied only to the land of Aramea to the west that had once been part of the Assyrian empire. This was to lead to both the Assyrians from Mesopotamia and Arameans and Phoenicians from the Levant being dubbed Syrians in Greco-Roman culture.
During Seleucid rule, Assyrians ceased to hold the senior military and civil positions they had enjoyed under the Achaemenids, being largely replaced by Greeks. The Greek language also replaced Mesopotamian East Aramaic as the lingua franca of the empire, although this did not affect the Assyrian population themselves, who were not Hellenised during the Seleucid era.
During the Seleucid period in southern Mesopotamia, Babylon was gradually abandoned in favour of a new city named Dura Seleucus, bringing an end to "Babylonia".
Parthian Assyria (150 BC – 116 AD); Adiabene (69 BC – 117 AD).
By 150 BC, Assyria was largely under the control of the Parthian Empire, once more as Athura (the Mesopotamian East Aramaic word for Assyria). The Parthians seem to have exercised only loose control over Assyria. Temples to the native gods of Assyria were resurrected in many towns and cities. A number of independent Neo-Assyrian states arose, the most notable being Adiabene (69 BC - 117 AD). Adiabene was described by historian Georges Roux as a virtual resurrection of Assyria.
The Assyrians began to convert to Christianity from Mesopotamian religion (Ashurism) during the period between the early 1st and 3rd centuries AD.
Roman Assyria (116 AD – 118 AD).
However, in 116 AD, under Trajan, Assyria and its independent states were taken over by Rome as the Roman Province of Assyria. Adiabene was destroyed as an independent state during this period. Roman rule lasted only a few years, and the Parthians once more regained control.
Parthian Assyria restored (119 AD – 225 AD), Osroene, Hatra.
Romans and Parthians fought over Assyria and the rest of Mesopotamia for the next century, allowing a number of other Neo-Assyrian states to arise, namely Osroene (132 BC to AD 244) and Hatra (155–241 AD). Osroene became the first Christian state in history, and a major center of Syriac literature and Syriac Christianity.
In addition, the ancient capital city of Ashur again flourished, and appears to have gained independence during the 2nd and 3rd centuries AD. Temples to the Assyrian national gods Ashur, Sin, Hadad, Ishtar and Shamash were once more dedicated throughout Assyria during this period. The noted Assyriologist Simo Parpola has speculated that Assyria may well have once again been fully independent for a while.
Sassanid Assyria (Assuristan (226 AD – circa 650 AD).
In 226 AD, Assyria was largely taken over by the Sassanid Empire. After driving out the Romans and Parthians, the Sassanid rulers set about destroying the independent states within Assyria; Hatra was dissolved in 241 AD, Osroene in 244 AD and Assur was sacked by Shapur I in 256 AD.
It was known as Asuristan (the Sassanid name for Assyria) during this period, and became the birthplace of the Church of the East (now split into the Assyrian Church of the East and Chaldean Catholic Church), with a flourishing Syriac (Assyrian) Christian culture which exists there to this day. Temples were still being dedicated to the national god Ashur in his home city and in Harran during the 4th century, indicating an Assyrian identity was still strong.
During the Sassanid period, much of what had once been Babylonia in southern Mesopotamia was incorporated into Assyria.
Parts of Assyria appear to have been semi independent as late as the latter part of the 4th century AD, with a king named Sennacherib II ruling the northern reaches in 370s AD.
Assyrians after Assyria.
Centuries of constant warfare between the Byzantine Empire and Sassanid Empire left both empires exhausted, depleted and battle fatigued, allowing the Muslim Arabs to break from the Arabian peninsula and invade territories hitherto held by these empires. After the Arab Islamic conquest in the 7th century, Assyria was dissolved as an entity. Under Arab rule, Mesopotamia as a whole underwent a gradual process of Arabisation and Islamification, and the region saw a gradual large influx of non indigenous Arabs, Kurds and Turkic peoples. However, the indigenous Assyrian population of northern Mesopotamia (known as Ashuriyun by the Arabs) resisted this process, retaining their language, religion, culture and identity.
The previously basic civilisation of the desert dwelling Arabs was greatly enhanced and enriched by the influence and knowledge of native Mesopotamian scientists, physicians, mathematicians, theologians, astronomers, architects, agriculturalists, artists and astrologers.
However, despite this, indigenous Assyrians became second class citizens in a greater Arab Islamic state, and those who resisted Arabisation and conversion to Islam were subject to religious, ethnic and cultural discrimination, and had certain restrictions imposed upon them. They were excluded from specific duties and occupations reserved for Muslims, did not enjoy the same political rights as Muslims, their word was not equal to that of a Muslim in legal matters, as Christians they were subject to payment of a special tax (jizyah), they were banned from spreading their religion further in Muslim ruled lands, but were also expected to adhere to the same laws of property, contract and obligation as the Muslim Arabs.
Although predominantly Christian, a minority of Assyrians still held onto their ancient Mesopotamian religion until as late as the 10th century AD.
Assyrian people, still retaining the Aramaic language and Church of the East Christianity, remained dominant in the north of Mesopotamia as late as the 14th century AD and the city of Assur was still occupied by Assyrians during the Islamic period until the mid-14th century when the Muslim Turco-Mongol ruler Tamurlane conducted a religiously motivated massacre of indigenous Assyrian Christians. After that, there are no traces of a settlement at Ashur in the archaeological and numismatic record, and from this point the Assyrian population was dramatically reduced in their homeland.
A religious schism among the Assyrians of northern Mesopotamia emerged in the 16th and 17th centuries AD, when a large number of hitherto Assyrian Church of the East Assyrians entered communion with the Roman Catholic Church, and after Rome changed the name of this new church from "The Church of Assyria and Mosul" (named as such in 1553 AD) to the "Chaldean Catholic Church" in 1681 AD, this group of Assyrians eventually became known as Chaldean Catholics or Chaldo-Assyrians despite having no ethnic, historical or geographic connections whatsoever to the long extinct Chaldean tribe of south east Mesopotamia.
The Assyrians suffered a number of religiously and ethnically motivated massacres throughout the 17th, 18th and 19th centuries AD, culminating in the large scale Hamidian massacres of unarmed men, women and children by Muslim Turks and Kurds in the late 19th century, further greatly reduced numbers.
The Assyrians suffered a catastrophic series of massacres known as the Assyrian Genocide, at the hands of the Ottomans and their Kurdish and Arab allies from 1915–1918. The genocide accounted for up to 300,000 unarmed Assyrian civilians, and the forced deportations of many more. The sizeable Assyrian presence in south eastern Asia Minor which had endured for over four millennia was reduced to a few thousand. As a consequence, the surviving Assyrians took up arms, and an Assyrian war of independence was fought during World War I, For a time, the Assyrians fought successfully against overwhelming numbers, scoring a number of victories over the Ottomans and Kurds, and also hostile Arab groups; then their Russian allies left the war following the Russian Revolution, and Armenian resistance broke. The Assyrians were left cut off, surrounded, and without supplies, forcing those in Asia Minor and Northwest Iran to fight their way, with civilians in tow, to the safety of British lines and their fellow Assyrians in northern Iraq.
The Assyrian Levies were founded by the British in 1928, with ancient Assyrian military rankings, such as Rab-shakeh, Rab-talia and Tartan, being revived for the first time in millennia for this force. The Assyrians were prized by the British rulers for their fighting qualities, loyalty, bravery and discipline, and were used to help the British put down insurrections among the Arabs and Kurds, guard the borders with Iran and Turkey and protect British military installations.
After Iraq was granted independence by the British in 1933, the Assyrians suffered the Simele Massacre, where thousands of unarmed villagers (men, women and children) were slaughtered by joint Arab-Kurdish forces of the Iraqi Army. These massacres followed a clash between Assyrian tribesmen and the Iraqi army, where the Iraqi forces suffered a defeat after trying to disarm the Assyrians, whom they feared would attempt to secede from Iraq. Armed Assyrian Levies were prevented by the British from going to the aid of these civilians.
During World War II, Eleven Assyrian companies saw action in Palestine and another four served in Cyprus. The Parachute Company was attached to the Royal Marine Commando and was involved in fighting in Albania, Italy and Greece. Assyrians played a major role in the victory at the Battle of Habbaniya in 1941, when the Iraqi government decided to join WW2 on the side of Nazi Germany. The British presence in Iraq lasted until 1954, and Assyrian Levies remained attached to British forces until this time.
The period from the 1940s through to 1963 saw a period of respite for the Assyrians. The regime of President Kassim in particular saw the Assyrians accepted into mainstream society. Many urban Assyrians became successful businessmen, others were well represented in politics and the military, their towns and villages flourished undisturbed, and Assyrians came to excel, and be over represented in sports such as Boxing, Football, Athletics, Wrestling and Swimming.
However in 1963, the Ba'ath Party took power by force in Iraq. The Baathists, though secular, were Arab Nationalists, and set about attempting to Arabize the non Arab peoples, including the Assyrians. This policy included refusing to acknowledge the Assyrians as an ethnic group, banning the publication of written material in Eastern Aramaic, and banning its teaching in schools, banning parents giving Assyrian names to their children, taking control of Assyrian churches,attempting to divide Assyrians on denominational lines (e.g. Assyrian Church of the East vs Chaldean Catholic Church) and forced relocations of Assyrians from their traditional homelands to major cities. These policies have also been mirrored in Turkey, whose government refuses to acknowledge the Assyrians as an ethnic group.
Many persecutions have befallen the Assyrians since, such as the Anfal campaign and Baathist, Arab and Kurdish nationalist and Islamist persecutions. In recent years, the Assyrians in Iraq and Syria have taken up arms, alongside other groups (such as the Kurds) in response to unprovoked attacks by Al Qaeda, ISIS/ISIL and other Islamic Fundamentalist groups. In 2014 Islamic terrorists of ISIS attacked Assyrian towns and villages in the Assyrian Homeland of northern Iraq, together with cities such as Mosul and Kirkuk which have large Assyrian populations. There have been reports atrocities committed by ISIS terrorists since, including; beheadings, crucifixions, child murders, rape, forced conversions, Ethnic Cleansing, robbery, and extortion in the form of illegal taxes levied upon non Muslims.
Thus far, the only people who have been attested with a high level of genetic, historical, linguistic and cultural research to be the descendants of the ancient Mesopotamians are the Assyrian Christians of Iraq and its surrounding areas in north west Iran, north east Syria and south eastern Turkey, although others have made unsubstantiated claims of continuity. Assyria continued to exist as a geopolitical entity until the Arab-Islamic conquest in the mid-7th century, and Assyrian identity, personal, family and tribal names, and both spoken and written evolutions of Mesopotamian Aramaic (which still contain many Akkadian loan words and an Akkadian grammatical structure) have survived among the Assyrian people from ancient times to this day. (see Assyrian people).
Assyrian religion.
The Assyrians, like the rest of the Mesopotamian peoples, followed the Sumero-Akkadian Mesopotamian Religion, with the national god Ashur having pride of place at the head of the pantheon. This religion survived in Assyria from c. 3500 BC through to its gradual decline in the face of Christianity between the 1st and 10th centuries AD.
Other major gods within the pantheon were Anu, Baal, Ea, Enlil, Ishtar (Astarte), Shamash, Tammuz, Adad/Hadad, Sin (Nanna), Dagan, Ninurta, Nisroch, Nergal, Tiamat, Ninlil, Mullissu, Zababa and El.
Native religion was still strongly followed at least until the 4th century AD, and survived in pockets until at least the 10th century AD, although Assyrians had begun to adopt Eastern Rite Christianity (as well as for a time Manicheanism and Gnosticism) which, like Syriac literature, had its birthplace in Assyria between the 1st and 3rd centuries AD. Assyrians today are exclusively Christian, with most following the Assyrian Church of the East, Chaldean Catholic Church, Ancient Church of the East and Syriac Orthodox churches.
Language.
During the 3rd millennium BC, a very intimate cultural symbiosis developed between the Sumerians and the Akkadians, which included widespread bilingualism. The influence of Sumerian on Akkadian (and vice versa) is evident in all areas, from lexical borrowing on a massive scale, to syntactic, morphological, and phonological convergence. This has prompted scholars to refer to Sumerian and Akkadian in the 3rd millennium BC as a "sprachbund".
Akkadian gradually replaced Sumerian as the spoken language of Mesopotamia somewhere around the turn of the 3rd and the 2nd millennium BC (the exact dating being a matter of debate), but Sumerian continued to be used as a sacred, ceremonial, literary and scientific language in Mesopotamia until the 1st century AD.
In ancient times, Assyrians spoke a dialect of the Akkadian language, an eastern branch of the Semitic languages. The first inscriptions, called Old Assyrian (OA), were made in the Old Assyrian period. In the Neo-Assyrian period the Aramaic language became increasingly common, more so than Akkadian—this was thought to be largely due to the mass deportations undertaken by Assyrian kings, in which large Aramaic-speaking populations, conquered by the Assyrians, were relocated to Assyria and interbred with the Assyrians. The ancient Assyrians also used the Sumerian language in their literature and liturgy, although to a more limited extent in the Middle- and Neo-Assyrian periods, when Akkadian became the main literary language.
The destruction of the Assyrian capitals of Nineveh and Assur by the Babylonians, Medes and their allies, ensured that much of the bilingual elite (but not all) were wiped out. By the 7th century BC, much of the Assyrian population used Akkadian influenced Eastern Aramaic and not Akkadian itself. The last Akkadian inscriptions in Mesopotamia date from the 1st century AD. However, Eastern Aramaic dialects, as well as Akkadian and Mesopotamian Aramaic personal and family names, still survive to this day among Assyrians in the regions of northern Iraq, southeast Turkey, northwest Iran and northeast Syria that constituted old Assyria.
After 90 years of effort, the University of Chicago has published an Assyrian Dictionary, whose form is more encyclopedia in style than dictionary.
Arts and sciences.
Assyrian art preserved to the present day predominantly dates to the Neo-Assyrian period. Art depicting battle scenes, and occasionally the impaling of whole villages in gory detail, was intended to show the power of the emperor, and was generally made for propaganda purposes. These stone reliefs lined the walls in the royal palaces where foreigners were received by the king. Other stone reliefs depict the king with different deities and conducting religious ceremonies. Many stone reliefs were discovered in the royal palaces at Nimrud (Kalhu) and Khorsabad (Dur-Sharrukin). A rare discovery of metal plates belonging to wooden doors was made at Balawat (Imgur-Enlil).
Assyrian sculpture reached a high level of refinement in the Neo-Assyrian period. One prominent example is the winged bull "Lamassu", or shedu that guard the entrances to the king's court. These were apotropaic meaning they were intended to ward off evil. C. W. Ceram states in "The March of Archaeology" that "lamassi" were typically sculpted with five legs so that four legs were always visible, whether the image were viewed frontally or in profile.
Although works of precious gems and metals usually do not survive the ravages of time, some fine pieces of Assyrian jewelry were found in royal tombs at Nimrud.
There is ongoing discussion among academics over the nature of the Nimrud lens, a piece of quartz unearthed by Austen Henry Layard in 1850, in the Nimrud palace complex in northern Iraq. A small minority believe that it is evidence for the existence of ancient Assyrian telescopes, which could explain the great accuracy of Assyrian astronomy. Other suggestions include its use as a magnifying glass for jewellers, or as a decorative furniture inlay. The Nimrud Lens is held in the British Museum.
The Assyrians were also innovative in military technology, with the use of heavy cavalry, sappers, siege engines etc.
Legacy.
Achaemenid Assyria (539–330 BC) retained a separate identity (Athura), official correspondence being in Imperial Aramaic, and there was even a determined revolt of the two Assyrian provinces of Mada and Athura in 520 BC. Under Seleucid rule (330 BC – approximately 150 BC), however, Aramaic gave way to Greek as the official administrative language. Aramaic was marginalised as an official language, but remained spoken in both Assyria and Babylonia by the general populace. It also remained the spoken tongue of the indigenous Assyrian/Babylonian citizens of all Mesopotamia under Persian, Greek and Roman rule, and indeed well into the Arab period it was still the language of the majority, particularly in the north of Mesopotamia, surviving to this day among the Assyrian Christians.
Between 150 BC and 226 AD, Assyria changed hands between the Parthians Iranians and Romans (Roman Province of Assyria) until coming under the rule of Sassanid Persia in 226–651 AD, where it was known as Asuristan.
A number of at least partly neo-Assyrian kingdoms existed in the area between in the late classical and early Christian period also; Adiabene, Hatra and Osroene.
Classical historiographers and Biblical writers had only retained a fragmented, very dim and often inaccurate picture of Assyria. It was remembered that there had been an Assyrian empire predating the Persian one, but all particulars were lost. Thus Jerome's "Chronicon" lists 36 kings of the Assyrians, beginning with Ninus, son of Belus, down to Sardanapalus, the last king of the Assyrians before the empire fell to Arbaces the Median. Almost none of these have been substantiated as historical, with the exception of the Neo-Assyrian and Babylonian rulers listed in Ptolemy's Canon, beginning with Nabonassar.
Mesopotamian empires such as the Akkadian Empire, Babylonian Empire, Middle Assyrian Empire, Neo Assyrian Empire and Neo Babylonian Empire asserted Mesopotamian dominance from the Caucasus Mountains to Arabia and Egypt, and from Cyprus and the east Mediterranean to Persia. Thus the influence exerted by the Babylonian-Assyrian religion was particularly profound on other Semites, including the Hebrews, Chaldeans, Canaanites, Arameans, Phoenicians and Arabs, while their astral theology affected the ancient world in general, including the Persians, Greeks, Armenians and the later Romans. The impetus to the purification of the old Semitic polytheistic religions to which the Hebrews for a long time clung in common with their fellows—the various branches of nomadic Arameans and Arabs—was largely furnished by the remarkable civilization unfolded in the Euphrates valley and in many of the traditions, myths and legends embodied in the Old Testament; traces of direct adaptation from and responses to Babylonia and Assyria may be discerned, while the indirect influences in the domain of the prophetical books, as also in the Psalms and in the so-called "wisdom literature", are even more noteworthy. Stories in the Tanakh, Old Testament and Quran such as; the Genesis creation narrative, Tower of Babel, The Great Flood and the book of Esther, as well as various biblical characters such as Noah, Nimrod, Lilith and Asnapper bear clear influence from Assyria and Babylonia.
Even when we reach the New Testament period, we have not passed entirely beyond the sphere of Babylonian-Assyrian influences. In such a movement as early Christian gnosticism, Assyrio-Babylonian elements—modified, to be sure, and transformed—are largely present, while the growth of an apocalyptic literature is ascribed with apparent justice by many scholars to the recrudescence of views, the ultimate source of which is to be found in the astral-theology of the Babylonian and Assyrian Priests.
The Assyrians began to form and adopt a distinct Eastern Rite Christianity, with its accompanying Syriac literature, between the 1st and 3rd centuries AD, however native religion was still alive and well into the 4th century AD, and pockets survived into the 10th century AD and possibly as late as the 17th century in Mardin. However, the religion is now dead, and the indigenous Assyrian (a.k.a. Chaldo-Assyrian) people, though still retaining Eastern Aramaic dialects as a mother tongue, are now wholly Christian.
The modern discovery of Babylonia and Assyria begins with excavations in Nineveh in 1845, which revealed the Library of Ashurbanipal. Decipherment of cuneiform was a formidable task that took more than a decade; but, by 1857, the Royal Asiatic Society was convinced that reliable reading of cuneiform texts was possible. Assyriology has since pieced together the formerly largely forgotten history of Mesopotamia. In the wake of the archaeological and philological rediscovery of ancient Assyria, Assyrian nationalism became increasingly popular among the surviving remnants of the Assyrian people, and has come to strongly identify with ancient Assyria.

</doc>
<doc id="2086" url="http://en.wikipedia.org/wiki?curid=2086" title="Abijah">
Abijah

Abijah (אביה " 'aḆiYaH"), alternatively spelled Abiah and Abia, in modern Hebrew Aviya, is a Biblical Hebrew unisex name that means "my Father is Yahweh".
The variant used in the Russian language is "" ("Aviya"), with "" or "" ("Abiya"), being older forms. Included into various, often handwritten, church calendars throughout the 17th–19th centuries, it was omitted from the official Synodal Menologium at the end of the 19th century. In Russian it is only used as a female name. Diminutives of this name include "" ("Ava") and "" ("Viya").

</doc>
<doc id="2087" url="http://en.wikipedia.org/wiki?curid=2087" title="Ark">
Ark

Ark may refer to:

</doc>
<doc id="2088" url="http://en.wikipedia.org/wiki?curid=2088" title="Aphasia">
Aphasia

Aphasia (, or ) is a disturbance of the comprehension and expression of language caused by dysfunction in the brain. This class of language disorder ranges from having difficulty remembering words to losing the ability to speak, read, or write. This also affects visual language such as sign language.
Aphasia is usually caused by brain damage, most commonly caused by stroke. Brain damage linked to aphasia can also be caused by other brain diseases, including cancer, epilepsy and Alzheimer's disease.
Acute aphasia disorders usually develop quickly as a result of head injury or stroke, and progressive forms of aphasia develop slowly from a brain tumor, infection, or dementia. The area and extent of brain damage or atrophy will determine the type of aphasia and its symptoms. Aphasia types include expressive aphasia, receptive aphasia, conduction aphasia, anomic aphasia, global aphasia, primary progressive aphasias and many others. Medical evaluations for the disorder range from clinical screenings by a neurologist to extensive tests by a speech-language pathologist or neuropsychologist.
Most acute aphasia patients can recover some or most skills by working with a speech-language pathologist. This rehabilitation can take two or more years and is most effective when begun quickly. Only a small minority will recover without therapy, such as those suffering a transient ischemic attack. Improvement varies widely, depending on the aphasia's cause, type, and severity. Recovery also depends on the patient's age, health, motivation, handedness, and educational level.
Classification.
The "Third International Webster's Dictionary" defines aphasia as: "The loss or impairment of the power to use words as symbols or ideas that results from a brain lesion." The word "aphasia" comes from the word ἀφασία "aphasia", in Ancient Greek, which means "speechlessness", derived from ἄφατος "aphatos", "speechless" from ἀ- "a-", "not, un" and φημί "phemi", "I speak".
Classifying the various and differing subtypes of aphasia is difficult and has led to disagreements among experts. The localizationist model is the original model, but modern anatomical techniques and analyses have shown that precise connections between brain regions and symptom classification do not exist. The neural organization of language is complicated; language is a comprehensive and complex behavior and it makes sense that it is not the product of some small, circumscribed region of the brain.
No classification of patients in subtypes and groups of subtypes has proven fully adequate. Only about 60% of patients will fit in a classification scheme such as fluent/nonfluent/pure aphasias. There is a huge variation among patients with the same diagnosis, and aphasias can be highly selective. For instance, patients with naming deficits (anomic aphasia) might show an inability only for naming buildings, or people, or colors.
Localizationist model.
The localizationist model attempts to classify the aphasia by major characteristics and then link these to areas of the brain in which the damage has been caused. The initial two categories here were devised by early neurologists working in the field, namely Paul Broca and Carl Wernicke. Other researchers have added to the model, resulting in it often being referred to as the "Boston-Neoclassical Model".
Progressive aphasias.
"Primary progressive aphasia (PPA)" is associated with progressive illnesses or dementia, such as 
frontotemporal dementia / Pick Complex Motor neuron disease, Progressive supranuclear palsy, and Alzheimer's disease, which is the gradual process of progressively losing the ability to think. It is characterized by the gradual loss of the ability to name objects. People suffering from PPA may have difficulties comprehending what others are saying. They can also have difficulty trying to find the right words to make a sentence. There are three classifications of Primary Progressive Aphasia : Progressive nonfluent aphasia (PNFA), Semantic Dementia (SD), and Logopenic progressive aphasia (LPA)
Progressive Jargon Aphasia is a fluent or receptive aphasia in which the patient's speech is incomprehensible, but appears to make sense to them. Speech is fluent and effortless with intact syntax and grammar, but the patient has problems with the selection of nouns. Either they will replace the desired word with another that sounds or looks like the original one or has some other connection or they will replace it with sounds. As such, patients with jargon aphasia often use neologisms, and may perseverate if they try to replace the words they cannot find with sounds. Substitutions commonly involve picking another (actual) word starting with the same sound (e.g., clocktower - colander), picking another semantically related to the first (e.g., letter - scroll), or picking one phonetically similar to the intended one (e.g., lane - late).
Tripartite classification: Fluent, non-fluent, and "pure" aphasias.
The different types of aphasia can be divided into three categories: fluent, non-fluent, and "pure" aphasias.
Primary and secondary cognitive processes.
Aphasias can be divided into primary and secondary cognitive processes.
Cognitive neuropsychological model.
Several neuropsychological models of aphasia have been introduced since Alexander Luria's seminal book in the 1960s titled "Higher Cortical Functions in Man". The cognitive neuropsychological model of Max Coltheart builds on cognitive neuropsychology. It assumes that language processing can be broken down into a number of modules, each of which with a specific function. Hence, there is a module that recognises phonemes as they are spoken and a module that stores formulated phonemes before they are spoken. In the clinical setting, use of this model involves conducting a battery of assessments (usually from the PALPA, the "psycholinguistic assessment of language processing in adult acquired aphasia ... that can be tailored to the investigation of an individual patient's impaired and intact abilities" ), each of which tests one or a number of these modules. Once a diagnosis is reached as to where the impairment lies, therapy can proceed to treat the individual module.
Deaf aphasia.
There have been many instances showing that there is a form of aphasia among deaf individuals. Sign language is, after all, a form of communication that has been shown to use the same areas of the brain as verbal forms of communication. Mirror neurons become activated when an animal is acting in a particular way or watching another individual act in the same manner. These mirror neurons are important in giving an individual the ability to mimic movements of hands. Broca's area of speech production has been shown to contain several of these mirror neurons resulting in significant similarities of brain activity between sign language and vocal speech communication. Facial communication is a significant portion of how animals interact with each other. Humans use facial movements to create, what other humans perceive, to be faces of emotions. While combining these facials movements with speech, a more full form of language is created which enables the species to interact with a much more complex and detailed form of communication. Sign language also uses these facial movements and emotions along with the primary hand movement way of communicating. These facial movement forms of communication come from the same areas of the brain. When dealing with damages to certain areas of the brain, vocal forms of communication are in jeopardy of severe forms of aphasia. Since these same areas of the brain are being used for sign language, these same, at least very similar, forms of aphasia can show in the Deaf community. Individuals can show a form of Wernicke's aphasia with sign language and they show deficits in their abilities in being able to produce any form of expressions. Broca's aphasia shows up in some patients, as well. These individuals find tremendous difficulty in being able to actually sign the linguistic concepts they are trying to express.
Signs and symptoms.
People with aphasia may experience any of the following behaviors due to an acquired brain injury, although some of these symptoms may be due to related or concomitant problems such as dysarthria or apraxia and not primarily due to aphasia.
Presentation.
Acute aphasias
The following table summarizes some major characteristics of different acute aphasias:
Subcortical aphasias
Causes.
Aphasia usually results from lesions to the language-relevant areas of the frontal, temporal and parietal lobes of the brain, such as Broca's area, Wernicke's area, and the neural pathways between them. These areas are almost always located in the left hemisphere, and in most people this is where the ability to produce and comprehend language is found. However, in a very small number of people, language ability is found in the right hemisphere. In either case, damage to these language areas can be caused by a stroke, traumatic brain injury, or other brain injury.
Aphasia may also develop slowly, as in the case of a brain tumor or progressive neurological disease, e.g., Alzheimer's or Parkinson's disease. It may also be caused by a sudden hemorrhagic event within the brain. Certain chronic neurological disorders, such as epilepsy or migraine, can also include transient aphasia as a prodromal or episodic symptom.
Aphasia can result from herpesviral encephalitis. The herpes simplex virus affects the frontal and temporal lobes, subcortical structures, and the hippocampal tissue, which can trigger aphasia.
Aphasia is also listed as a rare side-effect of the fentanyl patch, an opioid used to control chronic pain.
Adverse side effects including chronic aphasia can be caused by cortico-steroids.
Management.
There is no one treatment proven to be effective for all types of aphasias. The reason that there is no universal treatment for aphasia is because of the nature of the disorder and the various ways it is presented, as explained in the above sections. Aphasia is rarely exhibited identically, implying that treatment needs to be catered specifically to the individual. Studies have shown that, although there is no consistency on treatment methodology in literature, there is a strong indication that treatment in general has positive outcomes.
A multi-disciplinary team, including doctors (often a physician is involved, but more likely a clinical neuropsychologist will head the treatment team), physiotherapist, occupational therapist, speech-language pathologist, and social worker, works together in treating aphasia. For the most part, treatment relies heavily on repetition and aims to address language performance by working on task-specific skills. The primary goal is to help the individual and those closest to them adjust to changes and limitations in communication.
Treatment techniques mostly fall under two approaches:
Several treatment techniques include the following:
More recently, computer technology has been incorporated into treatment options. A key indication for good prognosis is treatment intensity. A minimum of two–three hours per week has been specified to produce positive results. The main advantage of using computers is that it can greatly increase intensity of therapy. These programs consist of a large variety of exercises and can be done at home in addition to face-to-face treatment with a therapist. However, since aphasia presents differently among individuals, these programs must be dynamic and flexible in order to adapt to the variability in impairments. Another barrier is the capability of computer programs to imitate normal speech and keep up with the speed of regular conversation. Therefore, computer technology seems to be limited in a communicative setting, however is effective in producing improvements in communication training.
Several examples of programs used are StepByStep, Lingraphica, Computer-Based Visual Communication (C-VIC), TouchSpeak (TS), and Sentence Shaper.
Melodic intonation therapy is often used to treat non-fluent aphasia and has proved to be very effective in some cases.
History.
The first recorded case of aphasia is from an Egyptian papyrus, the Edwin Smith Papyrus, which details speech problems in a person with a traumatic brain injury to the temporal lobe. During the second half of the 19th century, Aphasia was a major focus for scientists and philosophers who were working in the beginning stages in the field of psychology.
Prevention.
Following are some precautions that should be taken to avoid aphasia, by decreasing the risk of stroke, the main cause of aphasia:

</doc>
<doc id="2089" url="http://en.wikipedia.org/wiki?curid=2089" title="Aorta">
Aorta

The aorta () is the main artery in the human body, originating from the left ventricle of the heart and extending down to the abdomen, where it splits into two smaller arteries (the common iliac arteries). The aorta distributes oxygenated blood to all parts of the body through the systemic circulation.
Structure.
Sections.
In anatomical sources, the aorta is usually divided into sections.
One way of classifying a part of the aorta is by anatomical compartment, where the thoracic aorta (or thoracic part of the aorta) runs from the heart to the diaphragm. The aorta then continues downward as the abdominal aorta (or abdominal part of the aorta) diaphragm to the aortic bifurcation. Another system divides the aorta with respect to its course and the direction of blood flow. In this system, the aorta starts as the ascending aorta then travels superiorly from the heart and then makes a hairpin turn known as the aortic arch. Following the aortic arch, the aorta then travels inferiorly as the descending aorta. The descending aorta has two parts. The aorta begins to descend in the thoracic cavity, and consequently is known as the thoracic aorta. After the aorta passes through the diaphragm, it is known as the abdominal aorta. The aorta ends by dividing into two major blood vessels, the common iliac arteries and a smaller midline vessel, the median sacral artery.
Ascending aorta.
The ascending aorta begins at the opening of the aortic valve at the heart. It runs through a common pericardial sheath along with the pulmonary trunk. These two blood vessels twist around each other, causing the aorta to start out posterior to the pulmonary trunk, but ends by twisting to its right and anterior side.
The transition from ascending aorta to aortic arch is at the pericardial reflection on the aorta.
At the root of the ascending aorta, the lumen has three little pockets between the cusps of the aortic valve and the wall of the aorta, named the "aortic sinuses" or "sinuses of Valsalva". The left aortic sinus contains the origin of the left coronary artery and the right aortic sinus likewise gives rise to the right coronary artery. Together, these two arteries supply the heart. The posterior aortic sinus does not give rise to a coronary artery. For this reason the left, right and posterior aortic sinuses are also called left-coronary, right-coronary and non-coronary sinuses.
Aortic arch.
The aortic arch loops over the left pulmonary artery and the bifurcation of the pulmonary trunk, with which it remains connected by the ligamentum arteriosum, a remnant of the fetal circulation that is obliterated a few days after birth. In addition to these blood vessels, the aortic arch crosses the left main bronchus. Between it and the pulmonary trunk is a network of autonomic nerve fibers, the "cardiac" or "aortic plexus". The left vagus nerve, which passes anterior to the aortic arch, gives off a major branch, the recurrent laryngeal nerve, which loops under the aortic arch just lateral to the ligamentum arteriosum. It then runs back to the neck.
The aortic arch has three major branches: from proximal to distal they are the brachiocephalic trunk, which supplies the right side of the head and neck, as well as the right arm and chest wall, the left common carotid artery, and the left subclavian artery. The latter two together supply the left side of the same regions.
At the level of the intervertebral disc between the fourth and fifth thoracic vertebrae, the aortic arch ends and the descending aorta starts.
Thoracic aorta.
The thoracic descending aorta gives rise to the intercostal and subcostal arteries, as well as to the superior and inferior left bronchial arteries and variable branches to the esophagus, mediastinum, and pericardium. Its lowest pair of branches are the superior phrenic arteries, which supply the diaphragm, and the subcostal arteries for the twelfth rib.
Abdominal aorta.
The abdominal aorta gives rise to lumbar and musculophrenic arteries, renal and middle suprarenal arteries, and visceral arteries (the celiac trunk, the superior mesenteric artery and the inferior mesenteric artery). It ends in a bifurcation into the left and right common iliac arteries. At the point of the bifurcation, there also springs a smaller branch, the median sacral artery.
Development.
In mammalian and avian embryological development, the pharyngeal arch (aortic arches) arteries contribute to the normal pattern of the great arteries. The fourth aortic arch vessel survives in these vertebrates as the arch of the aorta, the third aortic arch vessel persists as the brachiocephalic artery or the root of the internal carotid, and the sixth arch contributes to the pulmonary arteries. The smooth muscle of the great arteries and the population of cells that form the aorticopulmonary septum that separates the aorta and pulmonary artery is derived from cardiac neural crest. This contribution of the neural crest to the great artery smooth muscle is unusual as most smooth muscle is derived from mesoderm. In fact the smooth muscle within the abdominal aorta is derived from mesoderm, and the coronary arteries, which arise just above the semilunar valves, possess smooth muscle of mesodermal origin. A failure of the aorticopulmonary septum to divide the great vessels results in persistent truncus arteriosus.
Histology.
The aorta is an elastic artery, and as such is quite distensible. The aorta consists of a heterogeneous mixture of smooth muscle, nerves, intimal cells, endothelial cells, fibroblast-like cells, and a complex extracellular matrix. The vascular wall consists of several layers known as the tunica adventitia, tunica media, and tunica intima. The thickness of the aorta encourages an extensive network of tiny blood vessels called vasa vasorum, which feed the outer layers of the aorta. The aortic arch contains baroreceptors and chemoreceptors that relay information concerning blood pressure and blood pH and carbon dioxide levels to the medulla oblongata of the brain. This information is processed by the brain and the autonomic nervous system mediates the homeostatic responses.
Within the tunica media, smooth muscle and the extracellular matrix are quantitatively the largest components of the aortic vascular wall. The fundamental unit of the aorta is the elastic lamella, which consists of smooth muscle and elastic matrix. The medial layer of the aorta consist of concentric musculoelastic layers (the elastic lamella) in mammals. The smooth muscle component does not dramatically alter the diameter of the aorta but rather serves to increase the stiffness and viscoelasticity of the aortic wall when activated. The elastic matrix dominates the biomechanical properties of the aorta. The elastic matrix forms lamellae, consisting of elastic fibers, collagens (predominately type III), proteoglycans, and glycoaminoglycans.
Variations.
Variations may occur in the location of the aorta, and the way in which arteries branch off the aorta. The aorta, normally on the left side of the body, may be found on the right in dextrocardia, in which the heart is found on the right, or situs inversus, in which the location of all organs are flipped.
Variations in the branching of individual arteries may also occur. For example, the left vertebral artery may arise from the aorta, instead of the left common carotid artery.
Function.
The aorta supplies all of the systemic circulation, which means that the entire body, except for the respiratory zone of the lung, gets its blood from the aorta. Broadly speaking, branches from the ascending aorta supply the heart; branches from the aortic arch supply the head, neck and arms; branches from the thoracic descending aorta supply the chest (excluding the heart and the respiratory zone of the lung); and branches from the abdominal aorta supply the abdomen. The pelvis and legs get their blood from the common iliac arteries.
Blood flow and velocity.
The pulsatile nature of blood flow creates a pulse wave that is propagated down the arterial tree, and at bifurcations reflected waves rebound to return to semilunar valves and the origin of the aorta. These return waves create the dicrotic notch displayed in the aortic pressure curve during the cardiac cycle as these reflected waves push on the aortic semilunar valve. With age, the aorta stiffens such that the pulse wave is propagated faster and reflected waves return to the heart faster before the semilunar valve closes, which raises the blood pressure. The stiffness of the aorta is associated with a number of diseases and pathologies, and noninvasive measures of the pulse wave velocity are an independent indicator of hypertension. Measuring the pulse wave velocity (invasively and non-invasively) is a means of determining arterial stiffness. Maximum aortic velocity may be noted as Vmax or less commonly as AoVmax. 
Mean arterial pressure (MAP) is highest in the aorta and the MAP decreases across the circulation from aorta to arteries to arterioles to capillaries to veins back to atrium. The difference between aortic and right atrial pressure accounts for blood flow in the circulation. When the left ventricle contracts to force blood into the aorta, the aorta expands. This stretching gives the potential energy that will help maintain blood pressure during diastole, as during this time the aorta contracts passively. This Windkessel effect of the great elastic arteries has important biomechanical implications. The elastic recoil helps conserve the energy from the pumping heart and smooth out the pulsatile nature created by the heart. Aortic pressure is highest at the aorta and becomes less pulsatile and lower pressure as blood vessels divide into arteries, arterioles, and capillaries such that flow is slow and smooth for gases and nutrient exchange.
In other animals.
All amniotes have a broadly similar arrangement to that of humans, albeit with a number of individual variations. In fish, however, there are two separate vessels referred to as aortas. The ventral aorta carries de-oxygenated blood from the heart to the gills; part of this vessel forms the ascending aorta in tetrapods (the remainder forms the pulmonary artery). A second, dorsal aorta carries oxygenated blood from the gills to the rest of the body, and is homologous with the descending aorta of tetrapods. The two aortas are connected by a number of vessels, one passing through each of the gills.
Amphibians also retain the fifth connecting vessel, so that the aorta has two parallel arches.
History.
The word 'Aorta' stems from the Late Latin "" from "aortē" (), from "aeirō", "I lift, raise" () This term was first applied by Aristotle when describing the aorta.

</doc>
<doc id="2093" url="http://en.wikipedia.org/wiki?curid=2093" title="Abimelech">
Abimelech

Abimelech (also spelled Abimelek or Avimelech; ) was the name of multiple Philistine kings mentioned in the Hebrew Bible.
Etymology.
Abimelech's name is thought to mean "my father is king", and could be simply a generic title given to a crown prince. This is supported in the "Haggada" when "Benmelech" ("son of the king"), son of Abimelech, changes his own name to Abimelech when he becomes king. Alternatively, it has been suggested to mean "my father is Moloch.
At the time of the Amarna tablets (mid-14th century BC), there was an Egyptian governor of Tyre similarly named Abimilki, who is sometimes speculated to be connected with one or more of the biblical Abimelechs.
Abimelech of Gerar.
Abimelech was most prominently the name of a polytheistic king of Gerar who is mentioned in two of the three wife-sister narratives in Genesis, in connection with both Abraham (chap. 20) and Isaac (chap. 26). The "Haggada" identifies them as references to separate people, the second being the first Abimelech's son, and that his original name was Benmelech ("son of the King") but changed his name to his father's.
King Abimelech of Gerar also appears in an extra-biblical tradition recounted in texts such as the "Kitab al-Magall", the "Cave of Treasures" and the "Conflict of Adam and Eve with Satan", as one of 12 regional kings in Abraham's time said to have built the city of Jerusalem for Melchizedek.
Other people with this name.
Apart from the king (or kings) of Gerar, the Bible also records this name for:
Other literary references include:

</doc>
<doc id="2099" url="http://en.wikipedia.org/wiki?curid=2099" title="Andrew Tridgell">
Andrew Tridgell

Andrew "Tridge" Tridgell (born 28 February 1967) is an Australian computer programmer best known as the author of and contributor to the Samba file server, and co-inventor of the rsync algorithm.
He is known for his analysis of complex proprietary protocols and algorithms, to allow compatible free and open source software implementations.
Projects.
Tridgell was a major developer of the Samba software, analysing the Server Message Block protocol used for workgroup and network file sharing by Microsoft Windows products. He developed the talloc hierarchical memory allocator, originally as part of Samba.
For his PhD thesis, he co-developed rsync, including the rsync algorithm, a highly efficient file transfer and synchronisation tool. He also was the original author of rzip, which uses a similar algorithm to rsync. He developed spamsum, based on the same locality-sensitive hashing algorithms.
He is the author of , a reinforcement-learning based chess engine.
Tridgell was also a leader in hacking the TiVo to make it work in Australia, which uses the PAL video format.
In April 2005, Tridgell tried to produce free software (now known as SourcePuller) that interoperated with the BitKeeper source code repository. This was cited as the reason that BitMover revoked a license allowing Linux developers free use of their BitKeeper product. Linus Torvalds, the creator of the Linux kernel, and Tridgell were thus involved in a public debate about the events, in which Tridgell stated that, not having bought or owned BitKeeper – and thus having never agreed to its license – he couldn't violate it, and was merely analysing the protocol ethically, as he had done with Samba. Tridgell's involvement in the project resulted in Linus accusing him of playing dirty tricks with BitKeeper. Tridgell claimed his analysis started with simply telneting to a BitKeeper server and typing codice_1.
In 2011 Tridgell got involved with the software development of ArduPilot Mega, an open source Arduino-based UAV controller board, working on an entry for the UAV Challenge Outback Rescue.
Academic achievements.
Attending Barker College Hornsby, NSW, Tridgell completed his Higher School Certificate in 1984. Tridgell completed a degree with majors in applied mathematics and physics at the University of Sydney in 1988, before moving to Canberra to complete an Honours degree at the Australian National University, in which he received first class honours in theoretical physics.
Tridgell completed a PhD at the Computer Sciences Laboratory of the Australian National University. His original doctorate work was in the area of speech recognition but was never completed. His submitted thesis 'Efficient Algorithms for Sorting and Synchronization' was based on his work on the rsync algorithm.
Employment.
Tridgell started his career working for Efam Resources from 1987 to 1988, designing computer models of financial markets. His work led to a product named The Options Analyst, which he marketed and sold for five years.
From 1988 to 1989, Tridgell worked as a software developer for a company named Sonartech Pty Ltd (now Sonartech Atlas), which developed sonar technologies for Australian submarines. He worked on passive sonar technology.
Between 1989 and 1990, Tridgell was employed at the Research School of Biological Sciences in the Australian National University, making computer models of physical and biological events and environments such as bushfire spread and population dynamics.
From 1991 to 1999, Tridgell held various other positions at the Australian National University, such as UNIX administration, satellite control, and supercomputer research. During this period he was seconded to the Cooperative Research Centre for Advanced Computational Systems, where he headed the PIOuS (Parallel Input/Output System) project—later HiDIOS (High-performance Distributed Input/Output System)—for parallel file systems on the Fujitsu AP1000 and AP+ supercomputers. Tridgell also went on to lecture, first as an associate lecturer, and then as a casual lecturer, in the university's Computer Science division. He remains a Visiting Fellow of the University.
In mid-1999, Tridgell joined the LinuxCare company's office in Canberra as their first Australian employee. He helped to assemble 14 staff for a research and development team known as OzLabs. Linux and open-source companies were quite a new concept at this stage. Tridgell was made a research fellow of LinuxCare in 2000.
In March 2001, Tridgell joined VA Linux Systems. He worked in the network attached storage division for VA Linux Systems, making enhancements to Samba and the Linux kernel to provide enhanced performance for their network-attached storage device range.
Tridgell continued his work with network-attached storage technologies when he joined Quantum Corporation as a Senior Engineer in the Storage Systems Group. His role once again involved developing functionality and efficiency modifications into Samba to enhance Quantum's GuardianOS-powered Snap Server network-attached storage device. One of the features that he added to Samba at this time was support for Microsoft's Active Directory technology, a new authentication system introduced with Microsoft's Windows 2000 Server product range.
In 2004, Tridgell was employed by IBM working remotely for the Almaden Research Center. In January 2005, he joined the OSDL on a one-year fellowship; he then returned to IBM.
Every year since 2009 Tridgell (with Bob Edwards) has taught a course titled at the Australian National University. This course is running for the fifth time in 2013.

</doc>
<doc id="2100" url="http://en.wikipedia.org/wiki?curid=2100" title="Applesoft BASIC">
Applesoft BASIC

Applesoft BASIC was a dialect of Microsoft BASIC, developed by Marc McDonald and Ric Weiland, supplied with the Apple II series of computers. It superseded Integer BASIC and was the BASIC in ROM in all Apple II series computers after the original Apple II model. It was also referred to as FP (from "floating point") because of the Disk Operating System (DOS) command used to invoke it, instead of INT for Integer BASIC. Applesoft BASIC was supplied by Microsoft and its name is derived from the names of both Apple and Microsoft. Apple employees, including Randy Wigginton, adapted Microsoft's interpreter for the Apple II and added several features. The first version of Applesoft was released in 1977 only on cassette tape and lacked proper support for high-resolution graphics. Applesoft II, which was made available on cassette and disk and in the ROM of the Apple II Plus and subsequent models, was released in 1978. It is this latter version, which has some syntax differences from the first as well as support for the Apple II high-resolution graphics modes, that most people mean by the term "Applesoft."
Background.
When Steve Wozniak wrote Integer BASIC for the Apple II, he did not implement support for floating point math because he was primarily interested in writing games, a task for which integers alone were sufficient. In 1976, Microsoft had developed a BASIC interpreter for the newly released 6502, but no production computer that used the microprocessor. Upon learning that Apple had a 6502 machine, Microsoft asked if the company were interested in licensing BASIC, but Steve Jobs replied that Apple already had one. The Apple II was unveiled to the public at the West Coast Consumer Electronics Expo in April 1977 and became available for sale in June. As Apple began to get buyer feedback, one of the most common complaints about the computer was BASIC's lack of floating-point capability. Integer BASIC was limited to whole numbers between -32767 and 32767 and caused problems for users attempting to write business applications with it. As Wozniak, the only person who understood Integer BASIC well enough to add floating point features, was busy with the Disk II drive and controller and with Apple DOS, Apple turned to Microsoft.
Apple reportedly obtained an eight-year license for Applesoft BASIC from Microsoft for a flat fee of $21,000, renewing it in 1985 through an arrangement that gave Microsoft the rights and source code for Apple's Macintosh version of BASIC. Applesoft was designed to be backwards-compatible with Integer BASIC and used the core of Microsoft's 6502 BASIC implementation, which included using the GET command for detecting key presses and not requiring any spaces on program lines. While Applesoft was slower than Integer BASIC, it had many features that the older BASIC lacked:
Conversely, Applesoft lacked the codice_9 (remainder) operator that had been present in Integer BASIC.
Speed issues, features.
Whereas Wozniak originally referred to his Integer BASIC as "Game BASIC," having written it so he could write a Breakout clone for his new computer, few action games were written in Applesoft BASIC for several reasons:
Other language features:
Early evolution.
The original Applesoft, stored in RAM as documented in its Reference Manual of November 1977, had smaller interpreter code than the later Applesoft II, occupying 8½ kb of memory, instead of the 10 kb used by the later Applesoft II. Consequently, it lacked a number of command features developed for the later, mainstream version:
as well as several the later version would have, that had already been present in Apple's Integer BASIC:
In addition, its low-resolution graphics commands had different names from their Integer BASIC/Applesoft II counterparts. All command names were of the form PLTx such that GR, COLOR=, PLOT, HLIN and VLIN were called PLTG, PLTC, PLTP, PLTH, and PLTV, respectively. The command for returning to text mode, known as TEXT in other versions, was simply TEX, and carried the proviso that it had to be the last statement in a program line.
The USR() function was also defined differently, serving as a stand-in for the absent CALL command. Its argument was not for passing a numerical value to the machine-language routine, but was instead the call-address of the routine itself; there was no "hook" to pre-define the address. All of several examples in the manual used the function only to access "system monitor ROM" routines, or short user-routines to manipulate the ROM routines. No mention was made of any code to calculate the value returned by the function itself; the function was always shown being assigned to "dummy" variables, which, without action to set a value by user-code, would just receive a meaningless value handed back to them. Even accessed ROM routines that returned values (in examples, those that provided the service of PDL() and SCRN() functions) merely had their values stored, by user-routines, in locations that were separately PEEKed in a subsequent statement.
Unlike in Integer BASIC and Applesoft II, the Boolean operators AND, OR and NOT performed bitwise operations on 16-bit integer values. If they were given values outside that range, an error resulted.
The terms OUT and PLT (and the aforementioned IN) appeared in the list of reserved words, but were not explained anywhere in the manual.
Sample code.
Hello World in Applesoft BASIC could be entered as the following:
 10 TEXT:HOME
 20 ?"HELLO WORLD"
Multiple commands could be included on the same line of code if separated by a colon (codice_18). The codice_19 can be used in Applesoft BASIC (and almost all versions of Microsoft BASIC) as a shortcut for "PRINT", though spelling out the word is not only acceptable but canonical—Applesoft converted "?" in entered programs to the same token as "PRINT" (thus no memory is actually saved by using "?"), thus either would appear as "PRINT" when a program was listed. The program above would appear in a codice_20 command as:
 10 TEXT : HOME
 20 PRINT "HELLO WORLD"
"This article includes text from , licensed under GFDL."
When Applesoft II BASIC was initially released in mid-1978, it came on cassette tape and could be loaded into memory via the Apple II's machine language monitor. When the enhanced Apple II+ replaced the original II in 1979, Applesoft was now included in ROM and automatically started on power-up if no bootable floppy disk was present. Conversely, Integer BASIC was now removed from ROM and turned into an executable file on the DOS 3.3 disk.
BASIC for the Apple ///.
Microsoft and Apple each developed their own versions of BASIC for the Apple /// computer. Apple /// Microsoft BASIC was designed to run on the CP/M platform available for the Apple ///. Apple Business BASIC, meanwhile, shipped with the Apple ///. Donn Denman ported Applesoft BASIC to SOS and reworked it to take advantage of the extended memory of the Apple ///.
Both languages introduced a number of new or improved features over Applesoft II, some of the same features as each other, and some unique to each. Both languages replaced Applesoft II's single-precision floating-point variables using 5-byte storage with the somewhat-reduced-pecision 4-byte variables, while also adding a larger numerical format. Apple /// Microsoft BASIC provided double-precision floating-point variables, taking 8 bytes of storage, while Apple Business BASIC offered an extra-long integer type, also taking 8 bytes for storage. Both languages also retained 2-byte integers, and maximum 255-character strings.
Other new features common to both languages included:
Differences of the same features:
Features specific to each language are described separately below.
Apple /// Microsoft BASIC additional new features.
There was no support for graphics provided within the language, nor for reading analog controls or buttons; nor was there a means of defining the "active window" of the text screen.
Apple Business BASIC additional new features.
Apple Business BASIC eliminated all references to absolute memory addresses. Thus, the POKE command and PEEK() function were removed from the language, and new features replaced the CALL statement and USR() function. Functionality of certain features in Applesoft that had been achieved with various PEEK and POKE locations was now provided by:
External binary subroutines and functions were now loaded into memory by a single INVOKE disk-command that loaded separately-assembled code modules, listing the names of all files to be used. A PERFORM statement would then be used to call an INVOKEd procedure by name, with an argument-list. INVOKEd functions would be referenced in expressions by EXFN. (floating-point) or EXFN%. (integer), with the function name appended, plus the argument-list for the function.
Graphics were supported with an INVOKEd module, with features including displaying text within graphics in various fonts, within four different graphics modes available on the Apple ///, including the precursor of Apple IIe "double-high-resolution" mode.

</doc>
<doc id="2101" url="http://en.wikipedia.org/wiki?curid=2101" title="Asterix">
Asterix

Asterix or The Adventures of Asterix (, ) is a series of French comics written by René Goscinny and illustrated by Albert Uderzo (Uderzo took over the writing after the death of Goscinny in 1977). The series first appeared in the Franco-Belgian comics magazine "Pilote" on 29 October 1959. As of 2013, 35 volumes have been released.
The series follows the exploits of a village of indomitable Gauls as they resist Roman occupation. They do so by means of a magic potion, brewed by their druid called Getafix in the English translations, which gives the recipient superhuman strength. The protagonist, the titular character Asterix, along with his friend Obelix have various adventures. The "ix" ending of both names (as well as all the other pseudo-Gaulish "ix" names in the series) "alludes" to the "rix" suffix (meaning "king") present in the names of many real Gaulish chieftains such as Vercingetorix, Orgetorix, and Dumnorix. Many of the stories have them travel to foreign countries, though others are set in and around their village. For much of the history of the series (Volumes 4 through 29), settings in Gaul and abroad alternated, with even-numbered volumes set abroad and odd-numbered volumes set in Gaul, mostly in the village.
The Asterix series is one of the most popular Franco-Belgian comics in the world, with the series being translated into over 100 languages, and it is popular in most European countries.
The success of the series has led to the adaptation of several books into 12 films: eight animated, and four live action. There have also been a number of games based on the characters, and a theme park near Paris, Parc Astérix.. To date, 325 million copies of 34 Asterix books have been sold worldwide, making co-creators René Goscinny and Albert Uderzo France's bestselling authors abroad.
History.
Prior to creating the Asterix series, Goscinny and Uderzo had previously had success with their series "Oumpah-pah", which was published in "Tintin" magazine.
"Astérix" was originally serialised in "Pilote" magazine, in the very first issue published on 29 October 1959. In 1961 the first book was put together, titled "Asterix the Gaul". From then on, books were released generally on a yearly basis. Their success was exponential; the first book sold 6,000 copies in its year of publication; a year later, the second sold 20,000. In 1963, the third sold 40,000; the fourth, released in 1964, sold 150,000. A year later, the fifth sold 300,000; 1966's "Asterix and the Big Fight" sold 400,000 upon initial publication. The ninth Asterix volume, when first released in 1967, sold 1.2 million copies in two days.
Uderzo's first sketches portrayed Asterix as a huge and strong traditional Gaulish warrior. But Goscinny had a different picture in his mind. He visualized Asterix as a shrewd small sized warrior who would prefer intelligence over strength. However, Uderzo felt that the small sized hero needed a strong but dim companion to which Goscinny agreed. Hence, Obelix was born. Despite the growing popularity of Asterix with the readers, the financial backing for Pilote ceased. Pilote was taken over by Georges Dargaud.
When Goscinny died in 1977, Uderzo continued the series alone on the demand of the readers who implored him to continue. He continued the series but on a less frequent basis. Most critics and fans of the series prefer Goscinny's albums. Uderzo created his own publishing company, Les Editions Albert-René, which published every album drawn and written by Uderzo alone since then. However, Dargaud, the initial publisher of the series, kept the publishing rights on the 24 first albums made by both Uderzo and Goscinny. In 1990, the Uderzo and Goscinny families decided to sue Dargaud to take over the rights. In 1998, after a long trial, Dargaud lost the rights to publish and sell the albums. Uderzo decided to sell these rights to Hachette instead of Albert-René, but the publishing rights on new albums were still owned by Albert Uderzo (40%), Sylvie Uderzo (20%) and Anne Goscinny (40%).
Although Uderzo declared he did not want anyone to continue the series after his death, which is similar to the request Hergé made regarding his "The Adventures of Tintin", his attitude changed and in December 2008 he sold his stake to Hachette, which took over the company and now owns the rights.
In a letter published in the French newspaper "Le Monde" in 2009, Uderzo's daughter, Sylvie, attacked her father's decision to sell the family publishing firm and the rights to produce new "Astérix" adventures after his death. She is reported as saying "...the co-creator of "Astérix", France’s comic strip hero, has betrayed the Gaulish warrior to the modern-day Romans – the men of industry and finance”. However, René Goscinny's daughter Anne also gave her agreement to the continuation of the series and sold her rights at the same time. She is reported to have said that "Asterix has already had two lives: one during my father's lifetime and one after it. Why not a third?". A few months later, Uderzo appointed three illustrators, who had been his assistants for many years, to continue the series. In 2011, Uderzo announced that a new Asterix album was due out in 2013, with Jean-Yves Ferri writing the story and Frédéric Mébarki drawing it. A year later, in 2012, the publisher Albert-René announced that Frédéric Mébarki had withdrawn from drawing the new album, due to the pressure he felt in following in the steps of Uderzo. Comic artist Didier Conrad was officially announced to take over drawing duties from Mébarki, with the due date of the new album in 2013 unchanged.
List of titles.
Numbers 1–24, 32 and 34 are by Goscinny and Uderzo. Numbers 25–31 and 33 are by Uderzo alone. Years stated are for their initial release. Number 35 is by Jean-Yves Ferri and 
Didier Conrad
"Asterix Conquers Rome" is a comics adaptation of the animated film "The Twelve Tasks of Asterix". It was released in 1976, and was the 23rd volume to be published, but it has been rarely reprinted and is not considered to be canonical to the series. The only English translation ever to be published were in the "Asterix Annual 1980" and as a standalone volume in 1984.
In 2007, Les Editions Albert René released a tribute volume titled "Astérix et ses Amis", a 60-page volume of one-to-four-page short stories. It was a tribute to Albert Uderzo on his 80th birthday by 34 European cartoonists. The volume was translated into nine languages, but has not been translated into English.
Synopsis and characters.
The main setting for the series is an unnamed coastal village in Armorica (present-day Brittany), a province of Gaul (modern France), in the year 50 BC. Julius Caesar has conquered nearly all of Gaul for the Roman Republic. The little Armorican village, however, has held out because the villagers can gain temporary superhuman strength by drinking a magic potion brewed by the local village druid, Getafix. His chief is Vitalstatistix.
The main protagonist and hero of the village is Asterix, who, because of his shrewdness, is usually entrusted with the most important affairs of the village. He is aided in his adventures by his rather fat and unintelligent friend, Obelix, who, because he fell into the druid's cauldron of the potion as a baby, has permanent superhuman strength. Obelix is usually accompanied by Dogmatix, his little dog. (Except for Asterix and Obelix, the names of the characters change with the language. For example, Obelix's dog's name is "Dogmatix" in English, but "Idéfix" in the original French edition.)
Asterix and Obelix (and sometimes other members of the village) go on various adventures both within the village and in far away lands. Places visited in the series include parts of Gaul (Lutetia, Corsica etc.), neighbouring nations (Belgium, Spain, Britain, Germany etc.), and far away lands (North America, Middle East, India etc.).
The series employs science-fiction and fantasy elements in the more recent books; for instance, the use of extraterrestrials in "Asterix and the Falling Sky" and the city of Atlantis in "Asterix and Obelix All at Sea".
Humour.
The humour encountered in the "Asterix" comics is often centering on puns, caricatures, and tongue-in-cheek stereotypes of contemporary European nations and French regions. Much of the humour in the initial Asterix books was French-specific, which delayed the translation of the books into other languages for fear of losing the jokes and the spirit of the story. Some translations have actually added local humour: In the Italian translation, the Roman legionaries are made to speak in 20th century Roman dialect and Obelix's famous "Ils sont fous ces romains" ("These Romans are crazy") is translated as "Sono pazzi questi romani", alluding to the Roman abbreviation "SPQR". In another example: Hiccups are written onomatopoeically in French as "hips," but in English as "hic," allowing Roman legionaries in at least one of the English translations to decline their hiccups in Latin ("hic, haec, hoc"). The newer albums share a more universal humour, both written and visual.
In spite of (or perhaps because of) this stereotyping, and notwithstanding some alleged streaks of French chauvinism, the humour has been very well received by European and Francophone cultures around the world.
Character names.
All the fictional characters in Asterix have names which are puns on their roles or personalities. Certain rules are followed (most of the time) such as Gauls (and their neighbours) having an 'ix' suffix for the males and ending in 'a' for the females, for example, Chief Vitalstatistix (so called due to his portly stature) and his wife Impedimenta (often at odds with the chief). The male Roman names end in 'us', echoing Latin nominitive male singular form, as in Gluteus Maximus, a muscle-bound athlete whose name is literally the butt of the joke. Other nationalities are treated to Pidgin translations from their language, like 'Huevos y Bacon', a Spanish chieftain (whose name (meaning Eggs and Bacon) is guidebook Spanish for tourists) or literary and other popular media references, like Doubleosix (a reference to James Bond's codename 007).
Most of these jokes, and hence the names of the characters, are specific to the translation, for example, the druid Getafix is Panoramix in the original French and Miraculix in German.
Translations.
The 35 volumes have been translated into more than 100 languages and dialects. Besides the original French language, most albums are available in Estonian, English, Czech, Dutch, German, Galician, Danish, Icelandic, Norwegian, Swedish, Finnish, Spanish, Catalan, Basque, Portuguese, Brazilian Portuguese, Italian, modern Greek, Hungarian, Polish, Romanian, Turkish, Slovene, Bulgarian, Serbian, Croatian, Latvian, Welsh as well as Latin.
Some albums have also been translated into languages such as Esperanto, Scottish Gaelic, Indonesian, Persian, Mandarin, Korean, Japanese, Bengali, Afrikaans, Arabic, Hindi, Hebrew, Frisian, Romansch, Vietnamese, Sinhalese and Ancient Greek.
In France, Finland, and especially in Germany, several volumes were translated into a variety of regional languages and dialects, such as Alsatian, Breton, Chtimi (Picard) and Corsican in France, Bavarian, Swabian and Low German in Germany, and Savo, Karelia, Rauma and Helsinki slang dialects in Finland. Also, in Portugal, a special edition of the first volume, Asterix the Gaul, was translated into local language Mirandese. In Greece, a number of volumes have appeared in the Cretan Greek, Cypriot Greek and Pontic Greek dialects. In the Italian version, while the Gauls speak standard Italian, the legionaries speak in the Romanesque dialect. In former Yugoslavia, "Forum" publishing house translated Corsican in "Asterix in Corsica" into Montenegrin dialect of Serbo-Croatian (today called Montenegrin language).
In the Netherlands several volumes were translated into Frisian, a language related to Old English spoken in the province of Friesland. Also in the Netherlands two volumes were translated into Limburgish, a regional language spoken not only in Dutch Limburg but also in Belgian Limburg and North Rhine-Westphalia, Germany. Hungarian-language books have been issued in Yugoslavia for the Hungarian minority living in Serbia. Although not a fully autonomic dialect, it slightly differs from the language of the books issued in Hungary. In Sri Lanka, the cartoon series was adapted into Sinhala ("Singhalese") as Sura Pappa, the only Sri Lankan translation of a foreign cartoon that managed to keep the spirit of the original series intact.
Most volumes have been translated into Latin and Ancient Greek with accompanying teachers' guides as a way of teaching these ancient languages.
English translation.
The translation of the books into English has been done by Derek Hockridge and Anthea Bell, and their English language rendition has been widely praised for maintaining the spirit and humour of the original French version.
Adaptations.
The series has been adapted into various media.
Films.
Various motion pictures based upon the series have been made.
Games.
Many gamebooks, boardgames and video games are based upon the Asterix series. In particular, many video games were released by various computer game publishers.
Theme park.
Parc Astérix, a theme park 22 miles north of Paris, based upon the series, was opened in 1989. It is one of the most visited sites in France, with around 1.6 million visitors per year.

</doc>
<doc id="2102" url="http://en.wikipedia.org/wiki?curid=2102" title="Arizona Cardinals">
Arizona Cardinals

The Arizona Cardinals are a professional American football team based in Glendale, Arizona. They currently are members of the West division of the National Football Conference (NFC) in the National Football League (NFL). The Cardinals were founded in 1898, and are the oldest continuously run professional American football club in the United States.
The team was established in Chicago in 1898 and was a charter member of the NFL in . Along with the Chicago Bears, the club is one of two NFL charter member franchises still in operation since the league's founding. (The Green Bay Packers were an independent team until they joined the NFL in 1921). The club then moved to St. Louis, Missouri in and played in that city through (sometimes referred to as the "Football Cardinals" and/or the "Big Red" to avoid confusion with the Major League Baseball St. Louis Cardinals). Other less commonly used nicknames were the "Gridbirds" (used only by a local newspaper columnist) or "Cardiac Cards" (used only to refer to the 1975 team). Before the 1988 NFL season, the team moved to Tempe, Arizona, a college suburb east of Phoenix, and played their home games for the next 18 years at Arizona State University's Sun Devil Stadium. In , the club began playing all home games at the newly constructed University of Phoenix Stadium in the northwestern suburb of Glendale, although the team's training facility is in Tempe.
The franchise has two NFL championships, both while it was based in Chicago. The first occurred in , but is the subject of controversy, with supporters of the Pottsville Maroons believing that Pottsville should have gotten the title. Their second title, and the first to be received through a championship game, came in , two decades before the first Super Bowl game was played.
In the six-plus decades since winning the championship in 1947, the team suffered many losing seasons, and currently hold the league's longest active championship drought. They have been to the playoffs six times and have won six playoff games, three of which were victories during their run in the 2008–09 NFL Playoffs. During that season, they won their only NFC Championship Game since the 1970 AFL-NFL Merger, and reached Super Bowl XLIII. The team has also won four division titles (, , , and ) since their 1947–1948 NFL championship game appearances.
In 2012 the Cardinals became the first NFL franchise to lose 700 games since its inception. The franchise's all-time mark at the conclusion of the 2013 season is 511–716–39.
From 1988 through 2012 (except 2005, when they trained in Prescott), the Cardinals conducted their annual summer training camp at Northern Arizona University in Flagstaff. The Cardinals moved their training camp to University of Phoenix Stadium in 2013.
Franchise history.
Logo and uniforms.
The team has worn cardinal red jerseys since Chris O'Brien bought them for the club in 1898. For most of their history, the Cardinals have used the same basic uniform design of white helmets, white pants with red stripes on the sides, and either red or white jerseys.
Starting in , the team had a logo of a cardinal bird perched on the stitches of a football. However, the club did not attach a logo to their helmets until they debuted a cardinal-head logo in , the year the franchise moved from Chicago to St. Louis.
During their 28 years in St. Louis, the Cardinals frequently wore white at home, especially for games vs. the Dallas Cowboys, hoping to bring out the "blue jersey jinx" which supposedly follows the Cowboys. The Cardinals wore white at home at least twice in every season between 1964 and 1981, and for every home game in 1964, 1965 and 1978. They wore white for their 1982 and 1983 home games vs. Dallas, but not at all from 1984 through 1987.
The Cardinals moved to Arizona in , and the flag of Arizona was added to the sleeves the following year. In , the team began wearing red pants with their white jerseys, as new coach Joe Bugel wanted to emulate his former employer, the Washington Redskins, who at the time wore burgundy pants with their white jerseys (the team has since changed to wearing gold pants with all their jerseys).
In , the Cardinals participated in the NFL's 75th anniversary throwback uniform program. The jerseys were similar to those of the 1920s Chicago Cardinals, with an interlocking "CC" logo and three stripes on each sleeve. The uniform numbers were relocated to the right chest. The pants were khaki to simulate the color and material used in that era. The Cardinals also stripped the logos from their helmets for the two games, at Cleveland (Sept. 18) and home vs. Pittsburgh (Oct. 30).
The Cardinal head on the helmet was repeated on the white jersey from 1988–1995. In 1996, the state flag of Arizona was moved higher on the sleeve after the Cardinal head was eliminated, and black was removed as an accent color, instead replaced with a blue to match the predominant color of the state flag.. In 2002, the Cardinals began to wear all-red and all-white combinations, and continued to do so through 2004, prior to the team's makeover.
In , the team unveiled its first major changes in a century. The cardinal-head logo was updated to look sleeker and meaner than its predecessor. Numerous fans had called the previous version a "parakeet". Black again became an accent color after an eight-year absence, while trim lines were added to the outside shoulders, sleeves, and sides of the jerseys and pants. Both the red and white jerseys have the option of red or white pants.
Hoping to break a six-game losing streak, the Cardinals wore the red pants for the first time on October 29, 2006, in a game at Lambeau Field against the Green Bay Packers. The Packers won 31–14, and the Cards headed into their bye week with a 1–7 mark. Following the bye week, the Cardinals came out in an all-red combination at home against the Dallas Cowboys and lost, 27–10. Arizona did not wear the red pants for the remainder of the season and won four of their last seven games. However, the following season, in , the Cardinals again wore their red pants for their final 3 home games. They wore red pants with white jerseys in games on the road at the Cincinnati Bengals and Seattle Seahawks. They paired red pants with red jerseys, the all-red combination, for home games against the Detroit Lions, San Francisco 49ers, Cleveland Browns, and St. Louis Rams. The red pants were not worn at all in , but they were used in home games vs. Seattle, Minnesota, and St. Louis in . The red pants were paired with the white road jersey for the first time in three years during a 2010 game at Carolina, but the white jersey/red pants combination was not used in 2011.
The Cardinals' first home game in Arizona, in 1988, saw them play in red jerseys. Thereafter, for the next 18 years in Arizona, the Cardinals, like a few other NFL teams in warm climates, wore their white jerseys at home during the first half of the season—forcing opponents to suffer in their darker jerseys during Arizona autumns that frequently see temperatures over 100 °F (38 °C). However, this tradition did not continue when the Cardinals moved from Sun Devil Stadium to University of Phoenix Stadium in 2006, as early-season games (and some home games late in the season) were played with the roof closed. With the temperature inside at a comfortable 70°F (21°C), the team opted to wear red jerseys at home full-time. The Cardinals wore white jerseys at home for the first time in University of Phoenix Stadium on August 29, 2008, in a preseason game against the Denver Broncos.
The Cardinals wore white at home for the first time in a regular season game at University of Phoenix Stadium against the Houston Texans on October 11, . In October 2009, the NFL recognized Breast Cancer Awareness Month, and players wore pink-accented items, including gloves, wristbands, and shoes. The team thought the pink accents looked better with white uniforms than with red.
On many occasions, when hosting the Dallas Cowboys, the Cardinals would wear white in order to force the Cowboys to don their "jinxed" blue jerseys. They have not done this since moving into University of Phoenix Stadium, however.
The season saw the Cardinals debut a new, alternate black jersey. Prior to its introduction, the Cardinals were the only NFL team without an alternate jersey or throwback kit, save for the NFL's 75th anniversary program in 1994.
Single-season records.
Points Scored: 427 ()
Passing
Rushing
Receiving
Returns
Kicking
Players of note.
Retired numbers.
Notes:
Pro Football Hall of Famers.
"italics" = played a portion of career with the Cardinals and enshrined representing another team<br>
Dierdorf, Smith, Wehrli and Wilson are members of the St. Louis Football Ring of Fame in the Edward Jones Dome, home of the St. Louis Rams.
Ring of Honor.
The Cardinals' Ring of Honor was started in to mark the opening of University of Phoenix Stadium. It honors former Cardinal greats from all eras of the franchise's history. Following is a list of inductees and the dates that they were inducted.
Radio and television.
The Cardinals' flagship radio station was KMVP, "ESPN Radio 860." KMVP assumed the broadcast rights in 2006 after many years on KSLX-FM and KDUS. Dave Pasch, Ron Wolfley, and Paul Calvisi handle the radio broadcast. Most preseason games are televised on KNXV, channel 15, the local ABC affiliate. Pasch and Wolfley are also the TV announcers.
On New Year's Day 2007, KMVP began a simulcast of KTAR, which switched to an all-sports format (the news/talk station became 92.3, KTAR-FM). For the 2007 season, KTAR was the official flagship station; however, some broadcasts were also heard on 92.3 FM because of conflicts with Arizona Diamondbacks baseball games on 620 AM.
Miscellaneous.
Due to Phoenix's high temperature and strong sunshine in early September, eight of the team's first 13 home openers in Arizona were held, at earliest, in week three. In 1990 and 1991, the Cardinals opened with three consecutive road games before finally coming home in week four. For the same reason, the team's home opener was a nationally-televised night game (two Monday Night Football games and 12 Sunday Night Football games) from 1988 to 2001. The team hosted ten straight home openers as Sunday Night Football games from 1989 to 1998.
Patrick Daniel "Pat" Tillman (November 6, 1976 – April 22, 2004) was an American football player who left his professional career while with the Arizona Cardinals and enlisted in the United States Army in June 2002 in the aftermath of the September 11 attacks. His service in Iraq and Afghanistan, and subsequent death, were the subject of much media attention.
One of the most popular players currently in Arizona cardinals uniform, Larry Fitzgerald, decided to restructure his contract in order to open up cap space for the team. This was extremely large news in the greater Phoenix area. The idea for the restructuring is to increase the chances of big signings in the off season for the Cardinals.

</doc>
<doc id="2103" url="http://en.wikipedia.org/wiki?curid=2103" title="Atlanta Falcons">
Atlanta Falcons

The Atlanta Falcons are a professional American football team based in Atlanta, Georgia. They are a member of the South Division of the National Football Conference (NFC) in the National Football League (NFL).
The Falcons joined the NFL in 1965 as an expansion team, after the NFL offered then-owner Rankin Smith a franchise to keep him from joining the rival American Football League (AFL). The AFL instead granted a franchise to Miami, Florida (the Miami Dolphins). They are tied with the Dolphins (who also began play in 1966) for being the oldest NFL franchise in the Deep South, and are the oldest NFC team in said region.
In their 48 years of existence, the Falcons have compiled a record of 316–414–6 with division championships in 1980, 1998, 2004, 2010 and 2012. Their only Super Bowl appearance was during the 1998 season in 
The Falcons play their home games at the Georgia Dome in downtown Atlanta, but construction began on New Atlanta Stadium in May 2014, with play beginning in the 2017 season. Their headquarters and practice facilities are located at a 50-acre site in Flowery Branch, Georgia.
Franchise history.
Professional football first came to Atlanta in 1962, when the American Football League staged two preseason contests, with one featuring the Denver Broncos vs. the Houston Oilers and the second pitting the Dallas Texans against the Oakland Raiders. Two years later, the AFL held another exhibition, this time with the New York Jets taking on the San Diego Chargers.
In 1965, after a stadium (Atlanta-Fulton County Stadium) was built, the city of Atlanta felt the time was right to start pursuing professional football. One independent group which had been active in NFL exhibition promotions in Atlanta applied for franchises in both the American Football League and the NFL, acting entirely on its own with no guarantee of stadium rights. Another group reported it had deposited earnest money for a team in the AFL.
With everyone running in different directions, some local businessmen worked out a deal and were awarded an AFL franchise on June 7, 1965, contingent upon acquiring exclusive stadium rights from city officials. NFL Commissioner Pete Rozelle, who had been moving slowly in Atlanta matters, was spurred by the AFL interest and headed on the next plane down to Atlanta to block the rival league's claim on the city of Atlanta. He forced the city to make a choice between the two leagues. By June 30, the city picked Rankin Smith and the NFL.
The Atlanta Falcons franchise began on June 30, 1965 when NFL Commissioner Pete Rozelle granted ownership to 41 year-old Rankin Smith Sr.. Smith an Executive Vice President of Life Insurance Company of Georgia at the time, paid $8.5 million the highest price in NFL history at the time 1965 for an NFL franchise. Former commissioner Pete Rozelle and Smith made the deal in about five minutes and the Atlanta Falcons brought the largest and most popular sport to the city of Atlanta. The Atlanta expansion franchise became the 15th NFL franchise, and they were awarded the first pick in the 1966 NFL Draft as well as the final pick in each of the first five rounds. The Falcons drafted All-American Linebacker Tommy Nobis from the University of Texas with the first pick of the draft, making him the first-ever Falcon. The league also held the 1966 NFL Expansion Draft six weeks later in which the Falcons selected unprotected players from existing franchises. Although the Falcons selected many good players in those drafts, they still were not able to win right away.
The Atlanta Falcons Football Club received its nickname on August 29, 1965. Miss Julia Elliott, a school teacher from Griffin, Georgia was singled out from many people who suggested "Falcons" as the Nickname for the new Georgia NFL franchise. She wrote: "the Falcon is proud and dignified, with great courage and fight. It never drops its prey. It is deadly and has a great sporting tradition."
Notable seasons.
1966 – 1977: The beginning.
The Falcons had their first season in , and their first preseason game on August 1, , losing to the Philadelphia Eagles. Under Head Coach Norb Hecker they lost their first nine regular-season games in 1966 and secured their first victory on the road against the New York Giants. The team finished the 1960s with only 12 wins. The Falcons had their first Monday Night Football game in Atlanta during the 1970 season. The 1971 season was their first with a winning record.
1978 – 1980: The playoffs.
In the 1978 season, the Falcons qualified for the playoffs for the first time and won the Wild Card game against the Philadelphia Eagles 14–13. The following week, they lost to the Dallas Cowboys 27–20 in the Divisional Playoffs.
In 1980, after a nine-game winning streak, the Falcons posted a franchise then-best record of 12–4 and captured their first NFC West division title. The next week, their dream season ended at home with a loss to the Cowboys 30–27 in the divisional playoffs. In the strike-shortened 1982 season, the Falcons made the playoffs but lost to the Minnesota Vikings, 30–24. Falcons coach Leeman Bennett was fired after the loss.
1989.
In 1989, the Falcons drafted CB Deion Sanders in the first round, who helped them for the next four years, setting many records for the franchise. "Neon Deion" (a.k.a. "Prime Time") had a flashy appeal and helped bring media attention to one of the league's most anonymous franchises. Sanders was also famous for playing on major league baseball teams (the New York Yankees and the Atlanta Braves) while simultaneously playing in the NFL.
1991 – 1992.
The Falcons' 1991 season ended in a divisional playoff loss to the Washington Redskins. In 1991, the Falcons drafted Brett Favre as the thirty-third overall pick. During his rookie season, he played in two games where he amassed a record of 5 passing attempts with 0 receptions and 2 interceptions. The following February, Favre was traded to the Green Bay Packers. 
In 1992, the Atlanta Falcons opened a new chapter in their history moving into the newly constructed Georgia Dome.
1997 – 2000: The Dan Reeves Era.
In 1998, under recently acquired head coach Dan Reeves, quarterback Chris Chandler and running back Jamal Anderson the "Dirty Bird" Falcons had their greatest season to date. On November 8, they beat the New England Patriots 41–10, ending a streak of 22 losses at cold-weather sites. The team finished with a franchise-best 14–2 regular season record and the NFC West division championship. On January 18, 1999, the Falcons upset the top-seeded Vikings at Minnesota in the NFC Championship Game 30–27, in an exciting overtime victory. However, in their first-ever Super Bowl appearance, they lost 34–19 to the defending champion Denver Broncos in Super Bowl XXXIII.
In the second game of the Falcons 1999 season, running back Jamal Anderson, who had been a key player in the Falcons' 1998 success, suffered a season-ending knee injury. The Falcons finished the season with a very disappointing 5–11 regular season record. In 2000, the Falcons suffered through another horrendous season finishing 4–12 and once again missing the playoffs.
2001 – 2006: The Michael Vick era.
In the 2001 NFL Draft, the Falcons orchestrated a trade with the San Diego Chargers, acquiring the first overall pick (which was used on quarterback Michael Vick) in exchange for wide receiver / return specialist Tim Dwight and the fifth overall pick (used on running back LaDainian Tomlinson).
The Falcons finished the 2001 season with a record of 7–9 and missed the playoffs. Jessie Tuggle retired following 14 seasons in Atlanta. On December 6, 2001, Arthur M. Blank reached a preliminary agreement with the Falcons’ Taylor Smith to purchase the team. In a special meeting prior to Super Bowl XXXVI in New Orleans on February 2, 2002, NFL owners voted unanimously to approve the purchase.
On March 19, 2003, the Falcons presented their new logo. During the 2003 preseason Michael Vick broke his leg and missed the first twelve games of the season. After losing 7 straight games, the decision was made to release head coach Dan Reeves. Wade Phillips acted as interim coach for the final 3 games. Although the Falcons won 3 of their last 4 games after the return of Michael Vick, they ended up with a dismal 5–11 record that year. In 2004, a new head coach, Jim L. Mora, was hired and Michael Vick returned for the full season. The Falcons went 11–5, winning their third division title and earning a first-round bye into the playoffs. In the divisional playoffs, the Falcons defeated the St. Louis Rams 47–17 in the Georgia Dome, advancing to the NFC Championship, which they lost to the Eagles 27–10.
The Falcons again fell short of achieving back-to-back winning seasons in , going 8–8. In , Michael Vick became the first quarterback in league history to rush for more than 1,000 yards in a season, with 1,039. After finishing the season 7–9, however, coach Jim Mora was dismissed and Bobby Petrino, the University of Louisville's football coach, replaced him. Before the 2007 season began, Vick was suspended indefinitely by the NFL after pleading guilty to charges involving dog fighting in the state of Virginia. On December 10, 2007, Vick received a 23-month prison sentence and was officially cut from the Atlanta roster.
2007: The lost year.
For the 2007 season, the Falcons were forced to start Joey Harrington at quarterback. On December 11, 13 games into his first NFL season as head coach, Bobby Petrino resigned without notice to coach at the University of Arkansas, leaving the beleaguered players only a note in the locker room. Secondary Coach Emmitt Thomas was named interim coach for the final three games of the season on December 12. The Falcons ended the year with a dismal 4–12 record.
2008 – present: Mike Smith/Matt Ryan era.
After the tumultuous and disappointing 2007 season, the Falcons made a number of moves, hiring a new General Manager and head coach, drafting a new starting quarterback, and signing a starting running back.
On January 13, 2008, the Falcons named former Patriots director of college football scouting Thomas Dimitroff General Manager. On January 23, Jacksonville Jaguars defensive coach and former linebackers coach for the 2000 Super Bowl champion Baltimore Ravens Mike Smith was named the Falcons' new head coach. Chargers back-up RB Michael Turner agreed to a 6-year deal worth $30 million on March 2. On April 26, Matt Ryan (quarterback from Boston College) was drafted third overall in the 2008 NFL Draft by the Falcons.
2008.
The Falcons finished the 2008 regular season with a record of 11–5, and the #5 seed in the playoffs. On December 21, 2008, Atlanta beat the Minnesota Vikings 24–17 to clinch a wild card spot, earning a trip to the playoffs for the first time since 2004. The Falcons would go on to lose in the wild-card round of the 2008 NFL playoffs to the eventual NFC champion Arizona Cardinals, 30–24.
Matt Ryan started all 16 games in his rookie season and was named the Associated Press Offensive Rookie of the Year. First-year head coach Mike Smith was named 2008 NFL Coach of the Year.
2009.
The Atlanta Falcons hold the record among all major American sports leagues for the longest streak of seasons without consecutive winning seasons, a streak that lasted from 1966–2008. Although they failed to make the playoffs in 2009, the streak ended when the team rallied to win their final three regular season games to record back-to-back winning seasons for the first time in franchise history. The Falcons defeated the Tampa Bay Buccaneers 20–10 in the final game of the season to improve their record to 9–7.
2010.
In 2010, with a regular season record of 13–3, their best regular season record since the 1998 Super Bowl season, the Falcons secured a third straight winning season, their fourth overall divisional title, and the top overall seed in the NFC playoffs; however, the Falcons were overpowered by the eventual Super Bowl XLV champion Green Bay Packers in the NFC Divisional Playoffs 48–21. The Falcons scored 414 points – third-most in franchise history in 2010. The Falcons 2010–2011 team sent an NFL-high and franchise-best nine players to the AFC-NFC Pro Bowl.
2011.
The Falcons made a surprise trade up with the Cleveland Browns in the 2011 NFL Draft to select Alabama wide receiver Julio Jones sixth overall. In exchange, the Falcons gave up their first-, second- and fourth-round draft picks in 2011, and their first and fourth draft picks in 2012. Jones, along with teammates Tony Gonzalez and Roddy White, have since been dubbed Atlanta's "Big Three" (based on their total number of reception yards). On August 30, 2011, Sports Illustrated senior writer Peter King, who correctly predicted the 2011 Super Bowl, made his predictions for the 2011 season and picked the Falcons to defeat the San Diego Chargers in the 2012 Super Bowl. The Falcons finished the season at 10–6, securing the fifth seed after a Week 17 beatdown of Tampa Bay in which the Falcons pulled their starters after leading 42–0 just twenty-three minutes into the game.
The Falcons then went on to play the New York Giants in a 2011 NFC Wild Card Game at Metlife Stadium in East Rutherford, New Jersey. The first half was a defensive struggle, with the first points coming off of a safety by the Falcons, giving Atlanta a 2–0 lead. In the 2nd quarter, though, Eli Manning connected with Hakeem Nicks for a short touchdown pass to make it 7–2 Giants heading into the 2nd half. Then the Giants took control, as Manning threw for two more TD passes to Mario Manningham and Nicks and the defense completed its shutout of the Falcons to give the New York Giants the win, 24–2, and the Falcons their third straight playoff loss with Matt Ryan and Mike Smith. After the season Defense Coordinator Brian VanGorder accepted a coaching job at Auburn University, and the offensive coordinator Mike Mularkey took the head coaching job in Jacksonville.
2012.
Atlanta exploded out of the gate, going a franchise best 8–0 and remaining the last unbeaten team in the NFL that year. Their hopes to get an undefeated season came to an end with a 27–31 loss to the New Orleans Saints. Julio Jones had a remarkable second year, grabbing ten touchdowns and 1,198 yards. The Falcons finished the season 13–3, and clinched the number one seed in the NFC playoffs.
The Falcons played the Seattle Seahawks in their first playoff game. Although they went down 28–27 with only 31 seconds left on the clock, Matt Ryan led the team to their first playoff victory, 30–28. It was the first playoff victory in the Mike Smith era.
The Atlanta Falcons then advanced to face the San Francisco 49ers. The Falcons seized control of the game early with a Matt Bryant field goal, a trio of Matt Ryan touchdown passes caught by Julio Jones and Tony Gonzalez coupled with outstanding defensive play. By the end of the half, the score was 24–14.The tides of the game began to shift in the second half as the 49ers rallied back with a pair of Frank Gore touchdown runs. Atlanta's offense attempted to reply but were ultimately shut down by the 49er defense. A few series later, late in the 4th quarter with little time remaining, Atlanta found themselves in a 4th and 7 situation at the 10-yard line. The Falcons needed just 10 more yards to secure victory and advance to their first Super Bowl berth in nearly 15 years. Matt Ryan fired a pass to Roddy White which was ultimately broken up by outside linebacker NaVorro Bowman, resulting in a 28–24 defeat.
2013.
Following the success of the previous season, the Falcons were an expected Super Bowl contender. However, injuries hampered the team's performance and the team finished the season 4-12. With that, the streak of consecutive winning seasons came to an end and Mike Smith had his first losing season as a head coach. Tony Gonzalez, in his final season in the NFL, was selected to the 2014 Pro Bowl as a starter representing Team Rice. Following the conclusion of the season, director of player personnel Les Snead departed the team to join the St. Louis Rams and Dave Caldwell, successor to general manager Thomas Dimitroff, left the team to join the Jacksonville Jaguars. Scott Pioli, former GM of the New England Patriots, was announced as the Falcons' new assistant GM. Mike Smith was given a one year extension on his contract as head coach. The Falcons had the 6th overall pick in the 2014 NFL Draft with which they selected Texas A&M Offensive tackle Jake Matthews.
New Atlanta Stadium.
In an effort to replace the aging Georgia Dome and potentially host a future Super Bowl, team owner Arthur Blank proposed a deal with the city of Atlanta to build a new state-of-the-art stadium not far from where the Georgia Dome is located. Blank will contribute $800 million and the city of Atlanta will contribute an additional $200 million via bonds backed by the city's hotel/motel tax towards the construction of a retractable roof stadium. Blank will contribute additional money for cost overruns if it is needed. The team will provide up to $50 million towards infrastructure costs that weren't included in the construction budget and to retire the remaining debt on the Georgia Dome. In addition, Blank's foundation and the city will each provide $15 million for development in surrounding neighborhoods. The total cost of the stadium is estimated to be $1 billion. In March 2013, the Atlanta City Council voted 11-4 in favor of the proposal. The new stadium is scheduled to be completed in time for the 2017 NFL season.
Logo and uniforms.
When the team debuted in 1966, the Falcons wore red helmets with a black falcon crest logo. In the center of the helmet was a center black stripe surrounded by 2 gold stripes and 2 white stripes. These colors represented the two college rival schools in the state of Georgia; rival schools Georgia Tech Yellow Jackets (White and Gold) and the Georgia Bulldogs (Red and Black) Although the gold was later taken out, the white remains to this day. They wore white pants and either black or white jerseys. At first, the falcon crest logo was also put on the jersey sleeves, but it was replaced by a red and white stripe pattern four years later. They switched from black to red jerseys in 1971, and the club began to wear silver pants in 1978.
A prototype white helmet was developed for the team prior to the 1974 season but was never worn.
In 1990, the uniform design changed to black helmets, silver pants, and either black or white jerseys. The numbers on the white jerseys were black, but were changed to red in 1997. (The red numerals could be seen on the away jerseys briefly in 1990.)
Both the logo and uniforms changed in 2003. The logo was redesigned with red and silver accents to depict a more powerful, aggressive falcon, which now more closely resembles the capital letter "F". Although the Falcons still wore black helmets, the new uniforms featured jerseys and pants with red trim down the sides. The uniform design consisted of either black or white jerseys, and either black or white pants. During that same year, a red alternate jersey with black trim was also introduced. The Falcons also started wearing black cleats with these uniforms.
In 2004, the red jerseys became the primary jerseys, and the black ones became the alternate, both worn with white pants. In select road games, the Falcons wear black pants with white jerseys. The Falcons wore an all-black combination for home games against their archrivals, the New Orleans Saints, winning the first two contests (24–21 in and 36–17 in ), but losing 31–13 in . The Falcons wore the all black combination against the New Orleans Saints for 4 straight seasons starting in 2004, With the last time being in 2007, losing 34–14. They wore the combination again in 2006, against the Tampa Bay Buccaneers in Week 2. The Falcons won that game, 14–3. The Falcons also wore their all-black uniform in 2007 against the New York Giants, and in 2008 against the Carolina Panthers and against the Tampa Bay Buccaneers (for the second time).
In the 1980s, the Falcons wore their white uniforms at home most of the time because of the heat. When the Falcons started playing in a dome, the team switched to their dark uniforms for home games but have worn their white uniforms at home a few times since switching to the dome. It was announced at the 2009 state of the franchise meeting that the Falcons would wear 1966 throwback uniforms for a couple games during the 2009 season. The Atlanta Falcons wore 1966 throwback jerseys for 2 home games in 2009 – against the Carolina Panthers on September 20 and against the Tampa Bay Buccaneers on November 29. The Falcons won both of those games. They donned the throwbacks again for 2 games in 2010, against Baltimore and San Francisco, winning both of those games as well.
Statistics.
Record vs. opponents.
Includes postseason records
Players.
Pro Football Hall of Famers.
Sanders and Humphrey are the only two players in the Hall of Fame that have been inducted based substantially on their service with the Falcons; however, three inductees played briefly and one coached for the Falcons during their careers:
"Ring of Honor".
The Atlanta Falcons organization does not officially retire jersey numbers; however in 2004, they began the "Ring of Honor" which honors specific players the same way as retiring numbers.
Coaching staff.
Head coaches.
In their history, the Atlanta Falcons have had 15 head coaches.
Radio and television.
As of 2011, the Falcons' radio flagship station is WSTR Star 94 FM, and WQXI 790 AM "The Zone", previously held since 2006 by WZGC 92.9 "Dave FM." Wes Durham, voice of the Georgia Tech Yellow Jackets and son of longtime North Carolina Tar Heels voice Woody Durham, is the Falcons' play-by-play announcer. 
Fox affiliate WAGA-TV aired most preseason games through the 2004 season. WAGA continues to have a relationship with the Falcons as their primary broadcaster of regular season games (serving in this capacity since the Falcons started play), which dates back to when WAGA was a CBS affiliate and the NFL/NFC games were on CBS. WATL aired most Falcons games in 1994, as WAGA did not switch to Fox until December 1994. In 2014, The CW affiliate WUPA became the official television station of the Falcons, gaining rights to its preseason games, which are produced by CBS Sports.
Atlanta Falcons fans are more prevalent in western North Carolina due to the fact the Carolina Panthers only existed since 1996. Historically, they can be found generally west of Interstate 26 from Asheville to Murphy. East of Interstate 26 is considered a neutral zone, but the majority are Carolina Panthers fans.
Radio Affiliates.
Atlana Falcon Radio Affiliates
Public interest initiatives.
A delegation from the Atlanta Falcons Cheerleaders, on January 26, 2009 traveled to the Guantánamo Bay detention camps, in Cuba, to sign autographs, and enhance the troops' morale.
While there, the cheerleaders toured the detention camps' hospital, and Camp IV, Camp V, & Camp VI.

</doc>
<doc id="2104" url="http://en.wikipedia.org/wiki?curid=2104" title="Ásatrú in the United States">
Ásatrú in the United States

 (from Icelandic for "faith/belief in the Æsir", pronounced , in Old Norse ) is a form of Germanic neopaganism which developed in the United States from the 1970s.
It focuses on historical Norse paganism of the Viking Age as described in the Eddas, but proponents also take a more inclusive approach, defining it as "Northern European Heathenry" not limited to a specific historical period.
Terminology.
' is an Icelandic (and equivalently Old Norse) term consisting of two parts. The first is "-", genitive of ', denoting one of the group of Norse gods called . The second part, "", means "faith, word of honour; religious faith, belief" (archaic English "troth" "loyalty, honesty, good faith"). Thus, Ásatrú means the "faith/belief in the Æsir". Even so, today, Stephen A. McNallen of the Asatru Folk Assembly maintains that Asatru means "belief in the gods", "those loyal to the Gods", or “those who believe in the Aesir and Vanir” as does Edred Wodanson (E. Max Hyatt, 1948 - January 21, 2010) of Wodan's Kindred and the Wodanesdag Press.However, in the past, and as early as 1982, McNallen defined Asatru as meaning, "faith of the Aesir". Why and when he decided to change his perspective of the meaning is unknown.
The term is the Old Norse/Icelandic translation of "", a neologism coined in the context of 19th century romantic nationalism, used by Edvard Grieg in his 1870 opera "Olaf Trygvason". The use of the term "Ásatrú" for Germanic heathenism preceding 19th century revivalist movements is therefore an anachronism.
' (plural '), the term used to identify those who practice Ásatrú, is a compound with ' (Old Norse ') "man". In English usage, the genitive "" "of Æsir faith" is often used on its own to denote adherents (both singular and plural).
Some adherents will use "Ásatrú" as synonymous with "Odinism", others will reject an equivalence between the two terms, while others use it synonymously, interchangeably, and also debunk those that have a conviction the two are completely separate. Some who use the term Odinism see no difference between the two terms, but as Odinism is historical established, other modern terms have met with limited success. In addition, some see it as synonymous with Wotanism and Wodenism also, while others object to this. Some put a curse on those that are folkish.
Differences from Scandinavian and German usage.
There are two main strains of contemporary Germanic Paganism known as "Ásatrú", originating near-simultaneously in Iceland ("", 1972) and the USA (Asatru Free Assembly, 1974). While the Scandinavian branch emphasizes polytheistic spirituality rooted in medieval and contemporary Scandinavian folklore, the American branch postulates a "native religion of the peoples of Northern Europe" reaching back into the paleolithic. In Germany, the term "Asatru" is used in the wider sense of Germanic neopaganism.
As "Ásatrú" implies a focus on polytheistic belief in the Æsir, usage of the term in Scandinavia has declined somewhat. In Scandinavia, "forn sed" / "forn siðr" "old custom", "Nordisk sed" "Nordic custom" or "hedensk sed" / "heiðinn siður" "heathen custom" are preferred. In both the Anglosphere and German-speaking Europe, the word Asatru is widely used interchangeably with other terms for Germanic Neopaganism.
There are notable differences of emphasis between "Ásatrú" as practiced in the USA and in Scandinavia. According to Strmiska and Sigurvinsson (2005), American Asatruar tend to prefer a more devotional form of worship and a more emotional conception of the Nordic gods than Scandinavian practitioners, reflecting the parallel tendency of highly emotional forms of Christianity prevalent in the United States.
Organizations.
Most organized Nordic Paganism in the United States occurs in numerous local Kindreds but there are three large national organizations. The largest is The Troth, followed by the Ásatrú Alliance, and the Ásatrú Folk Assembly.
The Troth, currently headed by Steve Abell, publishes the "Idunna" journal, which is the most widely distributed Asatru journal in publication. Yearly gatherings of The Troth, called "TrothMoot," usually draws attendance of around 50-75 people. The Troth held its 25th Anniversary Jubilee in 2012.
The Ásatrú Alliance is headed by Valgard Murray, and publishes the "Vor Tru" newsletter, and held its 25th annual "Althing" gathering in 2005.
The Ásatrú Folk Assembly, headed by Stephen McNallen, holds four major yearly events in addition to more local gatherings: A Midsummer event in California, a Freyfaxy celebration in the state of Washington every August, a Winter Nights festival in Pennsylvania, and an Ostara, or, springtime event in Florida. Attendance at these range from in excess of a hundred to around fifty.
A notable regional group is Jotun's Bane Kindred (JBK), headed by Mark Ludwig Stinson. Stinson promotes "regional heathenry" over "Internet heathenry" and formed an active network of "Midwest Tribes". If organized, it would be the largest organization in America. JBK's yearly event 'Lightning Across the Plains' regularly draws attendance of over 250.
History.
In the winter of 1971-1972, Stephen McNallen formed the Viking Brotherhood to honor the Norse deities and began publishing a newsletter titled The Runestone. The Viking Brotherhood received official recognition as a religious organization in August of 1972. The name was changed to the Asatru Free Assembly in 1976.
In 1986, the "folkish vs. universalist" dispute and the dispute over the stance of Ásatrú towards white supremacy escalated, resulting in the breakup of the "Asatru Free Assembly". The universalist branch reformed as The Troth, while the folkish branch became the Ásatrú Alliance (AA).
In 1994, McNallen formed a new organization, the Asatru Folk Assembly (AFA), which some refer to as "the new AFA".
In 1997, the Britain based Odinic Rite (OR) founded a US chapter (ORV).
In 2003 Volkshof Kindred was formed and was the first Asatru Church recognized in the state of Minnesota. They were a driving force in the midwest which resulted in the formation of several Midwest kindreds.
In the late 2000s, former Kansas City police sergeant Mark Stinson formed The Jotun's Bane Kindred (JBK).
The Ásatrú Alliance is the oldest surviving organization.
Beliefs and practice.
"Ásatrú" groups and the individual "Ásatrúarmenn" have no universal means of practice. Some general commonalities exist however, as outlined below:
Blót.
Many Ásatrú groups celebrate with "blóts". Historically, the blót was an event that focused on a communal sacrifice at various times of the year for a number of purposes. Families and extended family organizations would gather to participate in the communal event.
Modern blóts are celebrated several times during the year. Ásatrú communities (kindreds, hearths, mots) have different approaches to the frequency of blóts and their means of celebrating them.
Sumbel.
A central ritual of Ásatrú is the "sumbel", a drinking-ritual in which a drinking horn full of mead or ale is passed around and a series of toasts are made, usually to gods, ancestors, and/or heroes of the religion. The toasts vary by group, and some groups make a distinction between a "regular" sumbel and a "high" sumbel, which have different levels of formality, and different rules during toasting. Participants may also make boasts of their own deeds, or oaths or promises of future actions. Words spoken during the sumbel are considered carefully and any oaths made are considered sacrosanct, becoming part of the destiny of those assembled.
Goðar.
A "Goði" or "Gothi" (plural "goðar") is the historical Old Norse term for a priest and chieftain in Norse paganism. "Gyðja" signifies a priestess. Goði literally means "speaker for the gods", and is used to denote the priesthood or those who officiate over rituals in Ásatrú. Several groups, most notably the Troth have organized clergy programs. However, there is no universal standard for the Goðar amongst organizations, and the title is usually only significant to the particular group with whom they work.
Kindred.
In Germanic neopagan movements, a kindred is a local worship group and organizational unit. Other terms used are "hearth", "theod" (only within the Theodism), "blotgroup", "sippe", and other less popular ones such as "garth", "stead", "church", and others.
Kindreds are usually grassroots groups which may or may not be affiliated with a national organization such as the Asatru Alliance or The Troth rather than the Swedish Forn Sed Assembly or the Odinic Rite. A kindred not associated with any other group is known as an "independent kindred", which is more typical within the US than elsewhere.
Related movements.
Theodism.
"Theodism", or "Þéodisc Geléafa" (Old English: "tribal belief") is another form of Germanic neopaganism that developed in the United States contemporaneous with Asatru.
While there are some similarities between the two movements, Theodism derived its origins primarily as a reaction to Wicca. In 1971, Garman Lord and other practitioners of Gardnerian Wicca founded The Coven Witan of Anglo-Saxon Wicca. 
Theodism is focused on the lore, beliefs and social structure - particularly the concept of "thew" (Old English "þeaw") or "customary law" - of various specific Germanic tribes. The main distinction between Theodism and other modern manifestations of Germanic Neopaganism along with pre-Christian religions, the Theodish are also attempting to reconstruct aspects of pre-Christian Germanic social order (including sacral kingship). 
In general, Theodish religious festivities are referred to as 'fainings' (meaning 'celebration'). As a rule, there are two sorts of rituals; blót and symbel. Húsel is technically part of blót. Symbel is normally held after the feast, inasmuch as it is custom not to have food present.
Garman Lord formed the Witan Theod in Watertown, New York, in 1976. A few years later, the Moody Hill Theod emerged as an offshoot of the Witan Theod. In 1988 the Winland Rice was formed as an umbrella organization of Theodish groups. Gert McQueen, Elder and Redesman of the Ring of Troth, was successful in lobbying the U.S. Army Chaplain’s Corps to adopt guidelines for recognizing heathen religions and Theodish belief in particular.
The Winland Rice dissolved in 2002. Several groups that have continued to call themselves Theodish. Axenthof Thiad originated in the early 1990s as the Fresena Thiad and part of the Winland Rice. In 2005, Gerd Forsta Axenthoves changed the name to Axenthof Thiad. Eric Wodening founded Englatheod in July 2007, while Sweartfenn Theod was founded, by Jeffrey Runokivi, in December 2007. Both groups practice Anglo-Saxon Theodism, and have members that have belonged to both the Winland Rice and the Ealdriht. In New York, the New Normannii Reik of Theodish Belief was founded in 1997 and is led by Dan Halloran, but in 2009 many members split off and formed the Arfstoll Church of Theodish Belief, White Marsh Theod, and Álfröðull þjóð.
One famous follower of Theodism is New York City Councilman Daniel J. Halloran.
Politics and controversies.
Ásatrú organizations have memberships which span the entire political and spiritual spectrum. There is a history of political controversy within organized US Ásatrú, mostly surrounding the question of how to deal with such adherents as place themselves in a context of the far right and white supremacy, notably resulting in the fragmentation of the "Asatru Free Assembly" in 1986.
Externally, political activity on the part of Ásatrú organizations has surrounded campaigns against alleged religious discrimination, such as the call for the introduction of an Ásatrú "emblem of belief" by the United States Department of Veterans Affairs to parallel the Wiccan pentacle granted to the widow of Patrick Stewart in 2006. In May 2013 the "Hammer of Thor" was added to the list of United States Department of Veterans Affairs emblems for headstones and markers.
Folkish Ásatrú, Universalism and racialism.
Historically, the main dispute between the national organizations has generally centered on the interpretation of "Nordic heritage" as either something cultural, or as something genetic or racial. In the internal discourse within American Ásatrú, this cultural/racial divide has long been known as "universalist" vs. "folkish" Asatru. 
The Troth takes the "universalist" position, claiming "Asatru" as a synonym for "Northern European Heathenry" taken to comprise "many variations, names, and practices, including Theodism, Irminism, Odinism, and Anglo-Saxon Heathenry". In the UK, Germanic Neopaganism is more commonly known as Odinism or as "Heathenry". This is mostly a matter of terminology, and US Asatru may be equated with UK Odinism for practical purposes, as is evident in the short-lived International Asatru-Odinic Alliance of folkish Asatru/Odinist groups.
Some groups identifying as Ásatrú have been associated with neo-Nazi and "white power" movements. (See Wotanism for more details.)
This was notably an issue in the 1980s, when the "Asatru Free Assembly" disintegrated as a result of tensions between the folkish and the non-folkish factions.
Today, the three largest US American "Ásatrú" organizations have specifically denounced any association with racist groups. A dividing issue is whether a person is "Folkish", meaning that an emphasis on ancestry and ancestor worship is a part of their belief system.
Discrimination charges.
Inmates of the "Intensive Management Unit" at Washington State Penitentiary who are adherents of Ásatrú in 2001 were deprived of their Thor's Hammer medallions.
In 2007, a federal judge confirmed that Ásatrú adherents in US prisons have the right to possess a Thor’s Hammer pendant. An inmate sued the Virginia Department of Corrections after he was denied it while members of other religions were allowed their medallions.
In the Georgacarakos v. Watts case Peter N. Georgacarakos filed a pro se civil-rights complaint in the United States District Court for the District of Colorado against 19 prison officials for "interference with the free exercise of his Ásatrú religion" and "discrimination on the basis of his being Ásatrú".

</doc>
<doc id="2106" url="http://en.wikipedia.org/wiki?curid=2106" title="Ansible">
Ansible

An ansible is a fictional machine capable of instantaneous or superluminal communication. Typically it is depicted as a lunch-box-sized object with some combination of microphone, speaker, keyboard and display. It can send and receive messages to and from a corresponding device over any distance whatsoever with no delay. Ansibles occur as plot devices in science fiction literature.
Origin.
The word "ansible" was coined by Ursula K. Le Guin in her 1966 novel "Rocannon's World". Le Guin states that she derived the name from "answerable," as the device would allow its users to receive answers to their messages in a reasonable amount of time, even over interstellar distances. Her award-winning 1974 novel "The Dispossessed", a book in the Hainish Cycle, tells of the invention of the ansible.
Usage.
The name of the device has since been borrowed by authors such as Orson Scott Card, 
Vernor Vinge, Elizabeth Moon, Jason Jones, L.A. Graf, and Dan Simmons. It was also borrowed by Michael DeHaan to name his software project and company to manage computers.
Similar devices.
Similar devices are present in the works of numerous others, such as Frank Herbert and Philip Pullman, who called his a "lodestone resonator".
Anne McCaffrey's "Crystal Singer" series posited an instantaneous communication device powered by rare "Black Crystal" from the planet Ballybran. Black Crystals cut from the same mineral deposit could be "tuned" to sympathetically vibrate with each other instantly, even when separated by interstellar distances, allowing instantaneous telephone-like voice and data communication. Similarly, in Gregory Keyes' series "The Age of Unreason", "aetherschreibers" use two halves of a single "chime" to communicate, aided by scientific alchemy. While the speed of communication is important, so is the fact that the messages cannot be overheard except by listeners with a piece of the same original crystal.
Stephen R. Donaldson, in his Gap cycle, proposed a similar system, "Symbiotic Crystalline Resonance Transmission", clearly ansible-type technology but very difficult to produce and limited to text messages.
Some hard science fiction stories use small (possibly nano-sized) paired wormholes dedicated to communication by means of a laser which traverses the wormhole. In Robert L. Forward's novel "Timemaster", the wormhole is a living organism resembling a fourth-dimensional sea anemone, "stretched" to cover the distance between a spaceship and a satellite on the home planet.
Charles Stross's books "Singularity Sky" and "Iron Sunrise" make use of "causal channels" which use entangled particles for instantaneous two-way communication. The technique has drawbacks in that the entangled particles are expendable and the use of faster-than-light travel destroys the entanglement, so that one end of the channel must be transported below light speed. This makes them expensive and limits their usefulness somewhat.
In Richard K. Morgan's Takeshi Kovacs novels human colonies on distant planets maintain contact with earth and each other via "hyperspatial needlecast", a technology which moves information "...so close to instantaneously that scientists are still arguing about the terminology...".
One ansible-like device which predates Le Guin's is the "Dirac communicator" that features in several of the works of James Blish, notably his 1954 short story "Beep". As alluded to in the title, any active device received the sum of all transmitted messages in universal space-time, in a single pulse, so that demultiplexing yielded information about the past, present, and future.
In the story With Folded Hands (1947), by Jack Williamson, instant communication and power transfer through interstellar space is possible with something referred to as "rhodomagnetic waves".
Isaac Asimov solved the same communication problem with the "hyper-wave relay" in the "Foundation" series. Larry Niven later used the same term for the plot device used within his Known Space series of novels and short stories, notably in the "Ringworld" and associated Fleet of Worlds series.
In Ivan Yefremov's 1957 novel "Andromeda", a device for instant transfer of information and matter is made real by using "bipolar mathematics" to explore use of anti-gravitational shadow vectors through a zero field and the antispace, which enables them to make contact with the planet of Epsilon Tucanae.
Le Guin's ansible was said to communicate "instantaneously", but other authors have adopted the name for devices capable only of finite-speed communication, although still faster than light.
The "subspace radio", best known today from Star Trek and named for the method used in the series for achieving faster-than-light travel, was the most commonly used name for such a faster-than-light communicator in the science fiction of the 1930s to the 1950s.
In all the Stargate television series, characters are able to communicate instantaneously over long distances by transferring their consciousness into another person or being anywhere in the universe using "Ancient communication stones". It is not known how these stones operate, but the technology explained in the show usually revolves around wormholes for instant teleportation, faster-than-light, space-warping travel, and sometimes around quantum multiverses.
Jonathan Rosenberg, author/artist of the humorous science fiction webcomic "Scenes from a Multiverse", references an ansible powered by a quantum-entangled ferret in one of the comics.
In Avatar continuity, superluminal communication via a subtle control over the state of entangled particles is possible, but for practical purposes extremely slow and expensive: at a transmission rate of three bits of information per hour and a cost of $7,500 per bit, it is used for only the highest priority messages.
In the Doctor Who episode Nightmare in Silver a character references a broken ansible communicator.
In Le Guin's work.
In "The Word for World Is Forest", Le Guin explains that in order for communication to work with any pair of ansibles, at least one "must be on a large-mass body, the other can be anywhere in the cosmos."
In "The Left Hand of Darkness", the ansible 
Unlike McCaffrey's black crystal transceivers, Le Guin's ansibles are not mated pairs: it is possible for an ansible's coordinates to be set to any known location of a receiving ansible. Moreover, the ansibles Le Guin uses in her stories apparently have a very limited bandwidth which only allows for at most a few hundred characters of text to be communicated in any transaction of a dialog session. Instead of a microphone and speaker, Le Guin's ansibles are attached to a keyboard and small display to perform text messaging.
In Card's work.
Orson Scott Card's "Ender's Game" series uses the ansible as a plot device. "The official name is Philotic Parallax Instantaneous Communicator," explains Colonel Graff in "Ender's Game", "but somebody dredged the name "ansible" out of an old book somewhere."
Card's description of the ansible's functions in "Xenocide" involve a fictional subatomic particle, the philote. In the "Enderverse", the two quarks inside a pi meson can be separated by an arbitrary distance while remaining connected by "philotic rays". This concept is similar to quantum teleportation due to entanglement. However, in reality, quark confinement prevents quarks from being separated by any observable distance.
The ansible is also featured in the video game "Advent Rising", for which Card helped write the story.
In Elizabeth Moon's work.
There is a brief reference to the ansible in "Winning Colors". The ansible itself is a major plot element, nearly a MacGuffin in Moon's Vatta's War series. Much of the story line revolves around various parties attacking or repairing ansibles, and around the internal politics of ISC (InterStellar Communications), which holds a monopoly on the ansible technology.
In reality.
There is no currently known way to build an ansible. The theory of special relativity predicts that any such device would allow communication from the future to the past, which raises problems of causality, unless the device used general relativistic curved spacetimes as an integral part.
Quantum nonlocality is often proposed as a mechanism for superluminal communication. A 2008 quantum physics experiment performed in Geneva, Switzerland has determined that in any hypothetical nonlocal hidden-variables theory the speed of the "quantum non-local connection" would have to be at least 10,000 times the speed of light. Practical applications are shown to be impossible by the no-cloning theorem, and the fact that quantum field theories preserve causality, quantum correlations cannot be used to transfer information.
Time reports that the Delft Institute of Technology in The Netherlands has demonstrated the principle by isolating target entangled electrons inside two supercooled diamonds placed 10 meters apart, creating what one of the physicists described as “miniprisons” for them. They then manipulated their spin rate and determined that the behavior of one indeed continued to determine the spin of the other, and vice versa, even at that distance.
See time travel and faster-than-light for more discussion of these issues.

</doc>
<doc id="2108" url="http://en.wikipedia.org/wiki?curid=2108" title="Adalbert of Prague">
Adalbert of Prague

Adalbert of Prague (Czech: , , c. 956 – April 23, 997), was a Czech Roman Catholic saint, a Bishop of Prague and a missionary who was martyred in his efforts to convert the Baltic Prussians. He evangelized Poles and Hungarians. Adalbert was later made the patron saint of Bohemia, Poland, Hungary and Prussia.
Life.
Early years.
Adalbert (named "Vojtěch" at birth) was born into a noble Czech family of Prince Slavník and his wife Střezislava in Libice nad Cidlinou, Bohemia. His father was a rich and independent ruler of the Zličan princedom that rivaled Prague (see Slavník's dynasty). Adalbert had five full brothers: Soběslav (Slavnik's heir), Spytimír, Pobraslav, Pořej, Čáslav and a half-brother Radim (Gaudentius) from his father's liaison with another woman. Radim chose a clerical career as did Adalbert, and took the name Gaudentius. Adalbert was a well-educated man, having studied for about ten years (970-80) in Magdeburg under Saint Adalbert of Magdeburg. Upon the death of his mentor, he took the name Adalbert.
Religious acts.
In 980 Adalbert finished his studies at the Magdeburg school and returned to Prague, where he became a priest. In 981 his father, Prince Slavnik, and both his mentors died. In 982, still not yet 30 years old, Adalbert became the Bishop of Prague. Although Adalbert descended from a rich family and could afford comfort and luxury, he lived poorly of his own free will. He was noted for charity, austerity, and zealous service to the Church. His duty was difficult even in baptized Bohemia, as the pagan creed was deeply embedded in the peoples' minds. Adalbert complained of polygamy and idolatry, which still were not unusual among the Czechs. He also strongly resented the participation of baptized Christians in the slave trade.
In 989 he resigned from his bishop's cloth and left Prague. He went to Rome and lived as a hermit in St. Alexis Benedictine monastery. Four years later, in 993, Pope John XV sent him back to Bohemia, and Adalbert became the bishop again. That time he founded a monastery in Břevnov, near Prague, the first one in the Czech lands. Nonetheless, the nobility there continued to oppose his ministry. Also, according to Cosmas of Prague's chronicle, high clerical office was a burden to Adalbert, and in 994 he offered it to Strachkvas who was a member of the Přemyslid dynasty and Duke Boleslav's brother. Strachkvas, nevertheless, refused.
In 995, the Slavniks' former rivalry with the Přemyslids (allied with the powerful Bohemian clan, the Vršovcis) resulted in the storming of the Slavnik town of Libice nad Cidlinou led by the Přemyslid Boleslaus II the Pious. During the struggle four (or five) of Adalbert's brothers were killed. Nonetheless, the Zličan princedom became part of the Přemyslids' estate.
After the tragedy he could not stay in Bohemia and escaped from Prague, despite the Pope's call for him to return to his episcopal see. Strachkvas was eventually appointed to be his successor. However, when he was going to assume the Bishop office in Prague, he suddenly died during the ceremony itself. Circumstances of his death are still unclear.
As for Adalbert, he went to Hungary and baptized Géza of Hungary and his son Stephen in the city of Esztergom. Then he went to Poland where he was cordially welcomed by Bolesław I the Brave. After the short visit Adalbert went to Prussia with a Christian mission.
Mission and martyrdom in Prussia.
Adalbert of Prague had already in 977 entertained the idea of becoming a missionary in Prussia. After he had converted Hungary, he was sent by the Pope to convert the heathen Prussians. Boleslaus the Brave, duke of Poland (later king), sent soldiers with Adalbert. The bishop and his followers - including his half-brother Radim (Gaudentius) - entered Prussian territory and went along the Baltic Sea coast to Gdańsk.
It was a standard procedure of Christian missionaries to try to chop down sacred oak trees, which they had done in many other places, including Saxony. Because the trees were worshipped and the spirits who were believed to inhabit the trees were feared for their powers, this was done to demonstrate to the non-Christians that no supernatural powers protected the trees from the Christians. (See: Iconoclasm)
When they did not heed warnings to stay away from the sacred oak groves, Adalbert was martyred in April 997 on the Baltic Sea coast east of Truso (currently Elbląg, Elbing), or near Tenkitten and Fischhausen (see external link map St. Albrecht). It is recorded that his body was bought back for its weight in gold by Boleslaus the Brave.
Places and building named after it.
St Adalberts gradeschool in Port Richmond Philadelphia is named after it
Veneration.
A few years later Adalbert was canonized as Saint Adalbert of Prague. His life has been written about in "Vita Sancti Adalberti Pragensis" by various writers, the earliest being traced to imperial Aachen and Liège/Lüttich's bishop Notger von Lüttich, although it was assumed for many years that the Roman monk John Canaparius wrote the first "Vita" in 999. Another famous biographer of Adalbert was Saint Bruno of Querfurt who wrote his hagiography in 1001–1004.
Notably, Bohemian rulers (i.e., Přemyslids) initially refused to ransom Saint Adalbert's body from the Prussians who murdered him, so it was purchased by Poles. This fact may be explained by Saint Adalbert's belonging to the Slavniks family; it highlights the strength of the two clans' conflict. Thus Saint Adalbert's bones were stored in Gniezno and helped Boleslaus the Brave to improve Poland's position in Europe.
According to Bohemian accounts, in 1039 the Bohemian duke Břetislav I looted the bones of Saint Adalbert from Gniezno in a raid and moved them to Prague. According to Polish accounts he took the wrong relics, those of St Gaudensius, while Saint Adalbert's relics were hidden by the Poles and remain in Gniezno. In 1127 the severed head, which was not in the original purchase (according to "Roczniki Polskie") was found and moved to Gniezno. In 1928, one of the arms of Saint Adalbert, which Bolesław I had given to Otto III in the year 1000, was added to the bones preserved in Gniezno. Today Saint Adalbert has two elaborate shrines claiming to contain his remains, in the cathedrals of Prague and Gniezno, and which bones are authentic is not clear. For example, the saint has two skulls - one in Prague, a second in Gniezno (stolen in 1923).
The massive bronze Gniezno Doors of Gniezno Cathedral, of about 1175, are decorated with 18 reliefs of scenes from the saint's life, the only Romanesque church doors in Europe to contain a cycle illustrating the life of a saint.
April 1997 was the thousandth anniversary of Saint Adalbert's martyrdom. It was commemorated in the Czech Republic, Poland, Germany, Russia and other countries. Representatives of Catholic, Greek Orthodox, and Evangelical churches pilgrimaged to Gniezno, to the saint's tomb. John Paul II visited Gniezno and held a ceremonial divine service in which heads of seven European states and about a million believers took part.
In Kaliningrad Oblast, near Beregovoe village (former Tenkitten), where Adalbert's death hypothetically took place, a ten-meter cross was established.

</doc>
<doc id="2110" url="http://en.wikipedia.org/wiki?curid=2110" title="Ælfheah of Canterbury">
Ælfheah of Canterbury

Ælfheah (, "elf-high"; "c." 953 – 19 April 1012), officially remembered by the name Alphege within some churches, and also called Elphege, Alfege, or Godwine, was an Anglo-Saxon Bishop of Winchester, later Archbishop of Canterbury. He became an anchorite before being elected abbot of Bath Abbey. His perceived piety and sanctity led to his promotion to the episcopate, and eventually, to his becoming archbishop. Ælfheah furthered the cult of Dunstan and also encouraged learning. He was captured by Viking raiders in 1011 and killed by them the following year after refusing to allow himself to be ransomed. Ælfheah was canonised as a saint in 1078. Thomas Becket, a later Archbishop of Canterbury, prayed to him just before his own murder in Canterbury Cathedral.
Life.
Purportedly born in Weston on the outskirts of Bath, Ælfheah became a monk early in life. His birth took place around 953. He first entered the monastery of Deerhurst, but then moved to Bath, where he became an anchorite. He was noted for his piety and austerity, and rose to become abbot of Bath Abbey. The 12th century chronicler William of Malmesbury recorded that Ælfheah was a monk and prior at Glastonbury Abbey, but this is not accepted by all historians. Indications are that Ælfheah became abbot at Bath by 982, perhaps as early as around 977. He perhaps shared authority with his predecessor Æscwig after 968.
Probably due to the influence of Dunstan, the Archbishop of Canterbury (959–988), Ælfheah was elected Bishop of Winchester in 984, and was consecrated on 19 October that year. While bishop he was largely responsible for the construction of a large organ in the cathedral, audible from over a mile (1600 m) away and said to require more than 24 men to operate. He also built and enlarged the city's churches, and promoted the cult of Swithun and Swithun's predecessor, Æthelwold of Winchester. One act promoting Æthelwold's cult was the translation of Æthelwold's body to a new tomb in the cathedral at Winchester, which Ælfheah presided over on 10 September 996.
Following a Viking raid in 994, a peace treaty was agreed with one of the raiders, Olaf Tryggvason. Besides receiving danegeld, Olaf converted to Christianity and undertook never to raid or fight the English again. Ælfheah may have played a part in the treaty negotiations, and it is certain that he confirmed Olaf in his new faith.
In 1006 Ælfheah succeeded Ælfric as Archbishop of Canterbury, taking Swithun's head with him as a relic for the new location. He went to Rome in 1007 to receive his pallium—symbol of his status as an archbishop—from Pope John XVIII, but was robbed during his journey. While at Canterbury he promoted the cult of Dunstan, ordering the writing of the second "Life of Dunstan", which Adelard of Ghent composed between 1006 and 1011. He also introduced new practices into the liturgy, and was instrumental in the Witenagemot's recognition of Wulfsige of Sherborne as a saint in about 1012.
Ælfheah sent Ælfric of Eynsham to Cerne Abbey to take charge of its monastic school. He was present at the council of May 1008 at which Wulfstan II, Archbishop of York, preached his "Sermo Lupi ad Anglos" ("The Sermon of the Wolf to the English"), castigating the English for their moral failings and blaming the latter for the tribulations afflicting the country.
In 1011 the Danes again raided England, and from 8–29 September they laid siege to Canterbury. Aided by the treachery of Ælfmaer, whose life Ælfheah had once saved, the raiders succeeded in sacking the city. Ælfheah was taken prisoner and held captive for seven months. Godwine (Bishop of Rochester), Leofrun (abbess of St Mildrith's), and the king's reeve, Ælfweard were captured also, but the abbot of St Augustine's Abbey, Ælfmaer, managed to escape. Canterbury Cathedral was plundered and burned by the Danes following Ælfheah's capture.
Death.
Ælfheah refused to allow a ransom to be paid for his freedom, and as a result was killed on 19 April 1012 at Greenwich (then in Kent, now part of London), reputedly on the site of St Alfege's Church. The account of Ælfheah's death appears in the E version of the "Anglo-Saxon Chronicle": 
Ælfheah was the first Archbishop of Canterbury to die a violent death. A contemporary report tells that Thorkell the Tall attempted to save Ælfheah from the mob about to kill him by offering them everything he owned except for his ship, in exchange for Ælfheah's life; Thorkell's presence is not mentioned in the "Anglo-Saxon Chronicle", however. Some sources record that the final blow, with the back of an axe, was delivered as an act of kindness by a Christian convert known as "Thrum." Ælfheah was buried in St Paul's Cathedral. In 1023 his body was moved by King Cnut to Canterbury, with great ceremony. Thorkell the Tall was appalled at the brutality of his fellow raiders, and switched sides to the English king Æthelred the Unready following Ælfheah's death.
Veneration.
Pope Gregory VII canonised Ælfheah in 1078, with a feast day of 19 April. Lanfranc, the first post-Conquest archbishop, was dubious about some of the saints venerated at Canterbury. He was persuaded of Ælfheah's sanctity, but Ælfheah and Augustine of Canterbury were the only pre-conquest Anglo-Saxon archbishops kept on Canterbury's calendar of saints. Ælfheah's shrine, which had become neglected, was rebuilt and expanded in the early 12th century under Anselm of Canterbury, who was instrumental in retaining Ælfheah's name in the church calendar. After the 1174 fire in Canterbury Cathedral, Ælfheah's remains together with those of Dunstan were placed around the high altar, at which Thomas Becket is said to have commended his life into Ælfheah's care shortly before his martyrdom during the Becket controversy. The new shrine was sealed in lead, and was north of the high altar, sharing the honour with Dunstan's shrine, which was located south of the high altar. A "Life of Saint Ælfheah" in prose and verse was written by a Canterbury monk named Osbern, at Lanfranc's request. The prose version has survived, but the "Life" is very much a hagiography: many of the stories it contains have obvious Biblical parallels, making them suspect as a historical record.
In the late medieval period, Ælfheah's feast day was celebrated in Scandinavia, perhaps because of the saint's connection with Cnut. Few church dedications to him are known, with most of them occurring in Kent and one each in London and Winchester. In 1929 a new church in Bath was dedicated to Ælfheah, under the name Alphege, designed by Giles Gilbert Scott in homage to the ancient Roman church of Santa Maria in Cosmedin.

</doc>
<doc id="2112" url="http://en.wikipedia.org/wiki?curid=2112" title="Associative algebra">
Associative algebra

In mathematics, an associative algebra "A" is an associative ring (not necessarily unital) that has a compatible structure of a vector space over a certain field "K" or, more generally, of a module over a commutative ring "R". Thus "A" is endowed with binary operations of addition and multiplication satisfying a number of axioms, including associativity of multiplication and distributivity, as well as compatible multiplication by the elements of the field "K" or the ring "R".
For example, a ring of square matrices over a field "K" is an associative "K" algebra. More generally, given a ring "S" with center "C", "S" is an associative "C" algebra.
In some areas of mathematics, associative algebras are typically assumed to have a multiplicative unit, denoted 1. To make this extra assumption clear, these associative algebras are called unital algebras. Additionally, some authors demand that all rings be unital; in this article, the word "ring" is intended to refer to potentially non-unital rings as well.
Formal definition.
Let "R" be a fixed commutative ring. An associative "R"-algebra is an additive abelian group "A" which has the structure of both a ring and an "R"-module in such a way that ring multiplication is "R"-bilinear:
for all "r" ∈ "R" and "x", "y" ∈ "A".
We say "A" is unital if it contains an element 1 such that
for all "x" ∈ "A". Note that such an element 1 must be unique if it exists at all.
If "A" itself is commutative (as a ring) then it is called a commutative "R"-algebra.
From "R"-modules.
Starting with an "R"-module "A", we get an associative "R"-algebra by equipping "A" with an "R"-bilinear mapping "A" × "A" → "A" such that
for all "x", "y", and "z" in "A". This "R"-bilinear mapping then gives "A" the structure of a ring and an associative "R"-algebra. Every associative "R"-algebra arises this way.
Moreover, the algebra "A" built this way will be unital if and only if there exists an element 1 of "A" such that every element "x" of "A" satisfies 1"x" = "x"1 = "x".
This definition is equivalent to the statement that a unital associative "R"-algebra is a monoid in "R"-Mod (the monoidal category of "R"-modules).
From rings.
Starting with a ring "A", we get a unital associative "R"-algebra by providing a ring homomorphism formula_4 whose image lies in the center of "A". The algebra "A" can then be thought of as an "R"-module by defining
for all "r" ∈ "R" and "x" ∈ "A".
If "A" is commutative then the center of "A" is equal to "A", so that a commutative unital "R"-algebra can be defined simply as a homomorphism formula_4 of commutative rings.
Algebra homomorphisms.
A homomorphism between two associative "R"-algebras is an "R"-linear ring homomorphism. Explicitly, formula_7 is an associative algebra homomorphism if
For a homomorphism of "unital" associative "R"-algebras, we also demand that
The class of all unital associative "R"-algebras together with algebra homomorphisms between them form a category, sometimes denoted "R"-Alg.
The subcategory of commutative "R"-algebras can be characterized as the coslice category "R"/CRing where CRing is the category of commutative rings.
Examples.
The most basic example is a ring itself; it is an algebra over its center or any subring lying in the center. In particular, any commutative ring is an algebra over any of its subrings. Other examples abound both from algebra and other fields of mathematics.
Algebra
Analysis
Geometry and combinatorics
Associativity and the multiplication mapping.
Associativity was defined above quantifying over all "elements" of "A". It is possible to define associativity in a way that does not explicitly refer to elements. An algebra is defined as a vector space "A" with a bilinear map
(the multiplication map). An associative algebra is an algebra where the map "M" has the property
Here, the symbol formula_14 refers to function composition, and Id : "A" → "A" is the identity map on "A".
To see the equivalence of the definitions, we need only understand that each side of the above equation is a function that takes three arguments. For example, the left-hand side acts as
Similarly, a unital associative algebra can be defined as a vector space "A" endowed with a map "M" as above and, additionally, a linear map
(the unit map) which has the properties
Here, the unit map η takes an element "k" in "K" to the element "k1" in "A", where "1" is the unit element of "A". The map "t" is just plain-old scalar multiplication: formula_18; the map "s" is similar: formula_19.
Coalgebras.
An associative unital algebra over "K" is given by a "K"-vector space "A" endowed with a bilinear map "A"×"A"→"A" having 2 inputs (multiplicator and multiplicand) and one output (product), as well as a morphism "K"→"A" identifying the scalar multiples of the multiplicative identity. If the bilinear map "A"×"A"→"A" is reinterpreted as a linear map (i. e., morphism in the category of "K"-vector spaces) "A"⊗"A"→"A" (by the universal property of the tensor product), then we can view an associative unital algebra over "K" as a "K"-vector space "A" endowed with two morphisms (one of the form "A"⊗"A"→"A" and one of the form "K"→"A") satisfying certain conditions which boil down to the algebra axioms. These two morphisms can be dualized using categorial duality by reversing all arrows in the commutative diagrams which describe the algebra axioms; this defines the structure of a coalgebra.
There is also an abstract notion of F-coalgebra. This is vaguely related to the notion of coalgebra discussed above.
Representations.
A representation of a unital algebra "A" is a unital algebra homomorphism ρ: "A" → End("V") from "A" to the endomorphism algebra of some vector space (or module) "V". The property of ρ being a unital algebra homomorphism means that ρ preserves the multiplicative operation (that is, ρ("xy")=ρ("x")ρ("y") for all "x" and "y" in "A"), and that ρ sends the unity of "A" to the unity of End("V") (that is, to the identity endomorphism of "V").
If "A" and "B" are two algebras, and ρ: "A" → End("V") and τ: "B" → End("W") are two representations, then it is easy to define a (canonical) representation "A ⊗ B" → End("V ⊗ W") of the tensor product algebra "A ⊗ B" on the vector space "V ⊗ W". Note, however, that there is no natural way of defining a tensor product of two representations of a single associative algebra in such a way that the result is still a representation of that same algebra (not of its tensor product with itself), without somehow imposing additional conditions. Here, by "tensor product of representations", the usual meaning is intended: the result should be a linear representation of the same algebra on the product vector space. Imposing such additional structure typically leads to the idea of a Hopf algebra or a Lie algebra, as demonstrated below.
Motivation for a Hopf algebra.
Consider, for example, two representations formula_20 and formula_21. One might try to form a tensor product representation formula_22 according to how it acts on the product vector space, so that
However, such a map would not be linear, since one would have
for "k" ∈ "K". One can rescue this attempt and restore linearity by imposing additional structure, by defining an algebra homomorphism Δ: "A" → "A" ⊗ "A", and defining the tensor product representation as
Such a homomorphism Δ is called a comultiplication if it satisfies certain axioms. The resulting structure is called a bialgebra. To be consistent with the definitions of the associative algebra, the coalgebra must be co-associative, and, if the algebra is unital, then the co-algebra must be co-unital as well. A Hopf algebra is a bialgebra with an additional piece of structure (the so-called antipode), which allows not only to define the tensor product of two representations, but also the Hom module of two representations (again, similarly to how it is done in the representation theory of groups).
Motivation for a Lie algebra.
One can try to be more clever in defining a tensor product. Consider, for example,
so that the action on the tensor product space is given by
This map is clearly linear in "x", and so it does not have the problem of the earlier definition. However, it fails to preserve multiplication:
But, in general, this does not equal
This shows that this definition of a tensor product is too naive. It can be used, however, to define the tensor product of two representations of a Lie algebra (rather than of an associative algebra).

</doc>
<doc id="2113" url="http://en.wikipedia.org/wiki?curid=2113" title="Axiom of regularity">
Axiom of regularity

In mathematics, the axiom of regularity (also known as the axiom of foundation) is an axiom of Zermelo–Fraenkel set theory that states that every non-empty set "A" contains an element that is disjoint from "A". In first-order logic the axiom reads:
The axiom implies that no set is an element of itself, and that there is no infinite sequence ("an") such that "ai+1" is an element of "ai" for all "i". With the axiom of dependent choice (which is a weakened form of the axiom of choice), this result can be reversed: if there are no such infinite sequences, then the axiom of regularity is true. Hence, the axiom of regularity is equivalent, given the axiom of dependent choice, to the alternative axiom that there are no downward infinite membership chains.
The axiom of regularity was introduced by ; it was adopted in a formulation closer to the one found in contemporary textbooks by . Virtually all results in the branches of mathematics based on set theory hold even in the absence of regularity; see chapter 3 of . However, regularity makes some properties of ordinals easier to prove; and it not only allows induction to be done on well-ordered sets but also on proper classes that are well-founded relational structures such as the lexicographical ordering on formula_2
Given the other axioms of Zermelo–Fraenkel set theory, the axiom of regularity is equivalent to the axiom of induction. The axiom of induction tends to be used in place of the axiom of regularity in intuitionistic theories (ones that do not accept the law of the excluded middle), where the two axioms are not equivalent.
In addition to omitting the axiom of regularity, non-standard set theories have indeed postulated the existence of sets that are elements of themselves.
Elementary implications of regularity.
No set is an element of itself.
Let "A" be a set, and apply the axiom of regularity to {"A"}, which is a set by the axiom of pairing. We see that there must be an element of {"A"} which is disjoint from {"A"}. Since the only element of {"A"} is "A", it must be that "A" is disjoint from {"A"}. So, since "A" ∈ {"A"}, we cannot have "A" ∈ "A" (by the definition of disjoint).
No infinite descending sequence of sets exists.
Suppose, to the contrary, that there is a function, "f", on the natural numbers with "f"("n"+1) an element of "f"("n") for each "n". Define "S" = {"f"("n"): "n" a natural number}, the range of "f", which can be seen to be a set from the axiom schema of replacement. Applying the axiom of regularity to "S", let "B" be an element of "S" which is disjoint from "S". By the definition of "S", "B" must be "f"("k") for some natural number "k". However, we are given that "f"("k") contains "f"("k"+1) which is also an element of "S". So "f"("k"+1) is in the intersection of "f"("k") and "S". This contradicts the fact that they are disjoint sets. Since our supposition led to a contradiction, there must not be any such function, "f".
The nonexistence of a set containing itself can be seen as a special case where the sequence is infinite and constant.
Notice that this argument only applies to functions "f" that can be represented as sets as opposed to undefinable classes. The hereditarily finite sets, Vω, satisfy the axiom of regularity (and all other axioms of ZFC except the axiom of infinity). So if one forms a non-trivial ultrapower of Vω, then it will also satisfy the axiom of regularity. The resulting model will contain elements, called non-standard natural numbers, that satisfy the definition of natural numbers in that model but are not really natural numbers. They are fake natural numbers which are "larger" than any actual natural number. This model will contain infinite descending sequences of elements. For example, suppose "n" is a non-standard natural number, then formula_3 and formula_4, and so on. For any actual natural number "k", formula_5. This is an unending descending sequence of elements. But this sequence is not definable in the model and thus not a set. So no contradiction to regularity can be proved.
Simpler set-theoretic definition of the ordered pair.
The axiom of regularity enables defining the ordered pair ("a","b") as {"a",{"a","b"}}. See ordered pair for specifics. This definition eliminates one pair of braces from the canonical Kuratowski definition ("a","b") = .
Every set has an ordinal rank.
This was actually the original form of von Neumann's axiomatization.
For every two sets, only one can be an element of the other.
Let "X" and "Y" be sets. Then apply the axiom of regularity to the set {"X","Y"}. We see there must be an element of {"X","Y"} which is also disjoint from it. It must be either "X" or "Y". By the definition of disjoint then, we must have either "Y" is not an element of "X" or vice versa.
The axiom of dependent choice and no infinite descending sequence of sets implies regularity.
Let the non-empty set "S" be a counter-example to the axiom of regularity; that is, every element of "S" has a non-empty intersection with "S". We define a binary relation "R" on "S" by formula_6, which is entire by assumption. Thus, by the axiom of dependent choice, there is some sequence ("an") in "S" satisfying "anRan+1" for all "n" in N. As this is an infinite descending chain, we arrive at a contradiction and so, no such "S" exists.
Regularity and the rest of ZF(C) axioms.
Regularity was shown to be relatively consistent with the rest of ZF by , meaning that if ZF without regularity is consistent, then ZF (with regularity) is also consistent. For his proof in modern notation see for instance.
The axiom of regularity was also shown to be independent from the other axioms of ZF(C), assuming they are consistent. The result was announced by Paul Bernays in 1941, although he did not publish a proof until 1954. The proof involves (and led to the study of) Rieger-Bernays permutation models (or method), which were used for other proofs of independence for non-well-founded systems ( and ).
Regularity and Russell's paradox.
Naive set theory (the axiom schema of unrestricted comprehension and the axiom of extensionality) is inconsistent due to Russell's paradox. Set theorists have avoided that contradiction by replacing the axiom schema of comprehension with the much weaker axiom schema of separation. However, this makes set theory too weak. So some of the power of comprehension was added back via the other existence axioms of ZF set theory (pairing, union, powerset, replacement, and infinity) which may be regarded as special cases of comprehension. So far, these axioms do not seem to lead to any contradiction. Subsequently, the axiom of choice and the axiom of regularity were added to exclude models with some undesirable properties. These two axioms are known to be relatively consistent.
In the presence of the axiom schema of separation, Russell's paradox becomes a proof that there is no set of all sets. The axiom of regularity (with the axiom of pairing) also prohibits such a universal set, however this prohibition is redundant when added to the rest of ZF. If the ZF axioms without regularity were already inconsistent, then adding regularity would not make them consistent.
The existence of Quine atoms (sets that satisfy the formula equation "x" = {"x"}, i.e. have themselves as their only elements) is consistent with the theory obtained by removing the axiom of regularity from ZFC. Various non-wellfounded set theories allow "safe" circular sets, such as Quine atoms, without becoming inconsistent by means of Russell's paradox.
Regularity, the cumulative hierarchy, and types.
In ZF it can be proven that the class formula_7 (see cumulative hierarchy) is equal to the class of all sets. This statement is even equivalent to the axiom of regularity (if we work in ZF with this axiom omitted). From any model which does not satisfy axiom of regularity, a model which satisfies it can be constructed by taking only sets in formula_7.
 wrote that "The idea of rank is a descendant of Russell's concept of "type"". Comparing ZF with type theory, Alasdair Urquhart wrote that "Zermelo's system has the notational advantage of not containing any explicitly typed variables, although in fact it can be seen as having an implicit type structure built into it, at least if the axiom of regularity is included. The details of this implicit typing are spelled out in [Zermelo 1930], and again in a well-known article of George Boolos [Boolos 1971]." 
 went further and claimed that: 
"The truth is that there is only one satisfactory way of avoiding the paradoxes: namely, the use of some form of the "theory of types". That was at the basis of both Russell's and Zermelo's intuitions. Indeed the best way to regard Zermelo's theory is as a simplification and extension of Russell's. (We mean Russell's "simple" theory of types, of course.) The simplification was to make the types "cumulative". Thus mixing of types is easier and annoying repetitions are avoided. Once the later types are allowed to accumulate the earlier ones, we can then easily imagine "extending" the types into the transfinite—just how far we want to go must necessarily be left open. Now Russell made his types "explicit" in his notation and Zermelo left them "implicit"." (emphasis in original)
In the same paper, Scott shows that an axiomatic system based on the inherent properties of the cumulative hierarchy turns out to be equivalent to ZF, including regularity. 
History.
The concept of well-foundedness and rank of a set were both introduced by Dmitry Mirimanoff (1917) cf. and . Mirimanoff called a set "x" "regular" (French: "ordinaire") if every descending chain "x" ∋ "x1" ∋ "x2" ∋ ... is finite. Mirimanoff however did not consider his notion of regularity (and well-foundedness) as an axiom to be observed by all sets ; in later papers Mirimanoff also explored what are now called non-well-founded sets ("extraordinaire" in Mirimanoff's terminology) .
According to Adam Rieger, describes non-well-founded sets as "superfluous" (on p. 404 in van Heijenoort 's translation) and in the same publication von Neumann gives an axiom (p. 412 in translation) which excludes some, but not all, non-well-founded sets . In a subsequent publication, gave the following axiom (rendered in modern notation by A. Rieger):

</doc>
<doc id="2114" url="http://en.wikipedia.org/wiki?curid=2114" title="IBM AIX">
IBM AIX

AIX (Advanced Interactive eXecutive, pronounced ) is a series of proprietary Unix operating systems developed and sold by IBM for several of its computer platforms. Originally released for the IBM 6150 RISC workstation, AIX now supports or has supported a wide variety of hardware platforms, including the IBM RS/6000 series and later POWER and PowerPC-based systems, IBM System i, System/370 mainframes, PS/2 personal computers, and the Apple Network Server.
AIX is based on UNIX System V with 4.3BSD-compatible extensions. It is one of five commercial operating systems that have versions certified to The Open Group's UNIX 03 standard (the others being Mac OS X, Solaris, Inspur K-UX and HP-UX).
The AIX family of operating systems debuted in 1986, became the standard operating system for the RS/6000 series on its launch in 1990, and is still actively developed by IBM. It is currently supported on IBM Power Systems alongside IBM i and Linux.
AIX was the first operating system to utilize journaling file systems, and IBM has continuously enhanced the software with features like processor, disk and network virtualization, dynamic hardware resource allocation (including fractional processor units), and reliability engineering ported from its mainframe designs.
History.
AIX Version 1, introduced in 1986 for the IBM 6150 RT workstation, was based on UNIX System V Releases 1 and 2. In developing AIX, IBM and Interactive Systems Corporation (whom IBM contracted) also incorporated source code from 4.2 and 4.3 BSD UNIX.
Among other variants, IBM later produced AIX Version 3 (also known as AIX/6000), based on System V Release 3, for their POWER-based RS/6000 platform. Since 1990, AIX has served as the primary operating system for the RS/6000 series (later renamed "IBM eServer pSeries", then "IBM System p", and now "IBM Power Systems"). AIX Version 4, introduced in 1994, added symmetric multiprocessing with the introduction of the first RS/6000 SMP servers and continued to evolve through the 1990s, culminating with AIX 4.3.3 in 1999. Version 4.1, in a slightly modified form, was also the standard operating system for the Apple Network Server systems sold by Apple Computer to complement the Macintosh line.
In the late 1990s, under Project Monterey, IBM and the Santa Cruz Operation planned to integrate AIX and UnixWare into a single 32-bit/64-bit multiplatform UNIX with particular emphasis on running on Intel IA-64 (Itanium) architecture CPUs. A beta test version of AIX 5L for IA-64 systems was released, but according to documents released in the "SCO v. IBM" lawsuit, less than forty licenses for the finished Monterey Unix were ever sold before the project was terminated in 2002. In 2003, the SCO Group alleged that (among other infractions) IBM had misappropriated licensed source code from UNIX System V Release 4 for incorporation into AIX; SCO subsequently withdrew IBM's license to develop and distribute AIX. IBM maintains that their license was irrevocable, and continued to sell and support the product until the litigation was adjudicated.
AIX was a component of the 2003 "SCO v. IBM" lawsuit, in which the SCO Group filed a lawsuit against IBM, alleging IBM contributed SCO's intellectual property to the Linux codebase. The SCO Group, who argued they were the rightful owners of the copyrights covering the Unix operating system, attempted to revoke IBM's license to sell or distribute the AIX operating system. In March 2010 a jury returned a verdict finding that Novell, not the SCO Group, owns the rights to Unix.
AIX 6 was announced in May 2007 and ran an open beta from June 2007 until the general availability (GA) of AIX 6.1 on November 9, 2007. Major new features in AIX 6.1 included full role-based access control, workload partitions (which enable application mobility), enhanced security (Addition of AES encryption type for NFS v3 and v4) and Live Partition Mobility on the POWER6 hardware.
In April 2010, IBM published an announcement about the upcoming 7.1 release. Support is planned to continue on POWER4 or later hardware generations. Several new features, including better scalability, enhanced clustering and management capabilities are mentioned. The ability to run older versions of AIX as a WPAR keeps the opportunity to continue using 5.2 where the hardware doesn't support it. IBM intends to make 7.1 available with an Open Beta program again.
Supported hardware platforms.
IBM 6150 RT.
The original AIX (sometimes called AIX/RT) was developed for the IBM 6150 RT workstation by IBM in conjunction with Interactive Systems Corporation, who had previously ported UNIX System III to the IBM PC for IBM as PC/IX. According to its developers, the AIX source (for this initial version) consisted of one million lines of code. Installation media consisted of eight 1.2M floppy disks. The RT was based on the ROMP microprocessor, the first commercial RISC chip. This was based on a design pioneered at IBM Research (the IBM 801) .
One of the novel aspects of the RT design was the use of a microkernel, called Virtual Resource Manager (VRM). The keyboard, mouse, display, disk drives and network were all controlled by a microkernel. One could "hotkey" from one operating system to the next using the Alt-Tab key combination. Each OS in turn would get possession of the keyboard, mouse and display. Besides AIX v2, the PICK OS also utilized this microkernel.
Much of the AIX v2 kernel was written in the PL/I programming language, which proved troublesome during the migration to AIX v3. AIX v2 included full TCP/IP networking, as well as SNA and two networking file systems: NFS, licensed from Sun Microsystems, and Distributed Services (DS). DS had the distinction of being built on top of SNA, and thereby being fully compatible with DS on the IBM midrange AS/400 and mainframe systems. For the graphical user interfaces, AIX v2 came with the X10R3 and later the X10R4 and X11 versions of the X Window System from MIT, together with the Athena widget set. Compilers for Fortran and C were available. One of the more popular desktop applications was the PageMaker desktop publishing software.
IBM PS/2 series.
AIX PS/2 (also known as AIX/386) was developed by Locus Computing Corporation under contract to IBM. AIX PS/2, first released in 1989, ran on IBM PS/2 personal computers with Intel 386 and compatible processors.
The product was announced in September 1988 with a baseline tag price of $595, although some utilities like uucp were included in a separate Extension package priced at $250. nroff and troff for AIX were also sold separately in a Text Formatting System package priced at $200. The TCP/IP stack for AIX PS/2 retailed for another $300. The X Window package was priced at $195, while the C and FORTRAN compilers each had a price tag of $275. Locus also made available their DOS Merge virtual machine environment for AIX, which could run MS DOS 3.3 applications inside AIX; DOS Merge was sold separately for another $250. IBM also offered a $150 AIX PS/2 DOS Server Program, which provided file server and print server services for client computers running PC DOS 3.3.
The last version of PS/2 AIX is 1.3. It was released in 1992 and announced to add support for non-IBM (non-microchannel) computers as well. Support for PS/2 AIX ended in March 1995.
IBM mainframes.
In 1988, IBM announced AIX/370, also developed by Locus Computing. AIX/370 was IBM's third attempt to offer Unix-like functionality for their mainframe line, specifically the System/370 (the prior versions were a TSS/370 based Unix system developed jointly with AT&T c.1980, and VM/IX, a VM/370 based system developed jointly with Interactive Systems Corporation c.1984). AIX/370 was released in 1990 with functional equivalence to System V Release 2 and 4.3BSD as well as IBM enhancements. With the introduction of the ESA/390 architecture, AIX/370 was replaced by AIX/ESA in 1991, which was based on OSF/1, and also ran on the System/390 platform. This development effort was made partly to allow IBM to compete with Amdahl UTS. Unlike AIX/370, AIX/ESA ran both natively as the host operating system, and as a guest under VM. AIX/ESA, while technically advanced, had little commercial success, partially because UNIX functionality was added as an option to the existing mainframe operating system, MVS, which became MVS/ESA OpenEdition in 1999.
POWER/PowerPC-based systems.
The release of AIX version 3 (sometimes called AIX/6000) coincided with the announcement of the first POWER1-based IBM RS/6000 models in 1990. The RS/6000 was unique in that it not only outperformed all other machines in integer compute performance, but also beat the competition by a "factor of 10" in floating-point performance. The competition consisted of Unix workstations from the vendors Sun, HP and SGI, and, to a lesser degree, those from Intergraph and others. The machines were all roughly comparable, retailing in the $10K to $100K price range, and offering similar amounts of RAM, disk and networking, and roughly comparable graphics subsystems. The novelty of the floating-point unit was that it was tied into the integer pipeline, and performed a single multiply-add instruction per cycle (more precisely, in 3 cycles with a 3-cycle deep pipeline). The 'common wisdom' of the era was that only integer performance mattered, oddly belying the fact that many customers were running floating-point intensive numeric scientific computing workloads.
Releases of AIX version 3 also took advantage of the developments in the POWER architecture.
AIX v3 innovated in several ways on the software side. It was the first operating system to introduce the idea of a journaling file system, JFS, which allowed for fast boot times by avoiding the need to ensure the consistency of the file systems on disks (see fsck) on every reboot. Another innovation was shared libraries which avoid the need for static linking from an application to the libraries it used. The resulting smaller binaries used less of the hardware RAM to run, and used less disk space to install. Besides improving performance, it was a boon to developers: executable binaries could be in the tens of kilobytes instead of a megabyte for an executable statically linked to the C library. AIX v3 also scrapped the microkernel of AIX v2, a contentious move that resulted in v3 containing no PL/I code and being somewhat more "pure" than v2.
Other notable subsystems included:
As of 2011, AIX runs on IBM Power, System p, System i, System p5, System i5, eServer p5, eServer pSeries and eServer i5 server product lines, as well as IBM BladeCenter blades and IBM PureFlex compute nodes based on Power Architecture technology.
POWER7 AIX Features.
Performance Optimization With Enhanced RISC (POWER) version 7 enables a unique performance advantage for AIX OS. POWER7 features new capabilities using multiple cores and multiple CPU threads, creating a pool of virtual CPUs. Typically IBM POWER7 processors have eight cores with four threads per core, for a total capacity of 32 simultaneous threads or 32 virtual CPUs per processor circuit, while still using the same electricity consumption as the POWER6 processor circuit which could only support 8 virtual CPUs. AIX can harness POWER7's ability to execute instructions out-of-order instead of in-order, by using POWER7's aggressive out-of-order instruction set which drives highly efficient use of available execution paths.
AIX 7 includes a new built-in clustering capability called Cluster Aware AIX. AIX is able to organize multiple LPARs through the multipath communications channel to neighboring CPUs, enabling very high-speed communication between processors. This enables multi-terabyte memory address range and page table access to support global petabyte shared memory space for AIX POWER7 clusters so that software developers can program a cluster as if it were a single system, without using message passing (i.e. semaphore-controlled Inter-process Communication). AIX administrators can use this new capability to cluster a pool of AIX nodes. By default, AIX V7.1 pins kernel memory and includes support to allow applications to pin their kernel stack. Pinning kernel memory and the kernel stack for applications with real-time requirements can provide performance improvements by ensuring that the kernel memory and kernel stack for an application is not paged out.
AIX POWER7 systems include the Active Memory Expansion feature, which increases system flexibility where system administrators can configure logical partitions (LPARs) to use less physical memory. For example, an LPAR running AIX appears to the OS applications to be configured with 80 GB of physical memory but the hardware actually only consumes 60 GB of physical memory. Active Memory Expansion employs memory compression technology to transparently compress in-memory data, allowing more data to be placed into memory and thus expanding the memory capacity of POWER7 systems. Utilizing Active Memory Expansion can improve system utilization and increase a system’s throughput. AIX 7 automatically manages the size of memory pages used to automatically use 4K, 64K or a combination of those page sizes. This self-tuning feature results in optimized performance without administrative effort.
Apple Network Servers.
The Apple Network Server systems were PowerPC-based systems designed by Apple Computer to have numerous high-end features that standard Apple hardware did not have, including swappable hard drives, redundant power supplies, and external monitoring capability. These systems were more or less based on the Power Macintosh hardware available at the time but were designed to use AIX (versions 4.1.4 or 4.1.5) as their native operating system in a specialized version specific to the ANS.
AIX was only compatible with the Network Servers and was not ported to standard Power Macintosh hardware. Not to be confused is A/UX, Apple's earlier version of Unix for 68k-based Macintoshes.
IA-64 systems.
As part of Project Monterey, IBM released a beta test version of AIX 5L for the IA-64 (Itanium) architecture in 2001, but this never became an official product due to lack of interest.
User interfaces.
The default shell was Bourne shell up to AIX version 3, but was changed to Korn shell (ksh88) in version 4 in view of XPG4 and POSIX compliance.
Graphical.
The Common Desktop Environment (CDE) is AIX's default graphical user interface. As part of Linux Affinity and the free AIX Toolboxes for Linux Applications (ATLA), open-source KDE Plasma Workspaces and GNOME desktop are also available.
System Management Console.
SMIT is the System Management Interface Tool for AIX. It allows a user to navigate a menu hierarchy of commands, rather than using the command line. Invocation is typically achieved with the command codice_1. Experienced system administrators make use of the codice_2 function key which generates the command line that SMIT will invoke to complete it.
SMIT also generates a log of commands that are performed in the codice_3 file. The codice_3 file automatically records the commands with the command flags and parameters used. The codice_3 file can be used as an executable shell script to rerun system configuration tasks. SMIT also creates the codice_6 file, which contains additional detailed information that can be used by programmers in extending the SMIT system.
codice_1 and codice_8 refer to the same program, though codice_8 invokes the text-based version, while codice_1 will invoke an X Window System based interface if possible; however, if codice_1 determines that X Window System capabilities are not present, it will present the text-based version instead of failing. Determination of X Window System capabilities is typically performed by checking for the existence of the codice_12 variable.

</doc>
<doc id="2115" url="http://en.wikipedia.org/wiki?curid=2115" title="AppleTalk">
AppleTalk

AppleTalk is a proprietary suite of networking protocols developed by Apple Inc. for their Macintosh computers. AppleTalk included a number of features that allowed local area networks to be connected with no prior setup or the need for a centralized router or server of any sort. Connecting together AppleTalk equipped systems would automatically assign addresses, update the distributed namespace, and configure any required inter-networking routing. It was a plug-n-play system.
AppleTalk was released in 1985, and was the primary protocol used by Apple devices through the 1980s and 90s. Versions were also released for the IBM PC and compatibles, and the Apple IIGS. AppleTalk support was also available in most networked printers (especially laser printers), some file servers and a number of routers.
The rise of TCP/IP during the 1990s led to a re-implementation of most of these types of support on that protocol, and AppleTalk became unsupported as of the release of Mac OS X v10.6 in 2009. Many of AppleTalk's more advanced auto-configuration features have since been introduced in Bonjour, while Universal Plug and Play serves similar needs.
History.
AppleNet.
After the release of the Apple Lisa computer in January 1983, Apple invested considerable effort in the development of a local area networking (LAN) system for the machines. Known as AppleNet, it was based on the seminal Xerox XNS protocol stack but running on a custom 1 Mbit/s coaxial cable system rather than Xerox's 2.94 Mbit/s Ethernet. AppleNet was announced early in 1983 with a fall introduction at the target price of $500 for plug-in AppleNet cards for the Lisa and the Apple II.
At that time, early LAN systems were just coming to market, including Ethernet, Token Ring and ARCNET. This was a topic of major commercial effort at the time, dominating shows like the National Computer Conference (NCC) in Anaheim in May 1983. All of the systems were jockeying for position in the market, but even at this time Ethernet's widespread acceptance suggested it was to become a "de facto" standard. It was at this show that Steve Jobs asked Gursharan Sidhu a seemingly innocuous question, "Why has networking not caught on?"
Four months later, in October, AppleNet was cancelled. At the time, they announced that "Apple realized that it's not in the business to create a networking system. We built and used AppleNet in-house, but we realized that if we had shipped it, we would have seen new standards coming up." In January, Jobs announced that they would instead be supporting IBM's Token Ring, which he expected to come out in a "few months".
AppleBus.
Through this period, Apple was deep in development of the Macintosh computer. During development, engineers had made the decision to use the Zilog 8530 serial controller chip (SCC) instead of the lower cost and more common UART to provide serial port connections. The SCC cost about $5 more than a UART, but offered much higher speeds up to 250 kilobytes per second (or higher with additional hardware) and internally supported a number of basic networking-like protocols like IBM's Bisync.
The SCC was chosen because it would allow multiple devices to be attached to the port. Peripherals equipped with similar SCC's could communicate using the built-in protocols, interleaving their data with other peripherals on the same bus. This would eliminate the need for more ports on the back of the machine, and allowed for the elimination of expansion slots for supporting more complex devices. The initial concept was known as AppleBus, envisioning a system controlled by the host Macintosh polling "dumb" devices in a fashion similar to the modern Universal Serial Bus.
AppleBus networking.
The Macintosh team had already begun work on what would become the LaserWriter, and had considered a number of other options of how to share these expensive machines and other resources. A series of memos from Bob Belleville clarified these concepts, outlining the Mac, LaserWriter and a file server system which would become Macintosh Office. By late 1983 it was clear that IBM's Token Ring would not be ready in time for the launch of the Mac, and might miss the launch of these other products as well. In the end, Token Ring would not ship until October 1985.
Jobs' earlier question to Sidhu had already sparked a number of ideas. When AppleNet was cancelled in October, Sidhu led an effort to develop a new networking system based on the AppleBus hardware. This new system would not have to conform to any existing preconceptions, and was designed to be worthy of the Mac - a system that was user-installable, had zero-configuration, and no fixed network addresses - in short, a true plug-and-play network. Considerable effort was needed, but by the time the Mac was released, the basic concepts had been outlined, and some of the low-level protocols were on their way to completion. Sidhu mentioned the work to Belleville only two hours after the Mac was announced.
The "new" AppleBus was announced in early 1984, allowing direct connection from the Mac or Lisa through a small box that plugged into the serial port and connected via cables to the next computer upstream and downstream. Adaptors for Apple II and Apple III were also announced. Apple also announced that AppleBus networks could be attached to, and would appear to be a single node within, a Token Ring system. Details of how this would work were sketchy.
AppleTalk.
Just prior to its release in early 1985, AppleBus was renamed AppleTalk. The system had a number of limitations, including a speed of only 230.4 kbit/s, a maximum distance of 1000 feet from end to end, and only 32 nodes per LAN. But as the basic hardware was built into the Mac, adding nodes only cost about $50 for the adaptor box. In comparison, Ethernet or Token Ring cards cost hundreds or thousands of dollars. Additionally, the entire networking stack required only about 6 kB of RAM, allowing it to run on any Mac.
The relatively slow speed of AppleTalk allowed further reductions in cost. Instead of using RS-422's balanced transmit and receive circuits, the AppleTalk Personal Network cabling used a single common electrical ground, which limited speeds to about 500 kbit/s, but allowed one conductor to be removed. This meant that common three-conductor cables could be used for wiring. Additionally, the adaptors were designed to be "self-terminating", meaning that nodes at the end of the network could simply leave their last connector unconnected. There was no need for the wires to be connected back together into a loop, nor the need for hubs or other devices.
The system was designed for future expansion; the addressing system allowed for expansion to 255 nodes in a LAN (although only 32 could be used at that time), and by using "bridges" (which came to be known as "routers", although technically not the same) one could interconnect LANs into larger collections. "Zones" allowed devices to be addressed within a bridge-connected internet. Additionally, AppleTalk was designed from the start to allow use with any potential underlying physical link.
The main advantage of AppleTalk was that it was completely maintenance-free. To join a device to a network, you simply plugged the adaptor into the machine, then connected a cable from it to any free port on any other adaptor. AppleTalk's internal protocols negotiated a working network address number, automatically gave the computer a human-readable name, and collected up a list of the names and types of other machines on the network so the user could browse the devices through the GUI-based Chooser. AppleTalk was so easy to use that ad-hoc networks tended to appear whenever multiple Macs were in the same room. Apple would later use this in an advertisement showing a network being created between two seats in an airplane.
PhoneNet and other adaptors.
A thriving 3rd party market for AppleTalk devices developed over the next few years. One particularly notable example was an alternate adaptor designed by BMUG and commercialized by Farallon as PhoneNet in 1987. This was essentially a replacement for Apple's connector that had conventional phone jacks instead of Apple's round connectors. PhoneNet allowed AppleTalk networks to be connected together using normal telephone wires, and with very little extra work, could run analog phones and AppleTalk on a single four-conductor phone cable.
Other companies took advantage of the SCC's ability to read external clocks in order to support higher transmission speeds, up to 1 Mbit/s. In these systems the external adaptor also included its own clock, and used that to signal the SCC's clock input pins. The best known such system was Centram's FlashTalk, which ran at 768 kbit/s, and was intended to be used with their TOPS networking system. A similar solution was the 850 kbit/s DaynaTalk, which used a separate box that plugged in between the computer and a normal LocalTalk/PhoneNet box. Dayna also offered a PC expansion card that ran up to 1.7 Mbit/s when talking to other Dayna PC cards. Several other systems also existed with even higher performance, but these often required special cabling that was incompatible with LocalTalk/PhoneNet, and also required patches to the networking stack that often caused problems.
EtherTalk, TokenTalk and AppleShare.
By 1987 Ethernet was clearly winning the standards battle over Token Ring, and in the middle of that year Apple introduced EtherTalk 1.0 for the newly released Macintosh II computer. The package included both a NuBus card with Ethernet ports and a new Network control panel that allowed the user to select which physical connection to use for networking (from "Built-in" or "EtherTalk"). The release's new networking stack also expanded the system to allow a full 255 nodes per LAN. With its release, AppleTalk Personal Network was renamed LocalTalk. Token Ring would eventually be supported with the similar TokenTalk product, which used the same Network control panel and underlying software. Many third party companies would introduce compatible Ethernet and Token Ring cards that used these same drivers.
The appearance of EtherTalk also led to a problem: Networks with new and old Macs needed some way to communicate between each other. This could be as simple as a network of Ethernet Macs II trying to talk to a LaserWriter. Apple had considered the problem, and AppleTalk included the possibility for a low-cost LocalTalk-to-Ethernet bridge, but they felt it would be a low-volume product and left it to third parties. A number of companies responded, both existing communications vendors like Hayes and Cisco Systems, as well as newly formed companies like Kinetics. Contrary to Apple's belief these would be low-volume, by the end of 1987, 130,000 such systems were in use. AppleTalk was at that time the most used networking system in the world, with over three times the installations of any other vendor.
1987 also marked the introduction of the AppleShare product, a dedicated file server that ran on any Mac with 512 kB of RAM or more. A common AppleShare machine was the Mac Plus with an external SCSI hard drive. AppleShare was the #3 network operating system in the late 1980s, behind Novell NetWare and Microsoft MS-NET. AppleShare was effectively the replacement for the failed Macintosh Office efforts, which had been based on a dedicated file server device.
AppleTalk Phase II and other developments.
A significant re-design was released in 1989 as AppleTalk Phase II. In many ways, Phase II can be considered an effort to make the earlier version (never called Phase I) more generic. LANs could now support more than 255 nodes, and zones were no longer associated with physical networks, but were entirely virtual constructs used simply to organize nodes. For instance, one could now make a "Printers" zone that would list all the printers in an organization, or one might want to place that same device in the "2nd Floor" zone to indicate its physical location. Phase II also included changes to the underlying inter-networking protocols to make them less "chatty", which had previously been a serious problem on networks that bridged over wide-area networks.
By this point Apple had a wide variety of communications products under development, and many of these were announced along with AppleTalk Phase II. These included updates to EtherTalk and TokenTalk, AppleTalk software and LocalTalk hardware for the IBM PC, EtherTalk for Apple's A/UX operating system allowing it to use LaserPrinters and other network resources, and the Mac X.25 and MacX products.
Ethernet had become almost universal by 1990, and it was time to build Ethernet into Macs direct from the factory. However, the physical wiring used by these networks was not yet completely standardized. Apple solved this problem using a single port on the back of the computer into which the user could plug an adaptor for any given cabling system. This FriendlyNet system was based on the industry-standard Attachment Unit Interface or AUI, but deliberately chose a non-standard connector that was smaller and easier to use, which they called "Apple AUI", or AAUI. FriendlyNet was first introduced on the Quadra 700 and Quadra 900 computers, and used across much of the Mac line for some time. As with LocalTalk, a number of 3rd party FriendlyNet adaptors quickly appeared.
As 10-BASE-T became the de facto cabling system for Ethernet, second-generation Power Macintosh machines added a 10-BASE-T port in addition to the AAUI, and eventually dropped AAUI on Macs with the New World ROM, and 10-BASE-T was then universal.
The capital-I Internet.
In 1988 Apple had released MacTCP, a system that allowed the Mac to support TCP/IP on machines with suitable Ethernet hardware. However, this left many universities with the problem of supporting IP on their many LocalTalk-equipped Macs. Stanford University pioneered development of MacIP, which allowed IP packets to be routed over LocalTalk networks with the support of a suitable "gateway" machine. These were initially custom devices, but it was soon common to include MacIP support in LocalTalk-to-Ethernet bridges. MacTCP would now become a standard part of the Mac OS until 1994, by which time it also supported SNMP and PPP.
For some time in the early 1990s, the Mac was a primary client on the rapidly expanding Internet. Among the better known programs in wide use were Fetch, Eudora, eXodus, NewsWatcher and the NCSA packages, especially NCSA Mosaic and its offspring, Netscape Navigator. Additionally, a number of server products appeared that allowed the Mac to host Internet content. Through this period, Macs had about 2 to 3 times as many clients connected to the Internet as any other platform, despite the relatively small overall marketshare.
As the world quickly moved to IP for both LAN and WAN uses, Apple was faced with maintaining two increasingly outdated code bases on an ever-wider group of machines as well as the introduction of the PowerPC based machines. This led to the Open Transport efforts, which re-implemented both MacTCP and AppleTalk on an entirely new code base adapted from the Unix standard STREAMS. Early versions had problems and did not become stable for some time. By that point, Apple was deep in their ultimately doomed Copland efforts.
Legacy and abandonment.
With the purchase of NeXT and subsequent development of Mac OS X, AppleTalk was strictly a legacy system. Support was added to OS X in order to provide support for the large number of existing AppleTalk devices, notably laser printers and file shares, but alternate connection solutions common in this era, notably USB for printers, limited their demand. As Apple abandoned many of these product categories, and all new systems were based on IP, AppleTalk became less and less common. AppleTalk support was finally removed from the MacOS in Mac OS X v10.6 in 2009.
However, the loss of AppleTalk did not reduce the desire for networking solutions that combined its ease-of-use with IP routing. Apple has led development of many such efforts, from the introduction of the AirPort router to the development of the Zero configuration networking system and their implementation of it, Bonjour.
Design.
The AppleTalk design rigorously followed the OSI model of protocol layering. Unlike most of the early LAN systems, AppleTalk was not built using the archetypal Xerox XNS system. The intended target was not Ethernet, and it did not have 48-bit addresses to route. Nevertheless, many portions of the AppleTalk system have direct analogs in XNS.
One key differentiation for AppleTalk was it contained two protocols aimed at making the system completely self-configuring. The "AppleTalk address resolution protocol" ("AARP") allowed AppleTalk hosts to automatically generate their own network addresses, and the "Name Binding Protocol" ("NBP") was a dynamic system for mapping network addresses to user-readable names. Although systems similar to AARP existed in other systems, Banyan VINES for instance, nothing like NBP has existed until recently.
Both AARP and NBP had defined ways to allow "controller" devices to override the default mechanisms. The concept was to allow routers to provide the information or "hardwire" the system to known addresses and names. On larger networks where AARP could cause problems as new nodes searched for free addresses, the addition of a router could reduce "chattiness." Together AARP and NBP made AppleTalk an easy-to-use networking system. New machines were added to the network by plugging them and optionally giving them a name. The NBP lists were examined and displayed by a program known as the "Chooser" which would display a list of machines on the local network, divided into classes such as file-servers and printers.
Addressing.
An AppleTalk address was a 4-byte quantity. This consisted of a two-byte network number, a one-byte node number, and a one-byte socket number. Of these, only the network number required any configuration, being obtained from a router. Each node dynamically chose its own node number, according to a protocol (originally the LocalTalk Link Access Protocol LLAP and later the AppleTalk Address Resolution Protocol, AARP) which handled contention between different nodes accidentally choosing the same number. For socket numbers, a few well-known numbers were reserved for special purposes specific to the AppleTalk protocol itself. Apart from these, all application-level protocols were expected to use dynamically-assigned socket numbers at both the client and server end.
Because of this dynamism, users could not be expected to access services by specifying their address. Instead, all services had "names" which, being chosen by humans, could be expected to be meaningful to users, and also could be sufficiently long enough to minimize the chance of conflicts.
As NBP names translated to an address, which included a socket number as well as a node number, a name in AppleTalk mapped directly to a "service" being provided by a machine, which was entirely separate from the name of the machine itself. Thus, services could be moved to a different machine and, so long as they kept the same service name, there was no need for users to do anything different in order to continue accessing the service. And the same machine could host any number of instances of services of the same type, without any network connection conflicts.
Contrast this with "A records" in the DNS, where a name translates to a machine's address, not including the port number that might be providing a service. Thus, if people are accustomed to using a particular machine name to access a particular service, their access will break when the service is moved to a different machine. This can be mitigated somewhat by insistence on using "CNAME records" indicating service rather than actual machine names to refer to the service, but there is no way of guaranteeing that users will follow such a convention. Some newer protocols, such as Kerberos and Active Directory use DNS SRV records to identify services by name, which is much closer to the AppleTalk model.
Protocols.
AppleTalk Address Resolution Protocol.
AARP resolves AppleTalk addresses to link layer, usually MAC, addresses. It is functionally equivalent to ARP.
AARP is a fairly simple system. When powered on, an AppleTalk machine broadcasts an "AARP probe packet" asking for a network address, intending to hear back from controllers such as routers. If no address is provided, one is picked at random from the "base subnet", 0. It then broadcasts another packet saying "I am selecting this address", and then waits to see if anyone else on the network complains. If another machine has that address, it will pick another address, and keep trying until it finds a free one. On a network with many machines it may take several tries before a free address is found, so for performance purposes the successful address is "written down" in NVRAM and used as the default address in the future. This means that in most real-world setups where machines are added a few at a time, only one or two tries are needed before the address effectively become constant.
AppleTalk Data Stream Protocol.
This was a comparatively late addition to the AppleTalk protocol suite, done when it became clear that a TCP-style reliable connection-oriented transport was needed. Significant differences from TCP were:
Apple Filing Protocol.
The Apple Filing Protocol (AFP), formerly AppleTalk Filing Protocol, is the protocol for communicating with AppleShare file servers. Built on top of AppleTalk Session Protocol (for legacy AFP over DDP) or the Data Stream Interface (for AFP over TCP), it provides services for authenticating users (extensible to different authentication methods including two-way random-number exchange) and for performing operations specific to the Macintosh HFS filesystem. AFP is still in use in Mac OS X, even though most other AppleTalk protocols have been deprecated.
AppleTalk Session Protocol.
ASP was an intermediate protocol, built on top of ATP, which in turn was the foundation of AFP. It provided basic services for requesting responses to arbitrary "commands" and performing out-of-band status queries. It also allowed the server to send asynchronous "attention" messages to the client.
AppleTalk Transaction Protocol.
ATP was the original reliable transport-level protocol for AppleTalk, built on top of DDP. At the time it was being developed, a full, reliable connection-oriented protocol like TCP was considered to be too expensive to implement for most of the intended uses of AppleTalk. Thus, ATP was a simple request/response exchange, with no need to set up or tear down connections.
An ATP "request" packet could be answered by up to eight "response" packets. The requestor then sent an "acknowledgement" packet containing a bit mask indicating which of the response packets it received, so the responder could retransmit the remainder.
ATP could operate in either "at-least-once" mode or "exactly-once" mode. Exactly-once mode was essential for operations which were not idempotent; in this mode, the responder kept a copy of the response buffers in memory until successful receipt of a "release" packet from the requestor, or until a timeout elapsed. This way, it could respond to duplicate requests with the same transaction ID by resending the same response data, without performing the actual operation again.**
Datagram Delivery Protocol.
DDP was the lowest-level data-link-independent transport protocol. It provided a datagram service with no guarantees of delivery. All application-level protocols, including the infrastructure protocols NBP, RTMP and ZIP, were built on top of DDP. AppleTalk's DDP corresponds closely to the Network layer of the Open Systems Interconnection (OSI) communication model.
Name Binding Protocol.
NBP was a dynamic, distributed system for managing AppleTalk names. When a service started up on a machine, it registered a name for itself as chosen by a human administrator. At this point, NBP provided a system for checking that no other machine had already registered the same name. Later, when a client wanted to access that service, it used NBP to query machines to find that service. NBP provided browseability ("what are the names of all the services available?") as well as the ability to find a service with a particular name. Names were human readable, containing spaces, upper and lower case letters, and including support for searching.
AppleTalk Echo Protocol.
AEP (AppleTalk Echo Protocol) is a transport layer protocol designed to test the reachability of network nodes. AEP generates packets to be sent to the network node and is identified in the Type field of a packet as an AEP packet. The packet is first passed to the source DDP. After it is identified as an AEP packet, it is forwarded to the node where the packet is examined by the DDP at the destination. After the packet is identified as an AEP packet, the packet is then copied and a field in the packet is altered to create an AEP reply packet, and is then returned to the source node.
Printer Access Protocol.
PAP was the standard way of communicating with PostScript printers. It was built on top of ATP. When a PAP connection was opened, each end sent the other an ATP request which basically meant "send me more data". The client's response to the server was to send a block of PostScript code, while the server could respond with any diagnostic messages that might be generated as a result, after which another "send-more-data" request was sent. This use of ATP provided automatic flow control; each end could only send data to the other end if there was an outstanding ATP request to respond to.
PAP also provided for out-of-band status queries, handled by separate ATP transactions. Even while it was busy servicing a print job from one client, a PAP server could continue to respond to status requests from any number of other clients. This allowed other Macintoshes on the LAN that were waiting to print to display status messages indicating that the printer was busy, and what the job was that it was busy with.
Routing Table Maintenance Protocol.
RTMP was the protocol by which routers kept each other informed about the topology of the network. This was the only part of AppleTalk that required periodic unsolicited broadcasts: every 10 seconds, each router had to send out a list of all the network numbers it knew about and how far away it thought they were.
Zone Information Protocol.
ZIP was the protocol by which AppleTalk network numbers were associated with zone names. A "zone" was a subdivision of the network that made sense to humans (for example, "Accounting Department"); but while a network number had to be assigned to a topologically-contiguous section of the network, a zone could include several different discontiguous portions of the network.
Physical implementation.
The initial default hardware implementation for AppleTalk was a high-speed serial protocol known as "LocalTalk" that used the Macintosh's built-in RS-422 ports at 230.4 kbit/s. LocalTalk used a splitter box in the RS-422 port to provide an upstream and downstream cable from a single port. The topology was a bus: cables were daisy-chained from each connected machine to the next, up to the maximum of 32 permitted on any LocalTalk segment. The system was slow by today's standards, but at the time the additional cost and complexity of networking on PC machines was such that it was common that Macs were the only networked personal computers in an office. Other larger computers, such as UNIX or VAX workstations, would commonly be networked via Ethernet.
Other physical implementations were also available. One common replacement for LocalTalk was "PhoneNet", a 3rd party solution (from a company called Farallon, now called Netopia) that also used the RS-422 port and was indistinguishable from LocalTalk as far as Apple's LocalTalk port drivers were concerned, but ran over the two unused wires in standard four-wire phone cabling. PhoneNet was considerably less expensive to install and maintain. Ethernet and Token Ring was also supported, known as "EtherTalk" and "TokenTalk" respectively. EtherTalk in particular gradually became the dominant implementation method for AppleTalk as Ethernet became generally popular in the PC industry throughout the 1990s. Besides AppleTalk and TCP/IP, any Ethernet network could also simultaneously carry other protocols such as DECnet, NetBEUI, and IPX.
Cross-platform solutions.
When AppleTalk was first introduced, the dominant office computing platform was the PC compatible running MS-DOS. Apple introduced the AppleTalk PC Card in early 1987, allowing PCs to join AppleTalk networks and print to LaserWriter printers. A year later AppleShare PC was released, allowing PCs to access AppleShare file servers.
The "TOPS Teleconnector" MS-DOS networking system over AppleTalk system enabled MS-DOS PCs to communicate over AppleTalk network hardware; it comprised an AppleTalk interface card for the PC and a suite of networking software allowing such functions as file, drive and printer sharing. As well as allowing the construction of a PC-only AppleTalk network, it allowed communication between PCs and Macs with TOPS software installed. (Macs without TOPS installed could use the same network but only to communicate with other Apple machines.) The Mac TOPS software did not match the quality of Apple's own either in ease of use or in robustness and freedom from crashes, but the DOS software was relatively simple to use in DOS terms, and was robust.
The BSD and Linux operating systems support AppleTalk through an open source project called Netatalk, which implements the complete protocol suite and allows them to both act as native file or print servers for Macintosh computers, and print to LocalTalk printers over the network.
The Windows Server operating systems supported AppleTalk starting with Windows NT and ending after Windows Server 2003. Miramar included AppleTalk in its PC MacLAN product which was discontinued by CA in 2007. GroupLogic continues to bundle its AppleTalk protocol with its ExtremeZ-IP server software for Macintosh-Windows integration which supports Windows 2008 Server and Windows Vista as well prior versions. offers a proprietary implementation of the AppleTalk protocol stack, as part of their HELIOS UB2 server. This is essentially a File and Print Server suite that runs on a whole range of different platforms.
In addition, Columbia University released the Columbia AppleTalk Package (CAP) which implemented the protocol suite for various Unix flavors including Ultrix, SunOS, *BSD and IRIX. This package is no longer actively maintained.

</doc>
<doc id="2116" url="http://en.wikipedia.org/wiki?curid=2116" title="Apple II series">
Apple II series

The Apple II series (trademarked with square brackets as "Apple ][") is a set of home computers, one of the first highly successful mass-produced microcomputer products, designed primarily by Steve Wozniak, manufactured by Apple Computer (now Apple Inc.) and introduced in 1977 with the original Apple II. In terms of ease of use, features and expandability the Apple II was a major technological advancement over its predecessor, the Apple I, a limited-production bare circuit board computer for electronics hobbyists that pioneered many features that made the Apple II a commercial success. Introduced at the West Coast Computer Faire on April 16, 1977, the Apple II was among the first successful personal computers; it launched the Apple company into a successful business (and allowed several related companies to start). Throughout the years, a number of models were sold, with the most popular model remaining relatively little changed into the 1990s. While primarily an 8-bit computer, by mid-run a 16-bit model was introduced.
It was first sold on June 10, 1977. By the end of production in 1993, somewhere between five and six million Apple II series computers (including about 1.25 million Apple II models) had been produced. The Apple II was one of the longest running mass-produced home computers, being in production just under 17 years.
The Apple II became one of several recognizable and successful computers during the 1980s and early 1990s, although this was mainly limited to the USA. It was aggressively marketed through volume discounts and manufacturing arrangements to educational institutions which made it the first computer in widespread use in American secondary schools. The effort to develop educational and business software for the Apple II, including the 1979 release of the popular VisiCalc spreadsheet, made the computer especially popular with business users and families.
The original Apple II operating system was in ROM along with Integer BASIC. Programs were entered, then saved and loaded on cassette tape. When the Disk II was implemented in 1978 by Steve Wozniak, a Disk Operating System or DOS was commissioned from the company Shepardson where its development was done by Paul Laughton. The final and most popular version of this software was Apple DOS 3.3. Some commercial Apple II software booted directly and did not use standard DOS formats. This discouraged the copying or modifying of the software on the disks and improved loading speed. Apple DOS was superseded by ProDOS, which supported a hierarchical filesystem and larger storage devices. With an optional third-party Z80-based expansion card the Apple II could boot into the CP/M operating system and run WordStar, dBase II, and other CP/M software. At the height of its evolution, towards the late 1980s, the platform had the graphical look of a hybrid of the Apple II and Macintosh with the introduction of the Apple II. By 1992, the platform had 16-bit processing capabilities, a mouse-driven Graphical User Interface, and graphics and sound capabilities far beyond the original.
Despite the introduction of the Motorola 68000-based Apple Macintosh in 1984 the Apple II series still reportedly accounted for 85% of the company's sales in the first quarter of fiscal 1985, and remained the company's primary revenue source for most of the following decade. At its peak, it was a billion-dollar-a-year industry with its associated community of third-party developers and retailers. The Apple II was sold until the end of 1992; the last II-series Apple in production, the IIe, was discontinued on October 15, 1993.
Design.
The Apple II was designed to look more like a home appliance than a piece of electronic equipment. The lid popped off the beige plastic case without the use of tools, allowing access to the computer's internals, including the motherboard with eight expansion slots, and an array of random access memory (RAM) sockets that could hold up to 48 kilobytes worth of memory chips.
The Apple II had color and high-resolution graphics modes, sound capabilities and one of two built-in BASIC programming languages (initially Integer BASIC, later Applesoft BASIC). The Apple II was targeted for the masses rather than just hobbyists and engineers; it also influenced most of the microcomputers that followed it. Unlike preceding home microcomputers, it was sold as a finished consumer appliance rather than as a kit (unassembled or preassembled). "VanLOVEs Apple Handbook" and "The Apple Educators Guide" by Gerald VanDiver and Rolland Love reviewed more than 1,500 software programs that the Apple II series could use. The Apple dealer network used this book to emphasize the growing software developer base in education and personal use. 
The Apple II series had a keyboard built into the motherboard shell, with the exception of the Apple II which featured an external keyboard. An upgrade kit was sold later to house the motherboard of an Apple II in an Apple IIe case.
Models.
Early II-series models were usually designated "Apple ]["; later models "Apple //", plus a letter suffix.
Apple II.
The first Apple II computers went on sale on June 10, 1977 with a MOS Technology 6502 microprocessor running at 1 MHz, 4 KB of RAM, an audio cassette interface for loading programs and storing data, and the Integer BASIC programming language built into the ROMs. The video controller displayed 40 columns by 24 lines of monochrome, upper-case-only (the original character set matches ASCII characters 0x20 to 0x5F) text on the screen, with NTSC composite video output suitable for display on a TV monitor, or on a regular TV set by way of a separate RF modulator. The original retail price of the computer was US$1298 (with 4 kB of RAM) and US$2638 (with the maximum 48 kB of RAM). To reflect the computer's character cell color graphics capability, the Apple logo on the casing was represented using rainbow stripes, which remained a part of Apple's corporate logo until early 1998. The earliest Apple IIs were assembled in Silicon Valley, and later in Texas; printed circuit boards were manufactured in Ireland and Singapore.
An external 5¼-inch floppy disk drive, the Disk II, attached via a controller card that plugged into one of the computer's expansion slots (usually slot 6), was used for data storage and retrieval to replace cassettes. The Disk II interface, created by Steve Wozniak, was regarded as an engineering masterpiece for its economy of electronic components. While other controllers had dozens of chips for synchronizing data I/O with disk rotation, seeking the head to the appropriate track, and encoding the data into magnetic pulses, Wozniak's controller card had few chips; instead, the Apple DOS used software to perform these functions. The Group Code Recording used by the controller was simpler and easier to implement in software than the more common MFM. In the end, the low chip count of the controller helped make Apple's Disk II the first affordable floppy drive for personal computers. As a side effect, Wozniak's scheme made it easy for proprietary software developers to copy-protect the media on which their software shipped by changing the low-level sector format or stepping the drive's head between the tracks; inevitably, other companies eventually sold software to foil this protection. Another Wozniak optimization allowed him to omit Shugart's Track-0 sensor. When the Operating System wants to go to track 0, the controller simply moves 40 times toward the next-lower-numbered track, relying on the mechanical stop to prevent it going any further down than track 0. This process, called "recalibration", made a loud buzzing (rapid mechanical chattering) sound that often frightened Apple novices.
The approach taken in the Disk II controller was typical of Wozniak's design sensibility. The Apple II used several engineering shortcuts to save hardware and reduce costs. For example, taking advantage of the way that 6502 instructions only access memory every other clock cycle, the video generation circuitry's memory access on the otherwise unused cycles avoided memory contention issues and also eliminated the need for a separate refresh circuit for the DRAM chips. Rather than use a complex analog-to-digital circuit to read the outputs of the game controller, Wozniak used a simple timer circuit whose period was proportional to the resistance of the game controller, and used a software loop to measure the timer.
The text and graphics screens had a complex arrangement (the scanlines were not stored in sequential areas of memory) which was reputedly due to Wozniak's realization that doing it that way would save a chip; it was less expensive to have software calculate or look up the address of the required scanline than to include the extra hardware. Similarly, in the high-resolution graphics mode, color was determined by pixel position and could thus be implemented in software, saving Wozniak the chips needed to convert bit patterns to colors. This also allowed for sub-pixel font rendering since orange and blue pixels appeared half a pixel-width further to the right on the screen than green and purple pixels.
Color on the Apple II series took advantage of a quirk of the NTSC television signal standard, which made color display relatively easy and inexpensive to implement. The original NTSC television signal specification was black-and-white. Color was tacked on later by adding a 3.58-MHz subcarrier signal that was partially ignored by B&W TV sets. Color is encoded based on the "phase" of this signal in relation to a reference "color burst" signal. The result is that the position, size, and intensity of a series of pulses define color information. These pulses can translate into "pixels" on the computer screen.
The Apple II display provided two pixels per subcarrier cycle. When the color burst reference signal was turned on and the computer attached to a color display, it could display green by showing one alternating pattern of pixels, magenta with an opposite pattern of alternating pixels, and white by placing two pixels next to each other. Later, blue and orange became available by tweaking the offset of the pixels by half a pixel-width in relation to the colorburst signal. The high-resolution display offered more colors simply by compressing more, narrower pixels into each subcarrier cycle. The coarse, low-resolution graphics display mode worked differently, as it could output a short burst of high-frequency signal per pixel to offer more color options.
The epitome of the Apple II design philosophy was the Apple II sound circuitry. Rather than having a dedicated sound-synthesis chip, the Apple II had a toggle circuit that could only emit a click through a built-in speaker or a line out jack; all other sounds (including two, three and, eventually, four-voice music and playback of audio samples and speech synthesis) were generated entirely by software that clicked the speaker at just the right times. Not for nearly a decade would an Apple II be released with a dedicated sound chip (though with six expansion slots, users could add sound functionality with various sound cards). Similar techniques were used for cassette storage: the cassette output worked the same as the speaker, and the input was a simple zero-crossing detector that served as a crude (1-bit) audio digitizer. Routines in the ROM were used to encode and decode data in frequency-shift keying for the cassette. Since the Apple II mainboard had no interrupts, it was impossible to use the speaker without taking CPU time and so most games had little sound.
Wozniak's open design and the Apple II's multiple expansion slots permitted a wide variety of third-party devices, including Apple II peripheral cards such as serial controllers, display controllers, memory boards, hard disks, networking components, and realtime clocks. There were plug-in expansion cards – such as the "Z80-card" – that permitted the Apple to use the Z80 processor and run a multitude of programs developed under the CP/M operating system, including the dBase II database and the WordStar word processor. There was also a third-party 6809 card that would allow OS-9 Level One to be run. Third-party sound cards greatly improved audio capabilities, allowing simple music synthesis and text-to-speech functions. Eventually, Apple II accelerator cards were created to double or quadruple the computer's speed.
The original Apple II was discontinued at the start of 1981, having been superseded by the II+. An estimated 40,000 machines were sold for its 4-year production run.
Apple II Plus.
The Apple II Plus, introduced in June 1979, included the Applesoft BASIC programming language in ROM. This Microsoft-authored dialect of BASIC, which was previously available as an upgrade, supported floating-point arithmetic, and became the standard BASIC dialect on the Apple II series (though it ran at a noticeably slower speed than Steve Wozniak's Integer BASIC).
Except for improved graphics and disk-booting support in the ROM, and the removal of the 2k 6502 assembler/disassembler to make room for the floating point BASIC, the II+ was otherwise identical to the original II. RAM prices fell during 1980–81 and all II+ machines came from the factory with a full 48k of memory already installed. The language card in Slot 0 added another 16k, but it had to be bank switched since the remaining CPU address space was occupied by the ROMs and I/O area. For this reason, the extra RAM in the language card was bank-switched over the machine's built-in ROM, allowing code loaded into the additional memory to be used as if it actually were ROM. Users could thus load Integer BASIC into the language card from disk and switch between the Integer and Applesoft dialects of BASIC with DOS 3.3's INT and FP commands just as if they had the BASIC ROM expansion card. The language card was also required to use the UCSD Pascal and FORTRAN 77 compilers, which were released by Apple at about the same time. These ran under the UCSD p-System operating system, which had its own disk format and emitted code for a "virtual machine" rather than the actual 6502 processor.
A TEMPEST-approved version of the Apple II Plus was created in 1980 by the Georgia Tech Research Institute for U.S. Army FORSCOM, and used as a component in the earliest versions of the Microfix system. Fielded in 1982, the Microfix system was the first tactical system using video disk (Laserdisk) map technology providing zoom and scroll over map imagery coupled with a point database of intelligence data such as order of battle, airfields, roadways, and bridges.
Apple II Europlus and J-Plus.
After the success of the first Apple II in the United States, Apple expanded its market to include Europe, Australia and the Far East in 1979, with the Apple II Europlus (Europe, Australia) and the Apple II J-Plus (Japan). In these models, Apple made the necessary hardware, software and firmware changes in order to comply to standards outside of the U.S. The power supply was modified to accept the local voltage, and in the European and Australian model the video output signal was changed from color NTSC to monochrome PAL – an extra video card was needed for color PAL graphics, since the simple tricks Wozniak had used to generate a pseudo-NTSC signal with minimal hardware did not carry over to the more complex PAL system. In the Japanese version of the international Apple, the keyboard layout was changed to allow for Katakana writing (full Kanji support was clearly beyond the capabilities of the machine), but in most other countries the international Apple was sold with an unmodified American keyboard; thus the German model still lacked the umlauts, for example. For the most part, the Apple II Europlus and J-Plus were identical to the Apple II Plus. Production of the Europlus ended in 1983.
Apple IIe.
The Apple II Plus was followed in 1983 by the Apple IIe, a cost-reduced yet more powerful machine that used newer chips to reduce the component count and add new features, such as the display of upper and lowercase letters and a standard 64 kB of RAM.
The IIe RAM was configured as if it were a 48 kB Apple II Plus with a language card; the machine had no slot 0, but instead had an auxiliary slot that for most practical purposes took the place of slot 3, the most commonly used slot for 80-column cards in the II Plus.
The auxiliary slot could accept a 1 kB memory card to enable the 80-column display. This card contained only RAM; the hardware and firmware for the 80-column display was built into the Apple IIe, remaining fairly compatible with the older Videx-style cards, even though the low-level details were very different. An "extended 80-column card" with more memory expanded the machine's RAM to 128 kB.
As with the language card, the memory in the 80-column card was bank-switched over the machine's main RAM; this made the memory better suited to data storage than to running software, and in fact the ProDOS operating system, which was introduced with the Apple IIe, would automatically configure this memory as a RAM disk upon booting.
Third-party aux-slot memory cards later allowed expansion up to 1 MB. The 80-column card also enabled one new graphics mode, Double Lo-Res (80×48 pixels). The extended 80-column card enabled two, Double Lo-Res and Double Hi-Res (560×192 pixels). Both modes doubled the horizontal resolution in comparison to the standard Lo-Res (40×48) and Hi-Res (280×192) Modes; in the case of Double Hi-Res, the number of available colors was increased as well, from 6 to 15. Apple IIes from the very first production run could not use Double Hi-Res. Neither of these modes was directly supported by the built-in BASIC, however, so the user had to resort to the use of lots of POKE and CALL commands in BASIC, or assembly language programming, or one of a number of software Toolkits to exploit these modes.
While it was possible for software to switch out the 80-column firmware, making the firmware of a card in slot 3 available with a card in the auxiliary slot, it was not a common thing to do. However, even with the 80-column firmware enabled, slot 3's I/O memory range was still usable, giving it approximately the capability of slot 0 on a II or II plus. This meant that it actually was possible to use slot 3 for things, such as coprocessor cards and language cards, that did not use slot firmware space.
Introduced with the IIe was the DuoDisk, essentially two Disk II 5.25-inch drives in a single enclosure designed to stack between the computer and the monitor, and a new controller card to run it. This controller was (by design) functionally identical to the original Disk II controller but used a different connector, allowing a single cable to control both drives in the DuoDisk. The DuoDisk was plagued by reliability problems, however, and did not catch on as well as the Apple IIe itself.
The Apple IIe was the most popular Apple II ever built and was widely considered the "workhorse" of the line. It also has the distinction of being the longest-lived Apple computer of all time – it was manufactured and sold with only minor changes for nearly 11 years. In that time, following the original, two important variations were introduced known as the Apple IIe Enhanced (four new replacement chips to give it some of the features of the later model Apple IIc, including an upgraded processor called the 65C02) and the Apple IIe Platinum (a modernized new look for the case color to match other Apple products of the era, along with the addition of a built-in numeric keypad). An Enhanced IIe with 128 kB of RAM can be considered the minimum requirement for running most Apple II software released after about 1988. //e models were distinguished from the standard IIe by having 128k of memory, DHGR graphics mode, and a 65C02 CPU.
Two and a half years before the Apple IIe, Apple produced and unsuccessfully marketed a computer called the "Apple III" for business users. Some of its features were carried over in the design of the Apple IIe. Among them was the ProDOS operating system, which was based on Apple III's Sophisticated Operating System (SOS).
Apple IIc.
Apple released the Apple IIc in April 1984, billing it as a portable Apple II, because it could be easily carried, though unlike modern portables it lacked a built-in display and battery. The IIc even sported a carrying handle that folded down to prop the machine up into a typing position. It was the first of three Apple II models to be made in the Snow White design language, and the only one that used its unique creamy off-white color. (The other Snow White computers from the Apple II series, the II and the IIc Plus, were light gray, called "Platinum" by Apple.) The obsolete cassette port was omitted from the IIc.
The Apple IIc was the first Apple II to use the 65C02 low-power variant of the 6502 processor, and featured a built-in 5.25-inch floppy drive and 128 kB RAM, with a built-in disk controller that could control external drives, composite video (NTSC or PAL), serial interfaces for modem and printer, and a port usable by either a joystick or mouse. Unlike previous Apple II models, the IIc had no internal expansion slots at all, this being the means by which its compact size was attained. Third parties did eventually figure out how to wedge up to 1 MB of additional memory and a real-time clock into the machine, and a later revision of the motherboard provided an expansion slot that could accept an Apple memory card bearing up to 1 MB of RAM. The disk port, originally intended for a second 5.25-inch floppy drive, eventually was able to interface to 3½-inch disk drives and (via third parties) even hard disks.
IIc machines supported the 16 color DHGR (double hi-resolution graphics) graphics mode and from a software standpoint were identical to the //e.
To play up the portability, two different monochrome LCD displays were sold for use with the IIc's video expansion port, although both were short-lived due to high cost and poor legibility. (An Apple IIc with the smaller of these displays appeared briefly in the film "2010".) The IIc had an external power supply that converted AC power to 12 V DC, allowing third parties to offer battery packs and automobile power adapters that connected in place of the supplied AC adapter.
The Apple IIc (in its American version) was the first microcomputer to include support for the Dvorak Simplified Keyboard, which was activated using a switch above the keyboard. This feature was also later found in late-model American Apple IIe computers (though the switch was inside the computer) and in the Apple II (accessible via the built-in control panel). The international models used the same mechanism to switch between the localized and the American keyboard layouts, but did not offer Dvorak.
Apple II.
The next member of the line was the Apple II computer, released on September 15, 1986. A radical departure from the existing Apple II line, the II featured a true 16-bit microprocessor, the 65C816, operating at with 24-bit addressing, allowing expansion up to 8 MB of RAM without the bank-switching hassles of the earlier machines (RAM cards with more than 4 MB were never directly supported by Apple). It introduced two completely new graphic modes sporting higher resolutions with a palette of 4,096 colors and up to 256 colors on screen; however, only 4 (at 640×200 resolution) or 16 (at 320×200 resolution) colors could be used on a single line at a time.
In a departure from earlier Apple II graphics modes, the new modes laid out the scanlines sequentially in memory and up to 16 scanline changes could be made (i.e. 16 palettes of 16 distinct colors each, equals 256 colors) without slowing down the CPU. However, programmers in search of a graphics challenge could always turn to 3200-color mode, which involved precisely swapping in a different 16-color palette for each of the screen's 200 scanlines as the monitor's electron beam traced the screen line by line. This exotic technique did not leave many CPU cycles available for other processing, so this "mode" was best suited to displaying static images.
The Apple II stood out from any previous (or future) Apple II models, evolving and advancing the platform into the next generation of computing while still maintaining near-complete backward compatibility. The secret of the Apple II's compatibility was a single chip called the Mega II, which contained the functional equivalent of an entire Apple IIe computer (sans processor). This, combined with the flawless 65C02 emulation mode of the 65C816 processor, provided full support for legacy software.
The computer also included a 32-voice Ensoniq 5503, 'wavetable' sample-based music synthesizer chip with 64 kB dedicated RAM, 256 kB (or later 1.125 MB) of standard RAM, built-in peripheral ports (switchable between IIe-style card slots and IIc-style onboard controllers for disk drives, mouse, RGB video, and serial devices), built-in AppleTalk networking, and a ROM toolbox that supported a graphical user interface derived from the Macintosh toolbox. The computer could run existing 8-bit Apple II software (including software written for the very first Apple II in Integer BASIC), but also supported 16-bit software running under a new (albeit modified) OS called ProDOS 16 and later replaced by a full 16-bit OS called GS/OS. The new OS eventually included a Finder that could be used for managing disks and files and opening documents and applications, along with desk accessories – just like the Macintosh. The 16-bit operating system would automatically switch to the text display and downshift to 8-bit mode to run legacy software, while offering a consistent, Macintosh-like graphical interface for native 16-bit applications. Eventually, the II gained the ability to read and write Macintosh disks and, through third-party software, even multitasking (both cooperative and preemptive, the latter in the form of a Unix-type shell), outline TrueType font support, and in one case, even real-time 3D gaming using texture mapping.
The first 50,000 Apple II computers came with Steve Wozniak's ""Woz" signature silkscreened on the front and were referred to as the "Woz Limited Edition"". These machines are not functionally different from machines from the same time period without the signature.
Apple IIc Plus.
The final Apple II model was the Apple IIc Plus introduced in 1988. It was the same size and shape as the IIc that came before it, but the 5.25-inch floppy drive had been replaced with a 3½-inch drive, the power supply was moved inside (gone was the IIc's "brick on a leash" power supply), and the processor was a fast 65C02 processor that actually ran 8-bit Apple II software faster than the II. (Third-party accelerators for other models could, however, go as fast as , and II accelerators would eventually reach .) The IIc Plus's accelerator was derived from a design licensed from Zip Technologies, a third-party maker of accelerators for the Apple II, though Apple used separate chips instead of combining the processor, cache, and supporting logic on a multi-chip module as did Zip. Like later models of the original Apple IIc, the IIc Plus included a memory expansion slot that would accept a daughter-card carrying up to a megabyte of RAM. The IIc Plus also featured a new keyboard layout that matched the Platinum IIe and II. Unlike the IIe, IIc and II, the IIc Plus came only in one version (American) and was not officially sold anywhere outside the USA.
Many perceived the IIc Plus as Apple's attempt to compete with the Laser 128EX/2, a popular third party Apple-compatible machine that also had an accelerated processor and a built-in 3.5-inch drive. There were few other rational explanations for Apple expending resources on the continued development of a new 8-bit Apple II model rather than furthering the 16-bit Apple II. However, with its 3.5-inch drive and speedy processor, it was an excellent, compact machine for running the AppleWorks integrated productivity package, especially with the 1 MB memory upgrade.
Apple IIe Card.
Although not an extension of the Apple II line, in 1990 the Apple IIe Card, an expansion card for the LC line of Macintosh computers, was released. Essentially a miniaturized Apple IIe computer on a card (using the Mega II chip from the Apple II), it allowed the Macintosh to run 8-bit Apple IIe software through hardware emulation (although video was emulated in software and was slower at times than a IIe). Many of the LC's built-in Macintosh peripherals could be "borrowed" by the card when in Apple II mode (i.e. extra RAM, 3.5-inch floppy, AppleTalk networking, hard disk). The IIe card could not, however, run software intended for the 16-bit Apple II. The Macintosh LC with IIe Card was intended to replace the Apple II in schools and homes and was presumably the reason a new model Apple II that was confirmed by insiders to be in development at one point was cancelled and never released.
Final years.
Apple's Macintosh product line finally eclipsed the Apple II in the early 1990s. Even after the Macintosh's introduction, the Apple II had remained the company's primary revenue source for years. The computer was the first to attract a loyal user community and many outspoken Apple II fans were bitter that the company had invested its Apple II profits into the Macintosh rather than using them to further the Apple II series.
Apple continued to sell Apple II systems alongside the Macintosh until terminating the II in December 1992 and the IIe in November 1993.
Advertising, marketing, and packaging.
Mike Markkula, a retired Intel marketing manager, provided the early critical funding for Apple Computer. From 1977–1981, Apple used the Regis McKenna agency for its advertisements and marketing. In 1981, Chiat-Day acquired Regis McKenna's advertising operations and Apple used Chiat-Day. At Regis McKenna Advertising, the team assigned to launch the Apple II consisted of Rob Janoff, art director, Chip Schafer, copywriter and Bill Kelley, account executive. Janoff came up with the Apple logo with a bite out of it. The design was originally an olive green with matching company logotype all in lower case. Steve Jobs insisted on promoting the color capability of the Apple II by putting rainbow stripes on the Apple logo. In its letterhead and business card implementation, the rounded "a" of the logotype echoed the "bite" in the logo. This logo was developed simultaneously with an advertisement and a brochure; the latter being produced for distribution initially at the first West Coast Computer Faire. Ever since the original Apple II, Apple has paid high attention to its quality of packaging, partly because of Steve Jobs' personal preferences and opinions on packaging and final product appearance. All of Apple's packaging for the Apple II series looked similar, featuring lots of clean white space and showing the Apple rainbow logo prominently. For several years up until the late 1980s, Apple used the Motter Tektura font for packaging, until changing to the Apple Garamond font.
Apple ran the first advertisement for the Apple II, a two-page spread ad titled "Introducing Apple II", in "BYTE" in July 1977. The first brochure, was entitled "Simplicity" and the copy in both the ad and brochure pioneered "demystifying" language intended to make the new idea of a home computer more "personal." The Apple II introduction ad was later run in the September 1977 issue of "Scientific American".
For the Apple IIc, Apple wanted an advertisement to demonstrate the power of the machine despite its small size; they ran a memorable television commercial featuring a high-rise office building in which they claimed with words and images that the IIc had all the power necessary to run a large building, suggesting that it had more than enough power for the home user. (This ad, along with the "1984" Macintosh ad, was featured in a Marketing telecourse run on PBS.)
Apple later aired eight television commercials for the Apple II, emphasizing its benefits to education and students, along with some print ads.
Towards the end of 1982, art director Brent Thomas and Steve Hayden came up with the idea of doing an advertising campaign based on the timely tagline "Why 1984 will not be like 1984". Chiat-Day shopped it around to a number of clients, including Apple, where it was proposed to be used for a print ad in the Wall Street Journal promoting the Apple II. However, Apple did not go for it, and the idea was filed away until the spring of 1983, when they met with the Macintosh marketing team to start working on the launch, which was scheduled for January 1984. The idea eventually became the famous "1984" commercial which aired during the third quarter at Super Bowl XVIII.
Clones.
The Apple II was frequently cloned, both in the United States and abroad – similar cloning of the IBM PC later occurred. According to some sources (see below), more than 190 different models of Apple II clones were manufactured.
Without explicitly stating that they were Apple II clones, many had "fruit" names (for example, "Pineapple" and "Pearcom"). Apple successfully forced the "Pineapple" to change its name to "Pinecom". Well known in the Soviet Bloc were the Agat, an oversized Russian Apple II clone with a Cyrillic character set, and Bulgarian Pravetz series 8, a close Apple II replica with Cyrillic support.
Basis, a German company, created the Basis 108, a clone for the Apple II that included both a 6502 processor and the Zilog Z80, allowing it to run the CP/M operating system as well as most Apple II software. This machine was unusual in that it was housed in a heavy cast aluminum chassis. The Basis 108 was equipped with built-in Centronics (parallel) and RS232c (serial) ports, as well as the standard six Apple II compatible slots. Unlike the Apple II it came with a detached full-stroke keyboard (AZERTY/QWERTY) of 100 keys plus 15 functions keys and separate numeric and editing keypads.
Another European Apple II Clone was the Pearcom Pear II, which was quite a bit larger as the original as it sported not eight but fourteen expansion slots. It also had a numerical keypad. Pearcom initially used a pear shaped rainbow logo, but stopped using the logo after Apple threatened to sue.
A Bosnian (at the time part of Yugoslavia) company named IRIS Computers (sub company of biggest electric company in Bosnia and Herzegovina and Yugoslavia ENERGOINVEST) produced Apple II clones starting in the early 1980s. Their official brand name was IRIS 8. They were very expensive and hard to obtain and were produced primarily for use in early computerized digital telephone systems and for education. Their use in offices of the state companies, R&D labs and in the Yugoslav army was also reported. IRIS 8 machines looked like early IBM PCs, with a separate central unit accompanied by a cooling system and two 5.25-inch disks, monitor, and keyboard. Compatibility with the original Apple II was complete. Elite high schools in Yugoslavia and especially Bosnia and Herzegovina were equipped with clusters of 8, 16, or 32 IRIS 8 computers connected in a local network administrated by an IRIS 16 PC clone. The number of IRIS 8s produced is believed to be on the order of 10 or 20 thousand.
An Australian-produced clone of the Apple II was the Medfly, named after the Mediterranean fruit fly that attacks apples. The Medfly computer featured a faster processor, more memory, detached keyboard, lower and upper case characters, and a built-in disk controller.
Until 1992 in Brazil, it was illegal to import microcomputers. Because of that, the illegal cloning of Apple II-based computers was huge there. In the early 1980s, there were around 20 different clones of Apple II Plus computers in that country, all of them using illegally copied software and hardware (since the Apple II and II Plus used commonly-available TTL integrated circuits). Some of the names include Elppa ("Apple" backwards), Maxtro, Exato MC4000 (by CCE), AP II (by Unitron), and even an "Apple II plus" (manufactured by a company called Milmar, which was using the name illegally). There were only two clones of the Apple IIe, since this model used custom IC chips that couldn't be copied, and therefore had to be reversed-engineered and developed in the country. These clones were the TK3000 IIe by Microdigital and Exato IIe by CCE. In addiiton, the Laser IIc was manufactured by Milmar and, despite the name, was a clone of the Apple II Plus, not of the Apple IIc, although it had a design similar to that of the Apple IIc, with an integrated floppy controller and 80-column card, but without an integrated floppy disk drive.
The Ace clones from Franklin Computer Corporation are the best known and had the most lasting impact, as Franklin copied Apple's ROMs and software and freely admitted to doing so. Franklin's argument: a computer's ROM was simply a pattern of switches locked into a fixed position, and one cannot copyright a pattern of switches. Apple fought Franklin in court for about five years to get its clones off the market, and was ultimately successful when a court ruled that software stored in ROM was in fact copyrightable in the U.S. (See Apple Computer, Inc. v. Franklin Computer Corp.) Franklin later released non-infringing but less-compatible clones; these could run ProDOS and AppleWorks and had an Applesoft-like BASIC, but compatibility with other software was hit-or-miss.
Apple also challenged VTech's Laser 128, an enhanced clone of the Apple IIc first released in 1984, in court. This suit proved less fruitful for Apple, because VTech had reverse-engineered the Monitor ROM rather than copying it and had licensed Applesoft BASIC from its creator, Microsoft. Apple had neglected to obtain exclusive rights to the Applesoft dialect of BASIC from Microsoft; VTech was the first cloner to license it. The Laser 128 proved popular and remained on the market for many years, both in its original form and in accelerated versions that ran faster than . Although it was not 100% compatible with the Apple II, it was close, and its popularity ensured that most major developers tested their software on a Laser as well as on genuine Apple machines. Because it was frequently sold via mail order and mass-market retailers such as Sears, the Laser 128 may have cut into the sales of low-cost competitors such as Commodore Business Machines as much as it did Apple's.
While the first Apple II clones were generally exact copies of their Apple counterparts that competed mainly on price, many clones had extra capabilities too. A Franklin model, the Ace 1000, sported a numeric keypad and lower-case long before these features were added to the Apple II line. The Laser 128 series is sometimes credited with spurring Apple to release the Apple IIc Plus; the built-in 3½-inch drive and accelerated processor were features Laser had pioneered. The Laser 128 also had a IIe-style expansion slot on the side that could be used to add peripheral cards.
Bell & Howell, an audiovisual equipment manufacturer whose products (particularly film projectors) were ubiquitous in American schools, offered what appeared at first glance to be an Apple II Plus clone in a distinctive black plastic case. However, these were in fact real Apple II Plus units manufactured by Apple for B&H for a brief period of time. Many schools had a few of these Black Apple or Black "Darth Vader" Apples in their labs.
ITT made the ITT 2020, a licensed Apple ][ Plus clone, in the UK. It has the same shape as the Apple ][ but is matte silver (it was sometimes known as the "silver Apple") and is not an exact copy functionally. The ITT2020 produced a PAL video signal for the European market, where the domestic US market used NTSC. Software using the BIOS worked correctly on both the Apple and ITT, but software written to access the Apple's display hardware directly, bypassing the BIOS, displayed with vertical stripes on the ITT 2020. The Apple itself was later introduced in the UK, and both the Apple ][ and ITT 2020 were sold for a time, the ITT at a lower price.
Syscom 2 Inc (from Carson City, NV) created the Syscom 2 Apple ][+ clone. The case looked nearly identical. They had 48 k RAM and the normal expansion capabilities. These clones also supported lower case characters, toggled with a ^O keystroke.
An unknown company produced a clone called the RX-8800. One new feature it had was a numeric keypad.
One of the best Apple ][ clones, SEKON, made in Taiwan, had the same color plastic case as an Apple ][, sported 48k of RAM standard, and a lower-uppercase switch, located where the power light indicator was typically situated on Apple ]['s. Additionally, it featured a 5-amp power supply which supplied ample power for add-on cards, whereas Apple Corp. shipped Apple ]['s with 2.5 amp supplies which often burned up (along with the computer!). The SEKON company avoided shipments being confiscated by U.S. Customs, by shipping their computers without ROMS, leaving it to the dealers to populate the boards upon arrival to their private stores. Often these machines would boot up with a familiar logo - "Apple ][", after the dealers simply burned E-proms of original Apple ROMS and popped them in. The obvious motivation for this illegal activity was so that users could obtain a 100% Apple-compatible clone for usually around US$600, as opposed to US$2500 from Apple.
Although not technically a clone, Quadram produced an add-in ISA card, called the Quadlink, that provided hardware emulation of an Apple II+ for the IBM PC. The card had its own 6502 CPU and dedicated 80 K RAM (64 K for applications, plus 16 K to hold a reverse-engineered Apple ROM image, loaded at boot-time), and installed "between" the PC and its floppy drive(s), color display, and speaker, in a pass-through configuration. This allowed the PC to operate in a dual-boot fashion: when booted through the Quadlink, the PC could run the majority of II software, and read and write Apple-formatted floppies through the standard PC floppy drive. Because it had a dedicated processor, rather than any form of software emulation, this system ran at nearly the same speed as an equivalent Apple machine. Another company, Diamond Computer Systems, produced a similar card called the Trackstar, that had both a 6502 and a Z80, allowing use of software for both Apple DOS and Apple CP/M. The Trackstar also had a connector allowing use of an actual Apple floppy drive, which enhanced its compatibility with software that took advantage of Apple hardware for copy-protection.
Since the Apple II used so many unique concepts, many of them patented as well as copyrighted, Apple Computer was able to work with the U.S. Customs service to stop the importation of many of the clones into the United States.
Most of the clone manufacturers chose to stop production on their own once the IBM PC became popular since it was possible to make legitimate clones of the PC which wouldn't violate any of IBM's patents or copyrights.
General.
Data storage.
Originally the Apple II used audio cassette tapes for program and data storage. A dedicated tape recorder along the lines of the Commodore Datasette was never produced; Apple recommended using the Panasonic RQ309 in some of its early printed documentation. The uses of common consumer cassette recorders and a standard video monitor or television set (with a third party R-F modulator) made the total cost of owning an Apple II less expensive and helped contribute to the Apple II's success.
Cassette storage may have been inexpensive, but it was also slow and unreliable. The Apple II's lack of a disk drive was "a glaring weakness" in what was otherwise intended to be a polished, professional product. Recognizing that the II needed a disk drive to be taken seriously, Apple set out to develop a disk drive and a DOS to run it. Wozniak spent the 1977 Christmas holidays designing a disk controller that reduced the number of chips used by a factor of 10 compared to existing controllers. Still lacking a DOS, and with Wozniak inexperienced in operating system design, Jobs approached Shepardson Microsystems with the project. On April 10, 1978 Apple signed a contract for $13,000 with Sheperdson to develop the DOS.
Even after disk drives made the cassette input and output ports obsolete they were still used by enthusiasts as simple one-bit audio input-output ports. Ham radio operators used the cassette input to receive slow scan TV (single frame images). A commercial speech recognition Blackjack program was available, after some user-specific voice training it would recognize simple commands (Hit, stand). Bob Bishop's "Music Kaleidoscope" was a simple program which monitored the cassette input port and based on zero-crossings created color patterns on the screen, a predecessor to current audio visualization plug-ins for media players. Music Kaleidoscope was especially popular on projection TV sets in dance halls.
Apple and many third-party developers made software available on tape at first, but after the Disk II became available in 1978, tape-based Apple II software essentially disappeared from the market. The initial price of the Disk II drive and controller was $595 USD, although a $100 off coupon was available through the Apple newsletter "Contact". The controller could handle two drives and a second drive (without controller) retailed for $495.
The Disk II single-sided floppy drive used 5.25-inch floppy disks; double-sided disks could be used, one side at a time, by turning them over and notching a hole for the write protect sensor. The first disk operating systems for the Apple II were DOS 3.1 and DOS 3.2, which stored 113.75 kB on each disk, organized into 35 tracks of 13 256-byte sectors each. After about two years, DOS 3.3 was introduced, storing 140 kB thanks to a minor firmware change on the disk controller that allowed it to store 16 sectors per track. (This upgrade was user-installable as two PROMs on older controllers.) After the release of DOS 3.3, the user community discontinued use of DOS 3.2 except for running legacy software. Programs that required DOS 3.2 were fairly rare; however, as DOS 3.3 was not a major architectural change aside from the number of sectors per track, a program called MUFFIN was provided with DOS 3.3 to allow users to copy files from DOS 3.2 disks to DOS 3.3 disks. It was possible for software developers to create a DOS 3.2 disk which would also boot on a system with DOS 3.3 firmware.
Later, double-sided drives, with heads to read both sides of the disk, became available from third-party companies. (Apple only produced double-sided 5.25" disks for the Lisa 1 computer).
On a DOS 3.x disk, tracks 0, 1, and most of track 2 were reserved to store the operating system. (It was possible, with a special utility, to reclaim most of this space for data if a disk did not need to be bootable.) A short ROM program on the disk controller had the ability to seek to track zero – which it did without regard for the read/write head's current position, resulting in the characteristic "chattering" sound of a Disk II boot, which was the read/write head hitting the rubber stop block at the end of the rail – and read and execute code from sector 0. The code contained in there would then pull in the rest of the operating system. DOS stored the disk's directory on track 17, smack in the middle of the 35-track disks, in order to reduce the average seek time to the frequently used directory track. The directory was fixed in size and could hold a maximum of 105 files. Subdirectories were not supported.
Most game publishers did not include DOS on their floppy disks, since they needed the memory it occupied more than its capabilities; instead, they often wrote their own boot loaders and read-only file systems. This also served to discourage "crackers" from snooping around in the game's copy-protection code, since the data on the disk was not in files that could be accessed easily.
Some third-party manufacturers produced floppy drives that could write 40 tracks to most 5.25-inch disks, yielding 160 kB of storage per disk, but the format did not catch on widely, and no known commercial software was published on 40-track media. Most drives, even Disk IIs, could write 36 tracks; a two byte modification to DOS to format the extra track was common.
The Apple Disk II stored 140 kB on single-sided, "single-density" floppy disks, but it was very common for Apple II users to extend the capacity of a single-sided floppy disk to 280 kB by cutting out a second write-protect notch on the side of the disk using a "disk notcher" or hole puncher and inserting the disk flipped over. Double-sided disks, with notches on both sides, were available at a higher price, but in practice the magnetic coating on the reverse of nominally single-sided disks was usually of good enough quality to be used (both sides were coated in the same way to prevent warping, although only one side was certified for use). Early on, diskette manufacturers routinely warned that this technique would damage the read/write head of the drives or wear out the disk faster, and these warnings were frequently repeated in magazines of the day. In practice, however, this method was an inexpensive way to store twice as much data for no extra cost, and was widely used for commercially released floppies as well.
Later, Apple IIs were able to use 3.5-inch disks with a total capacity of 800 kB and hard disks. DOS 3.3 did not support these drives natively; third-party software was required, and disks larger than about 400 kB had to be split up into multiple "virtual disk volumes."
DOS 3.3 was succeeded by ProDOS, a 1983 descendent of the Apple ///'s SOS. It added the capabilities for subdirectories and larger storage capacities.
ProDOS became the Apple II operating system of choice for users with these larger disks thanks to its native support of volumes up to 32 MB in size and the fact that AppleWorks and other newer programs required it.
Renditions of the "II" name.
The "II" portion of the Apple II name was rendered in a variety of creative ways using stylized characters which resembled punctuation symbols on the front lids of the computers, and most printed material followed this lead. The II and II+ were labeled ][ and ][ plus. The II and II Plus were rendered in small caps. The Apple III, IIc, and IIe models used slashes: ///, //c and //e. There have been some errors in the Apple II's name due to the numerous variations and forms on the "II".
Legacy.
Today, emulators for various Apple II models are available to run Apple II software on OS X, Linux, Microsoft Windows, homebrew enabled Nintendo DS and other operating systems. Numerous disk images of Apple II software are available free over the Internet for use with these emulators. AppleWin and MESS are among the best emulators compatible with most Apple II images. The MESS emulator supports recording and playing back of Apple II emulation sessions, as does Home Action Replay Page (a.k.a. HARP).
However, many emulators cannot run software on copy-protected media, or can run only software employing fairly simple protection schemes, unless it is "cracked" (copy restrictions removed). Breaking protection on software was widely popular in the Apple II's heyday; even Apple itself apparently engaged in the practice. Commercial cracking software such as the popular Copy II+ program were sold in stores with the purpose of creating legitimate back-ups of protected software. Although creating back-ups was legitimate under copyright law of the time, the use of such software today is of questionable legality in the U.S. (see DMCA). For those who prefer to obtain their old software legally, the Lost Classics Project has the goal of convincing copyright holders of classic Apple II software to officially allow unrestricted free distribution of their software and has "freed" a number of programs.
In addition, an active retrocomputing community of vintage Apple II collectors and users, continue to restore, maintain and develop hardware and software for daily use of these original computers. Numerous websites and support groups exist for these enthusiasts who maintain and use their machines. There is still a small annual convention, KansasFest, dedicated to the platform.
Industry impact.
The Apple II series of computers had an enormous impact on the technology industry and on everyday life. The Apple II was the first personal computer many people ever saw. Its price was within the reach of many middle-class families, and a partnership with MECC helped make the Apple II popular in schools. By the end of 1980 Apple had already sold over 100,000 Apple IIs. Its popularity bootstrapped the computer game and educational software markets and began the boom in the word processor and computer printer markets. The first microcomputer program for business was VisiCalc, the earliest spreadsheet, and it ran first on the Apple II. Many businesses bought Apple IIs just to run VisiCalc.
The success of the Apple II in business spurred IBM to create the IBM PC, which was then purchased by middle managers in all lines of business to run spreadsheet and word processing software, at first ported from Apple II versions; later, whole new application software dynasties would be founded on the PC. The popularity of these PCs and their clones then transformed business again with LAN applications such as e-mail and later Internet applications such as Usenet and the WWW.
The first 1000 or so Apple IIs shipped with a 68 page mimeographed "Apple II Mini Manual" bound with brass paper fasteners. This was the basis for the "Apple II Reference Manual" (a/k/a Red book) which was published in January 1978. All existing customers who sent in their warranty cards were sent free copies of the Red Book.
The Apple II Reference Manual contained the complete schematic of the entire computer's circuitry and a complete source listing of the "Monitor" ROM firmware that served as the machine's BIOS.
A revised spiral bound guide released several years later with updated information had to be purchased separately, and in the case of the Apple II, the full technical documentation ran to several volumes.
The Apple II's slots, allowing any peripheral card to take control of the bus and directly access memory, enabled an independent industry of card manufacturers who together created a flood of hardware products that let users build systems that were far more powerful and useful (at a lower cost) than any competing system, most of which were not nearly as expandable and were universally proprietary. The first peripheral card was a blank prototyping card intended for electronics enthusiasts who wanted to design their own peripherals for the Apple II.
Specialty peripherals kept the Apple II in use in industry and education environments for many years after Apple Computer stopped supporting the Apple II. Well into the 1990s every clean-room (the super-clean facility where spacecraft are prepared for flight) at the Kennedy Space Center used an Apple II to monitor the environment and air quality. Most planetariums used Apple IIs to control their projectors and other equipment.
Even the game port was unusually powerful and could be used for digital and analog input and output. The early manuals included instructions for how to build a circuit with only four commonly available components (one transistor and three resistors) and a software routine to drive a common Teletype Model 33 machine. One hacker (Don Lancaster) used the game I/O to drive a LaserWriter printer.

</doc>
<doc id="2117" url="http://en.wikipedia.org/wiki?curid=2117" title="Apple III">
Apple III

The Apple III (often rendered as Apple ///) is a business-oriented personal computer produced and released by Apple Computer that was intended as the successor to the Apple II series, but was largely considered a failure in the market. Development work on the Apple III started in late 1978 under the guidance of Dr. Wendell Sander. It had the internal code name of "Sara", named after Sander's daughter. The machine was first announced and released on May 19, 1980, but due to serious stability issues that required a design overhaul and a recall of existing machines, it was formally reintroduced the following autumn. Development stopped and the Apple III was discontinued on April 24, 1984, and the III Plus was dropped from the Apple product line in September 1985.
The Apple III could be viewed as an enhanced Apple II – then the newest heir to a line of 8-bit machines dating back to 1976. However, the Apple III was not part of the Apple II line, but rather a close cousin. The key features business users wanted in a personal computer were a true typewriter-style upper/lowercase keyboard (as opposed to the Apple II which was based on a teletype keyboard) and 80 column display. In addition, the machine had to pass U.S. Federal Communications Commission (FCC) Radio Frequency Interference (RFI) qualifications for business equipment. In 1981, International Business Machines unveiled the IBM Personal Computer (IBM PC) – a completely new 16-bit design soon available in a wide range of inexpensive clones. The business market moved rapidly towards the PC DOS/MS-DOS platform, eventually pulling away from the Apple 8-bit computer line.
Despite numerous stability issues and a recall that included the first 14,000 units off the assembly line, Apple was eventually able to produce a reliable and dependable version of the machine. However, damage to the computer's reputation had already been done and it failed to do well commercially as a direct result. In the end, an estimated 65,000–75,000 Apple III computers were sold. The Apple III Plus brought this up to ~120,000. Apple co-founder Steve Wozniak stated that the primary reason for the Apple III's failure was that the system was designed by Apple's marketing department, unlike Apple's previous engineering-driven projects. The Apple III's failure led to Apple reevaluating their plan to phase out the Apple II, and eventual continuation of development of the older machine. As a result, later Apple II models incorporated some hardware, such as the Apple Scribe Printer, a thermal printer, and software technologies of the Apple III.
Design.
The Apple III was designed to be a business computer and an eventual successor for the Apple II. While the Apple II contributed to the inspirations of several important business products, such as VisiCalc, Multiplan and Apple Writer, the computer's hardware architecture, operating system and developer environment were limited. The Apple III addressed these weaknesses. According to Steve Wozniak, VisiCalc and Disk II had caused the Apple II's popularity, with 90% of sales going to businesses as opposed to the hobbyists that were its original market. Apple management intended to clearly establish market segmentation by designing the Apple III to appeal to the business market, leaving the Apple II to home and education users. Management believed that "once the Apple III was out, the Apple II would stop selling in six months", Wozniak said.
The Apple III was powered by a 1.8 MHz Synertek 6502A or B 8-bit CPU and, like some of the more advanced machines in the Apple II family, used bank switching techniques to address up to 256 KB of memory. Third-party vendors also produced memory upgrade kits that allowed the Apple III to reach up to 512 KB. Other Apple III built-in features included an 80-column, 24-line display with upper and lowercase characters, a numeric keypad, dual-speed (pressure-sensitive) cursor control keys, 6-bit (DAC) audio, and a built-in 140 KB 5.25" floppy disk drive. Graphics modes included 560x192 in black and white, and 280x192 with 16 colors or shades of gray. Unlike the Apple II, the Disk III controller was built into the logic board.
The Apple III was the first Apple product that allowed the user to choose both a screen font and a keyboard layout: either QWERTY or Dvorak. These choices could not be changed while programs were running, unlike the Apple IIc, which had a keyboard switch directly above the keyboard, allowing switching on the fly.
Software.
A major limitation of the Apple II and DOS 3.3 was the way it addressed resources, which made it highly desirable for peripherals to be installed in standardized locations (slot 5 and 6 reserved for storage devices, slot 2 reserved for serial communication interfaces, etc.) This forced the user to identify a peripheral by its physical location, such as PR#6, CATALOG, D1, and so on. The Apple III introduced an advanced operating system called Apple SOS, pronounced "apple sauce". Its ability to address resources by name instead of a physical location allowed the Apple III to be more scalable. Apple SOS also allowed the full capacity of a storage device to be used as a single volume, such as the Apple ProFile hard disk drive. Also, Apple SOS supported a hierarchical file system (HFS). Some of the features and code base of Apple SOS made their way into the Apple II's ProDOS and GS/OS operating systems, as well as Lisa 7/7 and Macintosh system software.
The Apple III also introduced a new BASIC interpreter called Apple III Business BASIC, and later an implementation of UCSD Pascal for more structured programming.
Because Apple did not view the Apple III as suitable for hobbyists, it did not provide much of the technical software information that accompanied the Apple II. Originally intended as a direct replacement to the Apple II series, it was designed to be backwards compatible with Apple II software. However, since Apple did not want to encourage continued development of the II platform, Apple II compatibility existed only in a special "Apple II Mode" which was limited in its capabilities to the emulation of a basic 48 KB Apple II+ configuration. Special chips were intentionally added to prevent access to the III's advanced features such as its larger memory. Since many business-oriented Apple II programs started requiring at least 64 KB of RAM (i.e. an 48 KB Apple II with an added 16 KB "language card") around the time the III was released, they were incompatible with the III, preventing some users from switching over.
The Apple III had a System Utilities program, which allowed system reconfiguration and file manipulation. Another program, Selector III, was designed to integrate with the System Utilities program and launch various applications. The program was developed by ON THREE, a large Apple III user group. Another company, Quark Software, developed a competing product, Catalyst, the cruder interface of which was offset by program-switching capabilities and support for copy-protection, which enabled companies to license users to run programs from a hard disk without worrying that their software might be backed up or copied without permission. When Apple decided to bundle Catalyst with its new ProFile hard disk, Quark celebrated, but ON THREE continued to market and sell Selector III through their monthly magazine. Selector III remained commercially available and supported long after Quark discontinued its Apple III product line.
Peripherals.
The Apple III had four expansion slots, a number that "inCider" in 1986 called "miserly". Apple II cards were compatible but risked violating government RFI regulations, and required Apple III-specific device drivers; "BYTE" stated that "Apple provides virtually no information on how to write them". As with software, Apple provided little hardware technical information with the computer but Apple III-specific products became available, such as one that made the computer compatible with the Apple IIe. Several new Apple-produced peripherals were developed for the Apple III. The original Apple III came with a built-in real-time clock, which was recognized by Apple SOS. The clock was later removed from the "revised" model, and instead was made available as an add-on.
Along with the built-in floppy drive, the Apple III could also handle up to three additional external Disk III floppy disk drives. The Disk III was only officially compatible with the Apple III. The Apple III Plus required an adapter from Apple to use the Disk III with its DB-25 disk port.
With the introduction of the revised Apple III a year after launch Apple began offering the ProFile external hard disk system. Costing US$3499 for 5MB, it also required a peripheral slot for the ProFile controller card.
Revisions.
Once the logic board design flaws were discovered, a newer logic board design was produced – which included a lower power requirement, wider traces and better designed chip sockets. The $3,495 revised model also included 256 KB RAM as a standard configuration. The 14,000 units of the original Apple III sold were returned and replaced with the entirely new revised model.
Apple III Plus.
The Apple III Plus was introduced in December 1983, while discontinuing the revised III model, at a price of US$2995. This newer version included a built-in clock, video interlacing, standardized rear port connectors, 256K RAM as standard, and a re-designed keyboard. The keyboard was designed in the style of the earlier beige Apple IIe.
Owners of the earlier Apple III could obtain the newer logic board as a service replacement. A keyboard upgrade kit, dubbed "Apple III Plus upgrade kit" was also made available – which included the keyboard, cover, keyboard encoder ROM and logo replacements. This upgrade had to be installed by an authorized service technician.
Design flaws.
According to Wozniak, the Apple III "had 100 percent hardware failures". Steve Jobs insisted on the idea of no fan or air vents – in order to make the computer run quietly. Jobs would later push this same ideology onto almost all Apple models he had control of – from the Apple Lisa and Macintosh 128K to the iMac. To allow the computer to dissipate heat, the base of the Apple III was made of heavy cast aluminum, which supposedly acted as a heat sink. One undeniable advantage to the aluminum case was a reduction in RFI (Radio Frequency Interference), a problem which had plagued the Apple II series throughout its history. Unlike the Apple II series, the power supply was mounted – without its own shell – in a compartment separate from the logic board. The decision to use an aluminum shell ultimately led to engineering issues which resulted in the Apple III's reliability problems. The lead time for manufacturing the shells was high, and this had to be done before the motherboard was finalized. Later it was realized that there wasn't enough room on the motherboard for all of the components unless narrow traces were used.
Many Apple IIIs were thought to have failed due to their inability to properly dissipate heat. "inCider" stated in 1986 that "Heat has always been a formidable enemy of the Apple ///", and some users reported that their Apple IIIs became so hot that the chips started dislodging from the board, causing the screen to display garbled data or their disk to come out of the the slot "melted". "BYTE" wrote, "the integrated circuits tended to wander out of their sockets". The fix Apple suggested in a technical bulletin was to lift the Apple III off the desk until it was three inches in the air and then drop it, repeating the procedure until the symptoms disappeared. While the fix was quite effective, many purchasers found the process alarming.
Case designer Jerry Manock denied the design flaw charges, stating that tests proved that the unit adequately dissipated the internal heat. The primary cause, he claimed, was a major logic board design problem. The logic board used "fineline" technology that was not fully mature at the time, with narrow, closely spaced traces. When chips were "stuffed" into the board and wave-soldered, solder bridges would form between traces that were not supposed to be connected. This caused numerous short circuits, which required hours of costly diagnosis and hand rework to fix. Apple designed a new circuit board, with more layers and normal-width traces. The new logic board was laid out by one designer on a huge drafting board, rather than using the costly CAD-CAM system used for the previous board, and the new design worked.
Earlier Apple III units came with a built-in real time clock. The hardware, however, would fail after prolonged use. Assuming that National Semiconductor would test all parts before shipping them, Apple did not perform this level of testing. Apple was soldering chips directly to boards, and could not easily change out a bad chip if one was found. Eventually, Apple solved this problem by removing the real-time clock from the Apple III's specification rather than shipping the Apple III with the clock pre-installed, and then sold the peripheral as a level 1 technician add-on.
Commercial failure.
For a variety of reasons, the Apple III was a commercial failure. With a starting price between $4,340 to $7,800 US, it was more expensive than many of the CP/M-based business computers that were available at the time. Little Apple III software was available besides VisiCalc, and while sold as Apple II compatible, the emulation that made this possible was intentionally hobbled; thus it could not make use of the advanced III features (specifically 64 KB RAM or higher, required by many Apple II software titles written in Apple Pascal), which limited its usefulness.
Early Apple III users were told that they had to use existing 40-column Apple II word processors and spreadsheet programs, which hurt sales since those programs could be used in 80-column mode on the Apple IIs with the suitable hardware installed. It was not until several months after the Apple III was introduced that native 80-column business software became available.
Influence.
The filesystem and some design ideas from Apple SOS, the Apple III's operating system, were part of Apple ProDOS and Apple GS/OS, the major operating systems for the Apple II series following the demise of the Apple III, as well as the Apple Lisa, which was the de facto business-oriented successor to the Apple III. The hierarchical file system influenced the evolution of the Macintosh: while the original Macintosh File System (MFS) was a flat file system designed for a floppy disk without subdirectories, subsequent file systems were hierarchical. By comparison, the IBM PC's first file system (again designed for floppy disks) was flat; likewise, later versions (designed for hard disks) were hierarchical.
External links.
 

</doc>
<doc id="2118" url="http://en.wikipedia.org/wiki?curid=2118" title="AVL tree">
AVL tree

In computer science, an AVL tree (Georgy Adelson-Velsky and Landis' tree, named after the inventors) is a self-balancing binary search tree. It was the first such data structure to be invented. In an AVL tree, the heights of the two child subtrees of any node differ by at most one; if at any time they differ by more than one, rebalancing is done to restore this property. Lookup, insertion, and deletion all take O(log "n") time in both the average and worst cases, where "n" is the number of nodes in the tree prior to the operation. Insertions and deletions may require the tree to be rebalanced by one or more tree rotations.
The AVL tree is named after its two Soviet inventors, Georgy Adelson-Velsky and E. M. Landis, who published it in their 1962 paper "An algorithm for the organization of information".
AVL trees are often compared with red-black trees because both support the same set of operations and take O(log "n") time for the basic operations. For lookup-intensive applications, AVL trees are faster than red-black trees because they are more rigidly balanced. Similar to red-black trees, AVL trees are height-balanced. Both are in general not weight-balanced nor μ-balanced for any formula_1; that is, sibling nodes can have hugely differing numbers of descendants.
Operations.
Basic operations of an AVL tree involve carrying out the same actions as would be carried out on an unbalanced binary search tree, but modifications are followed by zero or more operations called tree rotations, which help to restore the height balance of the subtrees.
Searching.
Once a node has been found in a balanced tree, the "next" or "previous" nodes can be explored in amortized constant time. Some instances of exploring these "nearby" nodes require traversing up to 2×log("n") links (particularly when moving from the rightmost leaf of the root's left sub tree to the leftmost leaf of the root's right sub tree; in the example AVL tree, moving from node 14 to the "next but one" node 19 takes 4 steps). However, exploring all "n" nodes of the tree in this manner would use each link exactly twice: one traversal to enter the sub tree rooted at that node, another to leave that node's sub tree after having explored it. And since there are "n"−1 links in any tree, the amortized cost is found to be 2×("n"−1)/"n", or approximately 2.
Insertion.
After inserting a node, it is necessary to check each of the node's ancestors for consistency with the rules of AVL. The balance factor is calculated as follows: balanceFactor = height(left subtree) - height(right subtree). For each node checked, if the balance factor remains −1, 0, or +1 then no rotations are necessary. However, if balance factor becomes less than -1 or greater than +1, the subtree rooted at this node is unbalanced. If insertions are performed serially, after each insertion, at most one of the following cases needs to be resolved to restore the entire tree to the rules of AVL.
Let us first assume the balance factor of a node L is 2 (as opposed to the other possible unbalanced value -2). This case is depicted in the left column of the illustration with L=5. We then look at the left subtree (the larger one) with root P. If this subtree does not lean to the right - i.e. P has balance factor 0 or 1 - we can rotate the whole tree to the right to get a balanced tree. This is labelled as the "Left Left Case" in the illustration with P=4. If the subtree does lean to the right - i.e. P has balance factor -1 - we first rotate the subtree to the left and end up the previous case. The second case is labelled as "Left Right Case" with P=5 in the illustration.
If the balance factor of the node L is -2 (this case is depicted in the right column of the illustration L=3) we can mirror the above algorithm. I.e. if the root P of the right subtree has balance factor 0 or -1 we can rotate the whole tree to the left to get a balanced tree. This is labelled as the "Right Right Case" in the illustration with P=4. If the root P of the right subtree has balance factor 1 we can rotate the subtree to the right to end up in the "Right Right Case".
The whole algorithm looks like this:
 if (balance_factor(L) == 2) { //The left column
 let P=left_child(L)
 if (balance_factor(P) == -1) { //The "Left Right Case"
 rotate_left(P) //reduce to "Left Left Case"
 //Left Left Case
 rotate_right(L);
 } else { // balance_factor(L) == -2, the right column
 let P=right_child(L)
 if (balance_factor(P) == 1) { //The "Right Left Case"
 rotate_right(P) //reduce to "Right Right Case"
 //Right Right Case
 rotate_left(L);
The names of the cases refer to the portion of the tree that is reduced in height.
In order to restore the balance factors of all nodes, first observe that all nodes requiring correction lie along the path used during the initial insertion. If the above procedure is applied to nodes along this path, starting from the bottom (i.e. the node furthest away from the root), then every node in the tree will again have a balance factor of -1, 0, or 1.
Deletion.
Let node X be the node with the value we need to delete, and let node Y be a node in the tree we need to find to take node X's place, and let node Z be the actual node we take out of the tree.
Steps to consider when deleting a node in an AVL tree are the following:
As with all binary trees, a node's in-order successor is the left-most child of its right subtree, and a node's in-order predecessor is the right-most child of its left subtree. In either case, this node will have zero or one children. Delete it according to one of the two simpler cases above.
In addition to the balancing described above for insertions, if the balance factor for the tree is 2 and that of the left subtree is 0, a right rotation must be performed on P. The mirror of this case is also necessary.
The retracing can stop if the balance factor becomes −1 or +1 indicating that the height of that subtree has remained unchanged.
If the balance factor becomes 0 then the height of the subtree has decreased by one and the retracing needs to continue.
If the balance factor becomes −2 or +2 then the subtree is unbalanced and needs to be rotated to fix it.
If the rotation leaves the subtree's balance factor at 0 then the retracing towards the root must continue since the height of this subtree has decreased by one.
This is in contrast to an insertion where a rotation resulting in a balance factor of 0 indicated that the subtree's height has remained unchanged.
The time required is O(log "n") for lookup, plus a maximum of O(log "n") rotations on the way back to the root, so the operation can be completed in O(log "n") time.
Comparison to other structures.
Both AVL trees and red-black trees are self-balancing binary search trees and they are very similar mathematically. The operations to balance the trees are different, but both occur on the average in O(1) with maximum in O(log "n"). The real difference between the two is the limiting height.
For a tree of size formula_2:
AVL trees are more rigidly balanced than red-black trees, leading to slower insertion and removal but faster retrieval.

</doc>
<doc id="2120" url="http://en.wikipedia.org/wiki?curid=2120" title="Aliphatic compound">
Aliphatic compound

 
In organic chemistry, compounds composed of carbon and hydrogen are divided into two classes: aromatic compounds and aliphatic compounds (; G. "aleiphar", fat, oil) also known as non-aromatic compounds. Aromatic compounds contain an aromatic-ring configuration of atoms, such as benzene whereas aliphatic compounds do not. Aliphatic compounds can be saturated, like hexane, or unsaturated, like hexene.
Structure.
In aliphatic compounds, carbon atoms can be joined together in straight chains, branched chains, or non-aromatic rings (in which case they are called alicyclic). Aliphatic compounds can be saturated, joined by single bonds (alkanes), or unsaturated, with double bonds (alkenes) or triple bonds (alkynes). Besides hydrogen, other elements can be bound to the carbon chain, the most common being oxygen, nitrogen, sulfur, and chlorine. 
The simplest aliphatic compound is methane (CH4). Aliphatics include alkanes, alkenes, and alkynes. Fatty acids consist of an unbranched aliphatic tail attached to a carboxylic acid functional group.
Properties.
Most aliphatic compounds are flammable, allowing the use of hydrocarbons as fuel, such as methane in Bunsen burners and as liquified natural gas (LNG), and acetylene in welding.
Examples of aliphatic compounds / non-aromatic.
The most important aliphatic compounds are:
Important examples of low-molecular aliphatic compounds can be found in the list below (sorted by the number of carbon-atoms):
A few structures can be shown as example:
But-1-ene can be shown as
CH2=CH-CH2-CH3
Aliphatic acids.
Aliphatic acids are the acids of nonaromatic hydrocarbons, such as acetic, propionic, and butyric acids.

</doc>
<doc id="2122" url="http://en.wikipedia.org/wiki?curid=2122" title="Astrology">
Astrology

Astrology consists of several systems of divination based on the premise that there is a relationship between astronomical phenomena and events in the human world. Many cultures have attached importance to astronomical events, and the Indians, Chinese, and Mayans developed elaborate systems for predicting terrestrial events from celestial observations. In the West, astrology most often consists of a system of horoscopes purporting to explain aspects of a person's personality and predict future events in their life based on the positions of the sun, moon, and other celestial objects at the time of their birth. The majority of professional astrologers rely on such systems. 
Throughout most of its history, astrology was considered a scholarly tradition. It was accepted in political and academic contexts, and was connected with other studies, such as astronomy, alchemy, meteorology, and medicine. At the end of the 17th century, new scientific concepts in astronomy and physics (such as heliocentrism and Newtonian mechanics) called astrology into question. Astrology thus lost its academic and theoretical standing, and common belief in astrology has largely declined.
Astrology has been rejected by the scientific community as a pseudoscience, having no validity or explanatory power for describing the universe. Among other issues, there is no proposed mechanism of action by which the positions and motions of stars and planets could affect people and events on Earth that does not contradict well understood basic aspects of biology and physics. Scientific testing of astrology has found no evidence to support any of the premises or purported effects outlined in astrological traditions. In one study, participating astrologers attempting to match natal charts with profiles generated by a psychological inventory produced results not significantly at variance with random chance.
Astrology has been dated to at least the 2nd millennium BCE, with roots in calendrical systems used to predict seasonal shifts and to interpret celestial cycles as signs of divine communications. A form of astrology was practised in the first dynasty of Mesopotamia (1950–1651 BCE). Chinese astrology was elaborated in the Zhou dynasty (1046–256 BCE). Hellenistic astrology after 332 BCE mixed Babylonian astrology with Egyptian Decanic astrology in Alexandria, creating horoscopic astrology. Alexander the Great's conquest of Asia allowed astrology to spread to Ancient Greece and Rome. In Rome, astrology was associated with "Chaldean wisdom". After the conquest of Alexandria in the 7th century, astrology was taken up by Islamic scholars, and Hellenistic texts were translated into Arabic and Persian. In the 12th century, Arabic texts were imported to Europe and translated into Latin, helping to initiate the European Renaissance, when major astronomers including Tycho Brahe, Johannes Kepler and Galileo practised as court astrologers. Astrological references appear in literature in the works of poets such as Dante Alighieri and Geoffrey Chaucer, and of playwrights such as Christopher Marlowe and William Shakespeare.
Etymology.
The word "astrology" comes from the early Latin word "astrologia", deriving from the Greek (from ἄστρον "astron", "star" and -λογία "-logia", "study of"), "account of the stars". "Astrologia" later passed into meaning 'star-divination' with "astronomia" used for the scientific term.
History.
Many cultures have attached importance to astronomical events, and the Indians, Chinese, and Mayans developed elaborate systems for predicting terrestrial events from celestial observations. In the West, astrology most often consists of a system of horoscopes purporting to explain aspects of a person's personality and predict future events in their life based on the positions of the sun, moon, and other celestial objects at the time of their birth. The majority of professional astrologers rely on such systems. 
Astrology has been dated to at least the 2nd millennium BCE, with roots in calendrical systems used to predict seasonal shifts and to interpret celestial cycles as signs of divine communications. A form of astrology was practised in the first dynasty of Mesopotamia (1950–1651 BCE). Chinese astrology was elaborated in the Zhou dynasty (1046–256 BCE). Hellenistic astrology after 332 BCE mixed Babylonian astrology with Egyptian Decanic astrology in Alexandria, creating horoscopic astrology. Alexander the Great's conquest of Asia allowed astrology to spread to Ancient Greece and Rome. In Rome, astrology was associated with 'Chaldean wisdom'. After the conquest of Alexandria in the 7th century, astrology was taken up by Islamic scholars, and Hellenistic texts were translated into Arabic and Persian. In the 12th century, Arabic texts were imported to Europe and translated into Latin, helping to initiate the European Renaissance, when major astronomers including Tycho Brahe, Johannes Kepler and Galileo practised as court astrologers. Astrological references appear in literature in the works of poets such as Dante Alighieri and Geoffrey Chaucer, and of playwrights such as Christopher Marlowe and William Shakespeare.
Throughout most of its history, astrology was considered a scholarly tradition. It was accepted in political and academic contexts, and was connected with other studies, such as astronomy, alchemy, meteorology, and medicine. At the end of the 17th century, new scientific concepts in astronomy and physics (such as heliocentrism and Newtonian mechanics) called astrology into question. Astrology thus lost its academic and theoretical standing, and common belief in astrology has largely declined.
Ancient world.
Astrology, in its broadest sense, is the search for meaning in the sky. Early evidence for humans making conscious attempts to measure, record, and predict seasonal changes by reference to astronomical cycles, appears as markings on bones and cave walls, which show that lunar cycles were being noted as early as 25,000 years ago. This was a first step towards recording the Moon's influence upon tides and rivers, and towards organizing a communal calendar. Agricultural needs were addressed with increasing knowledge of constellations which appear in the different seasons, allowing the rising of particular star-groups to herald annual floods or seasonal activities. By the 3rd millennium BCE, civilizations had sophisticated awareness of celestial cycles, and may have oriented temples in alignment with heliacal risings of the stars.
There is scattered evidence to suggest that the oldest known astrological references are copies of texts made in the ancient world. The Venus tablet of Ammisaduqa (compiled in Babylon around 1700 BCE) is reported to have been made during the reign of king Sargon of Akkad (2334–2279 BCE). A scroll documenting an early use of electional astrology is doubtfully ascribed to the reign of the Sumerian ruler Gudea of Lagash (c. 2144 – 2124 BCE). This describes how the gods revealed to him in a dream the constellations that would be most favourable for the planned construction of a temple. However, there is controversy about whether these were genuinely recorded at the time or merely ascribed to ancient rulers by posterity. The oldest undisputed evidence of the use of astrology as an integrated system of knowledge is therefore attributed to the records of the first dynasty of Mesopotamia (1950–1651 BCE). This astrology had some parallels with Hellenistic Greek (western) astrology, including the zodiac, a norming point near 9 degrees in Aries, the trine aspect, planetary exaltations, and the dodekatemoria (the twelve divisions of 30 degrees each). However, the Babylonians viewed celestial events as possible signs rather than as causes of physical events.
The system of Chinese astrology was elaborated during the Zhou dynasty (1046–256 BCE) and flourished during the Han Dynasty (2nd century BCE to 2nd century CE), during which all the familiar elements of traditional Chinese culture – the Yin-Yang philosophy, theory of the five elements, Heaven and Earth, Confucian morality – were brought together to formalise the philosophical principles of Chinese medicine and divination, astrology and alchemy.
Ancient objections.
Cicero stated the twins objection (that with close birth times, personal outcomes can be very different), later developed by Saint Augustine. He argued that since the other planets are much more distant from the earth than the moon, they could have only very tiny influence compared to the moon's. He also argued that if astrology explains everything about a person's fate, then it wrongly ignores the visible effect of inherited ability and parenting, changes in health worked by medicine, or the effects of the weather on people.
Plotinus argued that since the fixed stars are much more distant than the planets, it is laughable to imagine the planets' effect on mankind should depend on their position with respect to the zodiac. He also argues that the interpretation of the moon's conjunction with a planet as good when the moon is full, but bad when the moon is waning, is clearly wrong, as from the moon's point of view, half of her surface is always in sunlight; and from the planet's point of view, waning should be better, as then the planet sees some light from the moon, but when the moon is full to us, it is dark, and therefore bad, on the side facing the planet.
Favorinus argued that it was absurd to imagine that stars and planets would affect human bodies in the same way as they affect the tides, and equally absurd that small motions in the heavens cause large changes in people's fates. Sextus Empiricus argued that it was absurd to link human attributes with myths about the signs of the zodiac. Carneades argued that belief in fate denies free will and morality; that people born at different times can all die in the same accident or battle; and that contrary to uniform influences from the stars, tribes and cultures are all different.
Hellenistic Egypt.
In 525 BCE, Egypt was conquered by the Persians. The 1st century BCE Egyptian Dendera Zodiac shares two signs – the Balance and the Scorpion – with Mesopotamian astrology.
With the occupation by Alexander the Great in 332 BCE, Egypt became Hellenistic. The city of Alexandria was founded by Alexander after the conquest, becoming the place where Babylonian astrology was mixed with Egyptian Decanic astrology to create Horoscopic astrology. This contained the Babylonian zodiac with its system of planetary exaltations, the triplicities of the signs and the importance of eclipses. It used the Egyptian concept of dividing the zodiac into thirty-six decans of ten degrees each, with an emphasis on the rising decan, and the Greek system of planetary Gods, sign rulership and four elements. 2nd century BCE texts predict positions of planets in zodiac signs at the time of the rising of certain decans, particularly Sothis. The astrologer and astronomer Ptolemy lived in Alexandria. Ptolemy's work the "Tetrabiblos" formed the basis of Western astrology, and "enjoyed almost the authority of a Bible among the astrological writers of a thousand years or more".
Greece and Rome.
The conquest of Asia by Alexander the Great exposed the Greeks to ideas from Syria, Babylon, Persia and central Asia. Around 280 BCE, Berossus, a priest of Bel from Babylon, moved to the Greek island of Kos, teaching astrology and Babylonian culture. By the 1st century BCE, there were two varieties of astrology, one using horoscopes to describe the past, present and future; the other, theurgic, emphasising the soul's ascent to the stars. Greek influence played a crucial role in the transmission of astrological theory to Rome.
The first definite reference to astrology in Rome comes from the orator Cato, who in 160 BCE warned farm overseers against consulting with Chaldeans, who were described as Babylonian 'star-gazers'. Among both Greeks and Romans, Babylonia (also known as Chaldea) became so identified with astrology that 'Chaldean wisdom' became synonymous with divination using planets and stars. The 2nd-century Roman poet and satirist Juvenal complains about the pervasive influence of Chaldeans, saying "Still more trusted are the Chaldaeans; every word uttered by the astrologer they will believe has come from Hammon's fountain".
One of the first astrologers to bring Hermetic astrology to Rome was Thrasyllus, astrologer to the emperor Tiberius, the first emperor to have had a court astrologer, though his predecessor Augustus had used astrology to help legitimise his Imperial rights.
Mediæval world.
Islamic.
Astrology was taken up by Islamic scholars following the collapse of Alexandria to the Arabs in the 7th century, and the founding of the Abbasid empire in the 8th. The second Abbasid caliph, Al Mansur (754–775) founded the city of Baghdad to act as a centre of learning, and included in its design a library-translation centre known as "Bayt al-Hikma" 'House of Wisdom', which continued to receive development from his heirs and was to provide a major impetus for Arabic-Persian translations of Hellenistic astrological texts. The early translators included Mashallah, who helped to elect the time for the foundation of Baghdad, and Sahl ibn Bishr, ("a.k.a." "Zael"), whose texts were directly influential upon later European astrologers such as Guido Bonatti in the 13th century, and William Lilly in the 17th century. Knowledge of Arabic texts started to become imported into Europe during the Latin translations of the 12th century, the effect of which was to help initiate the European Renaissance.
Europe.
The first astrological book published in Europe was the "Liber Planetis et Mundi Climatibus" ("Book of the Planets and Regions of the World") which appeared between 1010 and 1027 AD, and may have been authored by Gerbert of Aurillac. Ptolemy's second century AD "Tetrabiblos" was translated into Latin by Plato of Tivoli in 1138. The Dominican theologian Thomas Aquinas followed Aristotle in proposing that the stars ruled the imperfect 'sublunary' body, while attempting to reconcile astrology with Christianity by stating that God ruled the soul. The thirteenth century mathematician Campanus of Novara is said to have devised a system of astrological houses which divides the prime vertical into 'houses' of equal 30° arcs, though the system was used earlier in the East. The thirteenth century astronomer Guido Bonatti wrote a textbook, the "Liber Astronomicus", a copy of which was owned at the end of the fifteenth century by king Henry VII of England.
In "Paradiso", the final part of the "Divine Comedy", the Italian poet Dante Alighieri referred "in countless details" to the astrological planets, though he adapted traditional astrology to suit his Christian viewpoint, for example using astrological thinking in his prophecies of the reform of Christendom.
Mediæval objections.
In the seventh century, Isidore of Seville argued in his "Etymologiae" that astronomy described the movements of the heavens, while astrology had two parts: one was scientific, describing the movements of the sun, the moon and the stars, while the other, making predictions, was theologically erroneous. In contrast, John Gower in the fourteenth century defined astrology as essentially limited to the making of predictions. The influence of the stars was in turn divided into natural astrology, with for example effects on tides and the growth of plants, and judicial astrology, with supposedly predictable effects on people. The fourteenth century skeptic Nicole Oresme however included astronomy as a part of astrology in his "Livre de divinacions". Oresme argued that current approaches to prediction of events such as plagues, wars, and weather were inappropriate, but that such prediction was a valid field of inquiry. However, he attacked the use of astrology to choose the timing of actions (so-called interrogation and election) as wholly false, and rejected the determination of human action by the stars on grounds of free will. The friar Laurens Pignon (c. 1368–1449) similarly rejected all forms of divination and determinism, including by the stars, in his 1411 "Contre les Devineurs". This was in opposition to the tradition carried by the Arab astronomer Albumasar (787-886) whose "Introductorium in Astronomiam" and "De Magnis Coniunctionibus" argued the view that both individual actions and larger scale history are determined by the stars.
Renaissance and Early Modern.
Renaissance scholars often practised astrology to pay for their research into other subjects. Gerolamo Cardano cast the horoscope of king Edward VI of England, while John Dee was the personal astrologer to queen Elizabeth I of England. Catherine de Medici paid Michael Nostradamus in 1566 to verify the prediction of the death of her husband, king Henry II of France made by her astrologer Lucus Gauricus. Major astronomers who practised as court astrologers included Tycho Brahe in the royal court of Denmark, Johannes Kepler to the Habsburgs and Galileo Galilei to the Medici. The astronomer and spiritual astrologer Giordano Bruno was burnt at the stake for heresy in Rome in 1600.
Ephemerides with complex astrological calculations, and almanacs interpreting celestial events for use in medicine and for choosing times to plant crops, were popular in Elizabethan England. In 1597, the English mathematician and physician Thomas Hood made a set of paper instruments using revolving overlays which enabled students to work out relationships between the fixed stars or constellations, the midheaven, and the twelve astrological houses. Hood's instruments also illustrated for pedagogical purposes the supposed relationships between the signs of the zodiac, the planets, and the parts of the human body which were believed to be governed by the planets and signs. While Hood's presentation was innovative, his astrological information was largely standard and was taken from Gerard Mercator's astrological disc made in 1551, or a source used by Mercator.
English astrology had reached its zenith by the 17th century. Astrologers were theorists, researchers, and social engineers, as well as providing individual advice to everyone from monarchs downwards. Among other things, astrologers could advise on the best time to take a journey or harvest a crop, diagnose and prescribe for physical or mental illnesses, and predict natural disasters. This underpinned a system in which everything - people, the world, the universe - was understood to be interconnected, and astrology co-existed happily with religion, magic and science.
Enlightenment period and onwards.
During The Enlightenment, intellectual sympathy for astrology fell away, leaving only a popular following supported by cheap almanacs. One English almanac compiler, Richard Saunders, followed the spirit of the age by printing a derisive "Discourse on the Invalidity of Astrology", while in France Pierre Bayle's "Dictionnaire" of 1697 stated that the subject was puerile. The Anglo-Irish satirist Jonathan Swift ridiculed the Whig political astrologer John Partridge.
Astrology saw a popular revival starting in the 19th century as part of a general revival of spiritualism and later New Age philosophy, and through the influence of mass media such as newspaper horoscopes. Early in the 20th century the psychiatrist Carl Jung developed some concepts concerning astrology, which led to the development of psychological astrology.
Principles and practice.
Advocates have defined astrology as a symbolic language, an art form, a science, and a method of divination. Although most cultural systems of astrology share common roots in ancient philosophies that influenced each other, many have unique methodologies which differ from those developed in the West. These include Hindu astrology (also known as "Indian astrology" and in modern times referred to as "Vedic astrology") and Chinese astrology, both of which have influenced the world's cultural history.
Western.
Western astrology is a form of divination based on the construction of a horoscope for an exact moment, such as a person's birth. It uses the tropical zodiac, which is aligned to the equinoctial points.
Western astrology is founded on the movements and relative positions of celestial bodies such as the Sun, Moon and planets, which are analyzed by their movement through signs of the zodiac (twelve spatial divisions of the ecliptic) and by their aspects (based on geometric angles) relative to one another. They are also considered by their placement in houses (twelve spatial divisions of the sky). Astrology's modern representation in western popular media is usually reduced to sun sign astrology, which considers only the zodiac sign of the Sun at an individual's date of birth, and represents only 1/12 of the total chart.
The horoscope visually expresses the set of relationships for the time and place of the chosen event. These relationships are between the seven 'planets', signifying tendencies such as war and love; the twelve signs of the zodiac; and the twelve houses. Each planet is in a particular sign and a particular house at the chosen time, when observed from the chosen place, creating two kinds of relationship. A third kind is the aspect of each planet to every other planet, where for example two planets 120° apart (in 'trine') are in a harmonious relationship, but two planets 90° apart ('square') are in a conflicted relationship. Together these relationships and their interpretations supposedly form "the language of the heavens speaking to learned men".
Along with tarot divination, astrology is one of the core studies of Western esotericism, and as such has influenced systems of magical belief not only among Western esotericists and Hermeticists, but also belief systems such as Wicca that have borrowed from or been influenced by the Western esoteric tradition. Tanya Luhrmann has said that "all magicians know something about astrology," and refers to a table of correspondences in Starhawk's "The Spiral Dance", organized by planet, as an example of the astrological lore studied by magicians.
Hindu.
The earliest Vedic text on astronomy is the "Vedanga Jyotisha"; Vedic thought later came to include astrology as well.
Hindu natal astrology originated with Hellenistic astrology by the 3rd century BCE, though incorporating the Hindu lunar mansions. The names of the signs (e.g. Greek 'Kpios' for Aries, Hindi 'Kriya'), the planets (e.g. Greek 'Helios' for Sun, astrological Hindi 'Heli'), and astrological terms (e.g. Greek 'apoklima' and 'sunaphe' for declination and planetary conjunction, Hindi 'apoklima' and 'sunapha' respectively) in Varaha Mihira's texts are considered conclusive evidence of a Greek origin for Hindu astrology. The Indian techniques may also have been augmented with some of the Babylonian techniques.
Chinese and East-Asian.
Chinese astrology has a close relation with Chinese philosophy (theory of the three harmonies: heaven, earth and man) and uses concepts such as yin and yang, the Five phases, the 10 Celestial stems, the 12 Earthly Branches, and shichen (時辰 a form of timekeeping used for religious purposes). The early use of Chinese astrology was mainly confined to political astrology, the observation of unusual phenomena, identification of portents and the selection of auspicious days for events and decisions.
The constellations of the Zodiac of western Asia and Europe were not used; instead the sky is divided into Three Enclosures (三垣 sān yuán), and Twenty-eight Mansions (二十八宿 èrshíbā xiù) in twelve Ci (). The Chinese zodiac of twelve animal signs is said to represent twelve different types of personality. It is based on cycles of years, lunar months, and two-hour periods of the day (the shichen). The zodiac traditionally begins with the sign of the Rat, and the cycle proceeds through 11 other animals signs: the Ox, Tiger, Rabbit, Dragon, Snake, Horse, Goat, Monkey, Rooster, Dog and Pig. Complex systems of predicting fate and destiny based on one's birthday, birth season, and birth hours, such as "ziping" and Zi Wei Dou Shu () are still used regularly in modern day Chinese astrology. They do not rely on direct observations of the stars.
The Korean zodiac is identical to the Chinese one. The Vietnamese zodiac is almost identical to Chinese zodiac except the second animal is the "Water Buffalo" instead of the "Ox", and the fourth animal is the "Cat" instead of the "Rabbit". The Japanese have since 1873 celebrated the beginning of the new year on 1 January as per the Gregorian Calendar. The Thai zodiac begins, not at Chinese New Year, but either on the first day of fifth month in the Thai lunar calendar, or during the Songkran festival (now celebrated every 13–15 April), depending on the purpose of the use.
Theological viewpoints.
Ancient.
St. Augustine (354-430) believed that the determinism of astrology conflicted with the Christian doctrines of man's free will and responsibility, and God not being the cause of evil, but he also grounded his opposition philosophically, citing the failure of astrology to explain twins who behave differently although conceived at the same moment and born at approximately the same time.
Mediæval.
Some of the practices of astrology were contested on theological grounds by medieval Muslim astronomers such as Al-Farabi (Alpharabius), Ibn al-Haytham (Alhazen) and Avicenna. They said that the methods of astrologers conflicted with orthodox religious views of Islamic scholars, by suggesting that the Will of God can be known and predicted in advance. For example, Avicenna's 'Refutation against astrology', "Risāla fī ibṭāl aḥkām al-nojūm", argues against the practice of astrology while supporting the principle that planets may act as agents of divine causation. Avicenna considered that the movement of the planets influenced life on earth in a deterministic way, but argued against the possibility of determining the exact influence of the stars. Essentially, Avicenna did not deny the core dogma of astrology, but denied our ability to understand it to the extent that precise and fatalistic predictions could be made from it. Ibn Qayyim Al-Jawziyya (1292–1350), in his "Miftah Dar al-SaCadah", also used physical arguments in astronomy to question the practice of judicial astrology. He recognized that the stars are much larger than the planets, and argued:
Modern.
Divination, including predictive astrology, is stated in the Catechism of the Catholic Church to be incompatible with modern Catholic beliefs such as free will:
Scientific analysis and criticism.
Astrology has been rejected by the scientific community as having no explanatory power for describing the universe and is considered a pseudoscience. Scientific testing of astrology has been conducted, and no evidence has been found to support any of the premises or purported effects outlined in astrological traditions. There is no proposed mechanism of action by which the positions and motions of stars and planets could affect people and events on Earth that does not contradict well understood, basic aspects of biology and physics. Those who continue to have faith in astrology have been characterized as doing so "in spite of the fact that there is no verified scientific basis for their beliefs, and indeed that there is strong evidence to the contrary".
It has also been shown that confirmation bias is a psychological factor that contributes to belief in astrology. Confirmation bias is a form of cognitive bias. According to available literature Astrology believers tend to selectively remember those predictions which have turned out to be true, and do not remember those predictions which happen to be false. Another, separate, form of confirmation bias also plays a role, where believers often fail to distinguish between messages that demonstrate special ability and those which do not. Thus there are two distinct forms of confirmation bias that are under study with respect to astrological belief.
Demarcation.
Under the criterion of falsifiability, first proposed by philosopher of science Karl Popper, astrology is a pseudoscience. Popper regarded astrology as "pseudo-empirical" in that "it appeals to observation and experiment", but "nevertheless does not come up to scientific standards". In contrast to scientific disciplines, astrology has not responded to falsification through experiment. In contrast to Popper, the philosopher Thomas Kuhn argued that it was not lack of falsifiability that makes astrology unscientific, but rather that the process and concepts of astrology are non-empirical.
To Kuhn, although astrologers had, historically, made predictions that "categorically failed", this in itself does not make it unscientific, nor do the attempts by astrologers to explain away the failure by claiming it was due to the creation of a horoscope being very difficult. Rather, in Kuhn's eyes, astrology is not science because it was always more akin to medieval medicine; they followed a sequence of rules and guidelines for a seemingly necessary field with known shortcomings, but they did no research because the fields are not amenable to research, and so "they had no puzzles to solve and therefore no science to practise". While an astronomer could correct for failure, an astrologer could not. An astrologer could only explain away failure but could not revise the astrological hypothesis in a meaningful way. As such, to Kuhn, even if the stars could influence the path of humans through life astrology is not scientific.
Philosopher Paul Thagard believed that astrology cannot be regarded as falsified in this sense until it has been replaced with a successor. In the case of predicting behaviour, psychology is the alternative. To Thagard a further criterion of demarcation of science from pseudoscience was that the state-of-the-art must progress and that the community of researchers should be attempting to compare the current theory to alternatives, and not be "selective in considering confirmations and disconfirmations". Progress is defined here as explaining new phenomena and solving existing problems, yet astrology has failed to progress having only changed little in nearly 2000 years. To Thagard, astrologers are acting as though engaged in Normal science believing that the foundations of astrology were well established despite the "many unsolved problems", and in the face of better alternative theories (Psychology). For these reasons Thagard viewed astrology as pseudoscience.
For the philosopher Edward W. James, astrology is irrational not because of the numerous problems with mechanisms and falsification due to experiments, but because an analysis of the astrological literature shows that it is infused with fallacious logic and poor reasoning.
Effectiveness.
Astrology has not demonstrated its effectiveness in controlled studies and has no scientific validity. Where it has made falsifiable predictions under controlled conditions, they have been falsified. One famous experiment included 28 astrologers who were asked to match over a hundred natal charts to psychological profiles generated by the California Psychological Inventory (CPI) questionnaire. The double-blind experimental protocol used in this study was agreed upon by a group of physicists and a group of astrologers nominated by the National Council for Geocosmic Research, who advised the experimenters, helped ensure that the test was fair and helped draw the central proposition of natal astrology to be tested. They also chose 26 out of the 28 eight astrologers for the tests (two more volunteered afterwards). The study, published in "Nature" in 1985, found that predictions based on natal astrology were no better than chance, and that the testing "clearly refutes the astrological hypothesis".
In 1955, astrologer and psychologist Michel Gauquelin stated that although he had failed to find evidence to support such indicators as the zodiacal signs and planetary aspects in astrology, he had found positive correlations between the diurnal positions of some of the planets and success in some professions which astrology traditionally associates with those planets. The best-known of Gauquelin's findings is based on the positions of Mars in the natal charts of successful athletes and became known as the "Mars effect". A study conducted by seven French scientists attempted to replicate the claim, but found no statistical evidence. They attributed the effect to selective bias on Gauquelin's part, accusing him of attempting to persuade them to add or delete names from their study.
Geoffrey Dean has suggested that the effect may be caused by self-reporting of birth dates by parents rather than any issue with the study by Gauquelin. The suggestion is that a small subset of the parents may have had changed birth times to be consistent with better astrological charts for a related profession. The sample group was taken from a time where belief in astrology was more common. Gauquelin had failed to find the Mars effect in more recent populations, where a nurse or doctor recorded the birth information. The number of births under astrologically undesirable conditions was also lower, indicating more evidence that parents choose dates and times to suit their beliefs.
Dean, a scientist and former astrologer, and psychologist Ivan Kelly conducted a large scale scientific test, involving more than one hundred cognitive, behavioural, physical and other variables, but found no support for astrology. Furthermore, a meta-analysis was conducted pooling 40 studies consisting of 700 astrologers and over 1,000 birth charts. Ten of the tests, which had a total of 300 participating, involved the astrologers picking the correct chart interpretation out of a number of others which were not the astrologically correct chart interpretation (usually 3 to 5 others). When the date and other obvious clues were removed no significant results were found to suggest there was any preferred chart.
Lack of mechanisms and consistency.
Testing the validity of astrology can be difficult because there is no consensus amongst astrologers as to what astrology is or what it can predict. Most professional astrologers are paid to predict the future or describe a person's personality and life, but most horoscopes only make vague untestable statements that can apply to almost anyone.
Many astrologers claim that astrology is scientific,
while some have proposed conventional causal agents such as electromagnetism and gravity. Scientists reject these mechanisms as implausible since, for example, the magnetic field, when measured from earth, of a large but distant planet such as Jupiter is far smaller than that produced by ordinary household appliances.
Western astrology has taken the earth's axial precession (also called precession of the equinoxes) into account since Ptolemy's "Almagest", so the 'first point of Aries', the start of the astrological year, continually moves against the background of the stars. The tropical zodiac has no connection to the stars, and as long as no claims are made that the constellations themselves are in the associated sign, astrologers avoid the concept that precession seemingly moves the constellations. Charpak and Broch, noting this, referred to astrology based on the tropical zodiac as being "...empty boxes that have nothing to do with anything and are devoid of any consistency or correspondence with the stars." Sole use of the tropical zodiac is inconsistent with references made, by the same astrologers, to the Age of Aquarius, which depends on when the vernal point enters the constellation of Aquarius.
Astrologers usually have only a small knowledge of astronomy and they often do not take into account basic features such as the precession of the equinoxes which would change the position of the sun with time; they commented on the example of Elizabeth Teissier who claimed that "the sun ends up in the same place in the sky on the same date each year" as the basis for claims that two people with the same birthday but a number of years apart should be under the same planetary influence. Charpak and Broch noted that "there is a difference of about twenty-two thousand miles between Earth's location on any specific date in two successive years" and that thus they should not be under the same influence according to astrology. Over a 40 years period there would be a difference greater than 780,000 miles.
Cultural impact.
Western politics and society.
In the West, political leaders have sometimes consulted astrologers. Louis de Wohl worked as an astrologer for the British intelligence agency MI5, after it was claimed that Adolf Hitler used astrology to time his actions. The War Office was "interested to know what Hitler's own astrologers would be telling him from week to week". In fact, de Wohl's predictions were so inaccurate that he was soon labelled a "complete charlatan" and it was later shown that Hitler considered astrology to be "complete nonsense". After John Hinckley's attempted assassination of U.S. President Ronald Reagan, first lady Nancy Reagan commissioned astrologer Joan Quigley to act as the secret White House astrologer. However, Quigley's role ended in 1988 when it became public through the memoirs of former chief of staff, Donald Regan.
There was a boom in interest in astrology in the late 1960s. The sociologist Marcello Truzzi described three levels of involvement of "Astrology-believers" to account for its revived popularity in the face of scientific discrediting. He found that most astrology-believers did not claim it was a scientific explanation with predictive power. Instead, those superficially involved, knowing "next to nothing" about astrology's 'mechanics', read newspaper astrology columns, and could benefit from "tension-management of anxieties" and "a cognitive belief-system that transcends science". Those at the second level usually had their horoscopes cast and sought advice and predictions. They were much younger than those at the first level, and could benefit from knowledge of the language of astrology and the resulting ability to belong to a coherent and exclusive group. Those at the third level were highly involved and usually cast horoscopes for themselves. Astrology provided this small minority of astrology-believers with a ""meaningful" view of their universe and [gave] them an "understanding" of their place in it." This third group took astrology seriously, possibly as a "sacred canopy", whereas the other two groups took it playfully and irreverently.
In 1953, sociologist Theodor W. Adorno conducted a study of the astrology column of a Los Angeles newspaper as part of a project examining mass culture in capitalist society. Adorno believed that popular astrology, as a device, invariably led to statements which encouraged conformity, and that astrologers who went against conformity with statement discouraging performance at work etc. would risk losing their jobs. Adorno concluded that astrology was a large-scale manifestation of systematic irrationalism, where individuals were subtly being led to believe that the author of the column was addressing them directly through the use of flattery and vague generalisations. Adorno drew a parallel with the phrase opium of the people, by Karl Marx, by commenting "occultism is the metaphysic of the dopes".
A 2005 Gallup poll and a 2009 survey by the Pew Research Center reported that 25% of U.S. adults believe in astrology. According to data released in the National Science Foundation's 2014 "Science and Engineering Indicators" study, "Fewer Americans rejected astrology in 2012 than in recent years." The NSF study noted that in 2012, "slightly more than half of Americans said that astrology was 'not at all scientific,' whereas nearly two-thirds gave this response in 2010. The comparable percentage has not been this low since 1983."
India and Japan.
In India, there is a long-established and widespread belief in astrology. It is commonly used for daily life, particularly in matters concerning marriage and career, and makes extensive use of electional, horary and karmic astrology. Indian politics have also been influenced by astrology. It is still considered a branch of the Vedanga. In 2001, Indian scientists and politicians debated and critiqued a proposal to use state money to fund research into astrology, resulting in permission for Indian universities to offer courses in Vedic astrology.
On February 2011, the Bombay High Court reaffirmed astrology's standing in India when it dismissed a case which had challenged its status as a science.
In Japan, a strong belief in astrology has led to dramatic changes in the fertility rate and the number of abortions in the years of "Fire Horse". Women born in "hinoeuma" years are believed to be unmarriageable and to bring bad luck to their father or husband. In 1966, the number of babies born in Japan dropped by over 25% as parents tried to avoid the stigma of having a daughter born in the hinoeuma year.
Literature and music.
The fourteenth-century English poets John Gower and Geoffrey Chaucer both referred to astrology in their works, including Gower's "Confessio Amantis" and Chaucer's "The Canterbury Tales". Chaucer commented explicitly on astrology in his "Treatise on the Astrolabe", demonstrating personal knowledge of one area, judicial astrology, with an account of how to find the ascendant or rising sign.
In the fifteenth century, references to astrology, such as with similes, became "a matter of course" in English literature.
In the sixteenth century, John Lyly's 1597 play, "The Woman in the Moon", is wholly motivated by astrology, while Christopher Marlowe makes astrological references in his plays "Doctor Faustus" and "Tamburlaine" (both c. 1590), and Sir Philip Sidney refers to astrology at least four times in his romance "The Countess of Pembroke's Arcadia" (c. 1580). Edmund Spenser uses astrology both decoratively and causally in his poetry, revealing "unmistakably an abiding interest in the art, an interest shared by a large number of his contemporaries", while George Chapman's play "Byron's Conspiracy" (1608) similarly uses astrology as a causal mechanism in the drama. William Shakespeare's attitude towards astrology is unclear, with contradictory references in plays including "King Lear", "Antony and Cleopatra", and "Richard II". Shakespeare was familiar with astrology and made use of his knowledge of astrology "in nearly every play he wrote", assuming a basic familiarity with the subject in his commercial audience. Outside theatre, the physician and mystic Robert Fludd practised astrology, as did the quack doctor Simon Forman. In Elizabethan England, "the usual feeling about astrology ... [was] that it is the most useful of the sciences".
The most famous piece of music to be influenced by astrology is the orchestral suite "The Planets". Written by the British composer Gustav Holst (1874–1934), and first performed in 1918, the framework of "The Planets" is based upon the astrological symbolism of the planets. Each of the seven movements of the suite is based upon a different planet, though the movements are not in the order of the planets from the Sun. The composer Colin Matthews wrote an eighth movement entitled "Pluto, the Renewer", first performed in 2000. In 1937, another British composer, Constant Lambert, wrote a ballet on astrological themes, called "Horoscope". In 1974, the New Zealand composer Edwin Carr wrote "The Twelve Signs: An Astrological Entertainment" for orchestra without strings.

</doc>
<doc id="2123" url="http://en.wikipedia.org/wiki?curid=2123" title="Abyssinia">
Abyssinia

Abyssinia may refer to:

</doc>
<doc id="2125" url="http://en.wikipedia.org/wiki?curid=2125" title="Algebraic extension">
Algebraic extension

In abstract algebra, a field extension "L"/"K" is called algebraic if every element of "L" is algebraic over "K", i.e. if every element of "L" is a root of some non-zero polynomial with coefficients in "K". Field extensions that are not algebraic, i.e. which contain transcendental elements, are called transcendental.
For example, the field extension R/Q, that is the field of real numbers as an extension of the field of rational numbers, is transcendental, while the field extensions C/R and Q(√2)/Q are algebraic, where C is the field of complex numbers.
All transcendental extensions are of infinite degree. This in turn implies that all finite extensions are algebraic. The converse is not true however: there are infinite extensions which are algebraic. For instance, the field of all algebraic numbers is an infinite algebraic extension of the rational numbers.
If "a" is algebraic over "K", then "K"["a"], the set of all polynomials in "a" with coefficients in "K", is not only a ring but a field: an algebraic extension of "K" which has finite degree over "K". In the special case where "K" = Q is the field of rational numbers, Q["a"] is an example of an algebraic number field.
A field with no nontrivial algebraic extensions is called algebraically closed. An example is the field of complex numbers. Every field has an algebraic extension which is algebraically closed (called its algebraic closure), but proving this in general requires some form of the axiom of choice.
An extension "L"/"K" is algebraic if and only if every sub "K"-algebra of "L" is a field.
Properties.
The class of algebraic extensions forms a distinguished class of field extensions, that is, the following three properties hold:
Generalizations.
Model theory generalizes the notion of algebraic extension to arbitrary theories: an embedding of "M" into "N" is called an algebraic extension if for every "x" in "N" there is a formula "p" with parameters in "M", such that "p"("x") is true and the set
is finite. It turns out that applying this definition to the theory of fields gives the usual definition of algebraic extension. The Galois group of "N" over "M" can again be defined as the group of automorphisms, and it turns out that most of the theory of Galois groups can be developed for the general case.

</doc>
<doc id="2126" url="http://en.wikipedia.org/wiki?curid=2126" title="Ani DiFranco">
Ani DiFranco

Ani DiFranco (; born Angela Maria DiFranco; September 23, 1970) is an American singer, guitarist, multi-instrumentalist, poet and songwriter. She has released more than 20 albums and is widely considered a feminist icon. DiFranco has received positive feedback from critics for much of her career.
Although DiFranco's music has been classified as both folk rock and alternative rock, she has reached across genres since her earliest albums incorporating first punk, then funk, hip hop, and jazz influences. She was one of the first independent musicians to create her own record label (Righteous Babe), a move that has given her significant creative freedom. 
From the earliest days of her career, DiFranco has lent her voice and her name to a broad range of social movements, performing benefit concerts, appearing on benefit albums, and speaking at rallies. Through the Righteous Babe Foundation, DiFranco has backed various grassroots cultural and political organizations, supporting causes ranging from abortion rights to gay visibility.
Life and career.
DiFranco was born in Buffalo, New York, the daughter of Elizabeth (Ross) and Dante Americo DiFranco, who had met while attending MIT. Her father was of Italian descent, and her mother was from Montreal. DiFranco started playing Beatles covers at local bars and busking with her guitar teacher, Michael Meldrum, at the age of nine. By fourteen she was penning her own songs and playing her original material at bars and coffee houses throughout her teen years. DiFranco graduated from the Buffalo Academy for Visual and Performing Arts high school at the age of sixteen and began attending classes at Buffalo State College that same year. She was already living alone, having moved out of her mother's apartment after she became an emancipated minor at age 15.
In 1989 at the age of 18, DiFranco started her own record company, Righteous Records. 
Her self-titled debut album was issued on the label in the winter of 1990 shortly after, she had relocated to New York City. In New York she took poetry classes at The New School where she met poet Sekou Sundiata who was to become a friend and mentor. She began touring vigorously for the next 15 years, essentially pausing briefly only to record albums. Appearances at Canadian folk festivals and increasingly larger venues in the U.S. cemented her growing presence on the North American folk and roots scene.
In September 1996, DiFranco participated in a concert at the Rock and Roll Hall of Fame in Cleveland Ohio, inaugurating the opening of the Woody Guthrie Archives in New York City. She later released a CD by Righteous Babe of the concert entitled "Til We Outnumber Em" (featuring artists such as DiFranco, Billy Bragg, Ramblin' Jack Elliott, Arlo Guthrie, Indigo Girls, Dave Pirner, Tim Robbins, and Bruce Springsteen) with 100% of proceeds going to the Woody Guthrie Foundation and Archives and the Rock and Roll Hall of Fame Museum educational department.
DiFranco toured solo throughout the early and mid 1990s and also as a duo with a Canadian drummer named Andy Stochansky. Bassist Sara Lee joined the touring group in 1996. Their rapport during live shows is showcased on the 1997 album "Living in Clip". DiFranco would later release Lee's solo album "Make It Beautifu"l on Righteous Babe.
In 1998, Stochansky left to pursue a solo career as a singer-songwriter. A new touring ensemble consisting of Jason Mercer on bass, Julie Wolf on keyboards, and Daren Hahn on drums, augmented at times by a horn section, accompanied DiFranco on tour from 1998–2002.
The 1990s were a period of heightened exposure for DiFranco, as she continued playing ever larger venues around the world and attracted international attention of the press, including cover stories in "Spin, Ms., "and" Magnet, "among others, as well as appearances on MTV and VH1. Her playfully ironic cover of the Bacharach/David song "Wishin' and Hopin'" appeared under the opening titles of the hit film "My Best Friends Wedding".
Beginning in 1999, Righteous Babe Records began to release albums by other artists including Sekou Sundiata, Michael Meldrum, Arto Lindsay, Bitch and Animal, That One Guy, Utah Phillips, Hamell on Trial, Andrew Bird, Kurt Swinghammer. Sara Lee, Buddy Wakefield, Anais Mitchell, and Nona Hendryx.
On September 11, 2001 DiFranco was in Manhattan and later penned the epic poem "Self Evident" about the experience. The poem was featured in the book "It's a Free Country: Personal Freedom in America After September 11, "edited by Danny Goldberg, Victoria Goldberg, and Robert Greenwald. The poem's title also became the name of DiFranco's first book of poetry released exclusively in Italy by Minimum Fax. It was later featured in a book of her poetry published in the U.S. by Seven Stories press, entitled "Verses". DiFranco has written and performed many spoken-word pieces throughout her career and was showcased as a poet on the HBO series "Def Poetry" in 2005
Her father died early in the summer of 2004. In July 2005, DiFranco developed tendonitis and took a nine-month hiatus from touring.
On September 11, 2007, she released the first retrospective of her career, a two disc compilation entitled "Canon" and simultaneously released a retrospective collection of poetry book "Verses". "Red Letter Year" was released on September 30, 2008.
DiFranco performed a live webcast from Ex'pression College for Digital Arts on June 24, 2010. She debuted a selection of new material, including the songs "Which Side Are You On?" (a reworking of the Florence Reece song with different lyrics penned by DiFranco), "Life Boat", "Unworry", "Promiscuity", "Splinter", "Amendment", "See See..." and "Hearse".
DiFranco's touring band and recordings have featured the bass player Todd Sickafoose since her 2005 release "Knuckle Down "(co-produced by Joe Henry) and in turns other musicians such as Allison Miller, Andy Borger, Herlin Riley, and Terence Higgins on drums and Mike Dillon on percussion and vibes.
In 2009 DiFranco appeared at Pete Seeger's 90th birthday celebration at Madison Square Garden, debuting her revamped version of the 1930s labor anthem "Which Side Are You On?" in a duet with Bruce Cockburn and also duetting with Kris Kristofferson on the folk classic " There's a Hole in the Bucket".
DiFranco released an album of new material on January 17, 2012, titled "¿Which Side Are You On?". It includes collaborations with Pete Seeger, Ivan Neville, Cyril Neville, Skerik, Adam Levy, Righteous Babe recording artist Anaïs Mitchell, CC Adcock, and a host of New Orleans-based horn players known for their work in such outfits as Galactic, Bonerama, and Rebirth Brass Band.
She and her husband currently reside in the Bywater neighborhood of New Orleans.
Relationships.
DiFranco identifies herself as bisexual, and has written songs about love and sex with women and men. She addressed the controversy about her sexuality with the song "In or Out". In 1998, she married sound engineer Andrew Gilchrist in a Unitarian Universalist service in Canada. DiFranco and Gilchrist divorced five years later.
DiFranco gave birth to a daughter, Petah Lucia DiFranco Napolitano, at her Buffalo home in 2007. She married the child's father Mike Napolitano, also her regular producer, in 2009.
In an interview on September 13, 2012, DiFranco mentioned that she was pregnant with her second child with husband Mike Napolitano. She gave birth to a second child, a son Dante DiFranco Napolitano, in 2013.
Critical reception.
DiFranco has been a critical success for much of her career, though not a commercial one by major label standards, with a career album average of 72 on Metacritic. "Living in Clip", DiFranco's 1998 double live album, is the only one to achieve gold record status to date. DiFranco has been praised by the "Buffalo News" as the "Buffalo's leading lady of rock music".
Starting in 2003, DiFranco was nominated four consecutive times for Best Recording Package at the Grammy Awards, winning in 2004, for "Evolve".
On July 21, 2006, DiFranco received the "Woman of Courage Award" at the National Organization for Women (NOW) Conference and Young Feminist Summit in Albany, New York. Past winners have included singer and actress Barbra Streisand and Sen. Barbara Boxer, D-Calif. DiFranco is one of the first musicians to receive the award, given each year to a woman who has set herself apart by her contributions to the feminist movement.
In 2009 DiFranco became a Woody Guthrie Award recipient, as a voice of positive social change.
Music.
Style.
DiFranco's guitar playing is often characterized by a signature staccato style, rapid fingerpicking and many alternate tunings. She delivers many of her lines in a speaking style notable for its rhythmic variation. Her lyrics, which often include alliteration, metaphor, word play and a more or less gentle irony, have also received praise for their sophistication.
Although DiFranco's music has been classified as both folk rock and alternative rock, she has reached across genres since her earliest albums incorporating first punk, then funk, hiphop, and jazz influences.
While primarlly an acoustic guitarist she has used a variety of instruments and styles: brass instrumentation was prevalent in 1998's "Little Plastic Castle"; a simple walking bass in her 1997 cover of Hal David and Burt Bacharach's "Wishin' and Hopin'"; strings on the 1997 live album "Living in Clip" and 2004's "Knuckle Down"; and electronics and synthesisers in 1999's "To the Teeth" and 2006's "Reprieve".
DiFranco herself noted that "folk music is not an acoustic guitar – that's not where the heart of it is. I use the word 'folk' in reference to punk music and rap music. It's an attitude, it's an awareness of one's heritage, and it's a community. It's subcorporate music that gives voice to different communities and their struggle against authority."
Musical collaborations, cover versions, and samples.
DiFranco has also collaborated with a wide range of artists. In 1997 she appeared on Canadian songwriter Bruce Cockburn's "Charity of Night" album. In 1998 she produced fellow folksinger Dan Bern's album "Fifty Eggs".
She developed a deep association with folksinger and social activist Utah Phillips throughout the mid-1990s, sharing her stage and her audience with the older musician until his death in 2008 and resulting in two collaborative albums: "The Past Didn't Go Anywhere", 1996, and "Fellow Workers",1999 (with liner notes by Howard Zinn). "The Past" is built around Phillips's storytelling, an important part of his art that had not previously been documented on recordings; on the album, DiFranco provides musical settings for his speaking voice. The followup, "Fellow Workers", was recorded live in Daniel Lanois's Kingsway Studio in New Orleans and features Phillips fronting DiFranco's touring band for a collection of songs and stories.
Prince recorded two songs with DiFranco in 1999, "Providence" on her "To the Teeth" album, and "I Love U, But I Don't Trust U Anymore" on Prince's "Rave Un2 the Joy Fantastic" album. Funk and soul jazz musician Maceo Parker and rapper Corey Parker have both appeared on DiFranco's albums and featured appearances by her on theirs.
She has appeared on several compilations of the songs of Pete Seeger and frequented his Hudson Clearwater Revival Festival. In 2001 she appeared on Brazilian artist Lenine's album "Falange Canibal". In 2002 her rendition of Greg Brown's "The Poet Game" appeared on "Going Driftless: An Artist’s Tribute to Greg Brown". Also in 2002 she recorded a duet with Jackie Chan of the Irving Gordon song "Unforgettable" for a record of unlikely collaborations entitled "When Pigs Fly: Songs You Never Thought You’d Hear".
In 2005 she appeared on Dar Williams' record "My Better Self", dueting on William's cover of Pink Floyd's "Comfortably Numb". She performed with Cyndi Lauper on "Sisters of Avalon" a track from Lauper's 2005 "The Body Acoustic" album. In 2006 she produced Hamell on Trial's album "Songs for Parents Who Enjoy Drugs". In 2008 she appeared on Todd Sickafoose's album "Tiny Resisters". In 2010 she co-produced a track with Margaret Cho called "Captain Cameltoe" for the comedian's "Cho Dependant" album. In 2011 she appeared on Rob Wasserman's album "Note of Hope", an exploration of the writings of Woody Guthrie with musical accompaniment, though the track in which she appeared, "Voice", was actually recorded 13 years earlier. Also in 2011 she duetted with Greg Dulli on the Twilight Singers record "Dynamite Steps".
Other artists have covered and sampled DiFranco's work throughout the years. Her spoken word poem "Self Evident" was covered by Public Enemy founder Chuck D's group called Impossebulls. Alana Davis had some commercial success with DiFranco's song 32 Flavors.
Samples from the track "Coming Up" were used by DJ Spooky in his album "Live Without Dead Time", produced for AdBusters Magazine in 2003.
Lyrics, politics and religion.
Although much of DiFranco's material is autobiographical, it is often also strongly political. Many of her songs are concerned with contemporary social issues such as racism, sexism, sexual abuse, homophobia, reproductive rights, poverty, and war. In 2008, she donated a song to Aid Still Required's CD to assist with the restoration of the devastation done to Southeast Asia from the 2004 Tsunami.
The combination of personal and political is partially responsible for DiFranco's early popularity among politically active college students, particularly those of the left wing, some of whom set up fan pages on the web to document DiFranco's career as early as 1994. DiFranco's rapid rise in popularity in the mid-1990s was fueled mostly by personal contact and word of mouth rather than mainstream media.
DiFranco has expressed political views outside of her music. During the 2000 U.S. presidential election, she actively supported and voted for Green Party candidate Ralph Nader. She supported Dennis Kucinich in the 2004 and 2008 Democratic primaries. Kucinich appeared with her at a number of concerts across the country during both primary seasons. DiFranco went on to perform at the 2008 Democratic National Convention.
DiFranco has described herself as an atheist. On the subject of religion, DiFranco has stated:
"Well, I'm not a religious person myself. I'm an atheist. I think religion serves a lot of different purposes in people's lives, and I can recognize the value of that, you know, the value of ceremony, the value of community, or even just having a forum to get together and talk about ideas, about morals – that's a cool concept. But then, of course, institutional religions are so problematic."
Label independence.
DiFranco was one of the first independent artists to own her own label, she cites her anti-corporate ethos for the main reason she decided to start her own label. This has allowed her a considerable degree of creative freedom over the years, including, for example, providing all instrumentals and vocals and recording the album herself at her home on an analog 8-track reel to reel, and handling much of the artwork and packaging design for her 2004 album "Educated Guess". She has referenced this independence from major labels in song more than once, including "The Million You Never Made" ("Not a Pretty Girl"), which discusses the act of turning down a lucrative contract, "The Next Big Thing" ("Not So Soft"), which describes an imagined meeting with a label head-hunter who evaluates the singer based on her looks, and "Napoleon" ("Dilate"), which sympathizes sarcastically with an unnamed friend who did sign with a label.
The business grew organically starting in 1990 with the first cassette tape. Connections were made when women in colleges started duplicating and sharing tapes. Offers to play at colleges started coming in and her popularity grew largely by word of mouth and through women's groups or organizations. Zango and Goldenrod, two music distributors specializing in women's music, started carrying DiFranco's music. In general they sold music to independent music stores and women's book stores. In 1995 Righteous Babe Records signed with Koch International for DiFranco's release of "Not a Pretty Girl". Her records could then be found in large and small record stores alike.
DiFranco has occasionally joined with Prince in discussing publicly the problems associated with major record companies. Righteous Babe Records employs a number of people in her hometown of Buffalo. In a 1997 open letter to "Ms. magazine" she expressed displeasure that what she considers a way to ensure her own artistic freedom was seen by others solely in terms of its financial success.
Activism.
From the earliest days of her career, Ani DiFranco has lent her voice and her name to a broad range of social movements, performing benefit concerts, appearing on benefit albums, speaking at rallies, and offering info table space to organizations at her concerts and the virtual equivalent on her website, among other methods and actions. In 1999 she created her own not-for-profit organization; as the Buffalo News has reported,"Through the Righteous Babe Foundation, DiFranco has backed various grassroots cultural and political organizations, supporting causes ranging from abortion rights to gay visibility."
During the first Gulf War, DiFranco participated in the anti-war movement. In the early 1993 she played Pete Seeger's Clearwater Folk Festival for the first time. In 1998 she was a featured performer in the Dead Man Walking benefit concert series raising money for Sister Helen Prejean's "Not in Our Name" anti-death penalty organization. DiFranco's commitment to opposing the death penalty is longstanding; she has also been a long time supporter of the Southern Center for Human Rights.
In 2004 DiFranco visited Burma in order to learn about the Burmese resistance movement and the country's fight for democracy. During her travels she met with then-detained resistance leader Aung San Suu Kyi. Her song "In The Way" was later featured on For the Lady, a benefit CD that donated all proceeds to the United States Campaign for Burma.
On the home front, DiFranco has also been outspoken defender of democracy. During the 2004 presidential primaries, she openly and enthusiastically supported liberal, anti-war Democrat Dennis Kucinich. Congressman Kucinich appeared on stage with her at several concerts and she spoke positively about him from the stage at many more of her concerts. After the primary season ended, and Kerry was the clear Democratic candidate, DiFranco wrote an open letter of conditional support for independent candidate Ralph Nader. The same year she launched a "Vote, Dammit" tour of swing states encouraging audience members to register to vote. In 2005 she lobbied Congress against the proliferation of nuclear power in general and the placement of nuclear waste dumps on Indian land in particular. In 2008 she backed candidate Dennis Kucinich in his bid for the presidency.
In 2002 Righteous Babe Records established the "Aiding Buffalo's Children"program in conjunction with members of the local community to raise funds for Buffalo's imperiled public school system. To kick off the program, DiFranco donated "a day's pay"—the performance fee from her concert that year at Shea's Performing Arts Center— to ABC and challenged her fans to do the same. Aiding Buffalo's Children has since been folded into the Community Foundation of Greater Buffalo, contributing to a variety of charitable funds.
In 2005 when Hurricane Katrina devastated DiFranco's newly adopted home town of New Orleans she collected donations from fans around the world through The Righteous Babe Store website for the Katrina Piano Fund, helping musicians replace instruments lost in the hurricane, raising over $47,500 for the cause.
In 2010 when the BP Oil Spill crippled the Gulf she donated her talents to the "For Our Coast”benefit concert joining Marianne Faithfull, C.C. Adcock and others at the Acadiana Center for the Arts Theater in Lafayette, raising money for Gulf Aid Acadiana, and the Gulf Aid show with Lenny Kravitz, Mos Def, and many more at Mardi Gras World River City in New Orleans, both shows raising money to help protect the wetlands, clean up the coast and to assist the fishermen and their families affected by the spill.
DiFranco also sits on the board for the Roots of Music Program, founded by Rebirth Brass Band drummer Derrick Tabb. The organization fills a void in music education in New Orleans educational institutions by providing free Marching Band instruction to area children in addition to academic tutoring and mentoring.
DiFranco joined about 500,000 people at the March for Women's Lives in DC in April 2004 to voice her support for women's rights. As an honored guest she marched in the front row for the three-mile route, along with Margaret Cho, Janeane Garofalo, Whoopi Goldberg, Gloria Steinem and many others. Later in the day, Ani played a few songs on the main stage in front of the Capitol, including "Your Next Bold Move".
Scot Fisher, Righteous Babe label president and DiFranco's longtime manager, has been a longtime advocate of the preservation movement in Buffalo. In 1999 he and DiFranco purchased a decaying church on the verge of demolition in downtown Buffalo and began the lengthy process of restoring it. In 2006 the building opened its doors again, first briefly as "The Church" and then as "Babeville,” housing two concert venues, the record label's business office, and Hallwalls Contemporary Arts Center.
2014 Righteous Retreat.
In 2013 DiFranco was criticized on social media and faced "a great deal of outcry" after the announcement that she was hosting a three-day artists' workshop billed as the "Righteous Retreat" at Iberville Parish's Nottoway Plantation in White Castle, Louisiana. Nottoway was one of the largest plantations in the South, and features the largest antebellum mansion. Its operator and founder John Randolph owned over 155 slaves in the year 1860. The grounds are now operated as a luxury resort. Critics charged that the resort's promotional material attempts to portray the plantation owner in a positive light, to downplay the suffering of the slaves, and to "sanitize" and "romanticize" the history of slavery for commercial gain. DiFranco's choice of venue for the retreat was called "a very blatant display of racism" on a petition at change.org that collected more than 2,600 signatures.
On December 29, 2013 DiFranco issued an apology and cancelled the retreat, stating that "i am not unaware of the mechanism of white privilege or the fact that i need to listen more than talk when it comes to issues of race. if nottoway is simply not an acceptable place for me to go and try to do my work in the eyes of many, then let me just concede before more divisive words are spilled. ... i think many positive and life-affirming connections would have been made at this conference, in its all of its complexity of design. i do not wish to reinvent the righteous retreat at this point to eliminate the stay at the Nottoway Plantation. at this point I wish only to cancel." The singer's statements were called "remarkably unapologetic" on jezebel.com, and "a variety of excuses and justifications" on ebony.com, and a piece at theguardian.com said the announcement made "much of the idea that this was all a mistake, with no indication of remorse."
DiFranco issued a second apology on January 2, 2014 following continued criticism. In it she wrote, "..i would like to say i am sincerely sorry. it is obvious to me now that you were right - all those who said we can't in good conscience go to that place and support it or look past for one moment what it deeply represents. i needed a wake up call and you gave it to me."

</doc>
<doc id="2127" url="http://en.wikipedia.org/wiki?curid=2127" title="Arene (disambiguation)">
Arene (disambiguation)

An Aromatic hydrocarbon or Arene is a hydrocarbon with alternating double and single bonds between carbon atoms forming rings.
Arene may also refer to:

</doc>
<doc id="2129" url="http://en.wikipedia.org/wiki?curid=2129" title="Arizona Diamondbacks">
Arizona Diamondbacks

The Arizona Diamondbacks (often shortened as the D-backs) are an American professional baseball team based in Phoenix, Arizona. They play in the West Division of Major League Baseball's National League. Since the team's inception in 1998, the franchise has played home games at Chase Field, formerly known as Bank One Ballpark. The ballpark was renamed in 2005 as a result of Bank One Corporation's merger with JPMorgan Chase & Co.. The Diamondbacks have won one World Series championship (in 2001), becoming the fastest expansion team in the major leagues to win a championship, doing it in only the fourth season since the franchise's inception in the 1998 Major League Baseball season.
Franchise history.
Baseball had a rich tradition in Arizona long before talk of bringing a major league team even started. The state has been a frequent spring training site since 1946. With a large number of people relocating to the state from the Midwest and the Northeast, as well as from California, many teams (most notably the Chicago Cubs, Chicago White Sox, New York Yankees, New York Mets, San Francisco Giants and the Los Angeles Dodgers) have normally had large followings in Arizona.
On March 9, 1995, Arizona was awarded a franchise to begin play for the 1998 season. A $130 million franchise fee was paid to Major League Baseball and on January 16, 1997, the Diamondbacks were officially voted into the National League.
Since their debut, the Diamondbacks have won five National League West titles, one National League Championship pennant and the 2001 World Series.
Logos.
The Diamondbacks' original colors were purple, black, turquoise and copper. Their first logo was an italicized block letter "A" with a diamond pattern and a snake's tongue. Prior to their inaugural season, they released their baseball caps. The home cap had a cream color crown with a purple visor and button. The road cap was black and had a turquoise visor and button. Their alternate cap had a turquoise crown with a purple visor and button. Depending on the cap, the "A" logo on the front of the cap had different color variations.
In the Diamondbacks' second season, they introduced a new logo which was a copper color snake in the shape of a letter "D". It was used on a solid black cap, which in the beginning, was worn as a road cap.
The franchise unveiled new uniforms and colors of Sedona Red, Sonoran Sand and black on November 8, 2006. The red shade is named for the sandstone canyon at Red Rock State Park near Sedona, while the beige (sand) shade is named for the Sonoran Desert. A sleeve patch was added featuring a lowercase "d" and "b" configured to look like a snake's head. The team also kept the "D" logo, but was slightly altered and put on an all red cap to be used as their game cap. They also kept the "A" logo with the new colors applied to it, with a solid black cap used as the alternate cap. A similar color scheme is currently used by the Arizona Coyotes of the National Hockey League.
Media.
The primary television play-by-play voice for the team's first nine seasons of play was Thom Brennaman, who also broadcasts baseball and college football games nationally for Fox Television. Brennaman was the TV announcer for the Chicago Cubs and Cincinnati Reds (along with his father Marty Brennaman) before being hired by Diamondbacks founder Jerry Colangelo in 1996, two years before the team would begin play.
In October 2006, Brennaman left the Diamondbacks to call games with his father for the Reds beginning in 2007, signing a four-year deal (his FOX duties remained unchanged).
The English language flagship radio station is KTAR. Greg Schulte is the regular radio play-by-play voice, a 25-year veteran of sports radio in the Phoenix market, also well known for his previous work on Phoenix Suns, Arizona Cardinals and Arizona State University (ASU) broadcasts.
Jeff Munn is a backup radio play-by-play announcer; he served as the regular public address announcer at Chase Field in the early days of the franchise. He is well-known to many Phoenix area sports fans, having also served as the public address announcer for the Suns at America West Arena (now US Airways Center) in the 1990s. He is also the play-by-play radio voice for ASU women's basketball.
On November 1, 2006, the team announced that the TV voice of the Milwaukee Brewers since 2002, Daron Sutton, would be hired as the Diamondbacks primary TV play-by-play voice. Sutton was signed to a five-year contract with a team option for three more years. Sutton is considered one of the best of the younger generation of baseball broadcasters. His signature chants include "let's get some runs" when the D'Backs trail in late innings. Sutton's father is Hall of Fame pitcher and current Atlanta Braves broadcaster Don Sutton.
Former Diamondback and Chicago Cub Mark Grace and former Major League knuckleball pitcher Tom Candiotti were the Diamondbacks primary color analysts for the 2006 and 2007 seasons. Former Diamondback player Matt Williams also does color commentary on occasion, as does former Cardinals and NBC broadcast legend Joe Garagiola, Sr., a longtime Phoenix-area resident and father of Joe Garagiola, Jr., the first GM of the Diamondbacks (as head of the Maricopa County Sports Authority in the early 1990s, Garagiola, Jr. was one of the primary people involved in Phoenix obtaining a Major League Baseball franchise).
The Diamondbacks announced in July 2007 that for the 2008 season, all regionally broadcast Diamondback TV games will be shown exclusively on Fox Sports Arizona; and a few could possibly be shown on the national MLB on Fox telecasts. Fox Sports Arizona (or FSArizona) is currently seen in 2.8 million households in Arizona & New Mexico. The previous flagship station, since the inaugural 1998 season, was KTVK, a popular over-the-air independent station in Phoenix.
From 2009 to 2012, Mark Grace and Daron Sutton were tagged as the main broadcasters of the Diamondbacks with pre-game and post-game shows on FSArizona, being hosted by former big-league closer Joe Borowski.
On June 21, 2012, Daron Sutton was suspended indefinitely, amidst rumors of insubordination. Then on August 24, the team announced that Mark Grace had requested an indefinite leave of absence after being arrested for his second DUI in less than two years. (Grace was later indicted on four DUI counts) For the remainder of the 2012 season, Sutton was replaced by Greg Schulte (Jeff Munn replaced Schulte on the radio broadcast) and Grace was replaced by Luis Gonzalez. At the end of the 2012 season, the team announced that neither Sutton nor Grace would be returning for the 2013 season.
On October 18, 2012, the team announced that Bob Brenly would be returning as a broadcaster, and that he would be joined by then-ESPN personality Steve Berthiaume.
The flagship Spanish language radio station is AM 710 with Miguel Quintana, Richard Saenz and Oscar Soria.
Games were televised in Spanish on KPHE-LP—with Oscar Soria and Jerry Romo as the announcers—but this arrangement ended prior to the 2009 season due to the team switching fully to Fox Sports Arizona and the lack of carriage of KHPE-LP on the Cox cable system.
Ford C. Frick Award recipients.
Names in bold received the award based on their work as Diamondbacks broadcasters.
Retired numbers.
On June 23, 2010, the Diamondbacks announced that the team would retire its first jersey number by honoring Luis Gonzalez. Gonzalez played with the Diamondbacks for eight seasons, 1999 to 2006, attended five All-Star games representing the team and had the game-winning hit to win the first World Series in franchise history. His number, #20, was retired in a pre-game ceremony which was held at Chase Field on August 7, 2010 in front of a sellout crowd of 48,946. After the ceremony, the Diamondbacks won the game against the San Diego Padres 6–5 after a walk-off home run by Chris Young, who also led the game off with a home run in the bottom of the first inning.
Championships.
 
 
 

</doc>
<doc id="2130" url="http://en.wikipedia.org/wiki?curid=2130" title="Aesthetics">
Aesthetics

Aesthetics (; also spelled æsthetics and esthetics) is a branch of philosophy dealing with the nature of art, beauty, and taste, with the creation and appreciation of beauty. It is more scientifically defined as the study of sensory or sensori-emotional values, sometimes called judgments of sentiment and taste. More broadly, scholars in the field define aesthetics as "critical reflection on art, culture and nature."
More specific aesthetic theory, often with practical implications, relating to a particular branch of the arts is divided into areas of aesthetics such as art theory, literary theory, film theory and music theory. An example from art theory is aesthetic theory as a set of principles underlying the work of a particular artist or artistic movement: such as the Cubist aesthetic.
Etymology.
The word "aesthetic" is derived from the Greek αἰσθητικός ("aisthetikos", meaning "esthetic, sensitive, sentient"), which in turn was derived from αἰσθάνομαι ("aisthanomai", meaning "I perceive, feel, sense"). The term "aesthetics" was appropriated and coined with new meaning in the German form "Æsthetik" (modern spelling "Ästhetik") by Alexander Baumgarten in 1735.
Aesthetics and the philosophy of art.
For some, aesthetics is considered a synonym for the philosophy of art since Hegel, while others insist that there is a significant distinction between these closely related fields. In practice aesthetic judgement refers to the sensory contemplation or appreciation of an object (not necessarily an art object), while artistic judgement refers to the recognition, appreciation or criticism of art or an art work.
Philosophical aesthetics has not only to speak about art and to produce judgments about art works, but has also to give a definition of what art is. Art is an autonomous entity for philosophy, because art deals with the senses (i. e. the etymology of aesthetics) and art is as such free of any moral or political purpose. Hence, there are two different conceptions of art in aesthetics: art as knowledge or art as action, but aesthetics is neither epistemology nor ethics.
Post-renaissance aesthetics.
From the late 17th to the early 20th century Western aesthetics underwent a slow revolution into what is often called modernism. German and British thinkers emphasised beauty as the key component of art and of the aesthetic experience, and saw art as necessarily aiming at absolute beauty.
For Alexander Gottlieb Baumgarten aesthetics is the science of the sense experiences, a younger sister of logic, and beauty is thus the most perfect kind of knowledge that sense experience can have. For Immanuel Kant the aesthetic experience of beauty is a judgment of a subjective but similar human truth, since all people should agree that "this rose is beautiful" if it in fact is. However, beauty cannot be reduced to any more basic set of features. For Friedrich Schiller aesthetic appreciation of beauty is the most perfect reconciliation of the sensual and rational parts of human nature.
For Friedrich Wilhelm Joseph Schelling, the philosophy of art is the "organon" of philosophy concerning the relation between man and nature. So aesthetics began now to be the name for the "philosophy of art". Friedrich von Schlegel, August Wilhelm Schlegel, Friedrich Schleiermacher and Georg Wilhelm Friedrich Hegel have also given lectures on aesthetics as "philosophy of art" after 1800.
For Hegel all culture is a matter of "absolute spirit" coming to be manifest to itself, stage by stage, changing to a perfection that only philosophy can approach. Art is the first stage in which the absolute spirit is manifest immediately to sense-perception, and is thus an objective rather than subjective revelation of beauty.
For Arthur Schopenhauer aesthetic contemplation of beauty is the most free that the pure intellect can be from the dictates of will; here we contemplate perfection of form without any kind of worldly agenda, and thus any intrusion of utility or politics would ruin the point of the beauty. It is thus for Schopenhauer one way to fight the suffering.
The British were largely divided into intuitionist and analytic camps. The intuitionists believed that aesthetic experience was disclosed by a single mental faculty of some kind. For Anthony Ashley-Cooper, 3rd Earl of Shaftesbury this was identical to the moral sense, beauty just is the sensory version of moral goodness. For Ludwig Wittgenstein aesthetics consisted in the description of a whole culture which is a linguistic impossibility. Hence his viewpoint can be paraphrased as "That which constitutes aesthetics lies outside the realm of the language game".
For Oscar Wilde, the contemplation of beauty for beauty's sake (augmented by John Ruskin's search for moral grounding) was more than the foundation for much of his literary career; he once stated, "Aestheticism is a search after the signs of the beautiful. It is the science of the beautiful through which men seek the correlation of the arts. It is, to speak more exactly, the search after the secret of life.".
Wilde famously toured the United States in 1882. He travelled across the United States spreading the idea of Aesthetics in a speech called "The English Renaissance." In his speech he proposed that Beauty and Aesthetics was "not languid but energetic. By beautifying the outward aspects of life, one would beautify the inner ones." The English Renaissance was, he said, "like the Italian Renaissance before it, a sort of rebirth of the spirit of man".
For Francis Hutcheson beauty is disclosed by an inner mental sense, but is a subjective fact rather than an objective one. Analytic theorists like Henry Home, Lord Kames, William Hogarth, and Edmund Burke hoped to reduce beauty to some list of attributes. Hogarth, for example, thinks that beauty consists of (1) fitness of the parts to some design; (2) variety in as many ways as possible; (3) uniformity, regularity or symmetry, which is only beautiful when it helps to preserve the character of fitness; (4) simplicity or distinctness, which gives pleasure not in itself, but through its enabling the eye to enjoy variety with ease; (5) intricacy, which provides employment for our active energies, leading the eye on "a wanton kind of chase"; and (6) quantity or magnitude, which draws our attention and produces admiration and awe. Later analytic aestheticians strove to link beauty to some scientific theory of psychology (such as James Mill) or biology (such as Herbert Spencer).
New Criticism and "The Intentional Fallacy".
During the first half of the twentieth century, a significant shift to general aesthetic theory took place which attempted to apply aesthetic theory between various forms of art, including the literary arts and the visual arts, to each other. This resulted in the rise of the New Criticism school and debate concerning "the intentional fallacy". At issue was the question of whether the aesthetic intentions of the artist in creating the work of art, whatever its specific form, should be associated with the criticism and evaluation of the final product of the work of art, or, if the work of art should be evaluated on its own merits independent of the intentions of the artist.
In 1946, William K. Wimsatt and Monroe Beardsley published a classic and controversial New Critical essay entitled "The Intentional Fallacy", in which they argued strongly against the relevance of an author's intention, or "intended meaning" in the analysis of a literary work. For Wimsatt and Beardsley, the words on the page were all that mattered; importation of meanings from outside the text was considered irrelevant, and potentially distracting.
In another essay, "The Affective Fallacy," which served as a kind of sister essay to "The Intentional Fallacy" Wimsatt and Beardsley also discounted the reader's personal/emotional reaction to a literary work as a valid means of analyzing a text. This fallacy would later be repudiated by theorists from the reader-response school of literary theory. Ironically, one of the leading theorists from this school, Stanley Fish, was himself trained by New Critics. Fish criticizes Wimsatt and Beardsley in his essay "Literature in the Reader" (1970).
As summarized by Gaut and Livingston in their essay "The Creation of Art": "Structuralist and post-structuralists theorists and critics were sharply critical of many aspects of New Criticism, beginning with the emphasis on aesthetic appreciation and the so-called autonomy of art, but they reiterated the attack on biographical criticisms's assumption that the artist's activities and experience were a privileged critical topic." These authors contend that: "Anti-intentionalists, such as formalists, hold that the intentions involved in the making of art are irrelevant or peripheral to correctly interpreting art. So details of the act of creating a work, though possibly of interest in themselves, have no bearing on the correct interpretation of the work."
Gaut and Livingston define the intentionalists as distinct from formalists stating that: "Intentionalists, unlike formalists, hold that reference to intentions is essential in fixing the correct interpretation of works." They quote Richard Wollheim as stating that, "The task of criticism is the reconstruction of the creative process, where the creative process must in turn be thought of as something not stopping short of, but terminating on, the work of art itself."
Post-modern aesthetics and psychoanalysis.
Early-twentieth-century artists, poets and composers challenged existing notions of beauty, broadening the scope of art and aesthetics. In 1941, Eli Siegel, American philosopher and poet, founded Aesthetic Realism, the philosophy that reality itself is aesthetic, and that "The world, art, and self explain each other: each is the aesthetic oneness of opposites."
Various attempts have been made to define Post-modern aesthetics. The challenge to the assumption that beauty was central to art and aesthetics, thought to be original, is actually continuous with older aesthetic theory; Aristotle was the first in the Western tradition to classify "beauty" into types as in his theory of drama, and Kant made a distinction between beauty and the sublime. What was new was a refusal to credit the higher status of certain types, where the taxonomy implied a preference for tragedy and the sublime to comedy and the Rococo.
Croce suggested that "expression" is central in the way that beauty was once thought to be central. George Dickie suggested that the sociological institutions of the art world were the glue binding art and sensibility into unities. Marshall McLuhan suggested that art always functions as a "counter-environment" designed to make visible what is usually invisible about a society. Theodor Adorno felt that aesthetics could not proceed without confronting the role of the culture industry in the commodification of art and aesthetic experience. Hal Foster attempted to portray the reaction against beauty and Modernist art in "The Anti-Aesthetic: Essays on Postmodern Culture". Arthur Danto has described this reaction as "kalliphobia" (after the Greek word for beauty, κάλλος "kallos"). André Malraux explains that the notion of beauty was connected to a particular conception of art that arose with the Renaissance and was still dominant in the eighteenth century (but was supplanted later). The discipline of aesthetics, which originated in the eighteenth century, mistook this transient state of affairs for a revelation of the permanent nature of art. Brian Massumi suggests to reconsider beauty following the aesthetical thought in the philosophy of Deleuze and Guattari.
Jean-François Lyotard re-invokes the Kantian distinction between taste and the sublime. Sublime painting, unlike kitsch realism, "... will enable us to see only by making it impossible to see; it will please only by causing pain."
Sigmund Freud inaugurated aesthetical thinking in Psychoanalysis mainly via the "Uncanny" as aesthetical affect. Following Freud and Merleau-Ponty, Jacques Lacan theorized aesthetics in terms of sublimation and the Thing.
The relation of Marxist aesthetics to postmodern aesthetics is still a contentious area of debate.
Recent aesthetics.
It is not always clear, easy, or relevant to categorize all recent aesthetics into either modern(ist) or post-modern.
Guy Sircello has pioneered efforts in analytic philosophy to develop a rigorous theory of aesthetics, focusing on the concepts of beauty, love and sublimity. In contrast to romantic theorists Sircello argued for the objectivity of beauty and formulated a theory of love on that basis.
British philosopher and theorist of conceptual art aesthetics, Peter Osborne, makes the point that post-conceptual art aesthetic does not concern a particular type of contemporary art so much as the historical-ontological condition for the production of contemporary art in general ..". Osborne noted that in a public lecture delivered in 2010.
Gary Tedman has put forward a theory of a subjectless aesthetics derived from Karl Marx’s concept of alienation, and Louis Althusser’s anti humanism, using elements of Freud’s group psychology, defining a concept of the 'aesthetic level of practice'.
Gregory Loewen has suggested that the subject is key in the interaction with the aesthetic object. The work of art serves as a vehicle for the projection of the individual’s identity into the world of objects, as well as being the irruptive source of much of what is uncanny in modern life. As well, art is used to memorialize individuated biographies in a manner that allows persons to imagine that they are part of something greater than themselves.
As already stated, the relation of Marxist aesthetics to postmodern aesthetics is still a contentious area of debate.
Aesthetics and science.
The field of experimental aesthetics was founded by Gustav Theodor Fechner in the 19th century. Experimental aesthetics is characterized by a subject-based, inductive approach. The analysis of individual experience and behavior based on experimental methods is a central part of experimental aesthetics. In particular, the perception of works of art, music, or modern items such websites or other IT products is studied. Experimental aesthetics is strongly oriented towards the natural sciences. Modern approaches mostly come from the fields of cognitive psychology or neuroscience (neuroaesthetics).
In the 1970s, Abraham Moles and Frieder Nake were among the first to analyze links between aesthetics, information processing, and information theory.
In the 1990s, Jürgen Schmidhuber described an algorithmic theory of beauty which takes the subjectivity of the observer into account and postulates: among several observations classified as comparable by a given subjective observer, the aesthetically most pleasing one is the one with the shortest description, given the observer's previous knowledge and his particular method for encoding the data. This is closely related to the principles of algorithmic information theory and minimum description length. One of his examples: mathematicians enjoy simple proofs with a short description in their formal language. Another very concrete example describes an aesthetically pleasing human face whose proportions can be described by very few bits of information, drawing inspiration from less detailed 15th century proportion studies by Leonardo da Vinci and Albrecht Dürer. Schmidhuber's theory explicitly distinguishes between what's beautiful and what's interesting, stating that interestingness corresponds to the first derivative of subjectively perceived beauty. Here the premise is that any observer continually tries to improve the predictability and compressibility of the observations by discovering regularities such as repetitions and symmetries and fractal self-similarity. Whenever the observer's learning process (which may be a predictive neural network; see also Neuroesthetics) leads to improved data compression such that the observation sequence can be described by fewer bits than before, the temporary interestingness of the data corresponds to the number of saved bits. This compression progress is proportional to the observer's internal reward, also called curiosity reward. A reinforcement learning algorithm is used to maximize future expected reward by learning to execute action sequences that cause additional interesting input data with yet unknown but learnable predictability or regularity. The principles can be implemented on artificial agents which then exhibit a form of artificial curiosity.
Truth as beauty, mathematics.
Mathematical considerations, such as symmetry and complexity, are used for analysis in theoretical aesthetics. This is different from the aesthetic considerations of applied aesthetics used in the study of mathematical beauty. Aesthetic considerations such as symmetry and simplicity are used in areas of philosophy, such as ethics and theoretical physics and cosmology to define truth, outside of empirical considerations. Beauty and Truth have been argued to be nearly synonymous, as reflected in the statement "Beauty is truth, truth beauty" in the poem Ode on a Grecian Urn by John Keats, or by the Hindu motto "Satyam Shivam Sundaram" (Satya (Truth) is Shiva (God), and Shiva is Sundaram (Beautiful)). The fact that judgments of beauty and judgments of truth both are influenced by processing fluency, which is the ease with which information can be processed, has been presented as an explanation for why beauty is sometimes equated with truth. Indeed, recent research found that people use beauty as an indication for truth in mathematical pattern tasks. However, scientists including the mathematician David Orrell and physicist Marcelo Gleiser have argued that the emphasis on aesthetic criteria such as symmetry is equally capable of leading scientists astray.
Computational inference of aesthetics.
Since about 2005, computer scientists have attempted to develop automated methods to infer aesthetic quality of images. Typically, these approaches follow a machine learning approach, where large numbers of manually rated photographs are used to "teach" a computer about what visual properties are of relevance to aesthetic quality. The Acquine engine, developed at Penn State University, rates natural photographs uploaded by users.
Notable in this area is Michael Leyton, professor of psychology at Rutgers University. Leyton is the president of the International Society for Mathematical and Computational Aesthetics and the
International Society for Group Theory in Cognitive Science and has developed a generative theory of shape.
There have also been relatively successful attempts with regard to chess and music. A relation between Max Bense's mathematical formulation of aesthetics in terms of "redundancy" and "complexity" and theories of musical anticipation was offered using the notion of Information Rate.
Evolutionary aesthetics.
Evolutionary aesthetics refers to evolutionary psychology theories in which the basic aesthetic preferences of "Homo sapiens" are argued to have evolved in order to enhance survival and reproductive success. One example being that humans are argued to find beautiful and prefer landscapes which were good habitats in the ancestral environment. Another example is that body symmetry is an important aspect of physical attractiveness which may be due to this indicating good health during body growth. Evolutionary explanations for aesthetical preferences are important parts of evolutionary musicology, Darwinian literary studies, and the study of the evolution of emotion.
Applied aesthetics.
As well as being applied to art, aesthetics can also be applied to cultural objects such as crucifix or tools. Aesthetic coupling between art-objects and medical topics was made by speakers working for the US Information Agency This coupling was made to reinforce the learning paradigm when English-language speakers used translators to address audiences in their own country. These audiences were generally not fluent in the English language. It can also be used in topics as diverse as mathematics, gastronomy, fashion and website design.
Aesthetic ethics.
Aesthetic ethics refers to the idea that human conduct and behaviour ought to be governed by that which is beautiful and attractive. John Dewey has pointed out that the unity of aesthetics and ethics is in fact reflected in our understanding of behaviour being "fair" — the word having a double meaning of attractive and morally acceptable. More recently, James Page has suggested that aesthetic ethics might be taken to form a philosophical rationale for peace education.
Aristotle, Beauty and Goodness.
Aristotle was passionate about goodness in men as he valued "taking [its] virtues to be central to a well-lived life." In "Politics", he writes, "Again, men in general desire the good, and not merely what their fathers had." To thoroughly comprehend goodness, Aristotle also studied Beauty. As noted in the Encyclopædia Britannica (1902), moreover, Aristotle, "ignores all conceptions of an absolute Beauty, and at the same time seeks to distinguish the Beautiful from the Good." Aristotle explains that men "will be better able to achieve [their] good if [they] develop a fuller understanding of what it is to flourish."
Aesthetic judgment.
Judgments of aesthetic value rely on our ability to discriminate at a sensory level. Aesthetics examines our affective domain response to an object or phenomenon.
Immanuel Kant, writing in 1790, observes of a man "If he says that canary wine is agreeable he is quite content if someone else corrects his terms and reminds him to say instead: It is agreeable to "me"," because "Everyone has his own (sense of) taste". The case of "beauty" is different from mere "agreeableness" because, "If he proclaims something to be beautiful, then he requires the same liking from others; he then judges not just for himself but for everyone, and speaks of beauty as if it were a property of things."
Aesthetic judgments usually go beyond sensory discrimination. For David Hume, delicacy of taste is not merely "the ability to detect all the ingredients in a composition", but also our sensitivity "to pains as well as pleasures, which escape the rest of mankind." (Essays Moral Political and Literary. Indianapolis, Literary Classics 5, 1987.) Thus, the sensory discrimination is linked to capacity for pleasure. For Kant "enjoyment" is the result when pleasure arises from sensation, but judging something to be "beautiful" has a third requirement: sensation must give rise to pleasure by engaging our capacities of reflective contemplation. Judgments of beauty are sensory, emotional and intellectual all at once.
Viewer interpretations of beauty possess two concepts of value: aesthetics and taste. Aesthetics is the philosophical notion of beauty. Taste is a result of an education process and awareness of elite cultural values learned through exposure to mass culture. Bourdieu examined how the elite in society define the aesthetic values like taste and how varying levels of exposure to these values can result in variations by class, cultural background, and education. According to Kant, beauty is subjective and universal; thus certain things are beautiful to everyone. The contemporary view of beauty is not based on innate qualities, but rather on cultural specifics and individual interpretations.
Factors involved in aesthetic judgment.
Judgments of aesthetical values seem often to involve many other kinds of issues as well. Responses such as disgust show that sensory detection is linked in instinctual ways to facial expressions, and even behaviors like the gag reflex. Yet disgust can often be a learned or cultural issue too; as Darwin pointed out, seeing a stripe of soup in a man's beard is disgusting even though neither soup nor beards are themselves disgusting. Aesthetic judgments may be linked to emotions or, like emotions, partially embodied in our physical reactions. Seeing a sublime view of a landscape may give us a reaction of awe, which might manifest physically as an increased heart rate or widened eyes. These unconscious reactions may even be partly constitutive of what makes our judgment a judgment that the landscape is sublime.
Likewise, aesthetic judgments may be culturally conditioned to some extent. Victorians in Britain often saw African sculpture as ugly, but just a few decades later, Edwardian audiences saw the same sculptures as being beautiful. Evaluations of beauty may well be linked to desirability, perhaps even to sexual desirability. Thus, judgments of aesthetic value can become linked to judgments of economic, political, or moral value. In a current context, one might judge a Lamborghini to be beautiful partly because it is desirable as a status symbol, or we might judge it to be repulsive partly because it signifies for us over-consumption and offends our political or moral values.
Aesthetic judgments can often be very fine-grained and internally contradictory. Likewise aesthetic judgments seem often to be at least partly intellectual and interpretative. It is what a thing means or symbolizes for us that is often what we are judging. Modern aestheticians have asserted that will and desire were almost dormant in aesthetic experience, yet preference and choice have seemed important aesthetics to some 20th-century thinkers. The point is already made by Hume, but see Mary Mothersill, "Beauty and the Critic's Judgment", in The Blackwell Guide to Aesthetics, 2004. Thus aesthetic judgments might be seen to be based on the senses, emotions, intellectual opinions, will, desires, culture, preferences, values, subconscious behavior, conscious decision, training, instinct, sociological institutions, or some complex combination of these, depending on exactly which theory one employs.
Are different art forms beautiful, disgusting, or boring in the same way?
A third major topic in the study of aesthetic judgments is how they are unified across art forms. We can call a person, a house, a symphony, a fragrance, and a mathematical proof beautiful. What characteristics do they share which give them that status? What possible feature could a proof and a fragrance both share in virtue of which they both count as beautiful? What makes a painting beautiful is quite different from what makes music beautiful, which suggests that each art form has its own language for the judgement of aesthetics.
At the same time, there is seemingly quite a lack of words to express oneself accurately when making an aesthetic judgment. An aesthetic judgment cannot be an empirical judgement. Therefore, due to impossibility for precision, there is confusion about what interpretations can be culturally negotiated. Due to imprecision in the standard English language, two completely different feelings experienced by two different people can be represented by an identical verbal expression. Wittgenstein stated this in his lectures on aesthetics and language games.
A collective identification of beauty, with willing participants in a given social spectrum, may be a socially negotiated phenomenon, discussed in a culture or context. Is there some underlying unity to aesthetic judgment and is there some way to articulate the similarities of a beautiful house, beautiful proof, and beautiful sunset? Defining it requires a description of the entire phenomenon, as Wittgenstein argued in his lectures on aesthetics. Likewise there has been long debate on how perception of beauty in the natural world, especially perception of the human form as beautiful, is supposed to relate to perceiving beauty in art or artefacts. This goes back at least to Kant, with some echoes even in St. Bonaventure. 
What is "art"?
How best to define the term "art" is a subject of constant contention; many books and journal articles have been published arguing over even the basics of what we mean by the term "art". Theodor Adorno claimed in 1969 "It is self-evident that nothing concerning art is self-evident." Artists, philosophers, anthropologists, psychologists and programmers all use the notion of art in their respective fields, and give it operational definitions that vary considerably. Furthermore, it is clear that even the basic meaning of the term "art" has changed several times over the centuries, and has continued to evolve during the 20th century as well.
The main recent sense of the word "art" is roughly as an abbreviation for creative art or "fine art." Here we mean that skill is being used to express the artist's creativity, or to engage the audience's aesthetic sensibilities, or to draw the audience towards consideration of the "finer" things. Often, if the skill is being used in a functional object, people will consider it a craft instead of art, a suggestion which is highly disputed by many Contemporary Craft thinkers. Likewise, if the skill is being used in a commercial or industrial way it may be considered design instead of art, or contrariwise these may be defended as art forms, perhaps called applied art. Some thinkers, for instance, have argued that the difference between fine art and applied art has more to do with the actual function of the object than any clear definitional difference. Art usually implies no function other than to convey or communicate an idea. 
Even as late as 1912 it was normal in the West to assume that all art aims at beauty, and thus that anything that wasn't trying to be beautiful couldn't count as art. The cubists, dadaists, Stravinsky, and many later art movements struggled against this conception that beauty was central to the definition of art, with such success that, according to Danto, "Beauty had disappeared not only from the advanced art of the 1960's but from the advanced philosophy of art of that decade as well." Perhaps some notion like "expression" (in Croce's theories) or "counter-environment" (in McLuhan's theory) can replace the previous role of beauty. Brian Massumi brought back "beauty" into consideration together with "expression". Another view, as important to the philosophy of art as "beauty," is that of the "sublime," elaborated upon in the twentieth century by the postmodern philosopher Jean-François Lyotard. A further approach, elaborated by André Malraux in works such as "The Voices of Silence", is that art is fundamentally a response to a metaphysical question ('Art', he writes, 'is an 'anti-destiny'). Malraux argues that, while art has sometimes been oriented towards beauty and the sublime (principally in post-Renaissance European art) these qualities, as the wider history of art demonstrates, are by no means essential to it.
Perhaps (as in Kennick's theory) no definition of art is possible anymore. Perhaps art should be thought of as a cluster of related concepts in a Wittgensteinian fashion (as in Weitz or Beuys). Another approach is to say that "art" is basically a sociological category, that whatever art schools and museums and artists define as art is considered art regardless of formal definitions. This "institutional definition of art" (see also Institutional Critique) has been championed by George Dickie. Most people did not consider the depiction of a Brillo Box or a store-bought urinal to be art until Andy Warhol and Marcel Duchamp (respectively) placed them in the context of art (i.e., the art gallery), which then provided the association of these objects with the associations that define art.
Proceduralists often suggest that it is the process by which a work of art is created or viewed that makes it art, not any inherent feature of an object, or how well received it is by the institutions of the art world after its introduction to society at large. If a poet writes down several lines, intending them as a poem, the very procedure by which it is written makes it a poem. Whereas if a journalist writes exactly the same set of words, intending them as shorthand notes to help him write a longer article later, these would not be a poem. Leo Tolstoy, on the other hand, claims in his "What is art?" (1897) that what decides whether or not something is art is how it is experienced by its audience, not by the intention of its creator. Functionalists like Monroe Beardsley argue that whether or not a piece counts as art depends on what function it plays in a particular context; the same Greek vase may play a non-artistic function in one context (carrying wine), and an artistic function in another context (helping us to appreciate the beauty of the human figure). '
Marxist attempts to define art focus on its place in the mode of production, such as in Walter Benjamin's essay "The Author as Producer", and/or its political role in class struggle. Revising some concepts of the Marxist philosopher Louis Althusser, Gary Tedman defines art in terms of social reproduction of the relations of production on the aesthetic level.
What should art be like?
Many goals have been argued for art, and aestheticians often argue that some goal or another is superior in some way. Clement Greenberg, for instance, argued in 1960 that each artistic medium should seek that which makes it unique among the possible mediums and then purify itself of anything other than expression of its own uniqueness as a form. The Dadaist Tristan Tzara on the other hand saw the function of art in 1918 as the destruction of a mad social order. "We must sweep and clean. Affirm the cleanliness of the individual after the state of madness, aggressive complete madness of a world abandoned to the hands of bandits." Formal goals, creative goals, self-expression, political goals, spiritual goals, philosophical goals, and even more perceptual or aesthetic goals have all been popular pictures of what art should be like.
The value of art.
Tolstoy defined art as the following: "Art is a human activity consisting in this, that one man consciously, by means of certain external signs, hands on to others feelings he has lived through, and that other people are infected by these feelings and also experience them." However, this definition is merely a starting point for his theory of art's value. To some extent, the value of art, for Tolstoy, is one with the value of empathy. However, sometimes empathy is not of value. In chapter fifteen of "What Is Art?", Tolstoy says that some feelings are good, but others are bad, and so art is only valuable when it generates empathy or shared feeling for good feelings. For example, Tolstoy asserts that empathy for decadent members of the ruling class makes society worse, rather than better. In chapter sixteen, he asserts that the best art is "universal art" that expresses simple and accessible positive feeling.
Other possible views are these: Art can act as a means to some special kind of knowledge. Art may give insight into the human condition. Art relates to science and religion. Art serves as a tool of education, or indoctrination, or enculturation. Art makes us more moral. It uplifts us spiritually. Art is politics by other means. Art has the value of allowing catharsis. In any case, the value of art may determine the suitability of an art form. Do they differ significantly in their values, or (if not) in their ability to achieve the unitary value of art?
But to approach the question of the value of art systematically, one ought to ask: for whom? For the artist? For the audience? For society at large, and/or for individuals beyond the audience? Is the "value" of art different in each of these different contexts?
Working on the intended value of art tends to help define the relations between art and other acts. Art clearly does have spiritual goals in many contexts, but what exactly is the difference between religious art and religion "per se"? The truth is complex; art is both useless in a functional sense, and also the most important human activity. 
An argument for the value of art, used in the fictional work "The Hitchhikers Guide to the Galaxy", proceeds that, if some external force presenting imminent destruction of Earth asked humanity what its value was—what should humanity's response be? The argument continues that the only justification humanity could give for its continued existence would be the past creation and continued creation of things like a Shakespeare play, a Rembrandt painting or a Bach concerto. The suggestion is that these are the things of value which define humanity. Whatever one might think of this claim — and it does seem to undervalue the many other achievements of which human beings have shown themselves capable, both individually and collectively — it is true that art appears to possess a special capacity to endure ("live on") beyond the moment of its birth, in many cases for centuries or millennia. This capacity of art to endure over time — what precisely it is and how it operates — has been widely neglected in modern aesthetics. 
Aesthetic universals.
The philosopher Denis Dutton identified six universal signatures in human aesthetics:
It might be objected, however, that there are rather too many exceptions to Dutton's categories. For example, the installations of the contemporary artist Thomas Hirschhorn deliberately eschew technical virtuosity. People can appreciate a Renaissance Madonna for aesthetic reasons, but such objects often had (and sometimes still have) specific devotional functions. "Rules of composition" that might be read into Duchamp's "Fountain" or John Cage's "4′33″" do not locate the works in a recognizable style (or certainly not a style recognizable at the time of the works' realisation). Moreover, some of Dutton's categories seem too broad: a physicist might entertain hypothetical worlds in his/her imagination in the course of formulating a theory. Another problem is that Dutton's categories seek to universalise traditional European notions of aesthetics and art forgetting that, as André Malraux and others have pointed out, there have been large numbers of cultures in which such ideas (including the idea "art" itself) were non-existent.
Criticism.
The philosophy of aesthetics as a practice has been criticized by some sociologists and writers of art and society. Raymond Williams argues that there is no unique and or individual aesthetic object which can be extrapolated from the art world, but that there is a continuum of cultural forms and experience of which ordinary speech and experiences may signal as art. By "art" we may frame several artistic "works" or "creations" as so though this reference remains within the institution or special event which creates it and this leaves some works or other possible "art" outside of the frame work, or other interpretations such as other phenomenon which may not be considered as "art".
Pierre Bourdieu disagrees with Kant's idea of the "aesthetic". He argues that Kant's "aesthetic" merely represents an experience that is the product of an elevated class habitus and scholarly leisure as opposed to other possible and equally valid "aesthetic" experiences which lay outside Kant's narrow definition.
History of aesthetics.
Any aesthetic doctrines that guided the production and interpretation of prehistoric art are mostly unknown. The civilizations that expressed themselves in ancient art, including Egypt, Mesopotamia, Persia, Greece, China, the Etruscans, Rome, India, the Celtic peoples, and the Maya, each developed a unique and characteristic style in its art.
Ancient Greek aesthetics.
Greece had the most influence on the development of aesthetics in the West. This period of Greek art saw a veneration of the human physical form and the development of corresponding skills to show musculature, poise, beauty and anatomically correct proportions. Furthermore, in many Western and Eastern cultures alike, traits such as body hair are rarely depicted in art that addresses physical beauty.
Greek philosophers initially felt that aesthetically appealing objects were beautiful in and of themselves. Plato believed that for us to have a perception of beauty there must be a transcendent "form" for beauty in which beautiful objects partake and which causes them to be beautiful also. He felt that beautiful objects incorporated proportion, harmony, and unity among their parts. Similarly, in the "Metaphysics", Aristotle found that the universal elements of beauty were order, symmetry, and definiteness. An example of ancient aesthetics in Greece through poetry is Plato's quote: "For the authors of those great poems which we admire, do not attain to excellence through the rules of any art; but they utter their beautiful melodies of verse in a state of inspiration, and, as it were, possessed by a spirit not their own."
Indian aesthetics.
Indian art evolved with an emphasis on inducing special spiritual or philosophical states in the audience, or with representing them symbolically. According to Kapila Vatsyayan, "Classical Indian architecture, sculpture, painting, literature ("kāvya"), music, and dancing evolved their own rules conditioned by their respective media, but they shared with one another not only the underlying spiritual beliefs of the Indian religio-philosophic mind, but also the procedures by which the relationships of the symbol and the spiritual states were worked out in detail."
In the Pan Indian philosophic thought the term 'Satyam Shivam Sundaram' is another name for the concept of the Supreme. 'Sat' is the truth value, 'Shiv' is the good value & 'Sundaram' is the beauty value. Man through his 'Srabana' or education, 'Manana' or experience and conceptualization and 'Sadhana' or practice, through different stages of life (Ashramas) comes to form and realize the idea of these three values to develop a value system. This Value-system helps develop two basic ideas 1) that of 'Daksha' or the adept/expert and 2) of Mahana/Parama or the Absolute and thus to judge anything in this universe in the light of these two measures, known as 'Adarsha'. A person who has mastered great amounts of knowledge of the grammars, rules, & language of an art-form are adepts (Daksha), whereas those who have worked through the whole system and journeyed ahead of these to become a law unto themselves is called a Mahana. Individuals idea of 'Daksha' and 'Mahana' is relative to the development of the concept of 'Satyam-Shivam-Sundaram.' For example, Tagore's idea of these two concepts should be above any common man's and many perceive Tagore as a 'Mahana' Artist in the realm of literature. This concept of Satyam-Shivam-Sundaram, a kind of Value Theory is the cornerstone of Indian Aesthetics.
Of particular concern to Indian drama and literature are the term 'Bhava' or the state of mind and "rasa" referring generally to the emotional flavors/essence crafted into the work by the writer and relished by a 'sensitive spectator' or "sahṛdaya". Poets like Kālidāsa were attentive to rasa, which blossomed into a fully developed aesthetic system. Even in contemporary India the term "rasa" denoting "flavor" or "essence" is used colloquially to describe the aesthetic experiences in films; "māsala mix" describes popular Hindi cinema films which serve a so-called balanced emotional meal for the masses, savored as rasa by these spectators.
Rasa theory blossoms beginning with the Sanskrit text Nātyashāstra ("nātya" meaning "drama" and "shāstra" meaning "science of"), a work attributed to Bharata Muni where the Gods declare that drama is the 'Fifth Veda' because it is suitable for the degenerate age as the best form of religious instruction. While the date of composition varies wildly among scholars, ranging from the era of Plato and Aristotle to the seventh century CE. The Nātyashāstra presents the aesthetic concepts of rasas and their associated bhāvas in Chapters Six and Seven respectively, which appear to be independent of the work as a whole. Eight rasas and associated bhāvas are named and their enjoyment is likened to savoring a meal: rasa is the enjoyment of flavors that arise from the proper preparation of ingredients and the quality of ingredients. What rasa actually is, in a theoretical sense, is not discussed and given the Nātyashāstra's pithy wording it is unlikely the exact understanding of the original author(s) will be known.
The theory of the rasas develops significantly with the Kashmiri aesthetician Ãndandavardhana's classic on poetics, the Dhvanyāloka which introduces the ninth rasa, shānta-rasa as a specifically religious feeling of peace ("śānta") which arises from its bhāva, weariness of the pleasures of the world. The primary purpose of this text is to refine the literary concept "dhvani" or poetic suggestion, by arguing for the existence of the "rasa-dhvani", primarily in forms of Sanskrit including a word, sentence or whole work "suggests" a real-world emotional state or bhāva, but thanks to aesthetic distance, the sensitive spectator relishes the rasa, the aesthetic flavor of tragedy, heroism or romance.
The 9th–10th century master of the religious system known as "the nondual Shaivism of Kashmir" (or "Kashmir Shaivism") and aesthetician, Abhinavagupta brought rasa theory to its pinnacle in his separate commentaries on the Dhvanyāloka, the Dhvanyāloka-locana (translated by Ingalls, Masson and Patwardhan, 1992) and the Abhinavabharati, his commentary on the Nātyashāstra, portions of which are translated by Gnoli and Masson and Patwardhan. Abhinavagupta offers for the first time a technical definition of rasa which is the universal bliss of the Self or Atman colored by the emotional tone of a drama. Shānta-rasa functions as an equal member of the set of rasas but is simultaneously distinct being the most clear form of aesthetic bliss. Abhinavagupta likens it to the string of a jeweled necklace; while it may not be the most appealing for most people, it is the string that gives form to the necklace, allowing the jewels of the other eight rasas to be relished. Relishing the rasas and particularly shānta-rasa is hinted as being as-good-as but never-equal-to the bliss of Self-realization experienced by yogis.
Chinese aesthetics.
Chinese art has a long history of varied styles and emphases. Confucius emphasized the role of the arts and humanities (especially music and poetry) in broadening human nature and aiding "li" (etiquette, the rites) in bringing us back to what is essential about humanity. His opponent Mozi, however, argued that music and fine arts were classist and wasteful, benefiting the rich over the poor.
By the 4th century AD artists had started debating in writing over the proper goals of art as well. Gu Kaizhi has left three surviving books on the theory of painting. Several later artists or scholars both created art and wrote about the creation of it. Religious and philosophical influences on art were common (and diverse) but never universal.
African aesthetics.
African art has existed in many forms and styles, with relatively little influence from outside Africa. Most of it followed traditional forms; the aesthetic norms were handed down orally as well as textually. Sculpture and performance art are prominent, and abstract and partially abstracted forms are valued, and were valued long before influence from the Western tradition began in earnest. The Nok culture is testimony to this. The mosque of Timbuktu shows that specific areas of Africa developed unique aesthetics.
Arab aesthetics.
Arab art for the last 1400 years has taken place under the context of Islam and is sometimes referred to as Islamic art, although many Arab artists throughout time have not been Muslim. The term "Islamic" refers not only to the religion, but to any form of art created by people in an Islamic culture or in an Islamic context, whether the artist is Islamic or not. Not all Muslims are in agreement on the use of art in religious observance, the proper place of art in society, or the relation between secular art and the demands placed on the secular world to conform to religious precepts. Islamic art frequently adopts secular elements and elements that are frowned upon, if not forbidden, by some Islamic theologians. Although the often cited opposition in Islam to the depiction of human and animal forms holds true for religious art and architecture, in the secular sphere, such representations have flourished in nearly all Islamic cultures.
The Islamic resistance to the representation of living beings ultimately stems from the belief that the creation of living forms is unique to God, and it is for this reason that the role of images and image makers has been controversial. The strongest statements on the subject of figural depiction are made in the Hadith (Traditions of the Prophet), where painters are challenged to "breathe life" into their creations and threatened with punishment on the Day of Judgment. The Qur'an is less specific but condemns idolatry and uses the Arabic term musawwir ("maker of forms," or artist) as an epithet for God. Partially as a result of this religious sentiment, figures in painting were often stylized and, in some cases, the destruction of figurative artworks occurred. Iconoclasm was previously known in the Byzantine period and aniconicism was a feature of the Judaic world, thus placing the Islamic objection to figurative representations within a larger context. As ornament, however, figures were largely devoid of any larger significance and perhaps therefore posed less challenge.
This tendency affected the narrowing field of artistic possibility to such forms of art as Arabesque, mosaic, Islamic calligraphy, and Islamic architecture, as well as any form of abstraction that can claim the status of non-representational art.
Limited possibilities have been explored by artists as an outlet to artistic expression, and has been cultivated to become a positive style and tradition, emphasizing the decorative function of art, or its religious functions via non-representational forms such as Geometric patterns, floral patterns, and arabesques.
Human portrayals can be found in early Islamic cultures with varying degrees of acceptance by religious authorities. Human representation for the purpose of worship is uniformly considered idolatry as forbidden in "Sharia" law.
The calligraphic arts grew out of an effort to devote oneself to the study of the Quran. By patiently transcribing each word of the text, the writer was made to contemplate the meaning of it. As time passed, these calligraphic works began to be prized as works of art, growing increasingly elaborate in the illumination and stylizing of the text. These illuminations were applied to other works besides the Quran, and it became a respected art form in and of itself.
Arabic is written from right to left, like other Semitic scripts, and consists of 17 characters, which, with the addition of dots placed above or below certain of them, provide the 28 letters of the Arabic alphabet. Short vowels are not included in the alphabet, being indicated by signs placed above or below the consonant or long vowel that they follow. Certain characters may be joined to their neighbors, others to the preceding one only, and others to the succeeding one only. The written letters undergo a slight external change according to their position within a word. When they stand alone or occur at the end of a word, they ordinarily terminate in a bold stroke; when they appear in the middle of a word, they are ordinarily joined to the letter following by a small, upward curved stroke. With the exception of six letters, which can be joined only to the preceding ones, the initial and medial letters are much abbreviated, while the final form consists of the initial form with a triumphant flourish. The essential part of the characters, however, remains unchanged.
Western medieval aesthetics.
Surviving medieval art is primarily religious in focus and funded largely by the State, Roman Catholic or Orthodox church, powerful ecclesiastical individuals, or wealthy secular patrons. These art pieces often served a liturgical function, whether as chalices or even as church buildings themselves. Objects of fine art from this period were frequently made from rare and valuable materials, such as gold and lapis, the cost of which commonly exceeded the wages of the artist.
Medieval aesthetics in the realm of philosophy built upon Classical thought, continuing the practice of Plotinus by employing theological terminology in its explications. St. Bonaventure's "Retracing the Arts to Theology", a primary example of this method, discusses the skills of the artisan as gifts given by God for the purpose of disclosing God to mankind, which purpose is achieved through four lights: the light of skill in mechanical arts which discloses the world of artifacts; which light is guided by the light of sense perception which discloses the world of natural forms; which light, consequently, is guided by the light of philosophy which discloses the world of intellectual truth; finally, this light is guided by the light of divine wisdom which discloses the world of saving truth.
Saint Thomas Aquinas's aesthetic is probably the most famous and influential theory among medieval authors, having been the subject of much scrutiny in the wake of the neo-Scholastic revival of the late 19th and early 20th centuries and even having received the approbation of the celebrated Modernist writer, James Joyce. Thomas, like many other medievals, never gives a systematic account of beauty itself, but several scholars have conventionally arranged his thought—though not always with uniform conclusions—using relevant observations spanning the entire corpus of his work. While Aquinas's theory follows generally the model of Aristotle, he develops a singular aesthetics which incorporates elements unique to his thought. Umberto Eco's "The Aesthetics of Thomas Aquinas" identifies the three main characteristics of beauty in Aquinas's philosophy: "integritas sive perfectio", "consonantia sive debita proportio", and "claritas sive splendor formae". While Aristotle likewise identifies the first two characteristics, St. Thomas conceives of the third as an appropriation from principles developed by neo-Platonic and Augustinian thinkers. With the shift from the Middle Ages to the Renaissance, art likewise changed its focus, as much in its content as in its mode of expression.

</doc>
<doc id="2134" url="http://en.wikipedia.org/wiki?curid=2134" title="Ark of the Covenant">
Ark of the Covenant

The Ark of the Covenant ( "ʾĀrôn Habbərît", modern pron. "Aron Habrit"), also known as the Ark of the Testimony, is a chest described in the Book of Exodus as containing the Tablets of Stone on which the Ten Commandments were inscribed. According to some traditional interpretations of the Book of Exodus, Book of Numbers, and the Letter to the Hebrews, the Ark also contained Aaron's rod, a jar of manna, and the first Torah scroll as written by Moses; however, the first of the Books of Kings says that at the time of King Solomon, the Ark contained only the two Tablets of the Law. According to the Book of Exodus, the Ark was built at the command of God, in accordance with the instructions given to Moses on Mount Sinai. God was said to have communicated with Moses "from between the two cherubim" on the Ark's cover.
The biblical account relates that about a year after the Israelites' exodus from Egypt, the Ark was created according to the pattern given to Moses by God when Israel was encamped at the foot of Mount Sinai. Thereafter the gold-plated acacia chest was carried by the Levites some 2,000 cubits in advance of the people when on the march or before the Israelite army, the host of fighting men. When the Ark was borne by Levites into the bed of the Jordan River, the waters parted as God had parted the waters of the Red Sea, opening a pathway for the entire host to pass through (Josh. 3:15–16; 4:7–18). The walls of the city of Jericho were shaken to the ground with no more than a shout from the army after the Ark of the Covenant was paraded round them for seven days by Levites accompanied by seven priests sounding seven trumpets of rams' horns (Josh. 6:4–20). When carried, the Ark was always hidden under a large veil made of skins and blue cloth, always carefully concealed, even from the eyes of the priests and the Levites who carried it. There are no contemporary extra-biblical references to the Ark.
Other uses of the term.
In the Roman Catholic and Eastern Orthodox churches, the Blessed Virgin Mary is sometimes allegorically referred to as the Ark of the Covenant, in that she bore Jesus Christ in similarity to the original tangible contents of the Ark, as cited in the Book of Revelation and (in Roman Catholicism) the Litany of Loreto.
Biblical account.
Construction and description.
According to the Book of Exodus, Yahweh instructed Moses on Mount Sinai during his 40-day stay upon the mountain within the thick cloud and darkness where God was (Ex. 19:20; 24:18) and he was shown the pattern for the tabernacle and furnishings of the Ark to be made of shittim wood to house the Tablets of Stone. Moses instructed Bezalel and Oholiab to construct the ark (Exodus 31). In Deuteronomy, however, the ark is said to have been built specifically by Moses himself without reference of Bezalel or Oholiab. 
The Book of Exodus gives detailed instructions on how the Ark is to be constructed. It is to be 2½ cubits in length, 1½ in breadth, and 1½ in height (approximately ). Then it is to be plated entirely with gold, and a crown or molding of gold is to be put around it. Four rings of gold are to be attached to its four feet—two on each side—and through these rings staves of shittim-wood overlaid with gold for carrying the Ark are to be inserted; and these are not to be removed. A golden cover, a "kapporet" (traditionally "Mercy Seat" in Christian translations) adorned with golden cherubim, is to be placed above the Ark. The Ark is finally to be placed behind a veil ("Parochet"), a full description of which is also given at .
Mobile vanguard.
After its creation by Moses, the Ark was carried by the Israelites during their 40 years of wandering in the desert. Whenever the Israelites camped, the Ark was placed in a special and sacred tent, called the Tabernacle.
When the Israelites, led by Joshua toward the Promised Land, arrived at the banks of the River Jordan, the Ark was carried in the lead preceding the people and was the signal for their advance (Joshua 3:3, 6). During the crossing, the river grew dry as soon as the feet of the priests carrying the Ark touched its waters, and remained so until the priests—with the Ark—left the river after the people had passed over (Josh. 3:15-17; 4:10, 11, 18). As memorials, twelve stones were taken from the Jordan at the place where the priests had stood (Josh. 4:1-9).
In the Battle of Jericho, the Ark was carried round the city once a day for seven days, preceded by the armed men and seven priests sounding seven trumpets of rams' horns (Josh. 6:4-15). On the seventh day, the seven priests sounding the seven trumpets of rams' horns before the Ark compassed the city seven times and, with a great shout, Jericho's wall fell down flat and the people took the city (Josh. 6:16-20). After the defeat at Ai, Joshua lamented before the Ark (Josh. 7:6-9). When Joshua read the Law to the people between Mount Gerizim and Mount Ebal, they stood on each side of the Ark. The Ark was again set up by Joshua at Shiloh, but when the Israelites fought against Benjamin at Gibeah, they had the Ark with them and consulted it after their defeat.
Capture by the Philistines.
The Ark is next spoken of as being in the Tabernacle at Shiloh during Samuel's apprenticeship (1 Sam. 3:3). After the settlement of the Israelites in Canaan, the Ark remained in the Tabernacle at Gilgal for a season before being removed to Shiloh until the time of Eli, between 300 and 400 years (Jeremiah 7:12), when it was carried into the field of battle, so as to secure, as they had hoped, victory to the Hebrews. The Ark was taken by the Philistines (1 Sam. 4:3-11) who subsequently sent it back after retaining it for seven months (1 Sam. 5:7, 8) because of the events said to have transpired.
After their first defeat at Eben-ezer, the Israelites had the Ark brought from Shiloh, and welcomed its coming with great rejoicing. In the second battle, the Israelites were again defeated, and the Philistines captured the Ark (1 Sam. 4:3-5, 10, 11). The news of its capture was at once taken to Shiloh by a messenger "with his clothes rent, and with earth upon his head." The old priest, Eli, fell dead when he heard it; and his daughter-in-law, bearing a son at the time the news of the capture of the Ark was received, named him Ichabod—explained as "The glory has departed Israel" in reference to the loss of the Ark (1 Sam. 4:12-22).
The Philistines took the Ark to several places in their country, and at each place misfortune befell them (1 Sam. 5:1-6). At Ashdod it was placed in the temple of Dagon. The next morning Dagon was found prostrate, bowed down, before it; and on being restored to his place, he was on the following morning again found prostrate and broken. The people of Ashdod were smitten with hemorrhoids; a plague of mice was sent over the land (1 Sam. 6:5). The affliction of boils was also visited upon the people of Gath and of Ekron, whither the Ark was successively removed (1 Sam. 5:8-12).
After the Ark had been among them for seven months, the Philistines, on the advice of their diviners, returned it to the Israelites, accompanying its return with an offering consisting of golden images of the tumors and mice wherewith they had been afflicted. The Ark was set in the field of Joshua the Beth-shemite, and the Beth-shemites offered sacrifices and burnt offerings (1 Sam. 6:1-15). Out of curiosity the men of Beth-shemesh gazed at the Ark; and as a punishment, seventy of them (fifty thousand and seventy in some mss.) were smitten by the Lord (1 Sam. 6:19). The Bethshemites sent to Kirjath-jearim, or Baal-Judah, to have the Ark removed (1 Sam. 6:21); and it was taken to the house of Abinadab, whose son Eleazar was sanctified to keep it. Kirjath-jearim remained the abode of the Ark for twenty years. Under Saul, the Ark was with the army before he first met the Philistines, but the king was too impatient to consult it before engaging in battle. In 1 Chronicles 13:3 it is stated that the people were not accustomed to consult the Ark in the days of Saul.
In the days of King David.
At the beginning of his reign, King David removed the Ark from Kirjath-jearim amid great rejoicing. On the way to Zion, Uzzah, one of the drivers of the cart that the Ark was carried on, put out his hand to steady the Ark, and was struck dead by God for touching it. David, in fear, carried the Ark aside into the house of Obed-edom the Gittite, instead of carrying it on to Zion, and there it stayed three months (2 Samuel 6:1-11; 1 Chronicles 13:1-13).
On hearing that God had blessed Obed-edom because of the presence of the Ark in his house, David had the Ark brought to Zion by the Levites, while he himself, "girded with a linen ephod," "danced before the Lord with all his might" and in the sight of all the public gathered in Jerusalem—a performance that caused him to be scornfully rebuked by his first wife, Saul's daughter Michal (2 Sam. 6:12-16, 20-22; 1 Chron. 15). In Zion, David put the Ark in the tabernacle he had prepared for it, offered sacrifices, distributed food, and blessed the people and his own household (2 Sam. 6:17-20; 1 Chron. 16:1-3; 2 Chron. 1:4).
The Levites were appointed to minister before the Ark (1 Chron. 16:4). David's plan of building a temple for the Ark was stopped at the advice of God (2 Sam. 7:1-17; 1 Chron. 17:1-15; 28:2, 3). The Ark was with the army during the siege of Rabbah (2 Sam. 11:11); and when David fled from Jerusalem at the time of Absalom's conspiracy, the Ark was carried along with him until he ordered Zadok the priest to return it to Jerusalem (2 Sam. 15:24-29).
In Solomon's Temple.
When Abiathar was dismissed from the priesthood by King Solomon for having taken part in Adonijah's conspiracy against David, his life was spared because he had formerly borne the Ark (1 Kings 2:26). Solomon worshipped before the Ark after his dream in which God promised him wisdom (1 Kings 3:15).
During the construction of Solomon's Temple, a special inner room, named "Kodesh Hakodashim" (Eng. Holy of Holies), was prepared to receive and house the Ark (1 Kings 6:19); and when the Temple was dedicated, the Ark—containing the original tablets of the Ten Commandments—was placed therein (1 Kings 8:6-9). When the priests emerged from the holy place after placing the Ark there, the Temple was filled with a cloud, "for the glory of the Lord had filled the house of the Lord" (1 Kings 8:10-11; 2 Chron. 5:13, 14).
When Solomon married Pharaoh's daughter, he caused her to dwell in a house outside Zion, as Zion was consecrated because of its containing the Ark (2 Chron. 8:11). King Josiah also had the Ark put in the Temple (2 Chron. 35:3), from which it appears to have been removed by one of his predecessors (cf. 2 Chron. 33-34 and 2 Kings 21-23).
The Babylonian Conquest and aftermath.
In 597 BC, the Babylonians destroyed Jerusalem and Solomon's Temple. There is no record of what became of the Ark in the Books of Kings and Chronicles. But the Greek 3rd Book of Ezra (1 Esdras) suggests that Babylonians took away the vessels of the ark of God (but does not mention taking away The Ark itself):
 And they took all the holy vessels of the Lord, both great and small, with the vessels of the ark of God, and the king's treasures, and carried them away into Babylon.
In Rabbinic Literature, the final disposition of the Ark is disputed. Some rabbis hold that it must have been carried off to Babylon, while others hold that it must have been hidden lest it be carried off into Babylon and never brought back. A late 2nd century rabbinic work known as the "Tosefta" brings down the opinions of these rabbis as to the Ark's whereabouts. There, it states anonymously that during the reign of Josiah the king of Judah he stored away the Ark, along with the jar of manna, and a jar containing the holy anointing oil, the rod of Aaron which budded and a chest given to Israel by the Philistines. This was said to have been done in order to prevent their being carried off into Babylon as had already happened to the other vessels. Rabbi Eliezer and Rabbi Shimon, in the same rabbinic work, purport that the Ark was, in fact, taken into Babylon. Rabbi Yehudah, dissenting, says that the Ark was stored away in its own place, meaning, somewhere on the Temple Mount.
References in Scripture.
Tanakh.
The Ark is first mentioned in the Book of Exodus, and then numerous times in Deuteronomy, Joshua, Judges, I Samuel, II Samuel, I Kings, I Chronicles, II Chronicles, Psalms and Jeremiah.
In the Book of Jeremiah, it is referenced by Jeremiah, who, speaking in the days of Josiah (Jer. 3:16), prophesied a future time, possibly the end of days, when the Ark will no longer be talked about or be made again:
Rashi comments on this verse that "The entire people will be so imbued with the spirit of sanctity that God's Presence will rest upon them collectively, as if the congregation itself was the Ark of the Covenant."
Second Book of Maccabees.
According to the Jewish Deuterocanonical book Second Maccabees, the Greek text in the Septuagint, at the beginning of chapter 2:
The "mountain from the top of which Moses saw God's promised land" would be Mount Nebo, located in what is now Jordan.
New Testament.
In the New Testament, the Ark is mentioned in the Letter to the Hebrews and the Revelation to St. John. states that the Ark contained "the golden pot that had manna, and Aaron's rod that budded, and the tablets of the covenant." says the prophet saw God's temple in heaven opened, "and the ark of his covenant was seen within his temple."
A number of Roman Catholic writers connect this verse with the Woman of the Apocalypse in , which immediately follows, and argue that the Blessed Virgin Mary is the "Ark of the New Covenant." Carrying the saviour of mankind within her, she herself became the Holy of Holies. This is the interpretation given in the fourth century by Saint Ambrose, Saint Ephraem of Syria and Saint Augustine.
It is also believed by Roman Catholics that Athanasius the bishop of Alexandria wrote about the connections between the Ark and the Virgin Mary: "O noble Virgin, truly you are greater than any other greatness. For who is your equal in greatness, O dwelling place of God the Word? To whom among all creatures shall I compare you, O Virgin? You are greater than them all O (Ark of the) Covenant, clothed with purity instead of gold! You are the Ark in which is found the golden vessel containing the true manna, that is, the flesh in which Divinity resides" ("Homily of the Papyrus of Turin"). However, some question the authenticity of this work and suggest it is an example of the writing of yet another Pseudo-Athanasius.
Qur'an.
In chapter 2 ("Sura" 2) of the Islamic Qur'an (Verse 248), the Children of Israel, at the time of Samuel and Saul, were given back the "Tabut E Sakina" (the casket of Shekhinah) which contained remnants of the household of Musa (Moses) and Harun (Aaron) carried by angels which confirmed peace and reassurance for them from their Lord. The Qur'an states:
The Islamic scholar Al Baidawi mentioned that the "sakina" could be Tawrat, the Books of Moses. According to Al-Jalalan, the relics in the Ark were the fragments of the two tablets, rods, robes, shoes, mitres of Moses and the vase of manna. Al-Tha'alibi, in "Qisas Al-Anbiya" (The Stories of the Prophets), has given an earlier and later history of the Ark.
According to most Muslim scholars, the Ark of the Covenant has a religious basis in Islam, and Islam gives it special significance. A Shia sect of Muslims believe that it will be found by Mahdi near the end of times from Lake Tiberias.
Possible locations.
Since its disappearance from the Biblical narrative, there have been a number of claims of having discovered or of having possession of the Ark, and several possible places have been suggested for its location.
Mount Nebo.
2 Maccabees 2:4-10, written around 100 BC, says that the prophet Jeremiah, "being warned by God" before the Babylonian invasion, took the Ark, the Tabernacle, and the Altar of Incense, and buried them in a cave on Mount Nebo, informing those of his followers who wished to find the place that it should remain unknown "until the time that God should gather His people again together, and receive them unto mercy." 
Mount Nebo is also described in the Bible (Deuteronomy 34) as the site from which Moses views the Promised Land, and apparently also is his final burial place. Mount Nebo is approximately 29 miles (47 km) slightly south of due east from Jerusalem, near the east bank of the Jordan River.
Ethiopia.
The Ethiopian Orthodox Church claims to possess the Ark of the Covenant, or "Tabot", in Axum. The object is currently kept under guard in a treasury near the Church of Our Lady Mary of Zion. Replicas of the Axum "tabot" are kept in every Ethiopian church, each with its own dedication to a particular saint; the most popular of these include Mary, George and Michael.
The "Kebra Nagast", composed to legitimise the new dynasty ruling Ethiopia following its establishment in 1270, narrates how the real Ark of the Covenant was brought to Ethiopia by Menelik I with divine assistance, while a forgery was left in the Temple in Jerusalem. Although the "Kebra Nagast" is the best-known account of this belief, the belief predates the document. Abu al-Makarim, writing in the last quarter of the twelfth century, makes one early reference to this belief that they possessed the Ark. "The Abyssinians possess also the Ark of the Covenant", he wrote, and, after a description of the object, describes how the liturgy is celebrated upon the Ark four times a year, "on the feast of the great nativity, on the feast of the glorious Baptism, on the feast of the holy Resurrection, and on the feast of the illuminating Cross."
In the 1992 book "The Sign and the Seal", controversial British writer Graham Hancock suggests, contrary to the "Kebra Nagast", that the ark spent several years in Egypt before it came to Ethiopia via the Nile River, where it was kept in the islands of Lake Tana for about four hundred years and finally taken to Axum. Archaeologist John Holladay of the University of Toronto called Hancock's theory "garbage and hogwash," while Edward Ullendorff, a former Professor of Ethiopian Studies at the University of London, said he "wasted a lot of time reading it."
On 25 June 2009, the patriarch of the Orthodox Church of Ethiopia, Abune Paulos, said he would announce to the world the next day the unveiling of the Ark of the Covenant, which he said had been kept safe and secure in a church in Axum, Ethiopia. The following day, on 26 June 2009, the patriarch announced that he would not unveil the Ark after all, but that instead he could attest to its current status.
Southern Africa.
The Lemba people of South Africa and Zimbabwe have claimed that their ancestors carried the Ark south, calling it the "ngoma lungundu" or "voice of God", eventually hiding it in a deep cave in the Dumghe mountains, their spiritual home.
On 14 April 2008, in a UK Channel 4 documentary, Tudor Parfitt, taking a literalist approach to the Biblical story, described his research into this claim. He says that the object described by the Lemba has attributes similar to the Ark. It was of similar size, was carried on poles by priests, was not allowed to touch the ground, was revered as a voice of their God, and was used as a weapon of great power, sweeping enemies aside.
In his book "The Lost Ark of the Covenant" (2008), Parfitt also suggests that the Ark was taken to Arabia following the events depicted in the Second Book of Maccabees, and cites Arabic sources which maintain it was brought in distant times to Yemen. One Lemba clan, the Buba, which was supposed to have brought the Ark to Africa, have a genetic signature called the Cohen Modal Haplotype. This suggests a male Semitic link to the Levant. Lemba tradition maintains that the Ark spent some time in Sena in Yemen. Later, it was taken across the sea to East Africa and may have been taken inland at the time of the Great Zimbabwe civilization. According to their oral traditions, some time after the arrival of the Lemba with the Ark, it self-destructed. Using a core from the original, the Lemba priests constructed a new one. This replica was discovered in a cave by a Swedish German missionary named Harald von Sicard in the 1940s and eventually found its way to the Museum of Human Science in Harare. Parfitt had this artifact radio-carbon dated to about 1350, which coincided with the sudden end of the Great Zimbabwe civilization.
Europe.
Chartres Cathedral, France.
French author Louis Charpentier claimed that the Ark was taken to Chartres Cathedral by the Knights Templar.
Rennes-le-Château, then to the United States.
Several recent authors have theorised that the Ark was taken from Jerusalem to the village of Rennes-le-Château in Southern France. Karen Ralls has cited Freemason Patrick Byrne, who believes the Ark was moved from Rennes-le-Château at the outbreak of World War I to the United States.
Rome.
The Ark of the Covenant was said to have been kept in the Basilica of St. John Lateran, surviving the pillages of Rome by Genseric and Alaric I but lost when the basilica burned.
United Kingdom.
In 2003, author Graham Phillips hypothetically concluded that the Ark was taken to Mount Sinai in the Valley of Edom by the Maccabees. Phillips claims it remained there until the 1180s, when Ralph de Sudeley, the leader of the Templars found the Maccabean treasure at Jebel al-Madhbah, and returned home to his estate at Herdewyke in Warwickshire, England taking the treasure with him.
Ireland.
During the turn of the 20th century British Israelites carried out some excavations of the Hill of Tara in Ireland looking for the Ark of the Covenant—the Royal Society of Antiquaries of Ireland campaigned successfully to have them stopped before they destroyed the hill.
Egypt.
Tutankhamun's tomb.
In 1922 in the Egyptian Valley of the Kings the tomb of Tutankhamun (KV62) was opened by Howard Carter and Lord Carnarvon. Among the artifacts was a processional ark, listed as Shrine 261, the Anubis Shrine. Almost immediately after publication of the photographs of this sensational archaeological find some claimed that the Anubis Shrine could be the Ark of the Covenant. John M. Lundquist, author of "The Temple of Jerusalem: past, present, and future" (2008), discounts this idea. The Anubis Shrine measures long, wide, and high in the shape of a pylon. The Biblical Ark of the Covenant is approximately long, wide, and high in the shape of a rectangular chest.
He points out that Shrine 261 is not strictly analogous to the Ark of the Covenant: it can only be said that the Anubis Shrine is "ark-like", constructed of wood, gessoed and gilded, stored within a sacred tomb, "guarding" the treasury of the tomb (and not the primary focus of that environment), that it contains compartments within it that store and hold sacred objects, that it has a figure of Anubis on its lid, and that it was carried by two staves permanently inserted into rings at its base and borne by eight priests in the funerary procession to Tutankhamun's tomb. Its value is the insight it provides to the ancient culture of Egypt.
In popular culture.
The Ark of the Covenant is the MacGuffin of Steven Spielberg's 1981 adventure film "Raiders of the Lost Ark", is mentioned briefly in the 1989 film "Indiana Jones and the Last Crusade" and appears in a cameo in "Indiana Jones and the Kingdom of the Crystal Skull".
In the Danish family film "The Lost Treasure of the Knights Templar" from 2006 the main part of the treasure found in the end is the Ark of the Covenant. The power of the ark comes from charged static electricity from different metal plates like a giant battery.

</doc>
<doc id="2136" url="http://en.wikipedia.org/wiki?curid=2136" title="Angles">
Angles

The Angles (Latin Anglii) were one of the main Germanic peoples who settled in Britain in the post-Roman period. They founded several of the kingdoms of Anglo-Saxon England, and their name is the root of the name "England". The name comes from the district of Angeln, an area located on the Baltic shore of what is now Schleswig-Holstein, the most northern state of Germany.
Name.
The name of the Angles was first recorded in Latinised form, as "Anglii", in the "Germania" of Tacitus. It is thought to derive from the name of the area they originally inhabited: "Angeln" in modern German, "Angel" in Danish. This name has been hypothesised to originate from the Germanic root for "narrow" (compare German "eng" = "narrow"), meaning "the Narrow [Water]", i.e. the Schlei estuary; the root would be angh, "tight". Another theory is that the name meant "hook", as in angling for fish; Julius Pokorny, a major Indo-European linguist, derives it from *ang-, "bend" (see ankle).
Gregory the Great in an epistle simplified the Latinised name "Anglii" to "Angli", the latter form developing into the preferred form of the word. The country remained "Anglia" in Latin. King Alfred's (Alfred the Great) translation of Orosius' history of the world uses "Angelcynn" (-kin) to describe England and the English people; Bede used "Angelfolc" (-folk); there are also such forms as "Engel", "Englan" (the people), "Englaland", and "Englisc", all showing i-mutation.
Greco-Roman historiography.
Tacitus.
The earliest recorded mention of the Angles may be in Tacitus' "Germania", chapter . Tacitus describes the "Anglii" as one of the more remote Suebic tribes compared to the Semnones and Langobardi, who lived on the Elbe and were better known to the Romans. He grouped the Angles with several other tribes in that region, the Reudigni, Aviones, Varini, Eudoses, Suarini and Nuitones. These were all living behind ramparts of rivers and woods; and therefore inaccessible to attack.
He gives no precise indication of their geographical situation but states that, together with six other tribes, they worshiped Nerthus, or Mother Earth, whose sanctuary was located on "an island in the Ocean". As the Eudoses are the Jutes, these names probably refer to localities in Jutland or on the Baltic coast, in which case their inhabitants would be Cimbri or Teutones for Pliny. The coast contains sufficient estuaries, inlets, rivers, islands, swamps and marshes to have been then inaccessible to those not familiar with the terrain, such as the Romans, who considered it unknown, inaccessible, with a small population and of little economic interest.
The majority of scholars believe that the Anglii lived on the coasts of the Baltic Sea, probably in the southern part of the Jutish peninsula. This view is based partly on Old English and Danish traditions regarding persons and events of the 4th century, and partly on the fact that striking affinities to the cult of Nerthus as described by Tacitus are to be found in pre-Christian Scandinavian, especially Swedish and Danish, religion.
Ptolemy.
Ptolemy in his "Geography" (2.10), half a century later, describes the "Sueboi Angeilloi", Latinised to "Suevi Angili", further south, living in a stretch of land between the northern Rhine and central Elbe, but apparently not touching either river, with the Suebic Langobardi on the Rhine to their west, and the Suebic Semnones on the Elbe stretching to their east.
These Suevi Angili would have been in Lower Saxony or near it, but they are not coastal. The three Suebic peoples are separated from the coastal Chauci, (between Ems and Elbe), and Saxones, (east of the Elbe mouth), by a series of tribes including, between Weser and Elbe, the Angrivarii, "Laccobardi" (probably another reference to Langobardi, but taken by Ptolemy from another source), and Dulgubnii. South of the Saxons, and east of the Elbe, Ptolemy lists "Ouirounoi" (Latinised as Viruni, and probably the Varini) and Teutonoari, which either denotes "the Teuton men", or else it denotes people living in the area where the Teutons had previously lived (who Ptolemy places still living to the east of the Teutonoari). Ptolemy describes the coast to the east of the Saxons as inhabited by the Farodini, a name not known from any other sources.
Owing to the uncertainty of this passage, there has been much speculation regarding the original home of the Anglii. One theory is that they or part of them dwelt or moved among other coastal people perhaps confederated up to the basin of the Saale (in the neighbourhood of the ancient canton of Engilin) on the Unstrut valleys below the Kyffhäuserkreis, from which region the "Lex Angliorum et Werinorum hoc est Thuringorum" is believed by many to have come. The ethnic names of Frisians and Warines are attested in the neighbourhood names of this Saxon or Swabian lands.
A second possible solution is that these Angles of Ptolemy are not those of Schleswig at all. According to Julius Pokorny the Angri- in Angrivarii, the -angr in Hardanger and the Angl- in Anglii all come from the same root meaning "bend", but in different senses. In other words, the similarity of the names is strictly coincidental and does not reflect any ethnic unity beyond Germanic.
On the other hand, Gudmund Schütte, in his analysis of Ptolemy, believes that the Angles have simply been moved by an error coming from Ptolemy's use of imperfect sources. He points out that Angles are placed correctly just to the northeast of the Langobardi, but that these have been duplicated, so that they appear once, correctly, on the lower Elbe, and a second time, incorrectly, at the northern Rhine.
Medieval historiography.
Bede states that the Anglii, before coming to Great Britain, dwelt in a land called Angulus, "which lies between the province of the Jutes and the Saxons, and remains unpopulated to this day."
Similar evidence is given by the "Historia Brittonum". King Alfred the Great and the chronicler Æthelweard identified this place with the district that is now called Angeln, in the province of Schleswig (Slesvig) (though it may then have been of greater extent), and this identification agrees with the indications given by Bede.
In the Norwegian seafarer Ohthere of Hålogaland's account of a two-day voyage from the Oslo fjord to Schleswig, he reported the lands on his starboard bow, and Alfred appended the note "on these islands dwelt the "Engle" before they came hither".
Confirmation is afforded by English and Danish traditions relating to two kings named Wermund and Offa of Angel, from whom the Mercian royal family claimed descent and whose exploits are connected with Angeln, Schleswig, and Rendsburg. Danish tradition has preserved record of two governors of Schleswig, father and son, in their service, Frowinus (Freawine) and Wigo (Wig), from whom the royal family of Wessex claimed descent. During the 5th century, the Anglii invaded Great Britain, after which time their name does not recur on the continent except in the title of "Suevi Angili".
The Angles are the subject of a legend about Pope Gregory I, who happened to see a group of Angle children from Deira for sale as slaves in the Roman market. As the story would later be told by the Anglo-Saxon monk and historian Bede, Gregory was struck by the unusual appearance of the slaves and asked about their background. When told they were called "Anglii" (Angles), he replied with a Latin pun that translates well into English: “"Bene, nam et angelicam habent faciem, et tales angelorum in caelis decet esse coheredes"” ("It is well, for they have an angelic face, and such people ought to be co-heirs of the angels in heaven"). Supposedly, this encounter inspired the Pope to launch a mission to bring Christianity to their countrymen.
Archaeology.
The province of Schleswig has proved rich in prehistoric antiquities that date apparently from the 4th and 5th centuries. A broad cremation cemetery has been found at Borgstedterfeld, between Rendsburg and Eckernförde, and it has yielded many urns and brooches closely resembling those found in pagan graves in England.
Of still greater importance are the great deposits at Thorsberg moor (in Angeln) and Nydam, which contained large quantities of arms, ornaments, articles of clothing, agricultural implements, etc., and in Nydam even ships. By the help of these discoveries, Angle culture in the age preceding the invasion of Britannia can be fitted together.
Anglian kingdoms in England.
According to sources such as the History of Bede, after the invasion of Britannia, the Angles split up and founded the kingdoms of the Northumbria, East Anglia and Mercia. H.R. Loyn has observed in this context that "a sea voyage is perilous to tribal institutions," and the apparently tribally-based kingdoms were produced in England. In early times there were two northern kingdoms (Bernicia and Deira) and two midland ones (Middle Anglia and Mercia). As a result of influence from the West Saxons, the tribes were collectively called Anglo-Saxons by the Normans, the West Saxon kingdom having conquered, united and founded the Kingdom of England by the 10th century. The regions of East Anglia and Northumbria are still known by their original titles. Northumbria once stretched as far north as what is now southeast Scotland, including Edinburgh, and as far south as the Humber Estuary.
The rest of that people stayed at the centre of the Angle homeland in the northeastern portion of the modern German "Bundesland" of Schleswig-Holstein, on the Jutland Peninsula. There, a small peninsular area is still called "Angeln" today and is formed as a triangle drawn roughly from modern Flensburg on the Flensburger Fjord to the City of Schleswig and then to Maasholm, on the Schlei inlet.

</doc>
<doc id="2137" url="http://en.wikipedia.org/wiki?curid=2137" title="Aster CT-80">
Aster CT-80

The Aster CT-80, an early (1982) home/personal computer developed by the small Dutch company MCP (later renamed to Aster Computers), was sold in its first incarnation as a kit for hobbyists. Later it was sold ready to use. It consisted of several Eurocard PCB's with DIN 41612 connectors, and a backplane all based on a 19-inch rack configuration. It was the first commercially available Dutch personal/home computer. The Aster computer could use the software written for the popular Tandy TRS-80 computer while fixing many of the problems of that computer, but it could also run CP/M software, with a big amount of free memory Transient Program Area, (TPA) and a full 80×25 display, and it could be used as a Videotext terminal. Although the Aster was a clone of the TRS-80 model I it was in fact more compatible with the TRS-80 model III, and ran all the software of these systems including games. It also had a built in speaker which was compatible with such games software.
Models.
Three models were sold. The first model (launched June 1982) looked like the later IBM PC (which came on the market years later), a rectangular base unit with two floppy drives on the front, and a monitor on top with a separate detachable keyboard. The second incarnation was a much smaller unit the width of two 5¼" floppy drives stacked on top of each other, and the third incarnation looked like a flattened Apple with a built-in keyboard.
All units ran much faster than the original TRS-80, at 4 MHz, (with a software selectable throttle to the original speed for compatibility purposes) and the display supported upper and lower case, hardware snow suppression (video ram bus arbitration logic), and an improved character font set. The floppy disk interface supported dual density, and disk capacities up to 800 KB, more than four times the capacity of the original TRS-80. A special version of NewDos/80, (an improved TRS-DOS compatible Disk operating system) was used to support these disk capacities when using the TRS-80 compatibility mode.
For the educational market a version of the first model was produced with a new plastic enclosure (the First Asters had an all-metal enclosure) that also had an opening on the top in which a cassette recorder could be placed. This model was used in a cluster with one Aster (with disk drives) for the teacher, and eight disk less versions for the pupils. The pupils could download software from the teachers computer through a network based on a fast serial connection, as well as sending back their work to the teachers computer. There was also hardware in place through which the teacher could see the display of each pupils screen on his own monitor.
Working modes.
The Aster used 64KB of RAM memory and had the unique feature of supporting two fundamentally different internal architectures: when turned on without a boot floppy or with a TRS-DOS floppy, the Aster would be fully TRS-80 compatible, with 48KB or RAM. When the boot loader detected a CP/M floppy, the Aster would reconfigure its internal memory architecture on the fly to optimally support CP/M with 60 KB free RAM for programs (TPA) and an 80 x 25 display. This dual-architecture capability only existed on one other TRS-80 clone, the LOBO Max-80.
With a special configuration tool, the CT-80 could reconfigure its floppy drivers to read and write the floppies of about 80 other CP/M systems.
A third mode was entered with a special boot floppy which turned the Aster into a Videotex terminal with a 40x25 display and a Videotex character set, The software used the built in RS232 interface of the Aster to control a modem through which it could contact a Prestel service provider.
Sales.
Most Aster CT-80's (about 10 thousand of them) were sold to schools for computer education, in a project first known as the "honderd scholen project" (one hundred schools project), but which later involved many more than just one hundred schools. MCP received this order from the Dutch government because their computer met all the technical and other demands, including the demand that the computers should be of Dutch origin and should be built in the Netherlands. Another important demand was that the computers could be used in a network (Aster developed special software and hardware for that). Later however the Government turned around and gave 50% of the order to Philips and their P2000 homecomputer even though the P2000 did not meet all the technical demands, was made in Austria and did not have network hard nor software.
The company.
Aster computers was based in the small town of Arkel near the town of Gorinchem.
Initially Aster computer b.v. was called MCP (Music print Computer Product), because it was specialized in producing computer assisted printing of sheet music. The director of the company was interested in Microprocessor technology and noticed there was a market for selling kits to computer building amateurs, so they started selling electronic kits to hobbyists, and employed four persons at that time . They also assembled kits for people without soldering skills, especially the "junior Computer" from Elektor (a copy of the KIM-1), and the ZX80 from Sinclair. Among the kits sold there were also alternative floppy disk drives for TRS-80 computers. But these needed the infamous TRS-80 expansion interface, which was very expensive, and had a very unreliable floppy disk controller because it used the WD1771 floppy disc controller chip without an external "data separator". To fix this problem MCP developed a small plugin board which could be plugged into the socket for the WD1771, and which contained a data separator, and a socket for the WD1791 to support dual-density operation. Still, the expansion interface was expensive and due to its design it was also unreliable. So they decided to also develop their own alternative in the form of an improved floppy disk controller and printer interface that could be built right into a floppy disk enclosure. The lack of RAM expansion offered by this solution was solved by a service in which the 16 KB RAM chips inside the base unit would be replaced by 64 KB RAM chips.
While this went on MCP renamed itself to "MCP CHIP" but ran into problems with the German computer magazine CHIP, and had to return to its former name. At that time MCP did also sell imported home computers like the TRS-80, the Video Genie, (another TRS-80 clone), the Luxor ABC 80 and the Apple II.
They also sold the exotic Olivetti M20, a very early 16 bit personal computer that was one of the very few systems to use a Z8000 CPU.
After designing their own fully functional replacement for the TRS-80 expansion interface (which was never commercialized) the company realized that they could do better than just re-designing the expansion interface. They observed that the TRS-80 was a great computer but it lacked in several areas. The display logic and resulting display 'snow' was irritating, as was the missing lower case support, the CPU speed could be improved, the quality and layout of the keyboard was bothersome, and the floppy disk capacity and reliability was low. Also the more interesting software offered for CP/M systems could not run well on a TRS-80. So they decided to designed a TRS-80 and CP/M software compatible computer system, which (following the lead of Apple Computer) they decided to name after a "typical Dutch flower". So they called it the Aster CT-80 (CP/M/Tandy-1980). Why they went with Aster, and not the more well known Tulip is unknown, perhaps they thought it would be to presumptuous, or perhaps the fact that "Aster" is also a Dutch girls name has something to do with it. Remarkably "Aster" was also the name given to a Dutch Supercomputer much later, in 2002.
The first version of the Aster consisted of four "Eurocard's", one Z80 CPU card with 64KB memory, one Motorola MC6845 based video card, one double density floppy disk controller card and one "keyboard/RS232/cassette interface" card. Plus a "backplane card", (which connected all the other cards) and a keyboard. And was intended for hobbyists, to be sold as a kit consisting of the parts and the PCB's for the computer and attached keyboard. After selling a few kits, MCP became convinced there was a much bigger market for an improved model sold as a completed working system. However the original kit version lacked many features that prevented its use as a serious computer system. Because the original designer had left the company another employee completely redesigned most of the system, (adding a display snow remover circuit, true 80/64 column text mode support, (with different size letters for TRS-80 and CP/M mode, so that in TRS-80 mode the full screen was also used, not just a 64x16 portion of the 80x25 screen) with an improved font set (adding "gray scale" version of the TRS-80 mozaik graphics and many special PETSCII like characters), and a more flexible and reliable floppy disk controller and keyboard interface plus many other small improvements), also an enclosure was developed for the main computer system, (in the form of a 19-inch rack for the Eurocards) and for two floppy disk drives and the power supply. A software engineer was hired to write the special "dual boot mode" BIOS and the special CP/M BIOS. The "dual boot mode" BIOS actually discovered whether a TRS-DOS, or Aster CP/M disk was placed in the drive, and would, depending on the type of disk, reorganise the internal memory architecture of the system, to either be 100% TRS-80 compatible or optimally support CP/M, with as much "workspace" as possible, and the 80x25 video mode. It also was responsible for switching to ROM BASIC when the system was turned on with the break key pressed, and later supported a primitive LAN system, using the RS232 port with modified cabling. The very first of the ready made computers were sold with the "kit" versions of the euro cards, the version with redesigned cards came a month or so later.
Soon the little shop became much too small and they moved to a much larger factory building nearby (formerly a window glass factory), and started mass-producing the Aster for a period of a few years, in which time its staff grew twentyfold.
After the Aster having been a few years on the Market Tandy released its own improved model, the TRS-80 Model 3 computer which solved many of the same problems that the Aster also had solved, but the model 3 still did not fully support CP/M as the Aster did. In the meantime IBM had released its original IBM PC, which incidentally looked remarkably like the Asters base with floppy drives + separate keyboard set-up.
The aster was chosen for Dutch schools by the Dutch ministry of education, in a set-up with eight disk-less Asters, and one Aster with high capacity floppy drives all connected by a LAN based on the Asters high-speed serial port hardware, and special cables that permitted that any single computer on the LAN could broadcast to all other computers. The floppy based system was operated by the teacher who could send programs from his floppy disk, and data, to the student's disk-less systems thanks to the special BIOS in those systems. The students could send programs and data back to the teacher through the same LAN, or could save to a cassette recorder built into the disk-less units. Through a special "video-switch" the teacher was also able to see a copy of each students display on his own screen. About a thousand of such systems were sold for many hundreds of Dutch schools.
Unfortunately, because of cash flow problems (resulting from growing too fast, insufficient financial backing, technical problems, and a sudden problem with Z80 processor deliveries) the company suddenly folded even before it came to full fruition.
Perhaps the Aster computer inspired another Dutch computer firm to name their computer after another typical Dutch flower — the Tulip's Tulip System-1 which appeared about the same time Aster folded.
Most of the engineers who designed the hardware and software of the Aster went on to design hardware and software for the (then new) MSX system for a company called "Micro Technology b.v.".
Unreleased add ons.
To enhance and modernize the Aster CT-80 the company also designed three alternative video display adapters to supplement or replace the TRS-80 compatible video card, (due to the modular nature of the Aster it was simply a matter of changing the video card, and/or CPU card to upgrade the system).
A hard disk interface was also in the works, which would, add a SCSI interface, and the necessary software. A working prototype was developed that added a 40MB hard disk.
On the software front, work was being done to implement the replacement for the aging "user interface" of CP/M, (the Command Console Processor CCP ) with the more modern ZCPR.
Finally a replacement for the aging Z80 processor was being developed in the form of an Intel 8086 board, and additional 512K 16 bit memory boards. Such replacements of CPU and memory system components were possible because the Aster CT-80 was designed to use a backplane that was designed to support both 8 and 16 bit processors, and used a modular Eurocard based design with slots to spare for expansion. In theory the system could support the Z80 and the 8086 simultaneously. Plans were formulated to support CP/M-86 and even MS-DOS.
Unfortunately none of these extensions to the system became available because the company folded before any of them could be released.

</doc>
<doc id="2138" url="http://en.wikipedia.org/wiki?curid=2138" title="Arthur Wellesley">
Arthur Wellesley

Arthur Wellesley may refer to:

</doc>
<doc id="2139" url="http://en.wikipedia.org/wiki?curid=2139" title="List of animated television series">
List of animated television series

These are lists of animated television series. Animated television series are television programs produced by means of animation. Animated series produced for theaters are not included in this lists; for those, see List of animated short series. These lists include compilation series of theatrical shorts such as "The Bugs Bunny Show" since they often feature some new wrap-around animation.

</doc>
<doc id="2140" url="http://en.wikipedia.org/wiki?curid=2140" title="Atlanta Braves">
Atlanta Braves

The Atlanta Braves are a Major League Baseball (MLB) team in Atlanta, Georgia, playing in the Eastern Division of the National League. The Braves have played home games at Turner Field since 1997 and play spring training games in Lake Buena Vista, Florida. In 2017, the team is to move to SunTrust Park, a new stadium complex in the Cumberland highrise district of Cobb County just north of the I-285 bypass.
The "Braves" name, which was first used in 1912, originates from a term for a Native American warrior. They are nicknamed "the "Bravos"", and often referred to as "America's Team" in reference to the team's games being broadcast on the nationally available TBS from the 1970s until 2007, giving the team a wide fan base.
From 1991 to 2005 the Braves were one of the most successful franchises in baseball, winning division titles an unprecedented 14 consecutive times in that period (omitting the strike-shortened 1994 season in which there were no official division champions). The Braves won the NL West 1991–93 and the NL East 1995–2005, and they returned to the playoffs as the National League Wild Card in 2010. The Braves advanced to the World Series five times in the 1990s, winning the title in 1995. Since their debut in the National League in 1876, the franchise has won 16 divisional titles, 17 National League pennants, and three World Series championships—in 1914 as the Boston Braves, in 1957 as the Milwaukee Braves, and in 1995 in Atlanta. The Braves are the only Major League Baseball franchise to have won the World Series in three different home cities.
The club is one of the National League's two remaining charter franchises (the other being the Chicago Cubs) and was founded in Boston, Massachusetts, in 1871 as the Boston Red Stockings (not to be confused with the American League's Boston Red Sox). They are considered "the oldest continuously playing team in major North American sports." There is an argument as to which team is actually older, because, although the Cubs are a full season "older" (formed as the Chicago White Stockings in 1870), Chicago did not sponsor a White Stockings team for two seasons due to the Great Chicago Fire; therefore, the Braves have played more consecutive seasons.
After various name changes, the team eventually began operating as the Boston Braves, which lasted for most of the first half of the 20th century. Then, in 1953, the team moved to Milwaukee, Wisconsin and became the Milwaukee Braves, followed by the final move to Atlanta in 1966. The team's tenure in Atlanta is noted for Hank Aaron breaking Babe Ruth's career home run record in 1974.
History.
Boston.
1870–1913.
The Cincinnati Red Stockings, established in 1869 as the first openly all-professional baseball team, voted to dissolve after the 1870 season. Player-manager Harry Wright then went to Boston, Massachusetts, at the invitation of Boston Red Stockings founder Ivers Whitney Adams, with brother George and two other Cincinnati players, to form the nucleus of the "Boston Red Stockings", a charter member of the National Association of Professional Base Ball Players (NAPBBP). The original Boston Red Stockings team and its successors can lay claim to being the oldest continuously playing team in American professional sports. (The only other team that has been organized as long, the Chicago Cubs, did not play for the two years following the Great Chicago Fire of 1871.) Two young players hired away from the Forest City club of Rockford, Illinois, turned out to be the biggest stars during the NAPBBP years: pitcher Al Spalding (founder of Spalding sporting goods) and second baseman Ross Barnes.
Led by the Wright brothers, Barnes, and Spalding, the Red Stockings dominated the National Association, winning four of that league's five championships. The team became one of the National League's charter franchises in 1876, sometimes called the "Red Caps" (as a new Cincinnati Red Stockings club was another charter member). Boston came to be called the "Beaneaters" in 1883, while retaining red as the team color.
The Boston Red Caps played in the first game in the history of the National League, on Saturday, April 22, 1876, defeating the Athletics, 6-5.
Although somewhat stripped of talent in the National League's inaugural year, Boston bounced back to win the 1877 and 1878 pennants. The Red Caps/Beaneaters were one of the league's dominant teams during the 19th century, winning a total of eight pennants. For most of that time, their manager was Frank Selee. The 1898 team finished 102–47, a club record for wins that would stand for almost a century. Stars of those 1890s Beaneater teams included the "Heavenly Twins", Hugh Duffy and Tommy McCarthy, as well as "Slidin'" Billy Hamilton.
The team was decimated when the American League's new Boston entry set up shop in 1901. Many of the Beaneaters' stars jumped to the new team, which offered contracts that the Beaneaters' owners did not even bother to match. They only managed one winning season from 1900 to 1913, and lost 100 games five times. In 1907, the Beaneaters (temporarily) eliminated the last bit of red from their stockings because their manager thought the red dye could cause wounds to become infected (as noted in "The Sporting News Baseball Guide" during the 1940s when each team's entry had a history of its nickname(s). See details in History of baseball team nicknames). The American League club's owner, Charles Taylor, wasted little time in adopting Red Sox as his team's first official nickname (up to that point they had been called by the generic "Americans"). Media-driven nickname changes to the "Doves" in 1907 and the "Rustlers" in 1911 did nothing to change the National League club's luck. The team became the "Braves" for the first time in 1912. Their owner, James Gaffney, was a member of New York City's political machine, Tammany Hall, which used an Indian chief as their symbol.
1914: Miracle.
Two years later, the Braves put together one of the most memorable seasons in baseball history. After a dismal 4–18 start, the Braves seemed to be on pace for a last place finish. On July 4, 1914, the Braves lost both games of a doubleheader to the Brooklyn Dodgers. The consecutive losses put their record at 26–40 and the Braves were in last place, "15 games" behind the league-leading New York Giants, who had won the previous three league pennants. After a day off, the Braves started to put together a hot streak, and from July 6 through September 5, the Braves went 41–12. On September 7 and 8, the Braves took two of three from the New York Giants and moved into first place. The Braves tore through September and early October, closing with 25 wins against six losses, while the Giants went 16–16. They were the only team, under the old eight-team league format, to win a pennant after being in last place on the Fourth of July. They were in last place as late as July 18, but were close to the pack, moving into fourth on July 21 and second place on August 12.
Despite their amazing comeback, the Braves entered the World Series as a heavy underdog to Connie Mack's Philadelphia A's. Nevertheless, the Braves swept the Athletics—the first unqualified sweep in the young history of the modern World Series (the 1907 Series had one tied game) to win the world championship. Meanwhile, Johnny Evers won the Chalmers Award.
The Braves played the World Series (as well as the last few games of the 1914 season) at Fenway Park, since their normal home, the South End Grounds, was too small. However, the Braves' success inspired owner Gaffney to build a modern park, Braves Field, which opened in August 1915. It was the largest park in the majors at the time, with 40,000 seats and a very spacious outfield. The park was novel for its time; public transportation brought fans right to the park.
1915–1953.
After contending for most of 1915 and 1916, the Braves only twice posted winning records from 1917 to 1932. The lone highlight of those years came when Judge Emil Fuchs bought the team in 1923 to bring his longtime friend, pitching great Christy Mathewson, back into the game. However, Mathewson died in 1925, leaving Fuchs in control of the team.
Fuchs was committed to building a winner, but the damage from the years prior to his arrival took some time to overcome. The Braves finally managed to be competitive in 1933 and 1934 under manager Bill McKechnie, but Fuchs' revenue was severely depleted due to the Great Depression.
Looking for a way to get more fans and more money, Fuchs worked out a deal with the New York Yankees to acquire Babe Ruth, who had started his career with the Red Sox. Fuchs made Ruth team vice president, and promised him a share of the profits. He was also granted the title of assistant manager, and was to be consulted on all of the Braves' deals. Fuchs even suggested that Ruth, who had long had his heart set on managing, could take over as manager once McKechnie stepped down—perhaps as early as 1936.
At first, it appeared that Ruth was the final piece the team needed in 1935. On opening day, he had a hand in all of the Braves' runs in a 4–2 win over the Giants. However, that proved to be the only time the Braves were over .500 all year. Events went downhill quickly. While Ruth could still hit, he could do little else. He could not run, and his fielding was so terrible that three of the Braves' pitchers threatened to go on strike if Ruth were in the lineup. It soon became obvious that he was vice president and assistant manager in name only and Fuchs' promise of a share of team profits was hot air. In fact, Ruth discovered that Fuchs expected him to invest some of "his" money in the team.
Seeing a franchise in complete disarray, Ruth retired on June 1—only six days after he clouted what turned out to be the last three home runs of his career. He had wanted to quit as early as May 12, but Fuchs wanted him to hang on so he could play in every National League park. The Braves finished 38–115, the worst season in franchise history. Their .248 winning percentage is the third-worst in baseball history, and the second-worst in National League history (behind only the 1899 Cleveland Spiders).
Fuchs lost control of the team in August 1935, and the new owners tried to change the team's image by renaming it the "Boston Bees". This did little to change the team's fortunes. After five uneven years, a new owner, construction magnate Lou Perini, changed the nickname back to the Braves. He immediately set about rebuilding the team. World War II slowed things down a little, but the team rode the pitching of Warren Spahn to impressive seasons in 1946 and 1947.
In 1948, the team won the pennant, behind the pitching of Spahn and Johnny Sain, who won 39 games between them. The remainder of the rotation was so thin that in September, "Boston Post" writer Gerald Hern wrote this poem about the pair:
The poem received such a wide audience that the sentiment, usually now paraphrased as "Spahn and Sain and pray for rain", entered the baseball vocabulary. However, in the 1948 season, the Braves actually had a better record in games that Spahn and Sain "did not" start than in games they did.
The 1948 World Series, which the Braves lost in six games to the Indians, turned out to be the Braves' last hurrah in Boston. In 1950, Sam Jethroe became the team's first African American player, making his major league debut on April 18. Amid four mediocre seasons, attendance steadily dwindled until, on March 13, 1953, Perini, who had recently bought out his original partners, announced he was moving the team to Milwaukee, where the Braves had their top farm club, the Brewers. Milwaukee had long been a possible target for relocation. Bill Veeck had tried to return his St. Louis Browns there earlier the same year (Milwaukee was the original home of that franchise), but his proposal had been voted down by the other American League owners.
Milwaukee (1953–1965).
Milwaukee went wild over the Braves, who were welcomed as genuine heroes. The Braves finished 92–62 in their first season in Milwaukee, and drew a then-NL record 1.8 million fans. The success of the team was noted by many owners. Not coincidentally, the Philadelphia Athletics, St. Louis Browns, Brooklyn Dodgers, and New York Giants would leave their original hometowns within the next five years.
As the 1950s progressed, the reinvigorated Braves became increasingly competitive. Sluggers Eddie Mathews and Hank Aaron drove the offense (they would hit a combined 1,226 home runs as Braves, with 850 of those coming while the franchise was in Milwaukee), while Warren Spahn, Lew Burdette, and Bob Buhl anchored the rotation. The 1956 Braves finished second, only one game behind the Brooklyn Dodgers.
In 1957, the Braves celebrated their first pennant in nine years spearheaded by Aaron's MVP season, as he led the National League in home runs and RBI. Perhaps the most memorable of his 44 round-trippers that season came on September 23, a two-run walk-off home run that gave the Braves a 4–2 victory over the St. Louis Cardinals and clinched the League championship. The team then went on to its first World Series win in over 40 years, defeating the New York Yankees of Berra, Mantle, and Ford in seven games. Burdette, the Series MVP, threw three complete game victories, giving up only two earned runs.
In 1958, the Braves again won the National League pennant and jumped out to a three games to one lead in the World Series against the New York Yankees once more, thanks in part to the strength of Spahn's and Burdette's pitching. But the Yankees stormed back to take the last three games, in large part to World Series MVP Bob Turley's pitching.
The 1959 season saw the Braves finish the season in a tie with the Los Angeles Dodgers, both with 86-68 records. Many residents of Chicago and Milwaukee were hoping for a Sox-Braves Series, as the cities are only about apart, but it was not to be because Milwaukee fell in a best-of-3 playoff with two straight losses to the Dodgers. The Dodgers would go on to defeat the Chicago White Sox in the World Series.
The next six years were up-and-down for the Braves. The 1960 season featured two no-hitters by Burdette and Spahn, and Milwaukee finished seven games behind the Pittsburgh Pirates, who ultimately were to win the World Series that year, in second place, one year after the Braves were on the winning end of the 13-inning near-perfect game of Pirates pitcher Harvey Haddix. The 1961 season saw a drop in the standings for the Braves down to fourth, despite Spahn recording his 300th victory and pitching another no-hitter that year.
Aaron hit 45 home runs in 1962, a Milwaukee career high for him, but this did not translate into wins for the Braves, as they finished fifth. The next season, Aaron again hit 44 home runs and notched 130 RBI, and Spahn was once again the ace of the staff, going 23–7. However, none of the other Braves produced at that level, and the team finished in the lower half of the league, or "second division", for the first time in its short history in Milwaukee.
The Braves were somewhat mediocre as the 1960s began, but fattened up on the expansion New York Mets and Houston Colt .45s. To this day, the Milwaukee Braves are the only major league team who played more than one season and never had a losing record.
Perini sold the Braves to a Chicago-based group led by William Bartholomay in 1962. Almost immediately Bartholomay started shopping the Braves to a larger television market. Keen to attract them, the fast-growing city of Atlanta, led by Mayor
Ivan Allen, Jr. constructed a new $18 million, 52,000-seat ballpark in less than one year, Atlanta Stadium, which was officially opened in 1965 in hopes of luring an existing major league baseball and/or NFL/AFL team. After the city failed to lure the Kansas City A's to Atlanta (the A's would move to Oakland in 1968), the Braves announced their intention to move to Atlanta for the 1965 season. However, an injunction filed in Wisconsin kept the Braves in Milwaukee for one final year. In 1966, the Braves completed the move to Atlanta.
Eddie Mathews is the only Braves player to have played for the organization in all three cities that they have been based in. Mathews played with the Braves for their last season in Boston, the team's entire tenure in Milwaukee, and their first season in Atlanta.
Atlanta.
1966–1974.
The Braves were a .500 team in their first few years in Atlanta; 85–77 in 1966, 77–85 in 1967, and 81–81 in 1968. The 1967 season was the Braves' first losing season since 1952, their last year in Boston. In 1969, with the onset of divisional play, the Braves won the first-ever National League West Division title, before being swept by the "Miracle Mets" in the National League Championship Series. They would not be a factor during the next decade, posting only two winning seasons between 1970 and 1981 – in some cases, fielding teams as bad as the worst Boston teams.
In the meantime, fans had to be satisfied with the achievements of Hank Aaron. In the relatively hitter-friendly confines and higher-than-average altitude of Atlanta Stadium ("The Launching Pad"), he actually increased his offensive production. Atlanta also produced batting champions in Rico Carty (in 1970) and Ralph Garr (in 1974). In the shadow of Aaron's historical home run pursuit, was the fact that three Atlanta sluggers hit 40 or more home runs in 1973 – Darrell Evans, Davey Johnson and, of course, Aaron.
By the end of the 1973 season, Aaron had hit 713 home runs, one short of Ruth's record. Throughout the winter he received racially motivated death threats, but stood up well under the pressure. The next season, it was only a matter of time before he set a new record. On April 4, opening day, he hit No.714 in Cincinnati, and on April 8, in front of his home fans and a national television audience he finally beat Ruth's mark with a home run to left-center field off left-hander Al Downing of the Los Angeles Dodgers. Aaron spent most of his career as a Milwaukee and Atlanta Brave before asking to be traded to the Milwaukee Brewers, while Ruth finished his career as a Boston Brave. In fact, until Barry Bonds eclipsed the 714 home runs hit by Babe Ruth in 2006, the top two home run hitters in Major League history had at one time been Braves.
1976–77: Ted Turner buys the team.
In 1976, the team was purchased by media magnate Ted Turner, owner of superstation WTBS, as a means to keep the team (and one of his main programming staples) in Atlanta. The financially strapped Turner used money already paid to the team for their broadcast rights as a down-payment. It was then that Atlanta Stadium was renamed Atlanta-Fulton County Stadium. Turner quickly gained a reputation as a quirky, hands-on baseball owner. On May 11, 1977, Turner appointed himself manager, but because MLB passed a rule in the 1950s barring managers from holding a financial stake in their teams, Turner was ordered to relinquish that position after one game (the Braves lost 2–1 to the Pittsburgh Pirates to bring their losing streak to 17 games).
Turner used the Braves as a major programming draw for his fledgling cable network, making the Braves the first franchise to have a nationwide audience and fan base. WTBS marketed the team as "The Atlanta Braves: America's Team", a nickname that still sticks in some areas of the country, especially the South. Among other things, in 1976 Turner suggested the nickname "Channel" for pitcher Andy Messersmith and jersey number 17, in order to promote the television station that aired Braves games. Major League Baseball quickly nixed the idea.
1978–1990.
After three straight losing seasons, Bobby Cox was hired for his first stint as manager for the 1978 season. He promoted 22-year-old slugger Dale Murphy into the starting lineup. Murphy hit 77 home runs over the next three seasons, but he struggled on defense, unable to adeptly play either catcher or first base. In 1980, Murphy was moved to center field and demonstrated excellent range and throwing ability, while the Braves earned their first winning season since 1974. Cox was fired after the 1981 season and replaced with Joe Torre, under whose leadership the Braves attained their first divisional title since 1969. Strong performances from Bob Horner, Chris Chambliss, pitcher Phil Niekro, and short relief pitcher Gene Garber helped the Braves, but no Brave was more acclaimed than Murphy, who won both a Most Valuable Player and a Gold Glove award. Murphy also won an MVP award the following season, but the Braves began a period of decline that defined the team throughout the 1980s. Murphy, excelling in defense, hitting, and running, was consistently recognized as one of the league's best players, but the Braves averaged only 65 wins per season between 1985 and 1990. Their lowest point came in 1988, when they lost 106 games. The 1986 season saw the return of Bobby Cox as general manager. Also in 1986, the team stopped using their Native American-themed mascot, Chief Noc-A-Homa.
1991–2004: Division dominance.
1991–1994.
Cox returned to the dugout as manager in the middle of the 1990 season, replacing Russ Nixon. The Braves finished the year with the worst record in baseball, at 65–97. They traded Dale Murphy to the Philadelphia Phillies after it was clear he was becoming a less dominant player. Pitching coach Leo Mazzone began developing young pitchers Tom Glavine, Steve Avery, and John Smoltz into future stars. That same year, the Braves used the number one overall pick in the 1990 MLB Draft to select Chipper Jones, who became one of the best hitters in team history. Perhaps the Braves' most important move was not on the field, but in the front office. Immediately after the season, John Schuerholz was hired away from the Kansas City Royals as general manager.
The following season, Glavine, Avery, and Smoltz would be recognized as the best young pitchers in the league, winning 52 games among them. Meanwhile, behind position players David Justice, Ron Gant and unexpected league Most Valuable Player and batting champion Terry Pendleton, the Braves overcame a 39–40 start, winning 55 of their final 83 games over the last three months of the season and edging the Los Angeles Dodgers by one game in one of baseball's more memorable playoff races. The "Worst to First" Braves, who had not won a divisional title since 1982, captivated the city of Atlanta (and the entire southeast) during their improbable run to the flag. They defeated the Pittsburgh Pirates in a very tightly contested seven-game NLCS only to lose the World Series, also in seven games, to the Minnesota Twins. The series, considered by many to be one of the greatest ever, was the first time a team that had finished last in its division one year went to the World Series the next; both the Twins and Braves accomplished the feat.
Despite the 1991 World Series loss, the Braves' success would continue. In 1992, the Braves returned to the NLCS and once again defeated the Pirates in seven games, culminating in a dramatic game seven win. Francisco Cabrera's two-out single that scored David Justice and Sid Bream capped a three-run rally in the bottom of the ninth inning that gave the Braves a 3–2 victory. It was the first time in post season history that the tying and winning runs had scored on a single play in the ninth inning. The Braves lost the World Series to the Toronto Blue Jays, however. In 1993, the Braves signed Cy Young Award winning pitcher Greg Maddux from the Chicago Cubs, leading many baseball insiders to declare the team's pitching staff the best in baseball. The 1993 team posted a franchise-best 104 wins after a dramatic pennant race with the San Francisco Giants, who won 103 games. The Braves needed a stunning 55–19 finish to edge out the Giants, who led the Braves by nine games in the standings as late as August 11. However, the Braves fell in the NLCS to the Philadelphia Phillies in six games.
In 1994, in a realignment of the National League's divisions following the 1993 expansion, the Braves moved to the Eastern Division. This realignment was the main cause of the team's heated rivalry with the New York Mets during the mid-to-late 1990s.
The player's strike cut short the 1994 season, prior to the division championships, with the Braves six games behind the Montreal Expos with 48 games left to play.
1995–2004.
The Braves returned strong the following strike-shortened (144 games instead of the customary 162) year and beat the Cleveland Indians in the 1995 World Series. This squelched claims by many Braves critics that they were the "Buffalo Bills of Baseball" (January 1996 issue of "Beckett Baseball Card Monthly"). With this World Series victory, the Braves became the first team in Major League Baseball to win world championships in three different cities. With their strong pitching as a constant, the Braves appeared in the and 1999 World Series (losing both to the New York Yankees, managed by Joe Torre, a former Braves manager), and had a streak of division titles from 1991 to 2005 (three in the Western Division and eleven in the Eastern) interrupted only in 1994 when the strike ended the season early. Pitching was not the only constant in the Braves organization —Cox was the Braves' manager, while Schuerholz remained the team's GM until after the 2007 season when he was promoted to team president. Terry Pendleton finished his playing career elsewhere, but returned to the Braves system as the hitting coach.
In October 1996, Time Warner acquired Ted Turner's Turner Broadcasting System and all of its assets, including its cable channels and the Atlanta Braves. Over the next few years, Ted Turner's presence as owner of the team would diminish.
A 95–67 record in produced a ninth consecutive division title. However, a sweep at the hands of the St. Louis Cardinals prevented the Braves from reaching the National League Championship Series for a ninth consecutive time.
In 2001, Atlanta won the National League East division yet again, swept the Houston Astros in the NLDS, then lost to the Arizona Diamondbacks in the National League Championship Series four games to one. One memorable game the Braves played that year came on September 21, when they played rival New York Mets in the first major professional sporting event held in New York City since 9/11.
In 2002, 2003 and 2004, the Braves won the Eastern division again, but lost in the NLDS in all three years in the same fashion: 3 games to 2 to the San Francisco Giants, Chicago Cubs, and Houston Astros.
Cy Young dominance.
Six National League Cy Young Awards in the 1990s were awarded to three Braves pitchers:
2005: A new generation.
In 2005, the Braves won the Division championship for the fourteenth consecutive time from 1991 to 2005. Fourteen consecutive division titles stands as the record for all major league baseball. The 2005 title marked the first time any MLB team made the postseason with more than 4 rookies who each had more than 100 ABs (Wilson Betemit, Brian McCann, Pete Orr, Ryan Langerhans, Jeff Francoeur). Catcher Brian McCann, right fielder Jeff Francoeur, and pitcher Kyle Davies all grew up in the suburbs of Atlanta. The large number of rookies to debut in 2005 were nicknamed the "Baby Braves" by fans and became an Atlanta-area sensation, helping to lead the club to a record of 90–72.
However, the season would end on a sour note as the Braves lost the National League Division Series to the Astros in four games. In Game 4, with the Braves leading by 5 in the eighth inning, the Astros battled back with a Lance Berkman grand slam and a two-out, ninth inning Brad Ausmus home run off of Braves closer Kyle Farnsworth. The game did not end until the 18th inning, becoming the longest game in playoff history at 5 hours 50 minutes. Chris Burke ended the marathon with a home run off of Joey Devine.
After the 2005 season, the Braves lost their long-time pitching coach Leo Mazzone, who left to go to the Baltimore Orioles. Roger McDowell took his place in the Atlanta dugout. Unable to re-sign shortstop Rafael Furcal, the Braves acquired shortstop Edgar Rentería from the Boston Red Sox.
2006: Struggles.
In 2006, the Braves did not perform at the level they had grown accustomed to. Due to an offensive slump, injuries to their starting rotation, and subpar bullpen performances, the Braves compiled a 6–21 record for the month of June, the worst month ever in the city of Atlanta, and just percentage points better than the Boston Braves of May 1935 (4–20).
The Braves made their move in July, going 14–10. However, the team remained in the bottom half of the NL East and trailed the Mets by a double-digit deficit for much of the season (13 games at the All-Star Break). However, despite their struggles, the Braves entered the break down by only six and a half games to the Dodgers for the NL Wild Card slot after winning seven of their last ten games.
After the break, the Braves came out with their bats swinging, setting many franchise records. They won five straight, sweeping the Padres and taking two from the Cardinals, tallying a total of 65 runs in that span. The 65 runs in five games is the best by the franchise since 1897, when the Boston Beaneaters totaled 78, including 25 in one game and 21 in another, from May 31 – June 3; the 2006 Braves also became the first team since the 1930 New York Yankees to score ten runs or more in five straight games. The Braves had a total of 81 hits during their five-game run and 98 hits in their last six games, going back to an 8–3 victory over Cincinnati on July 9, the last game before the All-Star break. Additionally, Chipper Jones was able to maintain a 20-game hitting streak and tie Paul Waner's 69-year-old Major League record with a 14-game extra-base hit streak.
The Braves made their first trade of the season on July 20 to shore up the bullpen, sending Class A Rome catcher Max Ramirez to Cleveland for closer Bob Wickman. He served as the Braves' closer for the remainder of the season, taking over for an embattled Jorge Sosa, who was subsequently traded on the July 31 trade deadline for St. Louis minor league pitcher Rich Scalamandre.
On July 29, the Braves traded reserve third baseman/shortstop Wilson Betemit to the Los Angeles Dodgers for reliever Danys Báez and infielder Willy Aybar. The move came on the night that starting third baseman Chipper Jones went on the 15-day disabled list with a strained oblique muscle. With Betemit gone, Atlanta called up infielder Tony Pena, Jr. from AAA Richmond to supplement Pete Orr.
Before the expansion of rosters on September 1, the Braves acquired Daryle Ward from the Washington Nationals for Class A Myrtle Beach pitcher Luis Atilano, in hopes that he would be a valuable pinch-hitter in the postseason.
However, on September 18, the New York Mets' win over the Florida Marlins mathematically eliminated the Braves from winning the NL East, ending the Atlanta Braves' eleven-year reign over the NL East. On September 24, the Braves' loss to the Colorado Rockies mathematically eliminated the Braves from winning the NL Wild Card, making 2006 the first year that the Braves would not compete in the postseason since 1990, not counting the strike-shortened 1994 season.
Also, a loss to the Mets on September 28 guaranteed the Braves their first losing season since 1990. Although the Braves won two of their last three games against the Astros, including rookie Chuck James besting Roger Clemens, Atlanta finished the season in third place, one game ahead of the Marlins, at 79–83.
After the season, the Atlanta coaching staff underwent a few changes. Brian Snitker became the third base coach after Fredi González left to become the manager for the Florida Marlins. Chino Cadahia replaced Pat Corrales as bench coach and former catcher Eddie Pérez became the new bullpen coach, replacing Bobby Dews.
Sale to Liberty Media.
In December 2005, team owner Time Warner, who inherited the Braves after purchasing TBS in 1996, announced it was placing the team for sale. Liberty Media began negotiations to purchase the team.
In February 2007, after more than a year of negotiations, Time Warner agreed to a deal that would sell the Braves to Liberty Media Group (a company which owned a large amount of stock in Time Warner, Inc.), pending approval by 75 percent of MLB owners and the Commissioner of Baseball, Bud Selig. The deal included the exchange of the Braves, valued in the deal at $450 million, a hobbyist magazine publishing company, and $980 million cash, for 68.5 million shares of Time Warner stock held by Liberty Media, then worth approximately $1.48 billion. Team President Terry McGuirk anticipated no change in the current front office structure, personnel, or day-to-day operations of the Braves. Liberty Media is not expected to take any type of "active" ownership in terms of day-to-day operations.
On May 16, 2007, Major League Baseball's owners approved the sale of the Braves from Time Warner to Liberty Media.
2007: More struggles.
The Braves made their first moves by re-signing Bob Wickman to a one-year deal and picking up John Smoltz's option in September 2006. They traded starting pitcher Horacio Ramírez to the Seattle Mariners for pitcher Rafael Soriano, an American League reliever with a 2.20 ERA in 2006. They also denied arbitration to pitcher Chris Reitsma and second baseman Marcus Giles. The Braves signed utility-man Chris Woodward to fill a spot on the bench. The biggest trade in the offseason involved first baseman Adam LaRoche and a minor league player for Pittsburgh Pirates closer Mike González and a minor league infielder, Brent Lillibridge. Gonzalez, who converted 24 of 24 save opportunities in 2006, joined Soriano as a set-up man for Wickman in the bullpen. The team then signed Craig Wilson to a one-year deal to platoon with Scott Thorman. The Braves also had solid relievers in Macay McBride, Blaine Boyer, and Tyler Yates. In addition, the majority of the Braves' offense, which was second in the NL in runs scored in 2006, returned in 2007. However, Mike Hampton was sidelined for the entire 2007 season with yet another surgery. Mike González was later sidelined for the season while recovering from Tommy John surgery.
The Braves' bullpen and offense came through in the clutch early on, helping the Braves to a 7–1 start, their best start since winning the World Series in 1995. The team finished April with a 16–9 record, but struggled during May, finishing 14–14. The Braves also struggled during interleague play, finishing with an NL-worst 4–11 record. On June 24, the Braves fell to .500 for the first time in the 2007 season, but rebounded by winning the next 5 games.
On July 5, Chipper Jones surpassed Dale Murphy for the Atlanta club record of 372 home runs by belting two against the Los Angeles Dodgers. On July 31, 2007, the Braves finalized the deal to acquire slugger first baseman Mark Teixeira and LHP Ron Mahay from the Texas Rangers for catcher Jarrod Saltalamacchia, SS Elvis Andrus, and three minor-leaguers. The Braves also acquired Octavio Dotel from the Kansas City Royals for Kyle Davies and also traded LHP Wilfredo Ledezma and RHP Will Startup to the San Diego Padres for Royce Ring. On August 19, 2007 John Smoltz passed Phil Niekro for 1st place on the Braves' all-time strikeout list. Braves manager Bobby Cox broke the all-time MLB record for most career ejections by a manager in August 2007.
After struggling during the second half of the 2007 season, Atlanta finished over .500 and missed the post season again. On October 12, 2007, John Schuerholz stepped down as General Manager to take over as team president. Assistant GM Frank Wren took over as General Manager.
2008: Plagued by injuries.
In December 2007, the team announced it would not re-sign center fielder Andruw Jones (who later would sign with the Dodgers). Another major move was acquiring CF Gorkys Hernández and RHP Jair Jurrjens from the Detroit Tigers in exchange for SS Edgar Rentería and cash considerations. Next, LHP Tom Glavine was signed to a one-year contract. They also acquired LHP Will Ohman and INF Omar Infante from the Cubs in exchange for RHP José Ascanio.
The team's first new move for 2008 was acquiring OF Mark Kotsay from the A's (to replace Jones) in exchange for RHP Joey Devine, RHP Jamie Richmond and cash considerations. Days later, Wren traded Willy Aybar, outfielder Tom Lindsey, and infielder Chase Fontaine to the Rays in exchange for left-hand reliever Jeff Ridgway.
Before the trade deadline the Braves traded 1B Mark Teixeira to the Los Angeles Angels for first baseman Casey Kotchman and minor league RHP Stephen Marek. The Braves failed to make the playoffs for the third straight season.
2009: The return of solid pitching.
On December 4, 2008, the Atlanta Braves received Javier Vázquez and Boone Logan, while the Chicago White Sox received prospects catcher Tyler Flowers, shortstop Brent Lillibridge, third baseman Jon Gilmore and pitcher Santos Rodriguez. On January 13, 2009, the Braves signed Japanese pitcher Kenshin Kawakami to a three-year deal, and two days later signed free agent pitcher Derek Lowe to a four-year contract. During the course of the offseason, the Braves signed veteran pitcher and former Brave Tom Glavine, while losing long-time Brave John Smoltz to the Boston Red Sox.
On February 25, 2009, just before the start of spring training, Atlanta agreed to terms on a one-year contract with free-agent outfielder Garret Anderson. The additional outfield depth allowed the Braves to trade Josh Anderson to the Detroit Tigers for minor league pitcher Rudy Darrow on March 30, 2009.
On June 3, 2009, the Braves acquired Nate McLouth from the Pittsburgh Pirates for prospects Jeff Locke, Charlie Morton and Gorkys Hernández. They also released veteran pitcher Tom Glavine. On July 10, 2009, the Braves traded outfielder Jeff Francoeur to the New York Mets for outfielder Ryan Church. On July 31, 2009, hours before the trade deadline, the Braves and Boston Red Sox swapped 1st basemen: Atlanta dealt Casey Kotchman to Boston and reacquired Adam LaRoche, whom the Braves had traded away during the 2006–07 off-season to Pittsburgh.
The Braves made a late-season surge, coming within 2 games of the wild card leading Colorado Rockies in late September. On October 1, 2009 with the Braves four games back, Colorado beat the Milwaukee Brewers 9–2 to clinch the wild card spot and end the Braves' 2009 postseason hopes.
2010: Cox's final season.
The 2010 Atlanta Braves Season features the Braves' attempt to reclaim a postseason berth for the first time since 2005. The Braves were once again skippered by Bobby Cox, now in his 25th and final season managing the team. The Braves started the 2010 season slowly and had a nine-game losing streak in April. Then they had a nine-game winning streak from May 26 through June 3, the Braves longest since 2000 when they won 16 in a row. On May 31, the Atlanta Braves defeated the then-first place Philadelphia Phillies at Turner Field to take sole possession of first place in the National League East standings, a position they had maintained through the middle of August. The last time the Atlanta Braves led the NL East on August 1 was in 2005. On July 13, 2010 at the 2010 MLB All-Star Game in Anaheim, Braves catcher Brian McCann was awarded the All-Star Game MVP Award for his clutch two-out, three-run double in the seventh inning to give the National League its first win in the All-Star Game since 1996. He became the first Brave to win the All-Star Game MVP Award since Fred McGriff did so in 1994. The Braves made two deals before the trade deadline to acquire Álex González, Rick Ankiel and Kyle Farnsworth from the Toronto Blue Jays and Kansas City Royals, giving up shortstop Yunel Escobar, pitchers Jo-Jo Reyes and Jesse Chavez, outfielder Gregor Blanco and three minor leaguers. On August 18, 2010 they traded three pitching prospects for first baseman Derrek Lee from the Chicago Cubs. On August 22, 2010 against the Chicago Cubs, Mike Minor struck out 12 batters across 6 innings; an Atlanta Braves single game rookie strikeout record. The Braves dropped to second in the NL East in early September, but won the NL Wild Card. They lost to the San Francisco Giants in the National League Division Series in four games. Every game of the series was determined by one run. After the series-clinching victory for the Giants in Game 4, Bobby Cox was given a standing ovation by the fans, also by players and coaches of both the Braves and Giants.
2011: Fredi González takes over.
On October 13, 2010, the Atlanta Braves announced that Fredi González would replace long-time Braves manager Bobby Cox as manager of the team in 2011. The announcement came just two days after the 2010 Braves were eliminated from the postseason. It was also announced that pitching coach Roger McDowell, third-base coach Brian Snitker, and bullpen coach Eddie Pérez would retain their current positions, while former hitting coach Terry Pendleton would replace Glenn Hubbard as the first-base coach and newcomer Carlos Tosca would become the new bench coach. Hubbard and former bench coach Chino Cadahia were not offered positions on the new coaching staff. Larry Parrish was hired as hitting coach on October 29, 2010.
On November 16, 2010 in an offseason trade, the Braves acquired Dan Uggla from the Florida Marlins in exchange for left-handed reliever Mike Dunn and infielder Omar Infante. According to Elias Sports Bureau, the Braves had an all-time franchise win-loss record over .500 for the first time since 1923 after their win over the Houston Astros on June 11, 2011. The Braves franchise became the third franchise in MLB history to reach 10,000 wins with their win over the Washington Nationals on July 15, 2011. On July 31, 2011, just sixteen days after registering their 10,000th win, the Florida Marlins defeated the Braves by a score of 3-1, handing the team the 10,000th loss in franchise history. The Braves become only the second team in big league history with 10,000 losses after the Philadelphia Phillies reached the plateau in 2007.
Players from the Braves' farm system, such as Freddie Freeman and Brandon Beachy, played regularly with the big league club, while Julio Teherán, Randall Delgado, and Mike Minor were called up for spot starts. With late season injuries to starters Jair Jurrjens and Tommy Hanson, these three young pitchers made their way into the starting rotation in their absence. Eight players made their major league debuts for the team in 2011.
September collapse.
The Braves led the National League Wild Card standings for much of the 2011 season, with the division-rival Philadelphia Phillies firmly in control of first place in the National League East. The Braves entered the final month of the regular season 25 games above .500 with a record of 80–55 and an -game lead in the Wild Card standings. The nearest team trailing them, the St. Louis Cardinals, who also trailed the National League Central-leading Milwaukee Brewers by games at the time, were considered a long-shot to gain a spot in the postseason. Just days prior on August 26, the Cardinals found themselves games behind and in third place.
With 27 games to play, the Braves went 9–18 in September to finish the season with a record of 89–73. The Cardinals, meanwhile, went 18–8 to finish at 90–72. Braves closer Craig Kimbrel, who had not surrendered a single earned run in July or August, carried a 4.76 ERA in September with three blown saves. After being dominant in his role for much of the season, Braves setup man Jonny Venters posted a 5.11 September ERA. These sharp declines in both relievers led many critics to question the handling of the bullpen by Braves manager Fredi González. Veteran starter Derek Lowe posted a win-loss record of 0–5 in September with an ERA of 8.75. Shortly into the offseason, Lowe would be traded to the Cleveland Indians. The Braves starters lasted six or more innings only three times over the last 23 games. Over the last five games, all of which were losses for the Braves, the team managed to score only seven runs. Braves catcher Brian McCann, often regarded as the best offensive catcher in the Majors, hit only .183 with two home runs in September. The offense as a whole hit for only a .235 batting average and a .300 on-base percentage in September, both second-worst in the National League. The .195 RISP average by Braves hitters was second worst in the Majors. Hitting coach Larry Parrish was fired two days following the last game of the season.
2012: Chipper's last season.
In 2012, the Braves began their 138th season after an upsetting end to the 2011 season. On March 22, the Braves announced that third baseman Chipper Jones would retire following the 2012 season after 19 Major League seasons with the team. The Braves also lost many key players through trades or free agency, including pitcher Derek Lowe, shortstop Alex González, and outfielder Nate McLouth. To compensate for this, the team went on to receive many key players such as outfielder Michael Bourn, along with shortstops Tyler Pastornicky and Andrelton Simmons. To fill the void of a quality starting pitcher left by Lowe (as well as a mid-season injury to Brandon Beachy), manager Fredi González elected relief pitcher Kris Medlen to the starting pitching rotation. The Braves went on to win every game Medlen started, setting the MLB record for most consecutive wins when a single pitcher starts (total of 23). Atlanta stayed close to the Washington Nationals in the race to win the National League East title. They also stayed on top of the National League Wild Card race. Washington ended up winning their first division title in franchise history, but the Braves remained in first place of the NL wild card race. Keeping with a new MLB rule for the 2012 season, the top two wild card teams in each league must play each other in a playoff game before entering into the Division Series.
The Braves played the St. Louis Cardinals in the first ever Wild Card Game. The Braves were behind 6–3 in the bottom of the eighth inning when Andrelton Simmons hit a fly ball to left field that dropped in between the Cardinals shortstop and left fielder. Umpire Sam Holbrook called Simmons out, citing the infield fly rule. Had an infield fly not been called, Simmons would have been credited with a single and Atlanta would have had the bases loaded with one out. Fans at Turner Field began to litter the field with debris, prompting the game to be delayed for 19 minutes. The Braves lost the game 6–3, ending their season.
2013: Braves win the East.
During the offseason following a gut wrenching exit against the St. Louis Cardinals in the Wild Card Game, the Braves spent the 2012-2013 offseason revamping and retooling their offense. The Braves turned heads across baseball by acquiring B.J. Upton from the Tampa Bay Rays, signing him to a 5-year $75.25 million contract and making him their starting center fielder, and uniting him with his younger brother Justin Upton from the Arizona Diamondbacks in a seven player trade that sent fan favorite utility man Martin Prado to the Diamondbacks, they also filled a need for a new Third Baseman in Chris Johnson after the retirement of Chipper Jones the previous year. The Braves began the 2013 season with a hot start in April by going 17-9 for the month, which saw the emergence of rookie sensation Evan Gattis, while taking hold of first place in the National League East division, a lead they would never relinquish for the rest of the season. The Braves suffered many injuries to key players throughout the season, including injuries to Jason Heyward, Brian McCann, Freddie Freeman, Eric O'Flaherty, Jonny Venters, Ramiro Pena and others, but found a way to win despite these blows to the team. Leading up to the All Star break, First Baseman Freddie Freeman was voted in to play for the 2013 National League All-Star Team, in the 2013 All Star Game, which he did not play. The Braves also witnessed the emergence of rookie pitcher Julio Teheran after much hype during Spring Training. From July 26 to August 10, the Braves won 14 games in a row. The winning streak was the longest of its kind since April–May 2000.
On June 28, 2013 the Atlanta Braves retired former third baseman Chipper Jones' jersey, number 10, before the game against the Arizona Diamondbacks. He was honored before 51,300 fans at Turner Field in Atlanta, Georgia. He served as a staple of the Braves franchise for 19 years before announcing his retirement at the beginning of the 2012 season. Chipper Jones played his last regular season game for the Braves on September 30, 2012.
The Braves opened up a 15-game lead on the Washington Nationals in the National League East on September 3, 2013, riding that lead en route to its first division title since 2005, the last of 14 straight division titles. This was also Braves manager Fredi Gonzalez's first division title since beginning his managerial career in 1990; including his first since becoming the manager of the Braves after the 2010 season. The Braves clinched the 18th division title in team history on September 22, 2013 after a Nationals loss to the Marlins in the first game of a double header; the Braves also won their game that day, beating the Chicago Cubs 5-2 at Wrigley Field.
2014.
On November 11, 2013, the Braves announced that they would vacate Turner Field for a new stadium in Cobb County, in the northwest suburbs outside of Atlanta in 2017. The move is to follow the expiration of the Braves' 20-year lease on Turner Field in 2016. The new stadium is to be constructed in a public/private partnership. During the offseason the Braves signed few of their young talents to multi year contracts; Craig Kimbrel (4 years/$42M), Freddie Freeman (8 years/$135M), Kris Medlen (1 year/$5.8M), Jason Heyward (2 years/$13.3M), Julio Teherán (6 years/$32.4M) and Andrelton Simmons (7 years/$58M).
World Series Championships.
Over its 138 seasons, the Braves franchise has won a total of three World Series Championships.
Radio and television.
After years of stability, the Braves have faced a period of transition in their radio and television coverage.
The 2007 season was the last for Braves baseball on the TBS Superstation. TBS showed 70 games throughout the country, then cleared the decks to make way for a new national broadcast package that began in earnest with the 2007 postseason, and expanded to Sunday afternoon games in 2008. Until his dismissal in 2009, Chip Caray, one of the Braves' current broadcasters, called play-by-play for the national package, which includes the Division Series every season and alternating coverage of the American League Championship Series and National League Championship Series. Caray is joined by Joe Simpson, who has provided color commentary for the Braves since 1992.
Braves baseball had been on TBS since it was WTCG in 1972 and had been a cornerstone of the national superstation since it began in 1976. WPCH-TV/Peachtree TV, formerly WTBS Atlanta, still carried Braves games after 2007, but only in parts of the Southern United States. After the transfer of the channel's operations from Time Warner to Meredith Corporation, all Peachtree TV games were simulcast on Fox Sports South outside of the Peachtree TV coverage area in 2011 and 2012. On February 27, 2013, it was announced that Fox Sports South and SportSouth would carry every regionally televised Braves game exclusively, ending the team's partnership with WPCH-TV after 40 years.
After the 2004 season, longtime radio flagship station 750 WSB was replaced by WGST 640AM. Due to WGST's weak signal at night, which fails to cover the entire Atlanta metropolitan area, all games began to be simulcast on FM radio when the rights were transferred. The games first appeared on 96.1 WKLS (formerly "96rock") in 2005, but moved to country music station 94.9 WUBL ("94.9 The Bull") in 2007 after WKLS underwent a change in format from classic rock to active rock and became Project 9–6–1. As of the 2009 season, the Braves returned to WKLS on the FM frequency but remained on WGST on AM. It was announced that for the 2010 season, the Braves will be flagshipped on WCNN 680 The Fan and in Atlanta on the AM dial and WNNX 100.5 FM.
The Atlanta Braves radio network currently serves 134 radio stations across the Southern United States, including 20 in Alabama, 4 in Florida, 68 in Georgia, 1 in Mississippi, 13 in North Carolina, 14 in South Carolina, and 14 in Tennessee.
Since 2009, the radio announcers have been former Brewers announcer Jim Powell and Don Sutton. Sutton was released after the 2006 season and called Washington Nationals games on television from 2007 to 2008, but he has since returned for the 2009 season. Longtime Braves voices Skip Caray and Pete Van Wieren were the primary play-by-play voices of Braves baseball until Skip's sudden death on August 3, 2008, and Van Wieren's retirement after the 2008 season.
External links.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

</doc>
<doc id="2141" url="http://en.wikipedia.org/wiki?curid=2141" title="Atari ST">
Atari ST

The Atari ST is a home computer released by Atari Corporation in June 1985. Development machines were distributed around May 1985 and it was available commercially from that summer into the early 1990s. The "ST" officially stands for "Sixteen/Thirty-two", which referred to the Motorola 68000's 16-bit external bus and 32-bit internals. Due to its graphical user interface, it was jokingly referred to as the "Jackintosh", a reference to Jack Tramiel.
The Atari ST is part of the 16/32 bit generation of home computers, based on the Motorola 68000 CPU, typically with 512 kB of RAM or more, a graphical user interface, and 3½" microfloppy disks as storage. It was similar to the Apple Macintosh, and its simple design allowed the ST to precede the Commodore Amiga's commercial release by almost two months. The Atari ST was also the first personal computer to come with a bit-mapped color GUI, using a version of Digital Research's GEM released that February.
The ST was primarily a competitor to the Macintosh, Amiga, and in certain markets the Acorn Archimedes. Where the Amiga has a graphics accelerator and wavetable synthesis based sound, the ST has a simple frame buffer and a 3 voice synthesizer chip but with a slightly faster CPU, and has a high-resolution monochrome display mode, ideal for business and CAD. In some markets, particularly Germany, the machine gained a strong foothold as a small business machine for CAD and Desktop publishing work. The Atari ST also enjoyed some market popularity in Canada. 
The ST was also the first home computer with integrated MIDI support. Thanks to its built-in MIDI, it enjoyed success for running music-sequencer software and as a controller of musical instruments among amateurs and professionals alike, being used in concert by bands and performers such as Jean Michel Jarre, Madonna, Eurythmics, Tangerine Dream, Fatboy Slim, and 1990s UK dance acts Utah Saints & 808 State, as well as naming German digital hardcore band Atari Teenage Riot.
The ST was later superseded by the Atari STE, Atari TT, Atari MEGA STE and Falcon computers.
Origins.
The Atari ST was born from the rivalry between home-computer makers Atari, Inc. and Commodore International.
Amiga contract.
Jay Miner, one of the original designers for the custom chips found in the Atari 2600 and Atari 8-bit family, tried to convince Atari management to create a new chipset for a video game console and computer. When his idea was rejected, Miner left Atari to form a small think tank called Hi-Toro in 1982 and began designing the new "Lorraine" chipset. The company, which was later renamed Amiga Corporation, was pretending to sell video game controllers to deceive competition while it developed a Lorraine-based computer.
Amiga ran out of capital to complete Lorraine's development, and Atari, owned by Warner Communications, paid Amiga to continue development work. In return Atari received exclusive use of the Lorraine design for one year as a video game console. After one year Atari would have the right to add a keyboard and market the complete computer, designated the 1850XLD. As Atari was heavily involved with Disney at the time, it was later code-named "Mickey", and the 256K memory expansion board was codenamed "Minnie".
Tramel Technology.
After leaving Commodore International in January 1984 Jack Tramiel formed Tramel Technology with his sons and other ex-Commodore employees, and in April began planning a new computer. The company initially considered the National Semiconductor NS320xx microprocessor, but was disappointed with its performance. This started the move to the 68000.
Tramiel learned that Warner wanted to sell Atari, which in mid-1984 was losing about a million dollars per day. Interested in Atari's overseas manufacturing and world wide distribution network for his new computer, Tramiel negotiated with Warner in May and June 1984. He secured funding and bought Atari's Consumer Division (which included the console and home computer departments) in July. As executives and engineers left Commodore to join Tramiel's new Atari Corporation, Commodore responded by filing lawsuits against four former engineers for theft of trade secrets. This was intended to, in effect, bar Tramiel from releasing his new computer.
One of Tramiel's first acts after forming Atari Corp. was to conduct rapid sweeping interviews of the Atari Inc. employee's. At the time of the purchase of Atari Inc's assets and inventories, the company had approx. 900 employee's remaining from its once high point of 10,000. Interviews were conducted and approx. 100 employees were hired to come to work at Atari Corp. Atari Corp. was actually a completely separate entity from Atari Inc. The company was originally called TTL (Tramiel Technologies Limited) and that company was renamed Atari Corp. A popular misconception is that Jack Tramiel fired most of the Atari Inc. employee's. This was completely false, the Tramiels did not purchase the employee contracts when they bought the assets of Atari Inc. The Tramiels in fact hired people to come to work for what was really a brand new Start Up Company - Atari Corp. Most were hired if they had 68000 experience, Operating System experience and other needed skills to work on project "RBP" (Rock Bottom Price - the codename for the Atari ST.) The Tramiels reviewed several on-going projects, but focused on their business and product plan to move forward. At one point a promising sound processor called AMY was reviewed and was initially going to be a component within the new ST computer design. However, not too long after that, the chips design was discovered to have issues and would need more time and work to complete. The Tramiels were already running on both a very slim budget and an extremely aggressive time line, so the AMY was dropped in favor of an off the shelf Yamaha sound chip. It was during this time in late July/early August that Leonard Tramiel discovered the original Amiga contract, which required Amiga Corporation to deliver the Lorraine chipset to Atari on June 30, 1984. Amiga Corp. had sought more monetary support from investors in spring 1984 (among them Tramel Technology, which wished to replace nearly everyone at Amiga).
Commodore and Amiga.
Having heard rumors that Tramiel was negotiating to buy Atari, Amiga Corp. entered into discussions with Commodore. The discussions led to Commodore wanting to purchase Amiga Corporation outright, which Commodore believed would cancel any outstanding contracts, including Atari's. Instead of Amiga Corp. delivering Lorraine to Atari, Commodore delivered a check of $500,000 to Atari on Amiga's behalf, in effect returning the funds Atari invested into Amiga for the chipset. Tramiel countersued Amiga Corp. on August 13, 1984. He sought damages and an injunction to bar Amiga (and effectively Commodore) from producing anything with its technology.
At Commodore, the Amiga team was in limbo during the summer of 1984 because of the lawsuit. No word on the status of the chipset, the Lorraine computer, or the team's fate was known. In the fall of 1984, Commodore informed the team that the Lorraine project was active again, the chipset was to be improved, the operating system developed, and the hardware design completed. While Commodore announced the Amiga 1000 with the Lorraine chipset in July 1985, the delay gave Atari, with its many former Commodore engineers, time to deliver the first Atari ST units in June 1985. In March 1987, the two companies settled the dispute out of court in a closed decision.
Operating system.
With the hardware design nearing completion, the Atari team started looking at solutions for the operating system. Soon after the Atari buyout, Microsoft approached Tramiel with the suggestion that they port Windows to the platform, but the delivery date was out by about two years, far too long for their needs. Another possibility was Digital Research, who were working on a new GUI-based system then known as Crystal, soon to become GEM. Another option was to write a new operating system in-house, but this was rejected as Atari management was unsure whether the company had the required expertise to do so.
Digital Research was fully committed to the Intel platform, so a team from Atari was sent to the Digital Research headquarters to work with the "Monterey Team" which comprised a mixture of Atari and Digital Research engineers. Atari's Leonard Tramiel was the Atari person overseeing "Project Jason" (aka — The Operating System) for the Atari ST line of computers. The name came from the original designer and developer, Jason Loveman. Tim Oren has describing the history of the project, from his series "Professional GEM".
CP/M-68K is essentially a direct port of CP/M's original, mature operating system. By 1985, it was becoming increasingly outdated in comparison to MS-DOS 2.0; for instance, CP/M does not support sub-directories. Digital Research was also in the process of building a new DOS-like operating system specifically for GEM, "GEMDOS", and there was some discussion of whether or not a port of GEMDOS could be completed in time for product delivery in June. The decision was eventually taken to port it, resulting in a GEMDOS file system which became part of TOS ("The Operating System") and colloquially known as the ("Tramiel Operating System"). This was beneficial as it gave the ST a fast, hierarchical file system, essential for hard drive storage disks, plus programmers had function calls similar to the IBM PC DOS.
Whitesmiths's OS called Idris was also available for Atari ST.
Debut.
After six months of intensive effort following Tramiel's takeover, Atari announced the "520ST" at the Winter Consumer Electronics Show in Las Vegas in January 1985. Due to its similarities to the original Apple Macintosh and Jack Tramiel's role in its development, it was quickly nicknamed the "Jackintosh". Atari's rapid development of the ST amazed many, but others were more skeptical, citing the ST's "cheap" appearance, Atari's uncertain financial health, and the poor relations Commodore under Tramiel had had with software developers. In 1984 "Ahoy!" had written, before he purchased Atari, that Tramiel "had never been able to establish very good relations with computer dealers ... Under his reign, computer retailers have accused Commodore of treating them as harshly as if they were suppliers or competitors". "Computer Gaming World" stated that his poor reputation likely made computer stores reluctant to deal with Atari, hurting the company's distribution of the ST. One retailer said, "If you can believe Lucy when she holds the football for Charlie Brown, you can believe Jack Tramiel", and another said that because of its experience with Tramiel "Our interest in Atari is zero, zilch". The majority of software companies were hesitant to support another platform beyond the IBM PC, Apple, and Commodore 64, and some were unsure of whether to choose the ST or the Amiga. The public saw both Commodore and Atari as selling, as John C. Dvorak wrote, "cheap disposable" game machines.
Atari ST advertisements stated "America, We Built It For You", and quoted Atari president Sam Tramiel: "We promised. We delivered. With pride, determination, and good old ATARI know how". Although Atari was out of cash, sales of its 8-bit computers were "very, very slow" according to Jack Tramiel, and employees feared that he would shut the company down, the 520ST shipped during spring 1985 to the press, developers, and user groups, and in early July 1985 for general retail sales, saving the company. The machine had gone from concept to store shelves in a little under a year. Atari had originally intended to release versions with 128 kB and 256 kB of RAM as the "130ST" and "260ST" respectively. However, with the OS loaded from floppy into RAM, there would be little or no room left over for applications to run. The 260ST did make its way into Europe on a limited basis.
The ST supports a monochrome or color monitor. The color hardware supports two different resolutions, 320 × 200 with 16 out of 512 colors, or 640 × 200 with 4 out of 512 colors. The monochrome monitor was less expensive, and has a single resolution of 640 × 400. Due to its higher vertical resolution and noninterlaced operation at 70 Hz, the monochrome monitor was better suited to business applications. The attached monitor determines available resolutions, so software either supports both types of monitors or only works with one. Color is required by a majority of games. Unlike the Amiga, Commodore 64, and Atari 8-bit computers, the ST does not have hardware-supported sprites. 
The early ST systems have no battery-backed clock so time needs to be set after turning on. Early models shipped with Atari Logo and "TOS" on disk; the operating system occupies 206K RAM, but were designed with four ROM sockets to make for easy upgrading to the future ROM-based "TOS". These became available only a few months later, and were included in all new machines, as well as being available to upgrade older machines. By late 1985 the machines were also upgraded with the addition of an RF modulator (for TV display), a version known as the 520STM.
Atari had originally intended to include GEM's GDOS (Graphical Device Operating System), which allowed programs to send GEM VDI (Virtual Device Interface) commands to drivers loaded by GDOS. This allowed developers to send VDI instructions to other devices simply by pointing to it. However, GDOS was not ready at the time the ST started shipping, and was included in software packages and later ST machines. Later versions of GDOS supported vector fonts.
A limited set of GEM fonts were also included within the ROMs. These fonts also feature an addition: The standard 8x8 pixel graphical character set for the ST (the main in-ROM "font" for GEM, and text-mode TOS operations in color modes) contains, following all the standard numbers, letters, symbols and accented characters, four unusual characters. These can be placed together in a square, forming a basic but recognisable facsimile of the face of J. R. "Bob" Dobbs, the figurehead of the Church of the Subgenius.
The ST was less expensive than most machines, including the Macintosh Plus, and tended to be faster than most. Largely as a result of the price/performance factor, the ST would go on to be a fairly popular machine, notably in European markets where the foreign-exchange rates amplified prices. Indeed, the company's English advertising strapline of the era was "power without the price". In fact, an Atari ST and terminal emulation software was much cheaper than a Digital VT220 terminal, which was commonly needed by offices with central computers.
Design.
Original housing.
The original 520ST case design was created by Ira Velinsky — Atari's chief Industrial Designer. The ST is basically wedge shaped, featuring bold angular lines and a series of grilles cut into the rear for airflow. The keyboard has soft tactile feedback and rhomboid-shaped function keys across the top. The 520ST is an all-in-one unit, similar to earlier home computers like the Commodore 64. By the time the 520ST reached the market, however, market and IBM compatibility concerns demanded a keyboard with cursor keys and a numeric keypad. For this reason, the 520ST ended up significantly larger than previous popular all-in-one machines like the Commodore 64.
The 520ST uses an external "brick" power supply, floppy disk, monitor and mouse. Even basic system setups thus suffer from cable spaghetti, a problem future versions would address to one degree or another. Early 520ST owners became accustomed to the "Atari Twist" and the "Atari Drop" service procedures. The "Atari Twist" seemed to help discharge built-up static electricity (Atari soldered-down the metal shielding to fix the problem) while the "Atari Drop" appeared to help re-seat chips which may have become partially unseated over time.
Port connections.
The 520ST features a large number of ports mounted at the rear of the machine. The basic port layout would remain largely unchanged over the machine's history.
Because of its bi-directional design, the Centronics printer port can be used for joystick input, and several games make use of available adaptors that plugged into the printer socket, providing two additional 9-pin joystick ports.
Atari initially used single-sided disk drives that could store up to 360 kB. Later drives were double-sided versions that stored 720 kB. Due to the early sales of so many of the single-sided drives, some commercial software, particularly games, shipped by default on single-sided disks, even supplying two 360kB floppies instead of a single double-sided one, for fear of alienating early adopters. The problem was exacerbated by the early drive's single read/write head being on the "wrong" side of the disc - that is, reading/writing the same side of the disc as a more standard 720kB drive's "second" head ("head 1") instead of its "first" ("head 0"). The boot sector and FAT was typically written to "side 0" by double-sided drives (in both STs and other marques fitted with 3.5" drives), so owners of single-sided machines could not read any useful data from a standard double-sided disc at all, not even the root directory listing, and might well mistakenly end up reformatting just one side of a seemingly "faulty" disc as a result.
ST magazines wishing to cater to the entire audience while still supplying a large amount of material on a single cover disc had to adopt innovative custom formats to work around this problem, forcing the bootsector and FAT onto "side 1", along with the disc's main feature program, and tucking supplemental programs onto "side 0" (typically falsely renamed "side B", in allusion to classic 45rpm singles), "inside" a particular file folder which would only open successfully for owners of 720kB drives. Owners of single-sided drives were encouraged, if they wished to gain access to "side B", to send the original coverdisk(s) back to the publisher with a token fee for postage and duplication, for which they would be sent a set of single-sided discs containing the full software complement. This scheme was also operated by some producers of productivity software in later years, mirroring the PC situation where software would ship by default on a particular disc format (3.5" or 5.25", double or high density) and a customer who bought the wrong type could have it replaced by mail order.
Another early sticking point with the ST's floppy drives was that, whilst double-sided drive equipped STs could happily read discs formatted under MS-DOS on IBM PCs, PCs could not themselves read Atari disks, because the initial versions of TOS could recognise, read, and write to - but not themselves create - discs in the same particular specification used and indeed demanded by MS-DOS (single-sided Atari drives were completely incompatible in either direction, as MS-DOS never officially supported single-sided 3.5" hardware, and still placed its filesystem information on "side 0"). Achieving successful data interchange between the two platforms using floppies thus required pre-formatting dedicated file transfer discs under MS-DOS, and copying the necessary data onto them from any unsuitable Atari formatted discs. This formatting issue was soon resolved by the emergence of third-party formatting and file copier software, MS-DOS disc imaging software capable of reading the unusual formats used by the ST and various other machines (such as the Commodore Amiga) and, a few years later, Atari's own version 1.4 (and later) TOS upgrades.
STF and STFM models.
Atari later upgraded the basic design in 1986 with the "1040STF" (also written "STF"). The machine is generally similar to the earlier 520ST, but moved the power supply and a double-sided floppy drive into the rear of the housing of the computer, as opposed to being external. This added to the size of the machine, but reduced cable clutter in the back. However, the joystick/mouse ports, formerly on the right side of the machine where the disk now sat, had to be moved to an awkward location in a cramped niche underneath the keyboard.
The "1040ST" was the first personal computer shipped with a base RAM configuration of 1 MB. When the list price was reduced to $999 in the U.S. it appeared on the cover of "BYTE" in March 1986 as the first computer to break the $1000/megabyte price barrier; "Compute" noted that, in fact, the "1040ST" was the first computer to break the $2500/megabyte price barrier. However, the ST remained generally the same internally over the majority of its several-year lifespan. The choice of model numbers was inherited from the model numbers of the "XE series" of the Atari 8-bit family of computers. A limited number of 1040STFs shipped with a single-sided floppy drive.
The same basic design was also used for a cut-down version, the 512 kB "520STFM", which replaced the earlier 520ST models in the market. The early 'STF' machines lack the 'M' modulator that allows a TV to be used and will only work with a monitor.
Mega models.
Initial sales were strong, especially in Europe where Atari sold 75% of its computers. Germany became Atari's strongest market, with small business users using them for desktop publishing and CAD.
To address this growing market segment, Atari came up with the "ST1". Debuted at Comdex in 1986, it was received favorably. Renamed the "Mega", this new machine includes a high-quality detached keyboard, a stronger case to support the weight of a monitor, and an internal bus expansion connector. A 20 MB hard drive called the SH204 could be purchased as an option and stacked below or above the main case of the Mega. The upcoming SLM804 laser printer would not come with a processor or memory, reducing costs. It would attach to the Mega through the ST DMA port and require the Mega computer to render the pages. As TOS was not a multitasking OS, this meant the computer could not be used while printing. Initially equipped with 2 or 4 MB (a 1 MB version, the "Mega 1" would later follow), the Mega machines would complement the Atari laser printer for a low-cost desktop publishing package, which received acclaim and was featured on the cover of Computer Shopper magazine.
A custom blitter co-processor was to be included to speed the performance of some graphics operations on the screen, but due to delays it was eventually released on the "Mega 2" and "Mega 4" machines. Developers wanting to use it had to detect for it in their programs because it was not present on all machines. However, properly written programs using the screen VDI commands can use the blitter seamlessly, since GEM API is a higher-level interface to "TOS".
Later models.
For about the first four years, no major design changes in the ST platform took place, as Atari focused on manufacturing problems and distribution.
STE models.
In late 1989, Atari released the "520STE" and "1040STE" (also written "STE"), enhanced version of the ST with improvements to the multimedia hardware and operating system. It features an increased color palette of 4096 colors from the ST's 512 (though the maximum displayable palette of these without programming tricks is still limited to 16 in the lowest 320x200 resolution, and even fewer in higher resolutions), Genlock support, and a graphics co-processor chip called Blitter, which can quickly move large blocks of data (most particularly, graphics sprites) around in RAM. It also includes a new 2-channels digital sound chip that could play 8-bit stereo samples in hardware at up to 50 kHz. Two enhanced joystick ports (EJP) were added (two normal joysticks can be plugged into each port with an adaptor), with the new connectors placed in more easily accessed locations on the side of the case. The enhanced joystick ports were re-used in Atari's Jaguar console, and are compatible. RAM was now much more simply upgradable via SIMMs. Despite all of this, it still runs at 8 MHz.
The STE models initially had software and hardware conflicts resulting in some applications and video games written for the ST line being unstable or even completely unusable, primarily caused by programming direct hardware calls which bypassed the operating system. Sometimes incompatibility could be solved by expanding the RAM. Furthermore, even having a joystick plugged in would sometimes cause strange behavior with a few applications (such as the WYSIWYG word-processor application First Word Plus).
The STE was the first Atari with PCM audio, which was probably one of the most attractive features of the machine. It has the ability to play back 8-bit (signed) samples using the SDMA at the following frequencies: 6258 Hz, 12517 Hz, 25033 Hz and 50066 Hz—sampling frequencies above audio CDs, although, the resolution is still only 8 bit. The channels are arranged as either a mono track or a track of LRLRLRLR... bytes.
Very little use was made of the extra features of the STE: STE-enhanced and STE-only software were rare, generally being limited to serious art-, CAD-, or music applications, with very few games taking advantage of the hardware, since it is found on so few machines.
The last STE machine, the "Mega STE", is an STE in a grey Atari TT case that had a switchable 16 MHz, dual-bus design (16-bit external, 32-bit internal), optional Motorola 68881 FPU, built-in 3½" floppy disk drive, VME expansion slot, a network port (very similar to that used by Apple's LocalTalk) and an optional built-in 3½" hard drive. It also shipped with TOS 2.00 (better support for hard drives, enhanced desktop interface, memory test, 1.44 MB floppy support, bug fixes). It was marketed as more affordable than a TT but more powerful than an ordinary ST.
Atari TT.
In 1990, Atari released the high-end workstation-oriented "Atari TT030", based on a 32 MHz Motorola 68030 processor. The "TT" name ("Thirty-two/Thirty-two") continued the nomenclature system as the 68030 chip had full 32-bit wide buses both internally and externally. Originally planned with a 68020 CPU, the TT included improved graphics and more powerful support chips. The case was a new design with an integrated hard-drive enclosure.
Atari Falcon.
The final ST computer is the multimedia-capable "Atari Falcon030". Like the TT, this was also 68030-based, operating at 16 MHz, but with improved video modes and an on-board Motorola 56001 audio digital signal processor. The Falcon, like the Atari STE, supports sampling frequencies above 44.1 kHz; the sampling master clock is 98340 Hz, which can be divided by a number between 2 and 16 to get the actual sampling frequencies. Apart from these frequencies, it is also able to play the STE sample frequencies (up to 50066 Hz) in 8 or 16 bit, mono/stereo, all by using the same DMA interface as the STE, with a few additions. The Falcon can both play back and record samples; it has 8 mono channels / 4 stereo channels; thus this allowed musicians to use the computer for harddisk recording. Although the 68030 microprocessor is capable of using 32-bit memory, the Falcon uses a 16-bit bus which affects performance, but also served to reduce its cost. In another cost-reduction measure, Atari shipped the Falcon in an inexpensive case much like that of the STF and STE. Aftermarket upgrade kits were available that allowed the Falcon to be put in a desktop or rack-mount case, with the keyboard separate.
Released in 1992, the Falcon was discontinued by Atari the following year. In Europe, C-Lab licenced the Falcon design from Atari, and released the C-Lab Falcon Mk I (the same as Atari's Falcon except for some slight modifications to the audio circuitry), Mk II (as Mk I but with an internal 500 MB SCSI hard disk) and Mk X (as Mk II but in a desktop case).
Aftermath.
In 1993, Atari ceased development on the ST computers to focus on the Jaguar.
Following the exit of Atari from the computer market, Medusa Computer Systems manufactured some powerful 3rd-party Atari Falcon/TT-compatible machines that used 68040 and 68060 processors, based on multimedia (particularly audio, but also video), CAD, and office uses.
Despite the lack of a hardware supplier, there is a small active community dedicated to keeping the ST platform alive. There have been advancements in the operating system, software emulators (for Windows, Mac, & Linux), and some hardware developments. There are accelerator cards, such as the CT60 & CT63, which is a 68060 based accelerator card for the Falcon, and there is the Atari Coldfire Project, which aims at developing an Atari-clone based on the Coldfire processor. Milan Computer of Germany also made 68040 and 68060-based Atari clones that can run either Atari TOS 4.5 or Milan Computer's MultiTOS operating system.
Software.
As with the Atari 8-bit computers, software publishers attributed their reluctance to produce Atari ST products in part to—as "Compute!" reported in 1988—the belief in the existence of a "higher-than-normal amount of software piracy". That year WordPerfect threatened to discontinue the Atari ST version of its word processor because the company discovered that pirate bulletin board systems (BBSs) were distributing it, causing "ST-Log" to warn that "we had better put a stop to piracy "now" ... it can have harmful effects on the longevity and health of your computer". In 1989 magazines published a letter by Gilman Louie, head of Spectrum Holobyte. He stated that he had been warned by competitors that releasing a game like "Falcon" on the ST would fail because BBSs would widely disseminate it. Within 30 days of releasing the non-copy protected ST version, the game was available on BBSs with maps and code wheels. Because the ST market was smaller than that for the IBM PC it was more vulnerable to piracy which, Louie said, seemed to be better organized and more widely accepted for the ST. He reported that the Amiga version sold in six weeks twice as much as the ST version in nine weeks, and that the Mac and PC versions had four times the sales. "Computer Gaming World" stated "This is certainly the clearest exposition ... we have seen to date" of why software companies produced less software for the ST than for other computers.
Music and sound.
The ST has built-in MIDI ports, and there was plenty of MIDI-related software for use professionally in music studios, or by amateur enthusiasts. The popular Windows/Macintosh applications "Cubase" and "Logic Pro" originated on the Atari ST (the latter as "Notator Logic", preceded by "Creator", "Notator" and "Notator-SL"). Another popular and powerful ST music sequencer application, Dr. T's "KCS", contains a "Multi-Program Environment" that allows ST users to run other applications, such as the synthesizer patch editing software XoR (now known as Unisyn on the Macintosh), from within the sequencer application.
Music tracker software was popular on the ST, such as the "TCB Tracker", aiding the production of quality music from the Yamaha synthesizer ('chiptunes').
An innovative music composition program that combines the sample playing abilities of a tracker with conventional music notation (which was usually only found in MIDI software) is called "Quartet" (after its 4-note polyphonic tracker, which displays one monophonic stave at a time on color screens).
Due to the ST having comparatively large amounts of memory for the time, sound sampling packages became a realistic proposition. The Microdeal Replay Professional product features a sound sampler that cleverly uses the ST cartridge port to read in parallel from the cartridge port from the ADC. For output of digital sound, it uses the on-board frequency output, sets it to 128 kHz (inaudible) and then modulates the amplitude of that.
Another program that had good success on the ST platform is "MasterTracks Pro" from Passport Designs, of Half Moon Bay, CA., that was first put out by Don Williams for the Macintosh. When the ST died, a PC version continued that one could port MIDI to using the generic .MID format. GVox bought out Passport, and continues the program for Windows and Mac OS along with the other Passport product, the notation program "Encore".
In addition to the sound-sampling functionalities, the availability of software packages with MIDI support for music composition and efficient sound analysis contributed to make the Atari ST a forerunner of later computer-based all-in-one studios.
The ST's low cost, built-in MIDI ports, and fast, low-latency response times made it a favorite with musicians:
Applications.
Also popular on the ST was professional desktop publishing software, such as "PageStream" and "Calamus"; office tools such as word processors ("WordPerfect", "Microsoft Write", "AtariWorks", "WordWriter ST", First Word and its Plus continuation, and others); spreadsheets ("3D-Calc", "LDW Power", "LDW Power 2", "LOGiSTiX Senior", "PowerLedger ST", "SwiftCalc ST", "VIP Professional", and others); turnkey programs ("Mail-Pro", "Sales-Pro 6", "Video-Pro", and others); database programs ("A-Calc Prime", "Data Manager", "Data Manager Professional", "DBMan V", "Base Two", "H&DBase", "Informer II", "DB Master One", "SBT Database Accounting Library" ("dLedger", "dInvoice", "dOrder", "dPurchases", and "dPayables)", "Superbase Personal", "Superbase Professional", "Tracker ST", and others); and various CAD and CAM tools from amateur hobbyist to professional grade (Campus CAD, DynaCADD, Leonard ST, Technobox CAD/2...): all being largely targeted at, or even limited to owners of high-resolution monochrome monitors.
Graphics programs such as "NEOchrome", Degas & Degas Elite, "Canvas", "Deluxe Paint", and "Cyber Paint" (which author Jim Kent would later evolve into "Autodesk Animator") featured advanced features such as 3D design and animation. One paint program, "Spectrum 512", uses the ST's rapid palette switching ability to expand the maximum number of colors to be displayed on-screen at once to 512 (up to 46 in each scan line — the STE never had a Spectrum4096, but other more minor applications filled this speciality niche, one even going so far as to program the shifter chip to palette shift at a rate enabling a display of 19200 colors).
3D computer graphics applications (like "Cyber Studio"s "CAD-3D", which author Tom Hudson would later develop into Autodesk "3D Studio"), brought 3D modelling, sculpting, scripting, and most important, computer animation (using delta-compression) to the desktop. Video-capture and -editing applications using special video-capture 'dongles' connected using the cartridge port — low frame rate, mainly silent and monochrome, but progressing to sound and basic color (in still frames) by the end of the machine's life. At the end, Spectrum 512 and CAD-3D teamed up to produce realistic 512-color textured 3D renderings, but processing was slow, and Atari's failure to deliver a machine with a math coprocessor had Hudson and Yost looking towards the PC as the future before a finished product could be delivered to the consumer.
The Atari ST was the computer upon which today's prevalent graphical touchscreen point of sale software for restaurants was originally developed. This software was created by Gene Mosher under the ViewTouch copyright and trademark. It does not feature the Atari ST's GEM graphical user interface but, instead, features an application specific graphical user interface and widget framework which he developed using, in part, the Neochrome paint program.
Software development.
The Atari ST has a wide variety of languages and tools for development. 68000 assemblers (MadMac from Atari Corp, HiSoft Systems's Devpac, TurboAss, GFA-Assembler), Pascal (OSS Personal Pascal, Maxon Pascal, PurePascal), Modula-2, C compilers (like Turbo C (Borland), Alcyon C, Lattice C, Megamax C, Mark Williams C, GNU C, Aztec C, AHCC (A Home Cooked C)), LISP, Prolog, Logo, and many others.
The initial development kit from Atari included a computer and manuals. At $5,000, this discouraged many from developing software for the ST. Later, the Atari Developer's Kit consisted of software and manuals (no hardware) for $300. Included with the kit were a resource kit, C compiler (first Alcyon C, then Mark Williams C), debugger, and 68000 assembler (plus the non-disclosure agreement).
The ST came bundled with a system disk that contained "ST BASIC", the first BASIC for the ST. However, due to its poor performance, users favored other BASICs, such as "GFA BASIC", FaST BASIC (notable for being one of the few programs to actually be supplied as a ROM cartridge instead of on disc), and the relatively famous "STOS", which then inspired and led to the creation of AMOS on the Amiga, and powerful enough that it was used (with a compiler, opposed to its usual runtime interpreter) for the production of at least two commercial titles and an innumerable host of good quality shareware and public domain games. In the late years of the Atari ST Omikron Basic was bundled with it in Germany.
Even novelty tools such as "SEUCK" were available.
Games.
The ST enjoyed success in gaming due to low cost, fast performance and colorful graphics.
Notable individuals who developed games on the ST include Peter Molyneux, Doug Bell, Jeff Minter, Éric Chahi, Jez San, and David Braben. An early real-time 3D role-playing video game, "Dungeon Master", was first developed and released on the ST, and was the best-selling software ever produced for the platform. Simulation games like "Falcon" and "Flight Simulator II" made use of the enhanced graphics found in the ST machines, as did many arcade ports. One game, MIDI Maze, uses the MIDI ports to connect up to 16 machines for interactive networked play, this is sometimes said to have inspired modern LAN games which became popular in the early 90s. Games simultaneously released on the Amiga that had identical graphics and sound were often accused by video game magazines of simply being ST ports. The reason for these accusations is because these games do not utilise the Amiga's ability to produce superior graphics and sound. The critically acclaimed game Another World was originally released for ST and Amiga in 1991 (but developed on Amiga though).
Garry Kasparov became the first player to register the commercial ChessBase, a popular commercial database program produced for storing and searching records of games of chess. The first version was built for Atari ST with his collaboration in January 1987. In his autobiography "Child of Change", he regards this facility as "the most important development in chess research since printing".
Utilities.
Utility software was available to drive hardware add-ons such as video digitisers. Office Productivity and graphics software was also bundled with the ST (HyperPaint II by Dimitri Koveos, HyperDraw by David Farmborough, 3D-Calc spreadsheet by Frank Schoonjans, and several others commissioned by Bob Katz, later of Electronic Arts).
There was a thriving output of public domain and shareware software which was distributed by, in the days long before public internet access, public domain software libraries that advertised in magazines and on popular dial-up bulletin board systems.
Remarkably, a modest core fanbase for the system, supporting a dwindling number of good quality print magazines, survived to the mid-'90s and the birth of the modern, publicly accessible Internet as we know it. Despite the limited graphics, memory, and temporary hard-storage capabilities of the system, several email, FTP, telnet, IRC, and even full-blown graphical World Wide Web browser applications were available and usable on the ST.
There were also DOS emulators released in the late 80s. "PC-Ditto" came in two versions, software-only-, and a hardware version that plugs into the cartridge slot or kludges internally. After running the PC-Ditto software, a DOS boot disk is required to load the system. Both allow users to run DOS programs in CGA mode, though much more slowly than on an IBM PC. Other options are the "PC-Speed" (NEC V30), "AT-Speed" (Intel 80286) and "ATonce-386SX" (Intel 80386sx) hardware emulator boards.
Technical specifications.
All STs are made up of both custom and commercial chips:
ST/STF/STM/STFM.
As originally released in the "520ST":
Very early machines included the OS on a floppy disk due to it not being ready to be burned to ROM (like the Amiga 1000 had). This early version of TOS was bootstrapped from a very small core boot ROM, but this was quickly replaced with (expanded capacity) ROM versions of TOS 1.0 when it was ready. (This change was also greatly welcomed as older ST machines with memory below 512 kB suffered, as GEM loaded its entire 192 kB code into RAM when booting the desktop). Having the OS loaded from disk was due to Atari trying to rush the machines to market without ironing out all the bugs in the OS. Soon after this change, most production models became STFs, with an integrated single- (520STF/512 kB RAM) or double-sided (1040STF/1024 kB RAM) double density floppy disk drive built-in, but no other changes. The next later models used an upgraded version of TOS: 1.02 (also known as TOS 1.2). Another early addition (after about 6 months) was an RF Modulator that allows the machine to be hooked to a color TV when run in its low or medium resolution (525/625 line 60/50 Hz interlace, even on RGB monitors) modes, greatly enhancing the machine's saleability and perceived value (no need to buy a prohibitively expensive, even if exceptionally crisp and clear, monitor). These models were known as the "520STM" (or "520STM"). Later "F" and "FM" models of the 520 had a built in double-sided disk drive instead of a single-sided one.
STE.
As originally released in the "520STE/1040STE":
Models.
The members of the ST family are listed below, in rough chronological order:
Related systems.
There were also some unreleased prototypes: Falcon 040 (based on a Motorola 68040, new case and slots), ST Pad/STylus (A4 (Letter paper) sized pen-operated portable ST computer, handheld and with an unlit monochrome LCD screen derived from the ST Book, forerunner of modern tablet PCs).

</doc>
<doc id="2142" url="http://en.wikipedia.org/wiki?curid=2142" title="List of artificial intelligence projects">
List of artificial intelligence projects

The following is a list of current and past, nonclassified notable artificial intelligence projects.

</doc>
<doc id="2144" url="http://en.wikipedia.org/wiki?curid=2144" title="Aaliyah">
Aaliyah

Aaliyah Dana Haughton () (January 16, 1979 – August 25, 2001) was an American singer, dancer, actress, and model. She was born in Brooklyn, New York, and raised in Detroit, Michigan. At the age of 10, she appeared on the television show "Star Search" and performed in concert alongside Gladys Knight. At age 12, Aaliyah signed with Jive Records and her uncle Barry Hankerson's Blackground Records. Hankerson introduced her to R. Kelly, who became her mentor, as well as lead songwriter and producer of her debut album, "Age Ain't Nothing but a Number". The album sold three million copies in the United States and was certified double platinum by the Recording Industry Association of America (RIAA). After facing allegations of an illegal marriage with R. Kelly, Aaliyah ended her contract with Jive and signed with Atlantic Records.
Aaliyah worked with record producers Timbaland and Missy Elliott for her second album, "One in a Million"; it sold 3.7 million copies in the United States and over eight million copies worldwide. In 2000, Aaliyah appeared in her first major film, "Romeo Must Die". She contributed to the film's soundtrack, which spawned the single "Try Again". The song topped the "Billboard" Hot 100 solely on airplay, making Aaliyah the first artist in "Billboard" history to achieve this feat. "Try Again" earned Aaliyah a Grammy Award nomination for Best Female R&B Vocalist. After completing "Romeo Must Die", Aaliyah filmed her part in "Queen of the Damned". She released her third and final album, "Aaliyah", in July 2001.
On August 25, 2001, Aaliyah and eight others were killed in a plane crash in The Bahamas after filming the music video for the single "Rock the Boat". The pilot, Luis Morales III, was unlicensed at the time of the accident and had traces of cocaine and alcohol in his system. Aaliyah's family later filed a wrongful death lawsuit against Blackhawk International Airways, which was settled out of court. Aaliyah's music has continued to achieve commercial success with several posthumous releases. Aaliyah sold 52 million records worldwide. She has been credited for helping redefine contemporary R&B and hip hop, earning her the nicknames "Princess of R&B" and "Queen of Urban Pop". She is listed by "Billboard" as the tenth most successful female R&B artist of the past 25 years and 27th most successful R&B artist in history.
Life and career.
1979–91: Early life and career beginnings.
Aaliyah Dana Haughton was born on January 16, 1979, in Brooklyn, New York. She had African and Oneida heritage, and was the younger child of Diane and Michael Haughton. Her name was the female version of "Ali" and in Arabic meant "highest, most exalted one, the best." Aaliyah really liked her name, calling it "beautiful" and expressing that she was "very proud of it". For her entire life, Aaliyah tried living up to her name every day. At a young age, Aaliyah was enrolled in voice lessons by her mother. She started performing at weddings, church choir and charity events. When she was five years old, her family moved to Detroit, Michigan, where she was raised along with her older brother, Rashad. She attended a Catholic school, Gesu Elementary, where in first grade, she received a part in the stage play "Annie". From then on, she was determined to become an entertainer. In Detroit, her father began working in the warehouse business, one of his brother-in-law Barry Hankerson's widening interests. Her mother stayed home and raised Aaliyah and her brother.
Throughout her life, she had a good relationship with her brother, which traced back to their childhood as Rashad reflected that growing up with Aaliyah was "amazing". He recalled her running around their home singing and that never being annoying due to her having a "beautiful voice". She and her brother became close with their cousin Jomo Hankerson, since growing up, they lived "about five blocks apart". Jomo walked Aaliyah and Rashad to their home from school when their mother was not able to pick them up and recalled the Haughton household being filled with music. Aaliyah's family was very close due to the struggles of her grandparents and when the Haughtons moved to Detroit, the Hankersons were ready to take them in if necessary. These same bonds led to ties in the music industry, under the Blackground Records label.
Aaliyah's mother was a vocalist, and her uncle, Barry Hankerson, was an entertainment lawyer who had been married to Gladys Knight. As a child, Aaliyah traveled with Knight and worked with an agent in New York to audition for commercials and television programs, including "Family Matters"; she went on to appear on "Star Search" at the age of ten. Aaliyah chose to begin auditioning while her mother made the decision to have her surname dropped. She auditioned for several record labels and at age 11 appeared in concerts alongside Knight. She had several pet animals in during her childhood, which included ducks, snakes and iguanas. Her cousin Jomo had a pet alligator, which Aaliyah felt was too much, remarking, "that was something I wasn't going to stroke."
Her grandmother died in 1991. Years after her death, Aaliyah said her grandmother supported everyone in the family and always wanted to hear her sing, as well as admitting that she "spoiled" her and her brother Rashad "to death." She also enjoyed Aaliyah's singing and would have Aaliyah to sing for her. Aaliyah stated that she thought of her grandmother whenever she fell into depression. Aaliyah's hands reminded her of her aunt, who died when she was "very young" and Aaliyah referred to her as an "amazingly beautiful woman".
Aaliyah attended Detroit schools growing up and believed she was well-liked, but got teased for her short stature. She recalled coming into her own prior to age 15 and grew to love her height. Her mother would tell her to be happy that she was small and compliment her. Other children disliked Aaliyah, but she did not stay focused on them. "You always have to deal with people who are jealous, but there were so few it didn't even matter. The majority of kids supported me, which was wonderful. When it comes to dealing with negative people, I just let it in one ear and out the other. Those people were invisible to me." Even in her adult life, she considered herself small. She had "learned to accept and love" herself and added: "...the most important thing is to think highly of yourself because if you don't, no one else will".
Aaliyah, who maintained a perfect 4.0 grade point average when graduating from Detroit High School for the Fine and Performing Arts, felt education was important. She saw fit to keep her grades up despite the pressures and time constraints brought on her during the early parts of her career. She labeled herself as a perfectionist and recalled always being a good student. Aaliyah reflected: "I always wanted to maintain that, even in high school when I first started to travel. I wanted to keep that 4.0. Being in the industry, you know, I don't want kids to think, 'I can just sing and forget about school.' I think it's very important to have an education, and even more important to have something to fall back on." She did this in her own life, as she planned to "fall back on" another part of the entertainment industry. She believed that if she could teach music history or open her own school to teach that or drama if she did not not make a living as a recording artist because, as she reasoned, "when you pick a career it has to something you love".
1991–95: "Age Ain't Nothing but a Number".
After Hankerson signed a distribution deal with Jive Records, he signed Aaliyah to his Blackground Records label at the age of 12. Hankerson later introduced her to recording artist and producer R. Kelly, who became Aaliyah's mentor, as well as lead songwriter and producer of the album, which was recorded when she was 14. Aaliyah's debut album, "Age Ain't Nothing but a Number", was released under Jive and Blackground Records; the album debut at number 24 on the "Billboard" 200 chart, selling 74,000 copies in its first week. It ultimately peaked at number 18 on the "Billboard" 200 and sold over three million copies in the United States, where it was certified two times Platinum by the RIAA. In Canada, the album sold over 50,000 copies and was certified gold by the CRIA. Aaliyah's debut single, "Back & Forth", topped the "Billboard" Hot R&B/Hip-Hop Songs chart for three weeks and was certified Gold by the RIAA. The second single, a cover of The Isley Brothers' "At Your Best (You Are Love)", peaked at number six on the "Billboard" Hot 100 and was also certified Gold by the RIAA. The title track, "Age Ain't Nothing but a Number", peaked at number 75 on the Hot 100. Additionally, she released "The Thing I Like" as part of the soundtrack to the 1994 film "A Low Down Dirty Shame".
"Age Ain't Nothing But a Number" received generally favorable reviews from music critics. Some writers noted that Aaliyah's "silky vocals" and "sultry voice" blended with Kelly's new jack swing helped define R&B in the 1990s. Her sound was also compared to that of female quartet En Vogue. Christopher John Farley of "Time" magazine described the album as a "beautifully restrained work", noting that Aaliyah's "girlish, breathy vocals rode calmly on R. Kelly's rough beats". Stephen Thomas Erlewine of AllMusic felt that the album had its "share of filler", but described the singles as "slyly seductive". He also claimed that the songs on the album were "frequently better" than that of Kelly's second studio album, "12 Play". The single "At Your Best (You Are Love)" was criticized by "Billboard" for being out of place on the album and for its length.
1996–99: "One in a Million".
In 1996, Aaliyah left Jive Records and signed with Atlantic Records. She worked with record producers Timbaland and Missy Elliott, who contributed to her second studio album, "One in a Million". Missy Elliott recalled Timbaland and herself being nervous to work with Aaliyah, since Aaliyah had already released her successful debut album while Missy Elliott and Timbaland were just starting out. Missy Elliott also feared she would be a diva, but reflected that Aaliyah "came in and was so warming; she made us immediately feel like family.”
The album yielded the single "If Your Girl Only Knew", which topped the "Billboard" Hot R&B/Hip-Hop Songs for two weeks. It also generated the singles "Hot Like Fire" and "4 Page Letter". The following year, Aaliyah was featured on Timbaland & Magoo's debut single, "Up Jumps da Boogie". "One in a Million" peaked at number 18 on the "Billboard" 200, selling over 3.7 million copies in the United States and over eight million copies worldwide.
The album was certified double platinum by the RIAA on June 16, 1997, denoting shipments of two million copies. The month prior to "One in a Million"'s release, on May 5, 1997, music publisher Windswept Pacific filed a lawsuit in U.S. District Court against Aaliyah claiming she had illegally copied Bobby Caldwell's "What You Won't Do for Love" for the single "Age Ain't Nothing but a Number".
Aaliyah attended the Detroit High School for the Fine and Performing Arts, where she majored in drama and graduated in 1997. Aaliyah began her acting career that same year; she played herself in the police drama television series "New York Undercover". During this time, Aaliyah participated in the Children's Benefit Concert, a charity concert that took place at the Beacon Theatre in New York. Aaliyah also became the spokesperson for Tommy Hilfiger Corporation. She contributed on the soundtrack album for the Fox Animation Studios animated feature "Anastasia", performing a cover version of "Journey to the Past" which earned songwriters Lynn Ahrens and Stephen Flaherty a nomination for the Academy Award for Best Original Song. Aaliyah performed the song at the 1998 Academy Awards ceremony and became the youngest singer to perform at the event. The song "Are You That Somebody?" was featured on the "Dr. Dolittle" soundtrack, which earned Aaliyah her first Grammy Award nomination. The song peaked at number 21 on the Hot 100.
2000–01: Acting and self-titled album.
In 2000, Aaliyah landed her first major movie role in "Romeo Must Die". Aaliyah starred opposite martial artist Jet Li, playing a couple who fall in love amid their warring families. It grossed US$18.6 million in its first weekend, ranking number two at the box office. Aaliyah purposely stayed away from reviews of the film to "make it easier on" herself, but she heard "that people were able to get into me, which is what I wanted." In addition to acting, Aaliyah served as an executive producer of the film soundtrack, where she contributed four songs. "Try Again" was released as a single from the soundtrack; the song topped the "Billboard" Hot 100, making Aaliyah the first artist to top the chart based solely on airplay; this led the song to be released in a 12" vinyl and 7" single. The music video won the Best Female Video and Best Video from a Film awards at the 2000 MTV Video Music Awards. It also earned her a Grammy Award nomination for Best Female R&B Vocalist. The soundtrack went on to sell 1.5 million copies in the United States. After completing "Romeo Must Die", Aaliyah began to work on her second film, "Queen of the Damned". She played the role of an ancient vampire, Queen Akasha, which she described as a "manipulative, crazy, sexual being". Prior to her death, she expressed the possibility of recording songs for the film's soundtrack and welcomed the possibility of collaborating with Jonathan Davis. She was scheduled to film for the sequels of "The Matrix" as the character Zee.
In May 2001, Shaquille O'Neal admitted that his remarks where he claimed to have engaged in sexual intercourse with Aaliyah, Cindy Crawford and Venus Williams were false after making the allegations during an appearance on a radio station and apologized to the three. All three denied the claims. The following month, June 2001, Aaliyah posed for a photo shoot with Eric Johnson. Johnson kept the images in his "private personal archive" for thirteen years before providing digital copies of 13 Aaliyah photographs to an online photography magazine and authorizing the publication to use the photographs for a story they were doing on Aaliyah. Not long after, he filed a lawsuit claiming ABC had infringed his rights since the corporation authorized further reproduction by reproducing them online.
Aaliyah released her self-titled album, "Aaliyah", in July 2001. It debuted at number two on the "Billboard" 200, selling 187,000 copies in its first week. The first single from the album, "We Need a Resolution", peaked at number 59 on the "Billboard" Hot 100. She finished recording the album in March 2001 after a year of recording tracks that began in March of the previous year. At the time she started recording the album, Aaliyah's publicist disclosed the album's release date as most likely being in October 2000.
Filming for "Queen of the Damned" delayed the release of "Aaliyah". Aaliyah enjoyed balancing her singing and acting careers. Though she called music a "first" for her, she also had been acting since she was young and had wanted to begin acting "at some point in my career," but "wanted it to be the right time and the right vehicle" and felt "Romeo Must Die" "was it".
"Aaliyah" was released five years after "One in a Million". Aaliyah had not intended for the albums to have such a gap between them. "I wanted to take a break after "One in a Million" to just relax, think about how I wanted to approach the next album. Then, when I was ready to start back up, “Romeo” happened, and so I had to take another break and do that film and then do the soundtrack, then promote it. The break turned into a longer break than I anticipated." Connie Johnson of the "Los Angeles Times" argued that Aaliyah having to focus on her film career may have caused her to not give the album "the attention it merited."
The week after Aaliyah's death, her third studio album, "Aaliyah", rose from number 19 to number one on the "Billboard" 200. "Rock the Boat" was released as a posthumous single. The music video premiered on BET's "Access Granted"; it became the most viewed and highest rated episode in the history of the show. The song peaked at number 14 on the "Billboard" Hot 100 and number two on the "Billboard" Hot R&B/Hip-Hop Songs chart. It was also included on the "Now That's What I Call Music! 8" compilation series; a portion of the album's profits was donated to the Aaliyah Memorial Fund. Promotional posters for "Aaliyah" that had been put up in major cities such as New York and Los Angeles became makeshift memorials for grieving fans.
"More than a Woman" and "I Care 4 U" were released as posthumuous singles and peaked within the top 25 of the "Billboard" Hot 100. The album was certified double Platinum by the RIAA and sold 2.95 million copies in the United States. "More than a Woman" reached number one on the UK singles chart making Aaliyah the first deceased artist to reach number one on the UK singles chart. "More than a Woman" was replaced by George Harrison's "My Sweet Lord" which is the only time in the UK singles chart's history where a dead artist has replaced another dead artist at number one. In July 2001, she allowed MTV's show "Diary" behind-the-scenes access to her life and stated "I am truly blessed to wake up every morning to do something that I love; there is nothing better than that." She continued, "Everything is worth it -- the hard work, the times when you're tired, the times when you are a bit sad. In the end, it's all worth it because it really makes me happy. I wouldn't trade it for anything else in the world. I've got good friends, a beautiful family and I've got a career. I thank God for his blessings every single chance I get."
Aaliyah was signed to appear in several future films, including "Honey", a romantic film titled "Some Kind of Blue", and a Whitney Houston-produced remake of the 1976 film "Sparkle". Whitney Houston recalled Aaliyah being "so enthusiastic" about the film and wanting to appear in the film "so badly". Houston also voiced her belief that Aaliyah was more than qualified for the role and the film was shelved after she died, since Aaliyah had "gone to a better place". Studio officials of Warner Brothers stated that Aaliyah and her mother had both read the script for "Sparkle". According to them, Aaliyah was passionate about playing the lead role of a young singer in a girl group.
The film was released in 2012, eleven years after Aaliyah's death. Before her death, Aaliyah had filmed part of her role in "The Matrix Reloaded" and was scheduled to appear in "The Matrix Revolutions" as Zee. Aaliyah told "Access Hollywood" that she was "beyond happy" to have landed the role.
The role was subsequently recast to Nona Gaye. Aaliyah's scenes were included in the tribute section of the "Matrix Ultimate Collection" series.
Artistry.
Voice and style.
Aaliyah had the vocal range of a soprano. With the release of her debut single "Back & Forth", Dimitri Ehrlich of "Entertainment Weekly" expressed that Aaliyah's "silky vocals are more agile than those of self-proclaimed queen of hip-hop soul Mary J. Blige." Aaliyah described her sound as "street but sweet", which featured her "gentle" vocals over a "hard" beat. Though Aaliyah did not write any of her own material, her lyrics were described as in-depth. She incorporated R&B, pop and hip hop into her music. Her songs were often uptempo and at the same time often dark, revolving around "matters of the heart". After her R. Kelly-produced debut album, Aaliyah worked with Timbaland and Missy Elliott, whose productions were more electronic. Sasha Frere-Jones of "The Wire" finds Aaliyah's "Are You That Somebody?" to be Timbaland's "masterpiece" and exemplary of his production's start-stop rhythms, with "big half-second pauses between beats and voices". Keith Harris of "Rolling Stone" cites "Are You That Somebody?" as "one of '90s R&B's most astounding moments".
Aaliyah's songs have been said to have "crisp production" and "staccato arrangements" that "extend genre boundaries" while containing "old-school" soul music. Kelefah Sanneh of "The New York Times" called Aaliyah "a digital diva who wove a spell with ones and zeroes", and writes that her songs comprised "simple vocal riffs, repeated and refracted to echo the manipulated loops that create digital rhythm", as Timbaland's "computer-programmed beats fitted perfectly with her cool, breathy voice to create a new kind of electronic music." When she experimented with other genres on "Aaliyah", such as Latin pop and heavy metal, "Entertainment Weekly"s Craig Seymour panned the attempt. As her albums progressed, writers felt that Aaliyah matured, calling her progress a "declaration of strength and independence". Stephen Thomas Erlewine of AllMusic described her eponymous album, "Aaliyah", as "a statement of maturity and a stunning artistic leap forward" and called it one of the strongest urban soul records of its time. She portrayed "unfamiliar sounds, styles and emotions", but managed to please critics with the contemporary sound it contained. Ernest Hardy of "Rolling Stone" felt that Aaliyah reflected a stronger technique, where she gave her best vocal performance. Prior to her death, Aaliyah expressed a desire to learn about the burgeoning UK garage scene she had heard about at the time.
Influences and image.
As an artist, Aaliyah often voiced that she was inspired by a number of performers. These include Michael Jackson, Stevie Wonder, Sade, En Vogue, Nine Inch Nails, Korn, Prince, Naughty by Nature, Johnny Mathis and Janet Jackson. Aaliyah expressed that Michael Jackson's "Thriller" was her "favorite album" and that "nothing will ever top "Thriller"." She stated that she admired Sade because "she stays true to her style no matter what... she's an amazing artist, an amazing performer... and I absolutely love her." Aaliyah expressed she had always desired to work with Janet Jackson, whom she had drawn frequent comparison to over the course of her career, stating "I admire her a great deal. She's a total performer... I'd love to do a duet with Janet Jackson." Jackson reciprocated Aaliyah's affections, commenting "I've loved her from the beginning because she always comes out and does something different, musically." Jackson also stated she would have enjoyed collaborating with Aaliyah.
Aaliyah focused on her public image throughout her career. She often wore baggy clothes and sunglasses, stating that she wanted to be herself. She described her image as being "important... to differentiate yourself from the rest of the pack". She often wore black clothing, starting a trend for similar fashion among women in United States and Japan. Aaliyah participated in fashion designer Tommy Hilfiger's All America Tour and was featured in Tommy Jean ads, which depicted her in boxer shorts, baggy jeans and a tube top. Hilfiger's brother, Andy, called it "a whole new look" that was "classy but sexy". When she changed her hairstyle, Aaliyah took her mother's advice to cover her left eye, much like Veronica Lake. The look has become known as her signature and been referred to as fusion of "unnerving emotional honesty" and "a sense of mystique". In 1998, she hired a personal trainer to keep in shape, and exercised five days a week and ate diet foods. Aaliyah was praised for her "clean-cut image" and "moral values". Robert Christgau of "The Village Voice" wrote of Aaliyah's artistry and image, "she was lithe and dulcet in a way that signified neither jailbait nor hottie—an ingenue whose selling point was sincerity, not innocence and the obverse it implies." She was also seen as a sex symbol. Aaliyah did not have problem with being considered one. "I know that people think I'm sexy and I am looked at as that, and it is cool with me. It's wonderful to have sex appeal. If you embrace it, it can be a very beautiful thing. I am totally cool with that. Definitely. I see myself as sexy. If you are comfortable with it, it can be very classy and it can be very appealing."
Personal life.
Family.
Aaliyah's father Michael Haughton, who died in 2012, served as her personal manager. Her mother assisted her in her career while brother Rashad Haughton and cousin Jomo Hankerson worked with her consistently. Aaliyah was known to have usually been accompanied by members of her immediate family and the "Rock the Boat" filming was credited by her brother Rashad as being the first and only time her family was not present. In October 2001, Rashad stated: "It really boggles everyone [that] from Day One, every single video she ever shot there's always been myself or my mother or my father there. The circumstances surrounding this last video were really strange because my mother had eye surgery and couldn't fly. That really bothered her because she always traveled. My dad had to take care of my mom at that time. And I went to Australia to visit some friends. We really couldn't understand why we weren't there. You ask yourself maybe we could have stopped it. But you can't really answer the question. There's always gonna be that question of why." Her friend Kidada Jones said in the last year of her life her parents had given her more freedom and she had talked about wanting a family. "She wanted to have a family, and we talked about how we couldn't wait to kick back with our babies."
Illegal marriage.
With the release of "Age Ain't Nothing but a Number", rumors circulated of a relationship between Aaliyah and R. Kelly. Shortly after, there was speculation about a secret marriage with the release of "Age Ain't Nothing but a Number" and the adult content that Kelly had written for Aaliyah. "Vibe" magazine later revealed a marriage certificate that listed the couple married on August 31, 1994, in Sheraton Gateway Suites in Rosemont, Illinois. Aaliyah, who was 15 at the time, was listed as 18 on the certificate; the illegal marriage was annulled in February 1995 by her parents. The pair continued to deny marriage allegations, stating that neither was married.
Aaliyah reportedly developed a friendship with R. Kelly during the recording of her debut album. As she recalled to Vibe magazine in 1994, she and R. Kelly would "go watch a movie" and "go eat" when she got tired and would then "come back and work". She described the relationship between her and R. Kelly as being "rather close." In December 1994, Aaliyah told the "Sun-Times" that whenever she was asked about being married to R. Kelly, she urged them not to believe "all that mess" and that she and R. Kelly were "close" and "people took it the wrong way."
In his 2011 book "The Man Behind the Man: Looking From the Inside Out", Demetrius Smith Sr, a former member of R. Kelly's entourage, wrote that R. Kelly told him "in a voice that sounded as if he wanted to burst into tears" that he thought Aaliyah was pregnant.
Aaliyah admitted in court documents that she had lied about her age. In May 1997, she filed suit in Cook County seeking to have all records of the marriage expunged because she was not old enough under state law to get married without her parents' consent. It was reported that she cut off all professional and personal ties with R. Kelly after the marriage was annulled and ceased having contact with him. In 2014, Jomo Hankerson stated that Aaliyah "got villainized" over her relationship with R. Kelly and the scandal over the marriage made it difficult to find producers for her second album. "We were coming off of a multi-platinum debut album and except for a couple of relationships with Jermaine Dupri and Puffy, it was hard for us to get producers on the album.” Hankerson also expressed confusion over why "they were upset" with Aaliyah given her age at the time.
Aaliyah was known to avoid answering questions regarding R. Kelly following the professional split. During an interview with Christopher John Farley, she was asked if she was still in contact with him and if she would ever work with him again. Farley said Aaliyah responded with a "firm, frosty" 'No' to both of the questions. "Vibe" magazine said Aaliyah changed the subject anytime "you bring up the marriage with her". A spokeswoman for Aaliyah told the "Chicago Sun-Times" in 2000 that when "R. Kelly comes up, she doesn't even speak his name, and nobody's allowed to ask about it at all".
R. Kelly would have other allegations made about him regarding underage girls in the years following her death and his marriage to Aaliyah was used to evidence his involvement with them. He refused to discuss his relationship with her, citing that she was deceased. "Out of respect for her, and her mom and her dad, I will not discuss Aaliyah. That was a whole other situation, a whole other time, it was a whole other thing, and I'm sure that people also know that." Aaliyah's mother Diane Haughton reflected that everything "that went wrong in her life" began with her relationship with R. Kelly. The allegations have been said to have done "little to taint Aaliyah's image or prevent her from becoming a reliable '90s hitmaker with viable sidelines in movies and modeling."
Relationships.
Quincy Jones said she was "like one of my daughters" and Aaliyah vacationed with him and his family in Fiji. She was close friends with his daughter Kidada Jones. By 2001, they had been best friends for five years and Jones described her as having a great sense of humor. Aaliyah and Jones would make prank phone calls to what Aaliyah referred to as "public establishments". At the time of her death, she and Jones were planning on starting a clothing line, benefited by Aaliyah's popularity as a "style-setter" and she sought to capitalize on her good taste. Her brother Rashad called her his best friend and stated that she "was my everything". Beyoncé stated after Aaliyah's death that she was "the very first person to embrace Destiny's Child." Aaliyah met Beyoncé as well as the other members of Destiny's Child around 1998 in Los Angeles. They were intimidated about meeting her, since she had already established herself and they were just making their names at the time.
In addition to working with them, Aaliyah had friendships with Missy Elliott and Timbaland. Aaliyah recalled her first time meeting Missy Elliott. "When we met, there was a bond that was established real quickly. A friendship formed and we built our studio relationship from that." Missy Elliott said in 2010 that "there’s not a day that goes by that I don’t think" of Aaliyah and that she misses her every day.
Missy Elliott said of Aaliyah during an appearance on RapFix Live in November 2012, "Aaliyah, she was like a comedian. She always wanted to laugh." Timbaland admitted in 2011 that he was in love with her, but did not act out on his feelings due to their age difference and determined he would just "be her brother". Despite this declaration, he still struggled with keeping his feelings to himself. Immediately following her death, Timbaland told MTV he considered her as his "little sister" and that he and Aaliyah had a "chemistry" and that he had lost half of his creativity with her death. He also said that fans needed to know that beyond music "she was a brilliant person." Aaliyah's death had a large impact on both of them as they had been her closest collaborators in the last five years of her career and they owed their initial success to her.
Engagement.
Aaliyah was dating co-founder of Roc-A-Fella Records Damon Dash at the time of her death and, though they were not formally engaged, in interviews given after Aaliyah's death Dash claimed the couple had planned to marry. Aaliyah and Dash met through his accountant and formed a friendship. Dash has said he is unsure of how he and Aaliyah started dating and that the two just understood each other. “I don’t know [how we got involved], just spending time, you know, we just saw things the same and it was new, you know what I mean? Meeting someone that is trying to do the same thing you are doing in the urban market, in the same urban market place but not really being so urban. It was just; her mind was where my mind was. She understood me and she got my jokes. She thought my jokes were funny.”
Dash expressed his belief that Aaliyah was the "one" and claimed the pair were not official engaged, but had spoken about getting married prior to her death.
Aaliyah publicly never addressed the relationship between her and Dash as being anything but platonic. In May 2001, she hosted a party for Dash's 30th birthday at a New York City club, where they were spotted together and Dash was seen escorting her to a bathroom. Addressing this, Aaliyah stated that she and Dash were just "very good friends" and chose to "keep it at that" for the time being. Just two weeks before her death, Aaliyah traveled from New Jersey to East Hampton, New York to visit Dash at the summer house he shared with Jay-Z.
Death.
On August 25, 2001, at 6:50 p.m. (EDT), Aaliyah and the members of the record company boarded a twin-engine Cessna 402B (registration N8097W) at the Marsh Harbour Airport in Abaco Islands, The Bahamas, to travel to the Opa-locka Airport in Florida, after they completed filming the music video for "Rock the Boat". They had a flight scheduled the following day, but with filming finishing early, Aaliyah and her entourage were eager to return to the United States and made the decision to leave immediately. The designated airplane was smaller than the Cessna 404 on which they had originally arrived, but the whole party and all of the equipment were accommodated on board. The plane crashed shortly after takeoff, about from the runway.
Aaliyah and the eight others on board—pilot Luis Morales III, hair stylist Eric Forman, Anthony Dodd, security guard Scott Gallin, video producer Douglas Kratz, stylist Christopher Maldonado, and Blackground Records employees Keith Wallace and Gina Smith—were all killed. Gallin survived the initial impact and spent his last moments worrying about Aaliyah's condition, according to ambulance drivers. The plane was identified as being owned by Florida-based company Skystream by Kathleen Bergen, spokeswoman for the US Federal Aviation Administration in Atlanta. Initial reports of the crash identified Luis Morales as "L Marael".
According to findings from an inquest conducted by the coroner's office in The Bahamas, Aaliyah suffered from "severe burns and a blow to the head", in addition to severe shock and a weak heart. The coroner theorized that she went into such a state of shock that even if she had survived the crash, her recovery would have been nearly impossible. The bodies were taken to the morgue at Princess Margaret Hospital in Nassau, where they were kept for relatives to help identify them. Some of the bodies were badly burned in the crash.
As the subsequent investigation determined, when the aircraft attempted to depart, it was over its maximum takeoff weight by and was carrying one excess passenger, according to its certification.
The National Transportation Safety Board (NTSB) report stated that "the airplane was seen lifting off the runway, and then nose down, impacting in a marsh on the south side of the departure end of runway 27 and then exploding in flames." It indicated that the pilot was not approved to fly the plane. Morales falsely obtained his Federal Aviation Administration (FAA) license by showing hundreds of hours never flown, and he may also have falsified how many hours he had flown in order to get a job with his employer, Blackhawk International Airways. Additionally, an autopsy performed on Morales revealed traces of cocaine and alcohol in his system.
Aaliyah's funeral was held on August 31, 2001, at the St. Ignatius Loyola Church in Manhattan. Her body was set in a silver-plated copper-deposit casket, which was carried in a glass hearse and was drawn by horse. An estimated 800 mourners were in attendance at the procession. Among those in attendance at the private ceremony were Missy Elliott, Timbaland, Gladys Knight, Lil' Kim and Sean Combs. After the service, 22 white doves were released to symbolize each year of Aaliyah's life. Aaliyah was interred in a private room at the end of a corridor in the Rosewood Mausoleum at the Ferncliff Cemetery in Hartsdale, New York. The inscription at the bottom of Aaliyah's portrait at the funeral read: "We Were Given a Queen, We Were Given an Angel.”
Posthumous career.
Immediately after Aaliyah's death, there was uncertainty over whether the music video for "Rock the Boat" would ever air. It made its world premiere on BET's "Access Granted" on October 9, 2001. She won two posthumous awards at the American Music Awards of 2002; Favorite Female R&B Artist and Favorite R&B/Soul Album for "Aaliyah". Her second and final film, "Queen of the Damned", was released in February 2002. Before its release, Aaliyah's brother, Rashad, re-dubbed some of her lines during post-production. It grossed US$15.2 million in its first weekend, ranking number one at the box office. On the first anniversary of Aaliyah's death, a candlelight vigil was held in Times Square; millions of fans observed a moment of silence; and throughout the United States, radio stations played her music in remembrance. In December 2002, a collection of previously unreleased material was released as Aaliyah's first posthumous album, "I Care 4 U". A portion of the proceeds was donated to the Aaliyah Memorial Fund, a program that benefits the Revlon UCLA Women's Cancer Research Program and Harlem's Sloan Kettering Cancer Center. It debuted at number three on the "Billboard" 200, selling 280,000 copies in its first week. The album's lead single, "Miss You", peaked at number three on the "Billboard" Hot 100 and topped the Hot R&B/Hip-Hop Songs chart. In August of the following year, clothing retailer Christian Dior donated profits from sales in honor of Aaliyah.
In 2005, Aaliyah's second compilation album, "Ultimate Aaliyah" was released in the UK by Blackground Records. "Ultimate Aaliyah" is a three disc set, which included a greatest hits audio CD and a DVD. Andy Kellman of AllMusic remarked ""Ultimate Aaliyah" adequately represents the shortened career of a tremendous talent who benefited from some of the best songwriting and production work by Timbaland, Missy Elliott, and R. Kelly." A documentary movie "Aaliyah Live in Amsterdam" was released in 2011., shortly before the tenth anniversary of Aaliyah's death. The documentary, by Pogus Caesar, contained previously unseen footage shot of her career beginnings in 1995 when she was appearing in the Netherlands.
In March 2012, music producer Jeffrey "J-Dub" Walker announced on his Twitter account that a song "Steady Ground", which he produced for Aaliyah's third album, would be included in the forthcoming posthumous Aaliyah album. This second proposed posthumous album would feature this song using demo vocals, as Walker claims the originals were somehow lost by his sound engineer. Aaliyah's brother Rashad later refuted Walker's claim, claiming that "no official album [is] being released and supported by the Haughton family."
On August 5, 2012, a song entitled "Enough Said" was released online. The song was produced by Noah "40" Shebib and features Canadian rapper Drake. Four days later, Jomo Hankerson confirmed a posthumous album is being produced and that it is scheduled to be released by the end of 2012 by Blackground Records. The album was reported to include 16 unreleased songs and have contributions from Aaliyah's longtime collaborators Timbaland and Missy Elliott, among others. On August 13, Timbaland and Missy Elliott dismissed rumors about being contacted or participating for the project. Elliott's manager Mona Scott-Young said in a statement to "XXL", "Although Missy and Timbaland always strive to keep the memory of their close friend alive, we have not been contacted about the project nor are there any plans at this time to participate. We've seen the reports surfacing that they have been confirmed to participate but that is not the case. Both Missy and Timbaland are very sensitive to the loss still being felt by the family so we wanted to clear up any misinformation being circulated." Elliott herself said, "Tim and I carry Aaliyah with us everyday, like so many of the people who love her. She will always live in our hearts. We have nothing but love and respect for her memory and for her loved ones left behind still grieving her loss. They are always in our prayers."
In June 2013, Aaliyah was featured on a new track by Chris Brown, titled "Don't Think They Know"; with Aaliyah singing the song's hook. The video features dancing holographic versions of Aaliyah. The song is set to appear on Brown's upcoming sixth studio album, "X". Timbaland voiced his disapproval for "Enough Said" and "Don't Think They Know" in July 2013. He exclaimed, “Aaliyah music only work with its soulmate, which is me”. Soon after, Timbaland apologized to Chris Brown over his remarks, which he explained were made due to Aaliyah and her death being a "very sensitive subject".
In January 2014, producer Noah "40" Shebib confirmed that the posthumous album was shelved due to the negative reception surrounding Drake's involvement. Shebib added, "Aaliyah's mother saying, 'I don't want this out' was enough for me [...] I walked away very quickly."
Legacy.
Aaliyah has been credited for helping redefine R&B and hip hop in the 1990s, "leaving an indelible imprint on the music industry as a whole." Steve Huey of AllMusic wrote Aaliyah ranks among the "elite" artists of the R&B genre, as she "played a major role in popularizing the stuttering, futuristic production style that consumed hip-hop and urban soul in the late 1990s." Described as one of "R&B's most important artists" during the 1990s, her second studio album, "One in a Million", became one of the most influential R&B albums of the decade. Music critic Simon Reynolds cited "Are You That Somebody?" as "the most radical pop single" of 1998. Kelefah Sanneh of "The New York Times" wrote that rather than being the song's focal point, Aaliyah "knew how to disappear into the music, how to match her voice to the bass line", and consequently "helped change the way popular music sounds; the twitchy, beat-driven songs of Destiny's Child owe a clear debt to 'Are You That Somebody'." Sanneh asserted that by the time of her death in 2001, Aaliyah "had recorded some of the most innovative and influential pop songs of the last five years." With sales of 8.1 million albums in the United States and an estimated 24 to 32 million albums worldwide, Aaliyah earned the nicknames "Princess of R&B" and "Queen of Urban Pop", as she "proved she was a muse in her own right". Ernest Hardy of "Rolling Stone" dubbed her as the "undisputed queen of the midtempo come-on". Japanese pop singer Hikaru Utada has said several times that "It was when I heard Aaliyah's "Age Ain't Nothing but a Number" that I got hooked on R&B.", after which Utada released her debut album "First Love" with heavy R&B influences.
Aaliyah was honored at the 2001 MTV Video Music Awards by Janet Jackson, Missy Elliott, Timbaland, Ginuwine and her brother, Rashad, who all paid tribute to her. In the same year, the United States Social Security Administration ranked the name Aaliyah one of the 100 most popular names for newborn girls. Aaliyah was ranked as one of "The Top 40 Women of the Video Era" in VH1's 2003 "The Greatest" series. She was also ranked at number 18 on BET's "Top 25 Dancers of All Time". Aaliyah appeared on both 2000 and 2001 list of "Maxim" Hot 100 in position 41 and the latter at 14. In memory of Aaliyah, the Entertainment Industry Foundation created the Aaliyah Memorial Fund to donate money raised to charities she supported. In December 2009, "Billboard" magazine ranked Aaliyah at number 70 on its Top Artists of the Decade, while her eponymous album was ranked at number 181 on the magazine's Top 200 Albums of the Decade. She is listed by "Billboard" as the tenth most successful female R&B artist of the past 25 years, and 27th most successful R&B artist overall. In 2012, VH1 ranked her number 48 in "VH1's Greatest Women in Music".
Aaliyah's work has influenced numerous artists including Adele, Ciara, Beyoncé Knowles, Monica, Chris Brown, Rihanna, Azealia Banks, Sevyn Streeter, Keyshia Cole, J. Cole, Kelly Rowland, Zendaya, Rita Ora, The xx, Omarion, Canadian R&B singer Keshia Chanté who was said to play as her in her pending biopic back in 2008, complimented the singer's futuristic style in music and fashion.
Keshia Chanté backed out of the biopic after speaking to Diane Haughton, but has expressed a willingness to do the project if "the right production comes along and the family's behind it". Keisha also mentioned that Aaliyah had been part of her life "since I was 6."
R&B singer and friend Brandy said about the late singer "She came out before Monica and I did, she was our inspiration. At the time, record companies did not believe in kid acts and it was just inspiring to see someone that was winning and winning being themselves. When I met her I embraced her, I was so happy to meet her." Rapper Drake said that the singer has had the biggest influence on his career. He also has a tattoo of the singer behind his back. Solange Knowles remarked on the tenth anniversary of her death that she idolized Aaliyah and proclaimed that she would never be forgotten.
In 2012, British singer-songwriter Katy B released the song "Aaliyah" as a tribute to Aaliyah's legacy and lasting impression on R&B music. The song first appeared on Katy B's "Danger" EP and featured Jessie Ware on guest vocals.
There has been continuing belief that Aaliyah would have achieved greater career success had it not been for her death. Emil Wilbekin mentioned the deaths of The Notorious B.I.G and Tupac Shakur in conjunction with hers and added: "Her just-released third album and scheduled role in a sequel to "The Matrix" could have made her another Janet Jackson or Whitney Houston". Director of "Queen of the Damned" Michael Rymer said of Aaliyah, "God, that girl could have gone so far" and spoke of her having "such a clarity about what she wanted. Nothing was gonna step in her way. No ego, no nervousness, no manipulation. There was nothing to stop her."
On July 18, 2014, it was announced that Alexandra Shipp has replaced Zendaya for the role of Aaliyah for the Lifetime TV biopic movie "", the TV biopic movie will premiere on Lifetime on November 15, 2014. Zendaya drew criticism because she is biracial while Aaliyah was African-American. She referred to Aaliyah as "one of her biggest inspirations" and insisted that while she could not "please everybody", she could "work really hard and just continue to show [Aaliyah's] legacy. That’s all I’m focused on is really, really portraying her in the best light possible. That’s all it’s about." She explained her decision to drop out of the film in three videos she posted on Instagram. "The reason why I chose not to do the Aaliyah movie had nothing to do with the haters or people telling me that I couldn’t do it, I wasn’t talented enough, or I wasn’t black enough. It had absolutely nothing to do with that.” Aaliyah's family has been vocal in their disapproving of the film. Her cousin Jomo Hankerson stated the family would prefer a "major studio release along the lines" of "What's Love Got to Do with It", the biopic loosely based on the life of Tina Turner. Aaliyah's family has consulted a lawyer to stop Lifetime from using “any of the music, or any of the photographs and videos” they own and Jomo Hankerson claimed the TV network "didn't reach out." On August 9, 2014, it was announced that Chattrisse Dolabaille and Izaak Smith had been cast as Aaliyah's collaborators Missy Elliott and Timbaland. Dolabaille received criticism for her appearance in comparison with that of Missy Elliot. "The Urban Daily" wrote: "The hushed frustrations around the industry are mainly pertaining to the fact that the actress is nothing like Missy Elliott. She is much lighter, she is much smaller and she doesn’t seem to have any Hip Hop or R&B background. Some feel that the biopic creators didn’t look hard enough for someone more appropriate to play Missy."
A feature film, scheduled for release in theaters in 2015, was reported in August 2014 to star B. Simone and have involvement from Aaliyah's uncle Barry Hankerson. The film is stated to feature unreleased music by the late singer.

</doc>
<doc id="2147" url="http://en.wikipedia.org/wiki?curid=2147" title="Armour">
Armour

 
Armour or armor (see spelling differences) is a protective covering that is used to prevent damage from being inflicted to an object, individual, or vehicle by direct contact weapons or projectiles, usually during combat, or from damage caused by a potentially dangerous environment or action (e.g., cycling, construction sites, etc.). Personal armour is used to protect soldiers and war animals such as war horses (the application for the latter is called barding). Vehicle armour is used on warships and armoured fighting vehicles.
Etymology.
The word "armour" was introduced into use in the Middle Ages as a borrowing from the French. It is dated from 1297, as a "mail, defensive covering worn in combat" from Old French "armoire", itself derived from the Latin "armatura" "arms and/or equipment" with the root "arma" "arms or gear".
Personal.
Armour has been used throughout recorded history. It has been made from a variety of materials; from rudimentary leather protection, personal armour evolved to Mail and full plated suits of armour. For much of military history the manufacture of metal personal armour has dominated the technology and employment of armour. Armour drove the development of many important technologies of the Ancient World, including wood lamination, mining, metal refining, vehicle manufacture, leather processing, and later decorative metal working. Its production was influential in the industrial revolution, and influenced commercial development of metallurgy and engineering. Armour was the single most influential factor in the development of firearms, which in turn revolutionised warfare.
History.
Significant factors in the development of armour include the economic and technological necessities of its production. For instance, plate armour first appeared in Medieval Europe when water-powered trip hammers made the formation of plates faster and cheaper. Also, modern militaries usually do not equip their forces with the best armour available because it would be prohibitively expensive. At times the development of armour has paralleled the development of increasingly effective weaponry on the battlefield, with armourers seeking to create better protection without sacrificing mobility.
Well-known armour types in European history include the lorica hamata, lorica squamata, and the lorica segmentata of the Roman legions, the mail hauberk of the early medieval age, and the full steel plate harness worn by later medieval and renaissance knights, and breast and back plates worn by heavy cavalry in several European countries until the first year of World War I (1914–15). The samurai warriors of feudal Japan utilised many types of armour for hundreds of years up to the 19th century.
Early.
Cuirasses and helmets were manufactured in Japan as early as the 4th century."Tankō", worn by foot soldiers and "keikō", worn by horsemen were both pre-samurai types of early Japanese armour constructed from iron plates connected together by leather thongs. Japanese lamellar armour ("keiko") passed through Korea and reached Japan around the 5th century. These early Japanese lamellar armours took the form of a sleeveless jacket and a helmet.
Armour did not always cover all of the body; sometimes no more than a helmet and leg plates were worn. The rest of the body was generally protected by means of a large shield. Examples of armies equipping their troops in this fashion were the Aztecs (13th to 15th century CE).
In East Asia many types of armour were commonly used at different times by various cultures including, scale armour, lamellar armour, laminar armour, plated mail, mail, plate armour and brigandine. Around the dynastic Tang, Song, and early Ming Period, cuirasses and plates (mingguangjia) were also used, with more elaborate versions for officers in war. The Chinese, during that time used partial plates for "important" body parts instead of covering their whole body since too much plate armour hinders their martial arts movement. The other body parts were covered in cloth, leather, lamellar, and/or Mountain pattern. In pre-Qin dynasty times, leather armour was made out of various animals, with more exotic ones such as the rhinoceros.
Mail, sometimes called "chainmail", made of interlocking iron rings is believed to have first appeared some time after 300 BCE. Its invention is credited to the Celts, the Romans were thought to have adopted their design.
Gradually, small additional plates or discs of iron were added to the mail to protect vulnerable areas. Hardened leather and splinted construction were used for arm and leg pieces. The coat of plates was developed, an armour made of large plates sewn inside a textile or leather coat.
Early plate in Italy, and elsewhere in the 13th–15th century were made of iron. Iron armour could be carburised or case hardened to give a surface of harder steel. Plate armour became cheaper than mail by the 15th century as it required much less labour and labour had become much more expensive after the Black Death, though it did require larger furnaces to produce larger blooms. Mail continued to be used to protect those joints which could not be adequately protected by plate, such as the armpit, crook of the elbow and groin. Another advantage of plate was that a lance rest could be fitted to the breast plate.
The small skull cap evolved into a bigger true helmet, the bascinet, as it was lengthened downward to protect the back of the neck and the sides of the head. Additionally, several new forms of fully enclosed helmets were introduced in the late 14th century.
Probably the most recognised style of armour in the World became the plate armour associated with the knights of the European Late Middle Ages, but continuing to the early 17th century Age of Enlightenment in all European countries.
By about 1400 the full harness of plate armour had been developed in armouries of Lombardy. Heavy cavalry dominated the battlefield for centuries in part because of their armour.
In the early 15th century, advances in weaponry allowed infantry to defeat armoured knights on the battlefield. The quality of the metal used in armour deteriorated as armies became bigger and armour was made thicker, necessitating breeding of larger cavalry horses. If during the 14–15th centuries armour seldom weighed more than 15 kg, then by the late 16th century it weighed 25 kg. The increasing weight and thickness of late 16th century armour therefore gave substantial resistance.
In the early years of low velocity firearms, full suits of armour, or breast plates actually stopped bullets fired from a modest distance. Crossbow bolts, if still used, would seldom penetrate good plate, nor would any bullet unless fired from close range. In effect, rather than making plate armour obsolete, the use of firearms stimulated the development of plate armour into its later stages. For most of that period, it allowed horsemen to fight while being the targets of defending arquebuseers without being easily killed. Full suits of armour were actually worn by generals and princely commanders right up to the second decade of the 18th century. It was the only way they could be mounted and survey the overall battlefield with safety from distant musket fire.
The horse was afforded protection from lances and infantry weapons by steel plate barding. This gave the horse protection and enhanced the visual impression of a mounted knight. Late in the era, elaborate barding was used in parade armour.
Later.
Gradually starting in the mid-16th century, one plate element after another was discarded to save weight for foot soldiers.
Back and breast plates continued to be used throughout the entire period of the 18th century and through Napoleonic times, in many European (heavy) cavalry units, until the early 20th century. From their introduction, muskets could pierce plate armour, so cavalry had to be far more mindful of the fire. In Japan armour continued to be used until the end of the samurai era, with the last major fighting in which armour was used happening in 1868.Samurai armour had one last short lived use in 1877 during the Satsuma Rebellion.
Though the age of the knight was over, armour continued to be used in many capacities. Soldiers in the American Civil War bought iron and steel vests from peddlers (both sides had considered but rejected body armour for standard issue). The effectiveness of the vests varied widely—some successfully deflected bullets and saved lives, but others were poorly made and resulted in tragedy for the soldiers. In any case the vests were abandoned by many soldiers due to their weight on long marches as well as the stigma they got for being cowards from their fellow troops.
At the start of World War I, thousands of the French Cuirassiers rode out to engage the German Cavalry who likewise used helmets and armour. By that period, the shiny armour plate was covered in dark paint and a canvas wrap covered their elaborate Napoleonic style helmets. Their armour was meant to protect only against sabres and light lances. The cavalry had to beware of high velocity rifles and machine guns like the foot soldiers, who at least had a trench to protect them.
Present.
Today, ballistic vests, also known as flak jackets, made of ballistic cloth (e.g. kevlar, dyneema, twaron, spectra etc.) and ceramic or metal plates are common among police forces, security staff, corrections officers and some branches of the military.
The US Army has adopted Interceptor body armour, which uses Enhanced Small Arms Protective Inserts (E-S.A.P.I) in the chest, sides and back of the armour. Each plate is rated to stop a range of ammunition including 3 hits from a 7.62×51 NATO AP round at a range of . Dragon Skin body armour is another ballistic vest which is currently in testing with mixed results.
Other types.
The first modern production technology for armour plating was used by navies in the construction of the Ironclad warship, reaching its pinnacle of development with the battleship. It was also naval engineers that constructed the first tanks during World War I, giving rise to armoured fighting vehicles. Aerial armour has been used to protect pilots and aircraft systems since the Second World War.
In modern ground forces' usage, the meaning of armour has expanded to include the role of troops in combat. After the evolution of armoured warfare, mechanised infantry were mounted in armoured fighting vehicles and replaced light infantry in many situations. In modern armoured warfare, armoured units equipped with tanks and infantry fighting vehicles serve the historic role of both the battle cavalry, light cavalry and dragoons, and belong to the armoured branch.
History.
Ships.
The first ironclad battleship, with iron armour over a wooden hull, "La Gloire", was launched by the French Navy in 1859; she prompted the British Royal Navy to build a counter. The following year they launched "Warrior", which was twice the size and had iron armour over an iron hull. After the first battle between two ironclads took place in 1862 during the American Civil War, it became clear that the ironclad had replaced the unarmoured line-of-battle ship as the most powerful warship afloat.
Ironclads were designed for several roles, including as high seas battleships, coastal defence ships, and long-range cruisers. The rapid evolution of warship design in the late 19th century transformed the ironclad from a wooden-hulled vessel which carried sails to supplement its steam engines into the steel-built, turreted battleships and cruisers familiar in the 20th century. This change was pushed forward by the development of heavier naval guns (the ironclads of the 1880s carried some of the heaviest guns ever mounted at sea), more sophisticated steam engines, and advances in metallurgy which made steel shipbuilding possible.
The rapid pace of change in the ironclad period meant that many ships were obsolete as soon as they were complete, and that naval tactics were in a state of flux. Many ironclads were built to make use of the ram or the torpedo, which a number of naval designers considered the crucial weapons of naval combat. There is no clear end to the ironclad period, but towards the end of the 1890s the term "ironclad" dropped out of use. New ships were increasingly constructed to a standard pattern and designated battleships or armoured cruisers.
Trains.
Armoured trains saw use during the 19th century in the American Civil War (1861–1865), the Franco-Prussian War (1870–1871), the First and Second Boer Wars (1880–81 and 1899–1902),the Polish–Soviet War (1919–1921); the First (1914–1918) and Second World Wars (1939–1945) and the First Indochina War (1946–1954). The most intensive use of armoured trains was during the Russian Civil War (1918–1920).
During the Second Boer War on 15 November 1899, Winston Churchill, then a war-correspondent, was travelling on board an armoured train when it was ambushed by "Boer commandos". Churchill and many of the train's garrison were captured, though many others escaped, including wounded placed on the train's engine.
Armoured fighting vehicles.
Towards the end of World War I, armies on both sides were experimenting with plate armour as protection against shrapnel and ricocheting projectiles. The first proposal for a tank was by the Austrian "Oberleutenant" Günther Burstyn who, in 1911, proposed a design for "motor artillery" ("Motorengeschütz") with a turret, but his design never progressed beyond a German patent in 1912.
Armoured cars were put into use by the British on the Western Front. Initially an innovation to aid the recovery of downed pilots, they were sidelined when the front became static. They continued to be used in the more open Middle East battlefields.
Tank or "landship" development, originally conducted by the British Navy under the auspices of the Landships Committee was sponsored by the First Lord of the Admiralty, Winston Churchill and proceeded through a number of prototypes culminating in the Mark I tank prototype, named "Mother". The first tank to engage in battle was designated "D1", a British Mark I, during the Battle of Flers-Courcelette (part of the Somme Offensive) on 15 September 1916.
In contrast to World War II, Germany fielded very few tanks during WWI, with only 15 of the A7V type being produced in Germany during the war. Most German tanks were captured British ones. The first tank versus tank action took place on 24 April 1918 at Second Battle of Villers-Bretonneux, when three British Mark IVs met an advance of three German A7Vs, supported by infantry. Tanks were knocked out on both sides, but the German attack failed and they retreated.
Mechanical problems, poor mobility and piecemeal tactical deployment limited the military significance of the tank in World War I and the tank did not fulfil its promise of rendering trench warfare obsolete. Nonetheless, it was clear to military thinkers on both sides that tanks would play a significant role in future conflicts.
Aircraft.
With the development of effective anti-aircraft artillery in the period before the Second World War, military pilots, once the "knights of the air" during the First World War, became far more vulnerable to ground fire. As a response armour plating was added to aircraft to protect aircrew and vulnerable areas such as fuel tanks and engine.
Present.
Tank armour has progressed from the Second World War armour forms, now incorporating not only harder composites, but also reactive armour designed to defeat shaped charges. As a result of this, the main battle tank (MBT) conceived in the Cold War era can survive multiple RPG strikes with minimal effect on the crew or the operation of the vehicle. The light tanks that were the last descendants of the light cavalry during the Second World War have almost completely disappeared from the world's militaries due to increased lethality of the weapons available to the vehicle-mounted infantry.
The armoured personnel carrier (APC) is a relatively recent development, stemming from trials and experiences during the Second World War. The APC allows the safe and rapid movement of infantry in a combat zone, minimising casualties and maximising mobility. APCs are fundamentally different from the previously used armoured half-tracks in that they offer a higher level of protection from artillery burst fragments, and greater mobility in more terrain types. The basic APC design was substantially expanded to an Infantry fighting vehicle (IFV) when properties of an armoured personnel carrier and a light tank were combined in one vehicle.
Naval armour has fundamentally changed from the Second World War doctrine of thicker plating to defend against shells, bombs and torpedos. Passive defence naval armour is limited to kevlar or steel (either single layer or as spaced armour) protecting particularly vital areas from the effects of nearby impacts. Since ships cannot carry enough armour to completely prevent penetration by anti-ship missiles, they depend more on destroying an incoming missile before it hits, or causing it to miss its target.
Although the role of the ground attack aircraft significantly diminished after the Korean War, it re-emerged during the Vietnam War, and in the recognition of this, the US Air Force authorised the design and production of what was later to become the A-10 dedicated anti-armour and ground-attack aircraft of the Cold War.

</doc>
<doc id="2148" url="http://en.wikipedia.org/wiki?curid=2148" title="Armoured fighting vehicle">
Armoured fighting vehicle

An armoured fighting vehicle (or armored fighting vehicle - see spelling differences) AFV is a combat vehicle, protected by strong armour and armed with weapons, which combines operational mobility, tactical offensive, and defensive capabilities. AFVs can be wheeled or tracked. It is not uncommon for AFVs to be simply referred to as "armour".
Armoured fighting vehicles are classified according to their intended role on the battlefield and characteristics. This classification is not absolute; at different times different countries will classify the same vehicle in different roles. For example, armoured personnel carriers were generally replaced by infantry fighting vehicles in a similar role, but the latter has some capabilities lacking in the former. There may also be hybrid vehicles, such as the Stryker family of AFVs; the M1128 Mobile Gun System, an armoured car which mounts a large 105mm gun normally used in tank destroyers, but can theoretically be reconfigured to the M1126 Infantry Carrier Vehicle.
Successful general-purpose armoured fighting vehicles often also serve as the base of a whole family of specialized vehicles, for example, the M113 and MT-LB tracked carriers, and the MOWAG Piranha wheeled AFV.
Evolution of AFVs.
History.
Conception.
Prior to the invention of the internal combustion engine and the advent of armoured warfare in the 20th century, the AFV classification did not exist. However, war machines with rudimentary armour have been used in battle for millennia. These designs historically struggled between the paradox of exposed-mobility, effective-firepower and cumbersome-protection. Siege engines, such as battering rams, would often be armoured in order to protect the crews from the defenders. 
The idea of a vehicle with a tortoise like cover has been known since antiquity. Frequently cited is Leonardo da Vinci's 15th century sketch of a mobile, protected gun platform; the drawings show a conical, wooden shelter with apertures for cannons around the circumference. The machine was to be mounted on four wheels which would be turned by the crew through a system of hand cranks and cage (or "lantern") gears. Leonardo quoted "I will build armored wagons which will be safe and invulnerable to enemy attacks. There will be no obstacle which it cannot overcome." However, modern replicas have demonstrated that the human crew would have been able to move it over only short distances.
The chariot was used as a mobile archery platform and as a "battle taxi". The original chariot was a fast, light, open, two-wheeled conveyance drawn by two or more horses hitched side by side. It was used for ancient warfare during the bronze and the iron ages. The war wagon were medieval weapon-platforms development during the Hussite Wars around 1420 by Hussite forces rebelling in Bohemia. These heavy wagon were given protective sides with firing slits and heavy firepower from either a cannon or a force of hand-gunners and crossbowmen, supported by infantry using pikes and flails.
Modern AFVs.
Armoured car.
The first modern AFVs were armoured cars, dating back virtually to the invention of the motor car. The Motor Scout was designed and built by British inventor F.R. Simms in 1898. It was the first armed petrol engine powered vehicle ever built. The vehicle was a De Dion-Bouton quadricycle with a mounted Maxim machine gun on the front bar. An iron shield in front of the car protected the driver.
The first armoured car was the Simms' Motor War Car, designed by Simms and built by Vickers, Sons & Maxim in1899. The vehicle had Vickers armour 6 mm thick and was powered by a four-cylinder 3.3-litre 16 hp Cannstatt Daimler engine giving it a maximum speed of around . The armament, consisting of two Maxim guns, was carried in two turrets with 360° traverse.
Another early armoured car of the period was the French Charron, Girardot et Voigt 1902, presented at the "Salon de l'Automobile et du cycle" in Brussels, on 8 March 1902. The vehicle was equipped with a Hotchkiss machine gun, and with 7 mm armour for the gunner. Armoured cars were first used in large numbers on both sides during World War I as scouting vehicles which offered armoured protection to the crew.
Tank.
The development of the AFV took a great leap forward during World War I, when the tracked tank was developed by Britain and France to break the stalemate on the Western Front. The tank was envisioned as an armoured machine that could cross ground under fire from machine guns and respond with fire from mounted guns. It was to move on caterpillar tracks to enable it to cross ground broken up by shellfire and trenches.
In Great Britain, the Landships Committee was formed by the First Lord of the Admiralty, Winston Churchill on 20 February 1915. The Director of Naval Construction for the Royal Navy, Eustace Tennyson d'Eyncourt, was appointed to head the Committee in view of his experience with the engineering methods it was felt might be required. The first design, Little Willie, ran for the first time in September 1915 and served to develop the form of the track but an improved design, better able to cross trenches, swiftly followed and in January 1916 the prototype, nicknamed "Mother", was adopted as the design for future tanks. Production models of "Male" tanks (armed with naval cannon and machine guns) and "Females" (carrying only machine-guns) would go on to fight in history's first tank action at the Somme in September 1916. Great Britain produced about 2,600 tanks of various types during the war.
In 1916, the French pioneered the use of a full 360° rotation turret in a tank for the first time, with the creation of the Renault FT light tank, with the turret containing the tank's main armament. In addition to the traversible turret, another innovative feature of the FT was its engine located at the rear. This pattern, with the gun located in a mounted turret and the engine at the back, became the standard for most succeeding tanks across the world. The FT was the most numerous tank of the War; over 3,000 were made by late 1918.
Other AFVs.
The tank proved highly successful, and as technology improved it became a weapon that could cross large distances at much higher speeds than supporting infantry and artillery. The need to provide the units that would fight alongside the tank led to the development of a wide range of specialised AFVs, especially during the Second World War.
The Armoured personnel carrier, designed to transport infantry troops to the frontline, emerged towards the end of WWI. During the first actions with tanks it had become clear that often infantry could not keep up with the tanks; they could not be transported in the tank, due to the poor atmosphere quality. In 1917, Lieutenant G.R. Rackham was ordered to design an armoured vehicle specifically for troop transport. The Mark IX tank was built by Armstrong, Whitworth & Co., although just three vehicles were finished at the time of the Armistice and only 34 were built in total.
Different tank classifications emerged in the interwar period. The tankette was conceived as a mobile, two-man model, mainly intended for reconnaissance. In 1925 Sir John Carden and Vivian Loyd produced the first such design - the Carden Loyd tankette. Tankettes saw use in the Italian Royal Army during the Italian invasion of Ethiopia, the Spanish Civil War, and almost every place Italian soldiers fought during World War II. The Imperial Japanese Army also used them for jungle warfare.
The British Gun Carrier Mark I was the first Self-propelled artillery and was fielded in 1917. It was based on the first tank, the British Mark I and carried a heavy field gun. The next major advance was the Birch gun developed for the motorised warfare experimental brigade (the Experimental Mechanized Force). This mounted a field gun, capable of the usual artillery trajectories, on a tank style chassis.
During WWII, most nations developed self-propelled artillery vehicles. These had mounted guns on a tracked chassis (often that of an obsolete or superseded tank) and provide an armoured superstructure to protect the gun and its crew. The first British design, "Bishop", carried the 25 pdr gun-howitzer, but in a mounting that severely limited the gun's performance. It was replaced by the more effective Sexton. The Germans created many examples of lightly armored self-propelled anti-tank guns using captured French equipment (example Marder I), their own obsolete light tank chassis (Marder II), or ex-Czech chassis (Marder III). These led to better protected tank destroyers, built on medium tank chassis such as the Jagdpanzer IV and Jagdpanther.
The Self-propelled anti-aircraft weapon debuted in WWI. The German 77 mm anti-aircraft gun, was truck-mounted and used to great effect against British tanks, and the British QF 3 inch 20 cwt was mounted on trucks for use on the Western Front. Although the Birch gun was a general purpose artillery piece on an armoured tracked chassis, it was capable of being elevated for anti-aircraft use. Vickers Armstrong developed one of the first SPAAGs based on the chassis of the Mk.E 6-ton light tank/Dragon Medium Mark IV tractor, mounting a Vickers QF-1 "Pom-Pom" gun of 40 mm. The Germans fielded the SdKfz 10/4 and 6/2, cargo halftracks mounting single 20 mm or 37 mm AA guns (respectively) by the start of the War.
By the end of World War II, most modern armies had vehicles to carry infantry, artillery and anti-aircraft weaponry . Most modern AFVs are superficially similar in design to their World War II counterparts, but with significantly better armour, weapons, engines and suspension. The increase in the capacity of transport aircraft has allowed AFVs to be practically transported by air. Many armies are replacing some or all of their traditional heavy vehicles with lighter airmobile versions, often with wheels instead of tracks.
Design.
Armour.
The level of armour protection between AFVs varies greatly - a main battle tank will normally be designed to take hits from other tank guns and anti-tank missiles, whilst light reconnaissance vehicles are often only armoured "just in case". Whilst heavier armour provides better protection, it makes vehicles less mobile (for a given engine power), limits its air-transportability, increases cost, uses more fuel and may limit the places it can go - for example, many bridges may be unable to support the weight of a main battle tank. A trend toward composite armour is taking place in place of steel - composites are stronger for a given weight, allowing the tank to be lighter for the same protection as steel armour, or better protected for the same weight. Armour is being supplemented with active protection systems on a number of vehicles, allowing the AFV to protect itself from incoming projectiles.
The level of protection also usually varies considerably throughout the individual vehicle too, depending on the role of the vehicle and the likely direction of attack. For example, a main battle tank will usually have the heaviest armour on the hull front and the turret, lighter armour on the sides of the hull and the thinnest armour on the top and bottom of the tank. Other vehicles - such as the MRAP family - may be primarily armoured against the threat from IEDs and so will have heavy, sloped armour on the bottom of the hull.
Weaponry.
Weaponry varies by a very wide degree between AFVs - lighter vehicles for infantry carrying, reconnaissance or specialist roles may have only a machine gun for self-defence (or no armament at all), whereas heavy self propelled artillery will carry large guns, mortars or rocket launchers. These weapons may be mounted on a pintle, affixed directly to the vehicle or placed in a turret or cupola.
The greater the recoil a weapon on an AFV is, the larger the turret ring needs to be. A larger turret ring necessitates a larger vehicle. To avoid listing to the side, turrets are usually located at the centre of the vehicle on vehicles that are capable of amphibious operations.
Grenade launchers provide a versatile launch platform for a plethora of munitions including, smoke, phosphorus, tear gas, illumination, anti-personnel, infrared and radar-jamming rounds.
Turret stabilization is an important capability because it enables firing on the move and prevents crew fatigue.
Engine.
Modern AFVs have primarily used either petrol (gasoline) or diesel piston engines. More recently gas turbines have been used. Most early AFVs used petrol engines, as they offer a good power-to-weight ratio. However, they fell out of favour during World War Two due to the flammability of the fuel.
Most current AFVs are powered by a diesel engine; modern technology including the use of turbo-charging help to overcome the lower power-to-weight ratio of diesel engines compared to petrol.
Gas turbine (turboshaft) engines offer a very high power-to-weight ratio and were starting to find favour in the late 20th century - however they offer very poor fuel consumption and as such some armies are switching from gas turbines back to diesel engines (i.e. the Russian T-80 used a gas turbine engine, whereas the later T-90 does not). The US M1 Abrams is a notable example of a gas turbine powered tank.
Modern classification by type and role.
Notable armoured fighting vehicles extending from post-World War I to today.
Tank.
The tank is an all terrain AFV designed primarily to engage enemy forces by the use of direct fire in the frontal assault role. Though several configurations have been tried, particularly in the early experimental days of tank development, a standard, mature design configuration has since emerged to a generally accepted pattern. This features a main artillery gun, mounted in a fully rotating turret atop a tracked automotive hull, with various additional machine guns throughout.
Philosophically, the tank is, by its very nature, an offensive weapon. Being a protective encasement with at least one gun position, it is essentially a pillbox or small fortress (though these are static fortifications of a purely defensive nature) that can move toward the enemy - hence its offensive utility.
Historically, tanks are divided into three categories: 
Cavalry tank, cruiser tank, infantry tank, and assault-breakthrough tank have been used by various countries to classify tanks by operational role. Tankette is used to describe particularly small one or two-man vehicles, typically armed with a machine gun and/or anti-air weapons.
In modern use, the heavy tank has fallen out of favour, being supplanted by more heavily-armed and armoured descendent of the medium tanks - the main battle tank. The light tank has in many militaries lost favour to cheaper, faster, lighter armoured cars and tank destroyers; however, light tanks (or similar vehicles with other names) are still in service with a number of forces as reconnaissance vehicles, most notably the Russian Marines with the PT-76, the British Army with the Scimitar, and the Chinese Army with the Type 63.
Main battle tank.
Modern main battle tanks incorporates recent advances in automotive, artillery, and armour technology to combine the best characteristics of the historic medium and heavy tanks into a single, all around type. They are also the most expensive to mass-produce. It is distinguished by its high level of firepower, mobility and armour protection relative to other vehicles of its era. It can cross comparatively rough terrain at high speeds, but its heavy-dependency on fuel, maintenance, and ammunition makes it logistically demanding. It has the heaviest armour of any IFV on the battlefield, and carries a powerful precision-guided munition weapon systems that may be able to engage a wide variety of both ground targets and air targets. It is among the most versatile and fearsome land-based weapon-systems of the 21st-century, valued for its shock action against other troops and high survivability, although it is still vulnerable to anti-tank warfare.
Tankette.
A tankette is a tracked armed and armoured vehicle resembling a small "ultra-light tank" roughly the size of a car, mainly intended for light infantry support or scouting. They were one or two-man vehicles armed with a machine gun. Colloquially it may also simply mean a "small tank".
Tankettes were designed and built by several nations between the 1920s and 1940s. They were very popular with smaller countries. Some saw some combat (with limited success) in World War II. However, the vulnerability of their light armour eventually caused the concept to be abandoned.
"Super"-heavy tank.
The term "super-heavy tank" has been used to describe armoured fighting vehicles of extreme size, generally over 75 tonnes. Programs have been initiated on several occasions with the aim of creating an invincible siegeworks/breakthrough vehicle for penetrating enemy formations and fortifications without fear of being destroyed in combat. Examples were designed in World War I and World War II, along with a few in the Cold War. However, few working prototypes were ever been built and there are no clear evidence any of these vehicles saw combat, as their immense size would have made most designs impracticable.
Flame tank.
A flame tank is a tank equipped with a flamethrower, most commonly used to supplement combined arms attacks against fortifications, confined spaces, or other obstacles. The type only reached significant use in the Second World War, during which the United States, Soviet Union, Germany, Italy, Japan and the United Kingdom (including members of the British Commonwealth) all produced flamethrower-equipped tanks.
A number of production methods were used. The flamethrowers used were either modified versions of existing infantry flame weapons (Flammpanzer I and II) or specially designed (Flammpanzer III). They were mounted externally (Flammpanzer II), replaced existing machine gun mounts, or replaced the tank's main armament (Flammpanzer III). Fuel for the flame weapon was either carried inside the tank, in armoured external storage, or in some cases in a special trailer behind the tank (Churchill Crocodile).
Flame tanks have been superseded by thermobaric weapons such as the Russian TOS-1.
Infantry tank.
The idea for this tank was developed during World War I by the British and French. The infantry tank was designed to work in concert with infantry in the assault, moving mostly at a walking pace, which required it to carry heavy armour to survive defensive fire. Its main purpose would have been to clear the battlefield of obstacles, suppress or destroy defenders, and protect the infantry on their advance into and through enemy lines by giving mobile overwatch and cover.
The British came back to the concept in the pre-Second World War era. The infantry tank did not need to be fast so it could carry more armour. One of the best-known infantry tanks was the Matilda II of World War II.
Cruiser tank.
A cruiser tank, or cavalry tank, was designed to move fast and exploit penetrations of the enemy front. The idea originated in "Plan 1919", a British plan to break the trench deadlock of World War I in part via the use of high-speed tanks. This concept was later implemented in the "fast tanks" pioneered by Walter Christie.
They were used by the United Kingdom during World War II. Cruiser tanks were designed to complement infantry tanks, exploiting gains made by the latter to attack and disrupt the enemy rear areas. In order to give them the required speed, cruiser designs sacrificed armour compared to the infantry tanks.
The Soviet fast tank ("bistrokhodniy tank", or BT tank) classification also came out of the infantry/cavalry concept of armoured warfare and formed the basis for the British cruisers after 1936. The T-34 was a development of this line of tanks as well, though their armament, armour, and all-round capability places them firmly in the medium tank category.
Armoured car.
The military's armoured car is a wheeled armoured vehicle, generally lighter than other armoured fighting vehicles, primarily being armoured and/or armed for self-defence of the occupants. Other multi-axled wheeled military vehicles can be quite large, and actually be superior to some smaller tracked vehicles in terms of armour and armament. They usually do not have attached weaponry. Armoured cars are often used in military marches and processions, or for the escorting of important figures.
In World War II, armoured cars were used for reconnaissance alongside scout cars. Their guns were suitable for some defence if they encountered enemy armoured vehicles, but they were not intended to engage enemy tanks.
Aerosani.
An "aerosani" (, literally "aerosled") is a type of propeller-driven snowmobile, running on skis, used for communications, mail deliveries, medical aid, emergency recovery and border patrolling in northern Russia, as well as for recreation. Aerosanis were used by the Soviet Red Army during the Winter War and World War II.
The first aerosanis may have been built by young Igor Sikorsky in 1909–10, before he built multi-engine airplanes and helicopters. They were very light plywood vehicles on skis, propelled by old airplane engines and propellers.
Scout car.
A scout car is military armored reconnaissance vehicle, capable of off-road mobility and often carrying mounted weapons such as machine guns for offensive capabilities and crew protection. They often only carry an operational crew aboard, which differentiates them from wheeled armored personnel carriers (APCs) and Infantry Mobility Vehicles (IMVs), but early scout cars, such as the open-topped US M3 Scout Car could carry a crew of seven. The term is often used synonymously with the more general term armored car, which also includes armored civilian vehicles. They are also differentiated by being designed and built for purpose, as opposed to improved technicals which might serve in the same role.
Internal security vehicle.
An internal security vehicle (ISV), also known as an armoured security vehicle (ASV), is a combat vehicle used for supporting contingency operations. Security vehicles are typically armed with a turreted heavy machine gun and auxiliary medium machine gun. The vehicle is designed to minimize firepower dead space and the vehicles weapons can be depressed to a maximum of 12°. Non-lethal water cannons and tear gas cannons can provide suppressive fire in lieu of unnecessary deadly fire.
The vehicle must be protected against weapons typical of riots. Protection from incendiary devices is achieved though coverage of the air intake and exhaust ports as well as a strong locking mechanism on the fuel opening. Turret and door locks prevent access to the interior of the vehicle by rioters. Vision blocks, ballistic glass and window shutters and outside surveillance cameras allow protected observation from within the vehicle. Wheeled 4x4 and 6x6 configurations are typical of security vehicles. Tracked security vehicles are often cumbersome and leave negative political connotations for being perceived as an imperial invading force.
Improvised fighting vehicle.
An improvised fighting vehicle is a combat vehicle resulting from modifications to a civilian or military non-combat vehicle in order to give it a fighting capability. Such modifications usually consist of the grafting of armour plating and weapon systems. Various militaries have procured such vehicles, ever since the introduction of the first automobiles into military service.
During the early days, the absence of a doctrine for the military use of automobiles or of an industry dedicated to producing them, lead to much improvisation in the creation of early armoured cars, and other such vehicles. Later, despite the advent of arms industries in many countries, several armies still resorted to using ad hoc contraptions, often in response to unexpected military situations, or as a result of the development of new tactics for which no available vehicle was suitable. The construction of improvised fighting vehicles may also reflect a lack of means for the force that uses them. This is especially true in developing countries, where various armies and guerrilla forces have used them, as they are more affordable than military-grade combat vehicles.
Modern examples include military gun truck used by units of regular armies or other official government armed forces, based on a conventional cargo truck, that is able to carry a large weight of weapons and armour. They have mainly been used by regular armies to escort military convoys in regions subject to ambush by guerrilla forces. "Narco tanks", used by Mexican drug cartels in the Mexican Drug War, are built from such trucks, which combines operational mobility, tactical offensive, and defensive capabilities.
Troop carriers.
Troop-carrying AFVs are divided into two main types - armoured personnel carriers (APCs) and infantry fighting vehicles (IFVs). The main difference between the two is down to their intended role - the APC is designed purely to transport troops and is armed for self-defence only - whereas the IFV is designed to provide fire support to the infantry it carries.
Infantry fighting vehicle.
An infantry fighting vehicle (IFV), also known as a mechanized infantry combat vehicle (MICV), is a type of armoured fighting vehicle used to carry infantry into battle and provide direct fire support. The first example of an IFV was the West German Schützenpanzer Lang HS.30 which served in the Bundeswehr from 1958 until the early 1980s..
IFVs are similar to armoured personnel carriers (APCs) and infantry carrier vehicles (ICVs), designed to transport a section or squad of infantry (generally between five and ten men) and their equipment. They are differentiated from APCs— which are purely "troop-transport" vehicles armed only for self-defense— because they are designed to give direct fire support to the dismounted infantry and so usually have significantly enhanced armament. IFVs also often have improved armour and some have firing ports (allowing the infantry to fire personal weapons while mounted).
They are typically armed with an autocannon of 20 to 40mm calibre, 7.62mm machine guns, anti-tank missiles (ATGMs) and/or surface-to-air missiles (SAMs). IFVs are usually tracked, but some wheeled vehicles fall into this category. IFVs are generally less heavily armed and armoured than main battle tanks. They sometimes carry anti-tank missiles to protect and support infantry against armoured threats, such as the NATO TOW missile and Soviet Bastion, which offer a significant threat to tanks. Specially-equipped IFVs have taken on some of the roles of light tanks; they are used by reconnaissance organizations, and light IFVs are used by airborne units which must be able to fight without the heavy firepower of tanks.
Armoured personnel carrier.
Armoured personnel carriers are intended to carry infantry quickly and relatively safely to point where they are deployed. In 1918, the British Mk V* (Mark Five Star) tank carried a small number of troops as an experiment, but the men were debilitated by the conditions inside the vehicle. The first purpose-built APC was the British Mk IX (Mark Nine). In the US the term "Infantry Carrier Vehicle (ICV)" is used. In 1944, the Canadian general Guy Simonds ordered the conversion of redundant armoured vehicles to carry troops (generically named "Kangaroos"). This proved highly successful, even without training, and the concept was widely used in the 21st Army Group. Post-war, specialised designs were built, such as the Soviet BTR-60 and US M113.
Infantry mobility vehicle.
An infantry mobility vehicle (IMV) or protected patrol vehicle (PPV) is a wheeled armored personnel carrier (APC) serving as a military patrol, reconnaissance or security vehicle. Examples include the ATF Dingo, AMZ Dzik, AMZ Tur, Mungo ESK, and Bushmaster IMV. This term also applies to the vehicles currently being fielded as part of the MRAP program.
IMVs were developed in response to the threats of modern counter insurgency warfare, with an emphasis on Ambush Protection and Mine-Resistance. Similar vehicles existed long before the term IMV was coined, such as the French VAB and South African Buffel. The term is coming more into use to differentiate light 4x4 wheeled APCs from the traditional 8x8 wheeled APCs. It is a neologism for what might have been classified in the past as an armoured scout car, such as the BRDM, but the IMV is distinguished by having a requirement to carry dismountable infantry. The up-armoured M1114 Humvee variant can be seen as an adaptation of the unarmoured Humvee to serve in the IMV role.
Amphibious vehicles.
Many modern military vehicles, ranging from light wheeled command and reconnaissance, through armoured personnel carriers and tanks, are manufactured with amphibious capabilities. Contemporary wheeled armoured amphibians include the French Véhicule de l'Avant Blindé and Véhicule Blindé Léger. The latter is a small, lightly armoured 4x4 all-terrain vehicle that is fully amphibious and can swim at 5.4 km/h. The VAB ("Véhicule de l'Avant Blindé" - "Armoured Vanguard Vehicle") is a fully amphibious armoured personnel carrier powered in the water by two water jets, that entered service in 1976 and produced in numerous configurations, ranging from basic personnel carrier, anti-tank missile platform.
During the Cold War the Soviet bloc states developed a number of amphibious APCs, fighting vehicles and tanks, both wheeled and tracked. Most of the vehicles the Soviets designed were amphibious, or could ford deep water. Wheeled examples are the BRDM-1 and BRDM-2 4x4 armoured scout cars, as well as the BTR-60, BTR-70, BTR-80 and BTR-94 8x8 armoured personnel carriers and the BTR-90 infantry fighting vehicle.
The United States started developing a long line of Landing Vehicle Tracked (LVT) designs from ca. 1940. The US Marine Corps currently uses the AAV7-A1 Assault Amphibious Vehicle, which was to be succeeded by the Expeditionary Fighting Vehicle, which was capable of planing on water and can achieve water speeds of 37–46 km/h. The EFV project has been cancelled.
A significant amount of tracked armoured vehicles that are primarily intended for land-use, have some amphibious cability, tactically useful inland, reducing dependence on bridges. They use their tracks, sometimes with added propeller or water jets for propulsion. As long as the banks have a shallow enough slopes to enter or leave the water they can cross rivers and water obstacles.
Some heavy tanks can operate amphibiously with a fabric skirt to add buoyancy. The Sherman DD tank used in the Normandy landings had this setup. When in water the waterproof float screen was raised and propellers deployed. Some modern vehicles use a similar skirt.
Armoured engineering vehicle.
Typically based on the platform of a main battle tank, these vehicles go by different names depending upon the country of use or manufacture. In the US the term "combat engineer vehicle (CEV)" is used, in the UK the term "Armoured Vehicle Royal Engineers (AVRE)" is used, while in Canada and other commonwealth nations the term "armoured engineer vehicle (AEV)" is used. There is no set template for what such a vehicle will look like, yet likely features include a large dozer blade or mine ploughs, a large calibre demolition cannon, augers, winches, excavator arms and cranes, or lifting booms.
These vehicles are designed to directly conduct obstacle breaching operations and to conduct other earth-moving and engineering work on the battlefield. Good examples of this type of vehicle include the UK Trojan AVRE, the Russian IMR, and the US M728 Combat Engineer Vehicle.
It should be noted that while the term "armoured engineer vehicle" is used specifically to describe these multi-purpose tank-based engineering vehicles, that term is also used more generically in British and Commonwealth militaries to describe all heavy tank-based engineering vehicles used in the support of mechanized forces. Thus, "armoured engineer vehicle" used generically would refer to AEV, AVLB, Assault Breachers, and so on.
Assault breacher vehicle.
An assault breacher vehicle (ABV), also known as a explosive ordnance disposal vehicle (EODV), or simply Breacher, is especially designed to clear pathways for troops and other vehicles through minefields and along roadside bombs and Improvised Explosive Devices. These vehicles are based on a tank-chassis with 1,500+ horsepower engines, but fitted with a 50-caliber machine gun and a front-mounted 5-meter-wide plow, supported by metallic skis that glide on the dirt and typically equipped with at least of Mine Clearing Line Charges: rockets carrying C-4 explosives up to 100–150 meters forward, detonating hidden bombs at a safe distance, so that troops and vehicles can pass through safely. They were called "the answer" to the deadliest threat facing NATO troops in modern asymmetrical conflict. 
Armoured bulldozer.
The armored bulldozer is a basic tool of combat engineering. These combat engineering vehicles combine the earth moving capabilities of the bulldozer with armor which protects the vehicle and its operator in or near combat. Most are civilian bulldozers modified by addition of vehicle armor/military equipment, but some are tanks stripped of armament and fitted with a dozer blade. Some tanks have bulldozer blades while retaining their armament, but this does not make them armored bulldozers as such, because combat remains the primary role — earth moving is a secondary task.
Armoured recovery vehicle.
An armoured recovery vehicle (ARV) is a type of vehicle recovery armoured fighting vehicle used to repair battle- or mine-damaged as well as broken-down armoured vehicles during combat, or to tow them out of the danger zone for more extensive repairs. To this end the term ""Armoured Repair and Recovery Vehicle" (ARRV)" is also used.
ARVs are normally built on the chassis of a main battle tank (MBT), but some are also constructed on the basis of other armoured fighting vehicles, mostly armoured personnel carriers (APCs). ARVs are usually built on the basis of a vehicle in the same class as they are supposed to recover; a tank-based ARV is used to recover tanks, while an APC-based one recovers APCs, but does not have the power to tow a much heavier tank.
Armoured vehicle-launched bridge.
An armoured vehicle-launched bridge (AVLB) is a combat support vehicle, sometimes regarded as a subtype of combat engineering vehicle, designed to assist militaries in rapidly deploying tanks and other armoured fighting vehicles across rivers. The AVLB is usually a tracked vehicle converted from a tank chassis to carry a folding metal bridge instead of weapons. The AVLB's job is to allow armoured or infantry units to cross water, when a river too deep for vehicles to wade through is reached, and no bridge is conveniently located (or sufficiently sturdy, a substantial concern when moving 60-ton tanks).
The bridge layer unfolds and launches its cargo, providing a ready-made bridge across the obstacle in only minutes. Once the span has been put in place, the AVLB vehicle detaches from the bridge, and moves aside to allow traffic to pass. Once all of the vehicles have crossed, it crosses the bridge itself and reattaches to the bridge on the other side. It then retracts the span ready to move off again. A similar procedure can be employed to allow crossings of small chasms or similar obstructions. AVLBs can carry bridges of or greater in length. By using a tank chassis, the bridge layer is able to cover the same terrain as main battle tanks, and the provision of armour allows them to operate even in the face of enemy fire. However, this is not a universal attribute: some exceptionally sturdy 6x6 or 8x8 truck chassis have lent themselves to bridge-layer applications.
Combat engineer section carriers.
The combat engineer section carriers are used to transport sappers (combat engineers) and can be fitted with a bulldozer's blade and other mine-breaching devices. They are often used as APCs because of their carrying ability and heavy protection. They are usually armed with machine guns and grenade launchers and usually tracked to provide enough tractive force to push blades and rakes. Some examples are the U.S. M113 APC, IDF Puma, Nagmachon, Husky, and U.S. M1132 ESV (a Stryker variant).
Air defense vehicles.
An anti-aircraft vehicle, also known as a self-propelled anti-aircraft weapon (SPAA) or self-propelled air defense system (SPAD), is a mobile vehicle with a dedicated anti-aircraft capability. The Russian equivalent of SPAAG is ZSU (from "zenitnaya samokhodnaya ustanovka" - "anti-aircraft self-propelled mount"). Specific weapon systems used include machine guns, autocannons, larger guns, or missiles, and some mount both guns and longer-ranged missiles. Platforms used include both trucks and heavier combat vehicles such as APCs and tanks, which add protection from aircraft, artillery, and small arms fire for front line deployment. Anti-aircraft guns are usually mounted in a quickly-traversing turret with a high rate of elevation, for tracking fast-moving aircraft. They are often in dual or quadruple mounts, allowing a high rate of fire. Today, missiles (generally mounted on similar turrets) have largely supplanted anti-aircraft guns.
Self-propelled artillery.
Self-propelled artillery vehicles give mobility to artillery. Within the term are covered self-propelled guns (or howitzers) and rocket artillery. They are highly mobile, usually based on tracked chassis carrying either a large howitzer or other field gun or alternatively a mortar or some form of rocket or missile launcher. They are usually used for long-range indirect bombardment support on the battlefield.
In the past, self-propelled artillery has included direct-fire "Gun Motor Carriage" vehicles such as assault guns and tank destroyers (also known as self-propelled anti-tank guns). These have been heavily armoured vehicles, the former providing danger-close fire-support for infantry and the latter acting as specialized anti-tank vehicles.
Modern self-propelled artillery vehicles may superficially resemble tanks, but they are generally lightly armoured, too lightly to survive in direct-fire combat. However, they protect their crews against shrapnel and small arms and are therefore usually included as armoured fighting vehicles. Many are equipped with machine guns for defence against enemy infantry.
The key advantage of self-propelled over towed artillery is that it can be brought into action much faster. Before the towed artillery can be used, it has to stop, unlimber and set up the guns. To move position, the guns must be limbered up again and brought — usually towed — to the new location. By comparison self-propelled artillery in combination with modern communications can stop at a chosen location and begin firing almost immediately, then quickly move on to a new position. This ability is very useful in a mobile conflict and particularly on the advance.
Conversely, towed artillery was and remains cheaper to build and maintain. It is also lighter and can be taken to places that self-propelled guns cannot reach, so despite the advantages of the self-propelled artillery, towed guns remain in the arsenals of many modern armies.
Assault gun.
An assault gun is a gun or howitzer mounted on a motor vehicle or armoured chassis, designed for use in the direct fire role in support of infantry when attacking other infantry or fortified positions.
Historically the custom-built fully armored assault guns usually mounted the gun or howitzer in a fully enclosed casemate on a tank chassis. The use of a casemate instead of a gun turret limited these weapons field of fire, but allowed a larger gun to be fitted relative to the chassis, more armour to be fitted for the same weight, and provided a cheaper construction. In most cases, these turretless vehicles also presented a lower profile as a target for the enemy.
Mortar carrier.
A mortar carrier is a self-propelled artillery vehicle carrying a mortar as its primary weapon. Mortar carriers cannot be fired while on the move and some must be dismounted to fire. In U.S. Army doctrine, mortar carriers provide close and immediate indirect fire support for maneuver units while allowing for rapid displacement and quick reaction to the tactical situation. The ability to relocate not only allows fire support to be provided where it is needed faster but also allows these units to avoid counter-battery fire. Mortar carriers have traditionally avoided direct contact with the enemy. Many units report never using secondary weapons in combat.
Prior to the Iraq War, American 120mm mortar platoons reorganized from six M1064 mortar carriers and two M577 fire direction centers (FDC) to four M1064 and one FDC. The urban environment of Iraq made it difficult to utilize mortars. New technologies such as mortar ballistic computers and communication equipment and are being integrated. Modern era combat is becoming more reliant on direct fire support from mortar carrier machine guns.
Multiple rocket launcher.
A multiple rocket launcher is a type of unguided rocket artillery system. Like other rocket artillery, multiple rocket launchers are less accurate and have a much lower (sustained) rate of fire than batteries of traditional artillery guns. However, they have the capability of simultaneously dropping many hundreds of kilograms of explosive, with devastating effect.
The Korean Hwacha is an example of an early weapon system with a resemblance to the modern-day multiple rocket launcher. The first modern multiple rocket launcher was the German "Nebelwerfer" of the 1930s, a small towed artillery piece. Only later in World War II did the Allies deploy similar weapons in the form of the Land Mattress.
The first self-propelled multiple rocket launchers — and arguably the most famous — were the Soviet BM-13 Katyushas, first used during World War II and exported to Soviet allies afterwards. They were simple systems in which a rack of launch rails was mounted on the back of a truck. This set the template for modern multiple rocket launchers. The Americans mounted tubular launchers atop M4 Sherman tanks to create the T34 Calliope rocket launching tank, only used in small numbers, as their closest equivalent to the Katyusha.
Tank destroyer.
Tank destroyers and tank hunters are armed with an anti-tank gun or missile launcher, and are designed specifically to engage enemy armoured vehicles. Many have been based on a tracked tank chassis, while others are wheeled. Since World War II, main battle tanks have largely replaced gun-armed tank destroyers; although lightly armoured anti tank guided missile (ATGM) carriers are commonly used for supplementary long-range anti-tank engagements.
In post-Cold War conflict, the resurgence of expeditionary warfare has seen the emergence of gun-armed wheeled vehicles, sometimes called "protected gun systems", which may bear a superficial resemblance to tank destroyers, but are employed as direct fire support units typically providing support in low intensity operations such as Iraq and Afghanistan. These have the advantage of easier deployment, as only the largest air transports can carry a main battle tank, and their smaller size makes them more effective in urban combat.
Many forces' IFVs carry anti-tank missiles in every infantry platoon, and attack helicopters have also added anti-tank capability to the modern battlefield. But there are still dedicated anti-tank vehicles with very heavy long-range missiles, or intended for airborne use. There have also been dedicated anti-tank vehicles built on ordinary armoured personnel carrier or armoured car chassis. Examples include the U.S. M901 ITV (Improved TOW Vehicle) and the Norwegian NM142, both on an M113 chassis, several Soviet ATGM launchers based on the BRDM reconnaissance car, the British FV438 Swingfire and FV102 Striker and the German Raketenjagdpanzer series built on the chassis of the HS 30 and Marder IFV.
Armoured train.
An armoured train is a railway train protected with armour. They are usually equipped with railroad cars armed with artillery and machine guns. They were mostly used during the late 19th and early 20th century, when they offered an innovative way to quickly move large amounts of firepower. Their use was discontinued in most countries when road vehicles became much more powerful and offered more flexibility, and because armoured trains were too vulnerable to track sabotage as well as attacks from the air. However, the Russian Federation used improvised armoured trains in the Second Chechen War in the late 1990s and 2000s.
The railroad cars on an armoured train were designed for many tasks such as carrying guns and machine guns, infantry units, anti-aircraft guns. During World War II, the Germans would sometimes put a "Fremdgerät" (such as a captured French Somua S-35 or Czech PzKpfw 38(t) light tank, or Panzer II light tank) on a flatbed car which could be quickly offloaded by means of a ramp and used away from the range of the main railway line to chase down enemy partisans
Different types of armour were used to protect from attack by tanks. In addition to various metal plates, concrete and sandbags were used in some cases for improvised armoured trains.
Armoured trains were sometimes escorted by a kind of rail-tank called a draisine. One such example was the 'Littorina' armoured trolley which had a cab in the front and rear, each with a control set so it could be driven down the tracks in either direction. Littorina mounted two dual 7.92mm MG13 machine gun turrets from Panzer I light tanks.

</doc>
<doc id="2151" url="http://en.wikipedia.org/wiki?curid=2151" title="Anton Drexler">
Anton Drexler

Anton Drexler (13 June 1884 – 24 February 1942) was a German far-right political leader of the 1920s who was instrumental in the formation of the pan-German and anti-Semitic German Workers' Party ("Deutsche Arbeiterpartei" - DAP), the antecedent of the Nazi Party ("Nationalsozialistische Deutsche Arbeiterpartei" - NSDAP). Drexler served as mentor to Adolf Hitler during his early days in politics.
Biography.
Born in Munich, Drexler was a machine-fitter before becoming a railway locksmith in Berlin. He joined the Fatherland Party during World War I. In March 1918 Drexler founded a branch of the "Freien Arbeiterausschuss für einen guten Frieden" (Free Workers' Committee for a good Peace) league. Thereafter in 1918, Karl Harrer (a journalist and member of the Thule Society), along with Drexler and several others formed the "Politischer Arbeiterzirkel" (Political Workers' Circle). The members met periodically for discussions with themes of nationalism and racism directed against the Jews. Drexler was a poet and a member of the völkisch agitators who, together with Harrer, founded the German Workers' Party (DAP), in Munich with Gottfried Feder and Dietrich Eckart on 5 January 1919.
At a meeting of the Party in Munich in September 1919, the main speaker was Gottfried Feder. When he had finished speaking, Adolf Hitler got involved in a heated political argument with a visitor, Professor Baumann, who questioned the soundness of Feder's arguments against capitalism and proposed that Bavaria should break away from Prussia and found a new South German nation with Austria. In vehemently attacking the man's arguments he made an impression on the other party members with his oratory skills and, according to Hitler, the "professor" left the hall acknowledging unequivocal defeat. Drexler approached Hitler and thrust a booklet into his hand. It was "My Political Awakening" and, according to Hitler, it reflected the ideals he already believed in. Impressed with Hitler, Drexler invited him to join the DAP. Hitler accepted on 12 September 1919, becoming the party's 55th member. In less than a week, Hitler received a postcard from Drexler stating he had officially been accepted as a DAP member and he should come to a "committee" meeting to discuss it. Hitler attended the "committee" meeting held at the run-down Alte Rosenbad beer-house.
Hitler began to make the party more public, and he organised their biggest meeting yet of 2,000 people, for 24 February 1920 in the "Staatliches Hofbräuhaus in München". Such was the significance of this particular move in publicity that Karl Harrer resigned from the party in disagreement. It was in this speech that Hitler, for the first time, enunciated the twenty-five points of the "German Worker's Party"'s manifesto that had been drawn up by Drexler, Feder, and Hitler. Through these points he gave the organisation a much bolder stratagem with a clear foreign policy (abrogation of The Treaty of Versailles, a Greater Germany, Eastern expansion, exclusion of Jews from citizenship). On the same day the party was renamed the "Nationalsozialistische Deutsche Arbeiterpartei" - NSDAP.
By 1921, Hitler was rapidly becoming the undisputed leader of the Party. In June 1921, while Hitler and Eckart were on a fundraising trip to Berlin, a mutiny broke out within the NSDAP in Munich. Members of its executive committee wanted to merge with the rival German Socialist Party (DSP). Hitler returned to Munich on 11 July and angrily tendered his resignation. The committee members realised that the resignation of their leading public figure and speaker would mean the end of the party. Hitler announced he would rejoin on the condition that he would replace Drexler as party chairman, and that the party headquarters would remain in Munich. The committee agreed; he rejoined the party as member 3,680. Drexler was thereafter moved to the purely symbolic position of honorary president, and left the Party in 1923.
Drexler was also a member of a "völkisch" political club for affluent members of Munich society known as the Thule Society. His membership in the NSDAP ended when it was temporarily outlawed in 1923 following the Beer Hall Putsch, in which Drexler had not taken part. In 1924 he was elected to the Bavarian state parliament for another party, in which he served as vice-president until 1928. He had no part in the NSDAP's refounding in 1925, and rejoined only after Hitler had come to power in 1933. He received the party's Blood Order in 1934 and was still occasionally used as a propaganda tool until about 1937, but he was never again allowed any real power or played an active part in the movement. He died in Munich in February 1942.
In popular culture.
In the 2003 film "", British actor Robert Glenister plays Drexler, although Drexler is inaccurately portrayed without his trademark spectacles and moustache.
External links.
 

</doc>
<doc id="2152" url="http://en.wikipedia.org/wiki?curid=2152" title="All Quiet on the Western Front">
All Quiet on the Western Front

All Quiet on the Western Front () is a novel by Erich Maria Remarque, a German veteran of World War I. The book describes the German soldiers' extreme physical and mental stress during the war, and the detachment from civilian life felt by many of these soldiers upon returning home from the front.
The novel was first published in November and December 1928 in the German newspaper "Vossische Zeitung" and in book form in late January 1929. The book and its sequel, "The Road Back", were among the books banned and burned in Nazi Germany. It sold 2.5 million copies in 22 languages in its first eighteen months in print.
In 1930, the book was adapted as an Oscar-winning film of the same name, directed by Lewis Milestone.
Title and translation.
The 1929 English translation by Arthur Wesley Wheen gives the title as " All Quiet on the Western Front". The literal translation of "Im Westen nichts Neues" is "In the West Nothing New," with "West" being the Western Front; the phrase refers to the content of an official communiqué at the end of the novel.
Brian Murdoch's 1993 translation would render the phrase as "there was nothing new to report on the Western Front" within the narrative. Explaining his retention of the original book-title, he says:
Although it does not match the German exactly, Wheen's title has justly become part of the English language and is retained here with gratitude.
The phrase "all quiet on the Western Front" has become a colloquial expression meaning stagnation, or lack of visible change, in any context.
Plot summary.
The book tells the story of Paul Bäumer, a German soldier who—urged on by his school teacher—joins the German army shortly after the start of World War I. His class was "scattered over the platoons amongst Frisian fishermen, peasants, and labourers." Bäumer arrives at the Western Front with his friends and schoolmates (Tjaden, Müller, Kropp and a number of other characters). There they meet Stanislaus Katczinsky, an older soldier, nicknamed Kat, who becomes Paul's mentor. While fighting at the front, Bäumer and his comrades have to engage in frequent battles and endure the dangerous and often dirty conditions of warfare.
At the very beginning of the book Erich Maria Remarque says "This book is to be neither an accusation nor a confession, and least of all an adventure, for death is not an adventure to those who stand face to face with it. It will try simply to tell of a generation of men who, even though they may have escaped (its) shells, were destroyed by the war." The book does not focus on heroic stories of bravery, but rather gives a view of the conditions in which the soldiers find themselves. The monotony between battles, the constant threat of artillery fire and bombardments, the struggle to find food, the lack of training of young recruits (meaning lower chances of survival), and the overarching role of random chance in the lives and deaths of the soldiers are described in detail.
The battles fought here have no names and seem to have little overall significance, except for the impending possibility of injury or death for Bäumer and his comrades. Only pitifully small pieces of land are gained, about the size of a football field, which are often lost again later. Remarque often refers to the living soldiers as old and dead, emotionally drained and shaken. "We are not youth any longer. We don't want to take the world by storm. We are fleeing from ourselves, from our life. We were eighteen and had begun to love life and the world; and we had to shoot it to pieces."
Paul's visit on leave to his home highlights the cost of the war on his psyche. The town has not changed since he went off to war; however, he finds that he does "not belong here anymore, it is a foreign world." He feels disconnected from most of the townspeople. His father asks him "stupid and distressing" questions about his war experiences, not understanding "that a man cannot talk of such things." An old schoolmaster lectures him about strategy and advancing to Paris, while insisting that Paul and his friends know only their "own little sector" of the war but nothing of the big picture.
Indeed, the only person he remains connected to is his dying mother, with whom he shares a tender, yet restrained relationship. The night before he is to return from leave, he stays up with her, exchanging small expressions of love and concern for each other. He thinks to himself, "Ah! Mother, Mother! How can it be that I must part from you? Here I sit and there you are lying; we have so much to say, and we shall never say it." In the end, he concludes that he "ought never to have come [home] on leave."
Paul feels glad to be reunited with his comrades. Soon after, he volunteers to go on a patrol and kills a man for the first time in hand-to-hand combat. He watches the man die, in pain for hours. He feels remorse and asks forgiveness from the man's corpse. He is devastated and later confesses to Kat and Albert, who try to comfort him and reassure him that it is only part of the war.
They are then sent on what Paul calls a "good job." They must guard a village that is being shelled too heavily. The men enjoy themselves but while evacuating the villagers, Paul and Albert are wounded.
They recuperate in a Catholic hospital and Paul returns to active duty.
By now, the war is nearing its end and the German Army is retreating. In despair, Paul watches as his friends fall one by one. It is the death of Kat that eventually makes Paul careless about living. In the final chapter, he comments that peace is coming soon, but he does not see the future as bright and shining with hope. Paul feels that he has no aims left in life and that their generation will be different and misunderstood. When he dies at the end of the novel, the situation report from the frontline states, "All is Quiet on the Western Front," symbolizing the insignificance of one individual's death during the war.
Themes.
One of the major themes of the novel is the difficulty of soldiers to revert to civilian life after having experienced extreme combat situations. Remarque comments in the preface that "[All Quiet on the Western Front] will try simply to tell of a generation of men who, even though they may have escaped its shells, were destroyed by the war." This internal destruction can be found as early as the first chapter as Paul comments that, although all the boys are young, their youth has left them.
When on leave from the front, Paul feels strongly isolated from his family and removed from daily life. Another topic concerns how soldiers' lives are put at risk by their commanding officers who seem unaware of the trauma of their charges.
Main characters.
Paul Bäumer.
Paul Bäumer is the main character and narrator. At 19 years of age, Paul enlists in the German Army and is deployed to the Western Front where he experiences the severe psychological and physical effects of the war. 
Before the war, Paul was a creative, sensitive and passionate person, writing poems and having a clear love for his family. But as the war changed his attitude and personality, poems and other aspects of his past life become something Paul could not remember having any link to, and he learns to disconnect himself from his feelings. He feels he can't tell anyone about his experiences, and feels like an outsider where his family is concerned.
By the end of the book, Paul realises that he no longer knows what to do with himself and decides that he has nothing more to lose. The war appears to have snuffed out his hopes and dreams, which he feels he can never regain. After years of fighting, Paul is finally killed in October 1918, on an extraordinarily quiet, peaceful day. The army report that day contains only one phrase: “All quiet on the Western Front.” As Paul dies, his face is calm, “as though almost glad the end had come."
Albert Kropp.
Kropp was in Paul's class at school and is described as the clearest thinker of the group. Kropp is wounded towards the end of the novel and undergoes an amputation. Both he and Bäumer end up spending time in a Roman Catholic hospital together, Bäumer suffering from shrapnel wounds to the leg and arm. Though Kropp initially plans to commit suicide if he requires an amputation, the book suggests he postponed suicide because of the strength of military camaraderie. Kropp and Bäumer part ways when Bäumer is recalled to his regiment after recovering. Paul comments that saying farewell was "very hard, but it is something a soldier learns to deal with."
Haie Westhus.
Haie is described as being tall and strong, and a peat-digger by profession. Overall, his size and behavior make him seem older than Paul, yet he is the same age as Paul and his school-friends (roughly 19 at the start of the book). Haie in addition has a good sense of humor. During combat, he is injured in his back, fatally (Chapter 6) — the resulting wound is large enough for Paul to see Haie's breathing lung when Himmelstoß carries him to safety.
Fredrich Müller.
Müller is about 18 and a half years of age, one of Bäumer's classmates, when he also joins the German army as a volunteer to go to the war. Carrying his old school books with him to the battlefield, he constantly reminds himself of the importance of learning and education. Even while under enemy fire, he "mutters propositions in physics". He became interested in Kemmerich's boots and inherits them when Kemmerich dies early in the novel. He is killed later in the book after being shot point-blank in the stomach with a flare gun. As he was dying "quite conscious and in terrible pain", he gave his boots which he inherited from Kemmerich to Paul.
Stanislaus "Kat" Katczinsky.
Kat has the most positive influence on Paul and his comrades on the battlefield. Katczinsky was a cobbler in civilian life; he is older than Paul Bäumer and his comrades, about 40 years old, and serves as their leadership figure. He also represents a literary model highlighting the differences between the younger and older soldiers. While the older men have already had a life of professional and personal experience before the war, Bäumer and the men of his age have had little life experience or time for personal growth.
Kat is also well known for his ability to scavenge nearly any item needed, especially food. At one point he secures four boxes of lobster. Bäumer describes Kat as possessing a sixth sense. One night, Bäumer along with a group of other soldiers are holed up in a factory with neither rations nor comfortable bedding. Katczinsky leaves for a short while, returning with straw to put over the bare wires of the beds. Later, to feed the hungry men, Kat brings bread, a bag of horse flesh, a lump of fat, a pinch of salt and a pan in which to cook the food.
Kat is hit by shrapnel at the end of the story, leaving him with a smashed shin. Paul carries him back to camp on his back, only to discover upon their arrival that a stray splinter had hit Kat in the back of the head and killed him on the way. He is thus the last of Paul's close friends to die in battle. It is Kat's death that eventually makes Bäumer careless whether he survives the war or not, but that he can face the rest of his life without fear. "Let the months and the years come, they can take nothing from me, they can take nothing more. I am so alone, and so without hope that I can confront them without fear."
Tjaden.
One of Bäumer's non-schoolmate friends. Before the war Tjaden was a locksmith. A big eater with a grudge against the former postman-turned corporal Himmelstoß (thanks to his strict 'disciplinary actions'), he manages to forgive Himmelstoß later in the book. Throughout the book, Paul frequently remarks on how much of an eater he is, yet somehow manages to stay as "thin as a rake." Tjaden appears in the sequel, "The Road Back".
Minor characters.
Kantorek.
Kantorek was the schoolmaster of Paul and his friends, including Kropp, Leer, Müller, and Behm. Behaving "in a way that cost [him] nothing," Kantorek is a strong supporter of the war and encourages Bäumer and other students in his class to join the war effort. Among twenty enlistees was Joseph Behm, the first of the class to die in battle. In an example of tragic irony, Behm was the only one who did not want to enter the war.
Kantorek is a hypocrite, urging the young men he teaches to fight in the name of patriotism, while not voluntarily enlisting himself. In a twist of fate, Kantorek is later called up as a soldier as well. He very reluctantly joins the ranks of his former students, only to be drilled and taunted by Mittelstädt, one of the students he had earlier persuaded to enlist.
Peter Leer.
Leer is an intelligent soldier in Bäumer's company, and one of his classmates. He is very popular with women; when he and his comrades meet three French women, he is the first to seduce one of them. Bäumer describes Leer's ability to attract women by saying "Leer is an old hand at the game". In chapter 11, Leer is hit by a shell fragment, which also hits Bertinck. The shrapnel tears open Leer's hip, causing him to bleed to death quickly. His death causes Paul to ask himself, "What use is it to him now that he was such a good mathematician in school?"
Bertinck.
Lieutenant Bertinck is the leader of Bäumer's company. His men have a great respect for him, and Bertinck has great respect for his men. He permits them to eat the rations of the men that had been killed in action, standing up to the chef Ginger who would only allow them their allotted share. Bertinck is genuinely despondent when he learns that few of his men had survived an engagement.
When he and the other characters are trapped in a trench under heavy attack, Bertinck, who has been injured in the firefight, spots a flamethrower team advancing on them. He gets out of cover and takes aim on the flamethrower but misses, and gets hit by enemy fire. With his next shot he kills the flamethrower, and immediately afterwards an enemy shell explodes on his position blowing off his chin. The same explosion also fatally wounds Leer.
Himmelstoß.
Corporal Himmelstoß (spelled Himmelstoss in some editions) was a postman before enlisting in the war. He is a power-hungry corporal with special contempt for Paul and his friends, taking sadistic pleasure in punishing the minor infractions of his trainees during their basic training in preparation for their deployment. Paul later figures that the training taught by Himmelstoß made them "hard, suspicious, pitiless, and tough" but most importantly it taught them comradeship. However, Bäumer and his comrades have a chance to get back at Himmelstoß because of his punishments, mercilessly whipping him on the night before they board trains to go to the front.
Himmelstoß later joins them at the front, revealing himself as a coward who shirks his duties for fear of getting hurt or killed, and pretends to be wounded because of a scratch on his face. Paul Bäumer beats him because of it and when a lieutenant comes along looking for men for a trench charge, Himmelstoß joins and leads the charge. He carries Haie Westhus's body to Bäumer after he is fatally wounded. Matured and repentant through his experiences Himmelstoß later asks for forgiveness from his previous charges. As he becomes the new staff cook, to prove his friendship he secures two pounds of sugar for Bäumer and half a pound of butter for Tjaden.
Detering.
Detering is a farmer who constantly longs to return to his wife and farm. He is also fond of horses and is angered when he sees them used in combat. He says, "It is of the vilest baseness to use horses in the war," when the group hears several wounded horses writhe and scream for a long time before dying during a bombardment. He tries to shoot them to put them out of misery, but is stopped by Kat to keep their current position hidden. He is driven to desert when he sees a cherry tree in blossom, which reminds him of home too much and inspires him to leave. He is found by military police and court-martialed, and is never heard from again.
Josef Hamacher.
Hamacher is a patient at the Catholic hospital where Paul and Albert Kropp are temporarily stationed. He has an intimate knowledge of the workings of the hospital. He also has a "shooting license," certifying him as sporadically not responsible for his actions due to a head wound, though he is clearly quite sane and exploiting his license so he can stay in the hospital and away from the war as long as possible.
Franz Kemmerich.
A young boy of only 19 years. Franz Kemmerich had enlisted in the army for World War I along with his best friend and classmate, Bäumer. Kemmerich is shot in the leg early in the story; his injured leg has to be amputated, and he dies shortly after. In anticipation of Kemmerich's imminent death, Müller was eager to get his boots. While in the hospital, someone steals Kemmerich's watch from him, causing him great distress, prompting him to ask about his watch every time his friends came to visit him in the hospital.
Joseph Behm.
A student in Paul's class. Behm was the only student that was not quickly influenced by Kantorek's patriotism to join the war. Eventually, due to pressure from friends and Kantorek, he joins the war. He is the first of Paul's friends to die. He is blinded in no man's land and believed to be dead by his friends. The next day, when he is seen walking blindly around no-man's-land, it is discovered that he was only unconscious. However, he is killed before he can be rescued.
Publication and Reception.
From November 10 to December 9, 1928, "All Quiet on the Western Front" was published in serial form in Vossische Zeitung magazine. It was released in book form the following year to smashing success, selling one and a half million copies that same year. Although publishers had worried that interest in the Great War had waned more than 10 years after the armistice, Remarque's realistic depiction of trench warfare from the perspective of young soldiers struck a chord with the war's survivors—soldiers and civilians alike—and provoked strong reactions, both positive and negative, around the world.
With "All Quiet on the Western Front", Remarque emerged as an eloquent spokesperson for a generation that had been, in his own words, "destroyed by war, even though it might have escaped its shells." Remarque's harshest critics, in turn, were his countrymen, many of whom felt the book denigrated the German war effort, and that Remarque had exaggerated the horrors of war to further his pacifist agenda. The strongest voices against Remarque came from the emerging National Socialist (Nazi) Party, an ultranationalist group in Germany led by the future Führer, Adolf Hitler. In 1933, when the Nazis rose to power, "All Quiet on the Western Front" became one of the first "degenerate" books to be publicly burnt.
However, objections to Remarque’s portrayal of the German army personnel during World War I were not limited to the Nazis. Dr. Karl Kroner () objected to Remarque’s depiction of the medical personnel as being inattentive, uncaring, or absent from frontline action. Dr. Kroner was specifically worried that the book would perpetuate German stereotypes abroad that had subsided since the First World War. He offered the following clarification: “People abroad will draw the following conclusions: if German doctors deal with their own fellow countrymen in this manner, what acts of inhumanity will they not perpetuate against helpless prisoners delivered up into their hands or against the populations of occupied territory?” 
A fellow patient of Remarque’s in the military hospital in Duisburg objected to the negative depictions of the nuns and patients, and of the general portrayal of soldiers: “There were soldiers to whom the protection of homeland, protection of house and homestead, protection of family were the highest objective, and to whom this will to protect their homeland gave the strength to endure any extremities”.
These criticisms suggest that perhaps experiences of the war and the personal reactions of individual soldiers to their experiences may be more diverse than Remarque portrays them; however, it is beyond question that Remarque gives voice to a side of the war and its experience that was overlooked or suppressed at the time. This perspective is crucial to understanding the true effects of World War I. The evidence can be seen in the lingering depression that Remarque and many of his friends and acquaintances were suffering a decade later.
In contrast, "All Quiet on the Western Front" was trumpeted by pacifists as an anti-war book. Remarque makes a point in the opening statement that the novel does not advocate any political position, but is merely an attempt to describe the experiences of the soldier.
The main artistic criticism was that it was a mediocre attempt to cash in on public sentiment. The enormous popularity the work received was a point of contention for some literary critics, who scoffed at the fact that such a simple work could be so earth-shattering. Much of this literary criticism came from Salomo Friedlaender, who wrote a book "Hat Erich Maria Remarque wirklich gelebt?" "Did Erich Maria Remarque ever live". Another author, Max Joseph Wolff, wrote a parody titled "Vor Troja nichts Neues" "Before Troja, nothing new" under the pseudonym "Emil Marius Requark". Friedlaender’s criticism's were mainly personal in nature—he attacked Remarque as being ego-centric and greedy. Remarque publicly stated that he wrote "All Quiet on the Western Front" for personal reasons, not for profit, as Friedlaender had claimed.
Adaptations.
Film.
In 1930, an American film of the novel was made, directed by Lewis Milestone. The screenplay was by Maxwell Anderson, George Abbott, Del Andrews, C. Gardner Sullivan, with uncredited work by Walter Anthony and Milestone. It stars Louis Wolheim, Lew Ayres, John Wray, Arnold Lucy and Ben Alexander.
The film won the Academy Award for Best Picture in 1930 for its producer Carl Laemmle Jr., and an Academy Award for Directing for Lewis Milestone. It was the first all-talking non-musical film to win the Best Picture Oscar. It also received two further nominations: Best Cinematography, for Arthur Edeson, and Best Writing Achievement for Abbott, Anderson and Andrews.
In June 2009, an announcement was made that "All Quiet on the Western Front" would be remade. Director Mimi Leder was linked with the film in 2011, but as of 2013, the film was still listed as being in pre-production.
TV film.
In 1979, the film was remade for CBS television by Delbert Mann, starring Richard Thomas of "The Waltons" as Paul Bäumer and Ernest Borgnine as Kat. The movie was filmed in Czechoslovakia.
Radio.
On November 9, 2008, a radio adaptation of the novel was broadcast on BBC Radio 3, starring Robert Lonsdale as Paul Bäumer and Shannon Graney as Katczinsky. Its screenplay was written by Dave Sheasby and the show was directed by David Hunter.
Music.
Elton John's 1982 album "Jump Up!" features the song, "All Quiet On The Western Front" (written by Elton and Bernie Taupin). The song is a sorrowful rendition of the novel's story ("It's gone all quiet on the Western Front / Male Angels sigh / ghosts in a flooded trench / As Germany dies").
Theatre.
In 2009 prior to a UK Tour, Nottingham Playhouse commissioned a play of the book by Robin Kingsland.

</doc>
<doc id="2154" url="http://en.wikipedia.org/wiki?curid=2154" title="African American">
African American

African Americans, also referred to as Black Americans or Afro-Americans, are citizens of the United States who have total or partial antebellum ancestry from any of the native populations of Sub-Saharan Africa.
African Americans constitute the second largest racial and ethnic minority in the United States. Most African Americans are of West and Central African descent and are descendants of enslaved blacks within the boundaries of the present United States. However, some immigrants from African, Caribbean, Central American, and South American nations, and their descendants, may be identified or self-identify with the term.
African-American history starts in the 16th century, with Africans forcibly taken to Spanish and English colonies in North America as slaves. After the founding of the United States, black people continued to be enslaved and treated as inferiors. These circumstances were changed by Reconstruction, development of the black community, participation in the great military conflicts of the United States, the elimination of racial segregation, and the Civil Rights Movement. In 2008, Barack Obama became the first African American to be elected president of the United States.
History.
Slavery era.
The first African slaves arrived in the present-day United States as part of the San Miguel de Gualdape colony (most likely located in the Winyah Bay area of present-day South Carolina), founded by Spanish explorer Lucas Vázquez de Ayllón in 1526. The ill-fated colony was almost immediately disrupted by a fight over leadership, during which the slaves revolted and fled the colony to seek refuge among local Native Americans. De Ayllón and many of the colonists died shortly afterwards of an epidemic and the colony was abandoned. The settlers and the slaves who had not escaped, returned to Haiti, whence they had come.
In 1565, the colony of Saint Augustine in Florida, founded by Pedro Menendez de Aviles, became the first permanent European settlement in North America. It included an unknown number of free and enslaved Africans that were part of this colonial expedition.
The first recorded Africans in British North America (including most of the future United States) were "20 and odd negroes" who came to Jamestown, Virginia via Cape Comfort in August 1619 as indentured servants. As English settlers died from harsh conditions, more and more Africans were brought to work as laborers. Typically, young men or women would sign a contract of indenture in exchange for transportation to the New World. The landowner received 50 acres of land from the state (headrights) for each servant purchased (around £6 per person [equivalent to 9 months income in the 17th century]) from a ships captain. An indentured servant (who could be white or black) would work for several years (usually four to seven) without wages. The status of indentured servants in early Virginia and Maryland was similar to slavery. Servants could be bought, sold, or leased and they could be physically beaten for disobedience or running away. Unlike slaves, they were freed after their term of service expired or was bought out, their children did not inherit their status, and on their release from contract they received "a year's provision of corn, double apparel, tools necessary" and a small cash payment called "freedom dues".
Africans could legally raise crops and cattle to purchase their freedom. They raised families, marrying other Africans and sometimes intermarrying with Native Americans or English settlers. By the 1640s and 1650s, several African families owned farms around Jamestown and some became wealthy by colonial standards and purchased indentured servants of their own. In 1640, the Virginia General Court recorded the earliest documentation of lifetime slavery when they sentenced John Punch, a Negro, to lifetime servitude under his master Hugh Gwyn for running away. One of Dutch African arrivals, Anthony Johnson, would later own one of the first black "slaves," John Casor, resulting from the court ruling of a civil case.
The popular conception of a race-based slave system did not fully develop until the 18th century. The Dutch West India Company introduced slavery in 1625 with the importation of eleven black slaves into New Amsterdam (present-day New York City). All the colony's slaves, however, were freed upon its surrender to the British. Massachusetts was the first British colony to legally recognize slavery in 1641. In 1662 Virginia passed a law that children of enslaved women (who were of African descent and thus foreigners) took the status of the mother, rather than that of the father, as under English common law. This principle was called "partus sequitur ventrum". By an act of 1699, the colony ordered all free blacks deported, virtually defining as slaves all persons of African descent who remained in the colony. In 1670 the colonial assembly passed a law prohibiting free and baptized negroes (and Indians) from purchasing Christians (in this act meaning English or European whites) but allowing them to buy persons "of their owne nation."
The earliest African-American congregations and churches were organized before 1800 in both northern and southern cities following the Great Awakening. By 1775, Africans made up 20% of the population in the American colonies, which made them the second largest ethnic group after the English. During the 1770s, Africans, both enslaved and free, helped rebellious English colonists secure American Independence by defeating the British in the American Revolution. Africans and Englishmen fought side by side and were fully integrated.
James Armistead, an African American, played a large part in making possible the 1781 Yorktown victory, which established the United States as an independent nation. Baron Closen, a German officer in the French Royal Deux-Ponts Regiment, estimated the American army at Yorktown to be about one quarter black and it is estimated that more than a third of the Americans actually engaged were black. Other prominent African Americans were Prince Whipple and Oliver Cromwell, both of whom are possibly depicted in the front of the boat in the famous "Washington Crossing the Delaware" portrait.
By 1860, there were 3.5 million enslaved African Americans in the United States due to the Atlantic slave trade, and another 500,000 African Americans lived free across the country. In 1863, during the American Civil War, President Abraham Lincoln signed the Emancipation Proclamation. The proclamation declared that all slaves in states which had seceded from the Union were free. Advancing Union troops enforced the proclamation with Texas being the last state to be emancipated in 1865.
Reconstruction and Jim Crow.
African Americans quickly set up congregations for themselves, as well as schools and community/civic associations, to have space away from white control or oversight. While the post-war reconstruction era was initially a time of progress for African Americans, in the late 1890s, Southern states enacted Jim Crow laws to enforce racial segregation and disenfranchisement. Most African Americans followed the Jim Crow laws, using a mask of compliance to prevent becoming victims of racially motivated violence. To maintain self-esteem and dignity, African Americans such as Anthony Overton and Mary McLeod Bethune continued to build their own schools, churches, banks, social clubs, and other businesses.
In the last decade of the 19th century, racially discriminatory laws and racial violence aimed at African Americans began to mushroom in the United States. These discriminatory acts included racial segregation—upheld by the United States Supreme Court decision in Plessy v. Ferguson in 1896—which was legally mandated by southern states and nationwide at the local level of government, voter suppression or disenfranchisement in the southern states, denial of economic opportunity or resources nationwide, and private acts of violence and mass racial violence aimed at African Americans unhindered or encouraged by government authorities.
Great Migration and Civil Rights Movement.
The desperate conditions of African Americans in the South that sparked the Great Migration of the early 20th century, combined with a growing African-American community in the Northern United States, led to a movement to fight violence and discrimination against African Americans that, like abolitionism before it, crossed racial lines. The Civil Rights Movement from 1954 to 1968 was directed at abolishing racial discrimination against African Americans, particularly in the Southern United States. The March on Washington for Jobs and Freedom and the conditions which brought it into being are credited with putting pressure on President John F. Kennedy and Lyndon B. Johnson.
Johnson put his support behind passage of the Civil Rights Act of 1964 that banned discrimination in public accommodations, employment, and labor unions, and the Voting Rights Act of 1965, which expanded federal authority over states to ensure black political participation through protection of voter registration and elections. By 1966, the emergence of the Black Power movement, which lasted from 1966 to 1975, expanded upon the aims of the Civil Rights Movement to include economic and political self-sufficiency, and freedom from white authority.
During the postwar period, many African Americans continued to be economically disadvantaged relative to other Americans. Average black income stood at 54% of that of white workers in 1947, and 55% in 1962. In 1959, median family income for whites was $5,600, compared with $2,900 for nonwhite families. In 1965, 43% of all black families fell into the poverty bracket, earning under $3,000 a year. The Sixties saw improvements in the social and economic conditions of many black Americans.
From 1965 to 1969, black family income rose from 54% to 60% of white family income. In 1968, 23% of black families earned under $3,000 a year, compared with 41% in 1960. In 1965, 19% of black Americans had incomes equal to the national median, a proportion that rose to 27% by 1967. In 1960, the median level of education for blacks had been 10.8 years, and by the late Sixties the figure rose to 12.2 years, half a year behind the median for whites.
Post-Civil Rights era.
Politically and economically, African Americans have made substantial strides during the post-civil rights era. In 1989, Douglas Wilder became the first African American elected governor in U.S. history. Currently, Deval Patrick of Massachusetts, is the only African-American governor in office. Clarence Thomas became the second African-American Supreme Court Justice. In 1992 Carol Moseley-Braun of Illinois became the first African-American woman elected to the U.S. Senate. There were 8,936 black officeholders in the United States in 2000, showing a net increase of 7,467 since 1970. In 2001 there were 484 black mayors.
On November 4, 2008, Democratic Senator Barack Obama defeated Republican Senator John McCain to become the first African American to be elected President. At least 95 percent of African-American voters voted for Obama. He also received overwhelming support from young and educated whites, a majority of Asians, Hispanics, and Native Americans picking up a number of new states in the Democratic electoral column. Obama lost the overall white vote, although he won a larger proportion of white votes than any previous nonincumbent Democratic presidential candidate since Jimmy Carter. Four years later, Obama was reelected president by a similar margin on November 6, 2012.
Demographics.
In 1790, when the first U.S. Census was taken, Africans (including slaves and free people) numbered about 760,000—about 19.3% of the population. In 1860, at the start of the Civil War, the African-American population had increased to 4.4 million, but the percentage rate dropped to 14% of the overall population of the country. The vast majority were slaves, with only 488,000 counted as "freemen". By 1900, the black population had doubled and reached 8.8 million.
In 1910, about 90% of African Americans lived in the South. Large numbers began migrating north looking for better job opportunities and living conditions, and to escape Jim Crow laws and racial violence. The Great Migration, as it was called, spanned the 1890s to the 1970s. From 1916 through the 1960s, more than 6 million black people moved north. But in the 1970s and 1980s, that trend reversed, with more African Americans moving south to the Sun Belt than leaving it.
The following table of the African-American population in the United States over time shows that the African-American population, as a percentage of the total population, declined until 1930 and has been rising since then.
By 1990, the African-American population reached about 30 million and represented 12% of the U.S. population, roughly the same proportion as in 1900. In 2010, 38.9 million Americans identified as "Black or African-American," representing 12.6% of the population. Controversy has surrounded the "accurate" population count of African Americans for decades. The NAACP believed it was under counted intentionally to minimize the significance of the black population in order to reduce their political power base.
At the time of the 2000 Census, 54.8% of African Americans lived in the South. In that year, 17.6% of African Americans lived in the Northeast and 18.7% in the Midwest, while only 8.9% lived in the western states. The west does have a sizable black population in certain areas, however. California, the nation's most populous state, has the fifth largest African-American population, only behind New York, Texas, Georgia, and Florida. According to the 2000 Census, approximately 2.05% of African Americans identified as Hispanic or Latino in origin, many of whom may be of Brazilian, Puerto Rican, Dominican, Cuban, Haitian, or other Latin American descent. The only self-reported "ancestral" groups larger than African Americans are the Irish and Germans. Because many African Americans trace their ancestry to colonial American origins, some simply self-identify as "American".
U.S. cities.
Almost 58% of African Americans lived in metropolitan areas in 2000. With over 2 million black residents, New York City had the largest black urban population in the United States in 2000, overall the city has a 28% black population. Chicago has the second largest black population, with almost 1.6 million African Americans in its metropolitan area, representing about 18 percent of the total metropolitan population.
Among cities of 100,000 or more, Detroit, Michigan had the highest percentage of black residents of any U.S. city in 2010, with 82%. Other large cities with African-American majorities include New Orleans, Louisiana (60%), Baltimore, Maryland (63%) Atlanta, Georgia (54%, see African Americans in Atlanta), Memphis, Tennessee (61%), and Washington, D.C. (50.7%).
The nation's most affluent county with an African-American majority is Prince George's County, Maryland, with a median income of $62,467. Within that county, among the wealthiest communities are Glenn Dale, Maryland and Fort Washington, Maryland. Other affluent predominantly African-American counties include Dekalb County in Georgia, and Charles City County in Virginia. Queens County, New York is the only county with a population of 65,000 or more where African Americans have a higher median household income than White Americans.
The oldest black community in the United States: Seatack. It survives today with a vibrant and very active civic community.
Education.
By 2000, African Americans had advanced greatly. They still lagged overall in education attainment compared to white or Asian Americans, with 14 percent with four-year and 5 percent with advanced degrees, though it was higher than for other minorities. African Americans attend college at about half the rate of whites, but at a greater rate than Americans of Hispanic origin. More African-American women attend and complete college than men. Black schools for kindergarten through twelfth grade students were common throughout the U.S., and a pattern towards re-segregation is currently occurring across the country.
Historically black colleges and universities remain today which were originally set up when segregated colleges did not admit African Americans. As late as 1947, about one third of African Americans over 65 were considered to lack the literacy to read and write their own names. By 1969, illiteracy as it had been traditionally defined, had been largely eradicated among younger African Americans.
US Census surveys showed that by 1998, 89 percent of African Americans aged 25 to 29 had completed high school, less than whites or Asians, but more than Hispanics. On many college entrance, standardized tests and grades, African Americans have historically lagged behind whites, but some studies suggest that the achievement gap has been closing. Many policy makers have proposed that this gap can and will be eliminated through policies such as affirmative action, desegregation, and multiculturalism.
The average graduation rate of blacks in the United States is 52%. Separating this statistic into component parts shows it varies greatly depending upon the state and the school district examined. 38% of black males graduated in the state of New York but in Maine 97% graduated and exceeded the white male graduation rate by 11 percentage points. In much of the southeastern United States and some parts of the southwestern United States the graduation rate of white males was in fact below 70% such as in Florida where a 62% of white males graduated high school. Examining specific school districts paints an even more complex picture. In the Detroit school district the graduation rate of black males was 20% but 7% white males. In the New York City school district 28% of black males graduate high school compared to 57% of white males. In Newark County 76% of black males graduated compared to 67% for white males.
In Chicago, Marva Collins, an African-American educator, created a low cost private school specifically for the purpose of teaching low-income African-American children whom the public school system had labeled as being "learning disabled". One article about Marva Collins' school stated,
Working with students having the worst of backgrounds, those who were working far below grade level, and even those who had been labeled as 'unteachable,' Marva was able to overcome the obstacles. News of third grade students reading at ninth grade level, four-year-olds learning to read in only a few months, outstanding test scores, disappearance of behavioral problems, second-graders studying Shakespeare, and other incredible reports, astounded the public. During the 2006–2007 school year, Collins' school charged $5,500 for tuition, and parents said that the school did a much better job than the Chicago public school system. Meanwhile, during the 2007–2008 year, Chicago public school officials claimed that their budget of $11,300 per student was not enough.
Economic status.
Economically, African Americans have benefited from the advances made during the Civil Rights era, particularly among the educated, but not without the lingering effects of historical marginalization when considered as a whole. The racial disparity in poverty rates has narrowed. The black middle class has grown substantially. In 2010, 45% of African Americans owned their homes, compared to 67% of all Americans. The poverty rate among African Americans has decreased from 26.5% in 1998 to 24.7% in 2004, compared to 12.7% for all Americans.
African Americans have a combined buying power of over $892 billion currently and likely over $1.1 trillion by 2012. In 2002, African American-owned businesses accounted for 1.2 million of the US's 23 million businesses. As of 2011 African American-owned business account for approximately 2 million US businesses. Black-owned businesses experienced the largest growth in number of businesses among minorities from 2002 to 2011.
In 2004, African-American men had the third-highest earnings of American minority groups after Asian Americans and non-Hispanic whites.
Twenty-five percent of blacks had white-collar occupations (management, professional, and related fields) in 2000, compared with 33.6% of Americans overall. In 2001, over half of African-American households of married couples earned $50,000 or more. Although in the same year African Americans were over-represented among the nation's poor, this was directly related to the disproportionate percentage of African-American families headed by single women; such families are collectively poorer, regardless of ethnicity.
In 2006, the median earnings of African-American men was more than black and non-black American women overall, and in all educational levels. At the same time, among American men, income disparities were significant; the median income of African-American men was approximately 76 cents for every dollar of their European American counterparts, although the gap narrowed somewhat with a rise in educational level.
Overall, the median earnings of African-American men were 72 cents for every dollar earned of their Asian American counterparts, and $1.17 for every dollar earned by Hispanic men. On the other hand by 2006, among American women with post-secondary education, African-American women have made significant advances; the median income of African-American women was more than those of their Asian-, European- and Hispanic American counterparts with at least some college education.
The US public sector is the single most important source of employment for African Americans. During 2008–2010, 21.2% of all Black workers were public employees, compared with 16.3% of non-Black workers. Both before and after the onset of the Great Recession, African Americans were 30% more likely than other workers to be employed in the public sector.
The public sector is also a critical source of decent-paying jobs for Black Americans. For both men and women, the median wage earned by Black employees is significantly higher in the public sector than in other industries.
In 1999, the median income of African-American families was $33,255 compared to $53,356 of European Americans. In times of economic hardship for the nation, African Americans suffer disproportionately from job loss and underemployment, with the black underclass being hardest hit. The phrase "last hired and first fired" is reflected in the Bureau of Labor Statistics unemployment figures. Nationwide, the October 2008 unemployment rate for African Americans was 11.1%, while the nationwide rate was 6.5%.
The income gap between black and white families is also significant. In 2005, employed blacks earned 65% of the wages of whites, down from 82% in 1975. "The New York Times" reported in 2006 that in Queens, New York, the median income among African-American families exceeded that of white families, which the newspaper attributed to the growth in the number of two-parent black families. It noted that Queens was the only county with more than 65,000 residents where that was true.
In 2011, it was reported that 72% of black babies were born to unwed mothers. The poverty rate among single-parent black families was 39.5% in 2005, according to Williams, while it was 9.9% among married-couple black families. Among white families, the respective rates were 26.4% and 6% in poverty.
Health.
The life expectancy for Black men in 2008 was 70.8 years. Life expectancy for Black women was 77.5 years in 2008. In 1900, when information on Black life expectancy started being collated, a Black man could expect to live to 32.5 years and a Black woman 33.5 years. In 1900, White men lived an average of 46.3 years and White women lived an average of 48.3 years. African-American life expectancy at birth is persistently five to seven years lower than European Americans.
Black people have higher rates of obesity, diabetes and hypertension than the US average. For adult Black men, the rate of obesity was 31.6% in 2010. For adult Black women, the rate of obesity was 41.2% in 2010. African Americans have higher rates of mortality than does any other racial or ethnic group for 8 of the top 10 causes of death. The cancer incidence rate among African Americans is 10% higher than among European Americans.
Violence has an impact upon African-American life expectancy. A report from the U.S. Department of Justice states "In 2005, homicide victimization rates for blacks were 6 times higher than the rates for whites". The report also found that "94% of black victims were killed by blacks."
AIDS is one of the top three causes of death for African-American men aged 25–54 and for African-American women aged 35–44 years. In the United States, African Americans make up about 48% of the total HIV-positive population and make up more than half of new HIV cases. The main route of transmission for women is through unprotected heterosexual sex. African-American women are 19 times more likely to contract HIV than other women.
Washington, D.C. has the nation's highest rate of HIV/AIDS infection, at 3%. This rate is comparable to what is seen in West Africa, and is considered a severe epidemic. Dr. Ray Martins, Chief Medical Officer at the Whitman-Walker Clinic, the largest provider of HIV care in Washington D.C., estimated that the actual underlying percent with HIV/AIDS in the city is "closer to five percent".
Sexuality.
According to a Gallup survey conducted from June to September 2012, it found that 4.6 percent of Black or African Americans self identify as LGBT; this is greater than the estimated 3.4 percent of American adults that self identify as LGBT in the total population.
Religion.
The majority of African Americans are Protestant of whom many follow the historically black churches. Black church refers to churches which minister predominantly African-American congregations. Black congregations were first established by freed slaves at the end of the 17th century, and later when slavery was abolished more African Americans were allowed to create a unique form of Christianity that was culturally influenced by African spiritual traditions.
According to a 2007 survey, more than half of the African-American population are part of the historically black churches. The largest Protestant denomination among African Americans are the Baptists, distributed mainly in four denominations, the largest being the National Baptist Convention, USA and the National Baptist Convention of America. The second largest are the Methodists, the largest sects are the African Methodist Episcopal Church and the African Methodist Episcopal Zion Church.
Pentecostals are distributed among several different religious bodies with the Church of God in Christ as the largest among them by far. About 16% of African-American Christians are members of white Protestant communions, these denominations (which include the United Church of Christ) mostly have a 2 to 3% African-American membership. There are also large numbers of Roman Catholics, constituting 5% of the African-American population. Of the total number of Jehovah's Witnesses, 22% are black.
Some African Americans follow Islam. Historically, between 15 to 30% of enslaved Africans brought to the Americas were Muslims, but most of these Africans were converted to Christianity during the era of American slavery. However during the 20th century, some African Americans converted to Islam, mainly through the influence of black nationalist groups that preached with distinctive Islamic practices; these include the Moorish Science Temple of America, though the largest organization was the Nation of Islam, founded during the 1930s, which attracted at least 20,000 people as of 1963, prominent members included activist Malcolm X and boxer Muhammad Ali.
Malcolm X is considered the first person to start the movement among African Americans towards mainstream Islam, after he left the Nation and made the pilgrimage to Mecca. In 1975, Warith Deen Mohammed, the son of Elijah Muhammad who took control of the Nation after his death, guided majority of its members to orthodox Islam. However, few members rejected these changes, in particular Louis Farrakhan, who revived the Nation of Islam in 1978 based on its original teachings.
African-American Muslims constitute 20% of the total U.S. Muslim population, the majority are Sunni or orthodox Muslims, some of these identify under the community of W. Deen Mohammed. The Nation of Islam led by Louis Farrakhan has a membership from 20,000–50,000 members.
There are relatively few African-American Jews; estimates of their number range from 20,000 to 200,000. Most of these Jews are part of mainstream groups such as the Reform, Conservative, or Orthodox branches of Judaism; although there are significant numbers of people who are part of non-mainstream Jewish groups, largely the Black Hebrew Israelites, whose beliefs include the claim that African Americans are descended from the Biblical Israelites.
Contemporary issues.
African Americans have improved their social and economic standing significantly since the Civil Rights Movement and recent decades have witnessed the expansion of a robust, African American middle class across the United States. Unprecedented access to higher education and employment in addition to representation in the highest levels of American government has been gained by African Americans in the post-civil rights era.
Nevertheless, due in part to the legacy of slavery, racism and discrimination, African Americans as a group remain at a pronounced economic, educational and social disadvantage in many areas relative to European Americans. Persistent social, economic and political issues for many African Americans include inadequate health care access and delivery; institutional racism and discrimination in housing, education, policing, criminal justice and employment; crime, poverty and substance abuse.
One of the most serious and long standing issues within African-American communities is poverty. Poverty itself is a hardship as it is related to marital stress and dissolution, health problems, low educational attainment, deficits in psychological functioning, and crime. In 2004, 24.7% of African-American families lived below the poverty level. In 2007, the average African-American income was $33,916, compared with $54,920 for whites.
Politics and social issues.
Collectively, African Americans are more involved in the American political process than other minority groups in the United States, indicated by the highest level of voter registration and participation in elections among these groups in 2004. African Americans collectively attain higher levels of education than immigrants to the United States. African Americans also have the highest level of Congressional representation of any minority group in the U.S.
The large majority of African Americans support the Democratic Party. In the 2004 Presidential Election, Democrat John Kerry received 88% of the African-American vote compared to 11% for Republican George W. Bush. Although there is an African-American lobby in foreign policy, it has not had the impact that African-American organizations have had in domestic policy.
Until the New Deal, African Americans were supporters of the Republican Party because it was Republican President Abraham Lincoln who helped in granting freedom to American slaves; at the time, the Republicans and Democrats represented the sectional interests of the North and South, respectively, rather than any specific ideology, and both right and left were represented equally in both parties.
The African-American trend of voting for Democrats can be traced back to the 1930s during the Great Depression, when Franklin D. Roosevelt's New Deal program provided economic relief to African Americans; Roosevelt's New Deal coalition turned the Democratic Party into an organization of the working class and their liberal allies, regardless of region. The African-American vote became even more solidly Democratic when Democratic presidents John F. Kennedy and Lyndon B. Johnson pushed for civil rights legislation during the 1960s.
After over 50 years, marriage rates for "all" Americans began to decline while divorce rates and out-of-wedlock births have climbed. These changes have been greatest among African Americans. After more than 70 years of racial parity black marriage rates began to fall behind whites. Single-parent households have become common, and according to US census figures released in January 2010, only 38 percent of black children live with both their parents.
In 2008, Democrats overwhelmingly voted 70% against California Proposition 8, African Americans voted 58% in favor of it while 42% voted against Proposition 8. On May 9, 2012, Barack Obama, the first African-American president, became the first US president to support same sex marriage. After Obama's endorsement there is a rapid growth in support for same sex marriage among African Americans. Now 59% of African Americans support same sex marriage, which is higher than support among the national average (53%) and white Americans (50%).
Polls in North Carolina, Pennsylvania, Missouri, Maryland, Ohio, Florida, and Nevada have also shown an increase in support for same sex marriage among African Americans. On November 6, 2012, Maryland, Maine, and Washington all voted for approve of same-sex marriage, along with Minnesota rejecting a constitutional amendment banning same-sex marriage. Exit polls in Maryland show about 50% of African Americans voted for same-sex marriage, showing a vast evolution among African Americans on the issue and was crucial in helping pass same-sex marriage in Maryland.
Blacks hold far more conservative opinions on abortion, extramarital sex, and raising children out of wedlock than Democrats as a whole. On financial issues, however, African Americans are very much in line with Democrats, generally supporting a more progressive tax structure to provide more services and reduce injustice and as well as more government spending on social services.
News media and coverage.
Some activists and academics contend that news media coverage of African-American news concerns or dilemmas is inadequate
or the news media present distorted images of African Americans. To combat this, Robert L. Johnson founded Black Entertainment Television, a network that targets young African Americans and urban audiences in the United States. Most programming on the network consists of rap and R&B music videos and urban-oriented movies and series. The channel also shows syndicated television series, original programs, and some public affairs programs. On Sunday mornings, BET broadcasts a lineup of network-produced Christian programming; other, non-affiliated Christian programs are also shown during the early morning hours daily. BET is now a global network that reaches 90 million households in the United States, Caribbean, Canada, and the United Kingdom.
In addition to BET there is Centric, which is a spin-off cable television channel of BET, created originally as "BET on Jazz" to showcase jazz music-related programming, especially that of black jazz musicians. Programming has been expanded to include a block of urban programs as well as some R&B, soul, and world music.
TV One is another African-American-oriented network and a direct competitor to BET, targeting African American adults with a broad range of programming. The network airs original lifestyle and entertainment-oriented shows, movies, fashion and music programming, as well as classic series such as 227, Good Times, Martin, Boston Public and It's Showtime at the Apollo. The network primarily owned by Radio One. Founded and controlled by Catherine Hughes, it is one of the nation's largest radio broadcasting companies and the largest African-American-owned radio broadcasting company in the United States.
Other African-American networks scheduled to launch in 2009 are the Black Television News Channel founded by former Congressman J. C. Watts and Better Black Television founded by Percy Miller. In June 2009, NBC News launched a new website named The Grio in partnership with the production team that created the black documentary film, Meeting David Wilson. It is the first African-American video news site which focuses on underrepresented stories in existing national news. The Grio consists of a broad spectrum of original video packages, news articles, and contributor blogs on topics including breaking news, politics, health, business, entertainment and Black History.
Cultural influence in the United States.
From their earliest presence in North America, African Americans have contributed literature, art, agricultural skills, foods, clothing styles, music, language, social and technological innovation to American culture. The cultivation and use of many agricultural products in the United States, such as yams, peanuts, rice, okra, sorghum, grits, watermelon, indigo dyes, and cotton, can be traced to African and African-American influences. Notable examples include George Washington Carver, who created 300 products from peanuts, 118 products from sweet potatoes, and 75 from pecans; and George Crum, who invented the potato chip in 1853. Soul food is a variety of cuisine popular among African-Americans. It is closely related to the cuisine of the Southern United States. The descriptive terminology may have originated in the mid-1960s, when "soul" was a common definer used to describe African-American culture (for example, soul music).
African-American music is one of the most pervasive African-American cultural influences in the United States today and is among the most dominant in mainstream popular music. Hip hop, R&B, funk, rock and roll, soul, blues, and other contemporary American musical forms originated in black communities and evolved from other black forms of music, including blues, doo-wop, barbershop, ragtime, bluegrass, jazz, and gospel music.
African-American-derived musical forms have also influenced and been incorporated into virtually every other popular musical genre in the world, including country and techno. African-American genres are the most important ethnic vernacular tradition in America, as they have developed independent of African traditions from which they arise more so than any other immigrant groups, including Europeans; make up the broadest and longest lasting range of styles in America; and have, historically, been more influential, interculturally, geographically, and economically, than other American vernacular traditions.
African Americans have also had an important role in American dance. Bill T. Jones, a prominent modern choreographer and dancer, has included historical African-American themes in his work, particularly in the piece "Last Supper at Uncle Tom's Cabin/The Promised Land". Likewise, Alvin Ailey's artistic work, including his "Revelations" based on his experience growing up as an African American in the South during the 1930s, has had a significant influence on modern dance. Another form of dance, Stepping, is an African-American tradition whose performance and competition has been formalized through the traditionally black fraternities and sororities at universities.
Many African-American authors have written stories, poems, and essays influenced by their experiences as African Americans. African-American literature is a major genre in American literature. Famous examples include Langston Hughes, James Baldwin, Richard Wright, Zora Neale Hurston, Ralph Ellison, Nobel Prize winner Toni Morrison, and Maya Angelou.
African-American inventors have created many widely used devices in the world and have contributed to international innovation. Norbert Rillieux created the technique for converting sugar cane juice into white sugar crystals. Moreover, Rillieux left Louisiana in 1854 and went to France, where he spent ten years working with the Champollions deciphering Egyptian hieroglyphics from the Rosetta Stone. Most slave inventors were nameless, such as the slave owned by the Confederate President Jefferson Davis who designed the ship propeller used by the Confederate navy.
By 1913 over 1,000 inventions were patented by black Americans. Among the most notable inventors were Jan Matzeliger, who developed the first machine to mass-produce shoes, and Elijah McCoy, who invented automatic lubrication devices for steam engines. Granville Woods had 35 patents to improve electric railway systems, including the first system to allow moving trains to communicate. Garrett A. Morgan developed the first automatic traffic signal and gas mask.
Lewis Howard Latimer invented an improvement for the incandescent light bulb. More recent inventors include Frederick McKinley Jones, who invented the movable refrigeration unit for food transport in trucks and trains. Lloyd Quarterman worked with six other black scientists on the creation of the atomic bomb (code named the Manhattan Project.) Quarterman also helped develop the first nuclear reactor, which was used in the atomically powered submarine called the Nautilus.
A few other notable examples include the first successful open heart surgery, performed by Dr. Daniel Hale Williams, and the air conditioner, patented by Frederick McKinley Jones. Dr. Mark Dean holds three of the original nine patents on the computer on which all PCs are based. More current contributors include Otis Boykin, whose inventions included several novel methods for manufacturing electrical components that found use in applications such as guided missile systems and computers, and Colonel Frederick Gregory, who was not only the first black astronaut pilot but the person who redesigned the cockpits for the last three space shuttles. Gregory was also on the team that pioneered the microwave instrumentation landing system.
Political legacy.
African Americans have fought in every war in the history of the United States.
The gains made by African Americans in the Civil Rights and Black Power movements not only obtained certain rights for African Americans, but changed American society in far-reaching and fundamentally important ways. Prior to the 1950s, Black Americans in the South were subject to de jure discrimination, or Jim Crow. They would often be the victims of extreme cruelty and violence, sometimes resulting in deaths: by the post WWII era, African Americans became increasingly discontented with their long-standing inequality. In the words of Martin Luther King, Jr., African Americans and their supporters challenged the nation to "rise up and live out the true meaning of its creed that all men are created equal ..."
The Civil Rights Movement marked a sea-change in American social, political, economic and civic life. It brought with it boycotts, sit-ins, demonstrations, court battles, bombings and other violence; prompted worldwide media coverage and intense public debate; forged enduring civic, economic and religious alliances; and disrupted and realigned the nation's two major political parties.
Over time, it has changed in fundamental ways the manner in which blacks and whites interact with and relate to one another. The movement resulted in the removal of codified, "de jure" racial segregation and discrimination from American life and law, and heavily influenced other groups and movements in struggles for civil rights and social equality within American society, including the Free Speech Movement, the disabled, women, Native Americans, and migrant workers.
Terminology.
Political overtones.
The term "African American" carries important political overtones. Earlier terms used to describe Americans of African ancestry referred more to skin color than ancestry, and were conferred upon the group by colonists and Americans of European ancestry; people with dark skins were considered inferior in fact and in law. The terms (such as "colored", "person of color", or "negro") were included in the wording of various laws and legal decisions which some thought were being used as tools of white supremacy and oppression. There developed among blacks in America a growing desire for a term of self-identification of their own choosing.
With the political consciousness that emerged from the political and social ferment of the late 1960s and early 1970s, blacks no longer approved of the term Negro. They believed it had suggestions of a moderate, accommodationist, even "Uncle Tom" connotation. In this period, a growing number of blacks in the United States, particularly African-American youth, celebrated their blackness and their historical and cultural ties with the African continent. The Black Power movement defiantly embraced "Black" as a group identifier. It was a term social leaders themselves had repudiated only two decades earlier, but they proclaimed, "Black is beautiful".
In this same period, a smaller number of people favored "Afro-American", a common shortening (as is 'Anglo-American'). However, after the decline in popularity of the 'Afro' hairstyle in the late 1970s, the term fell out of use.
In the 1980s the term "African American" was advanced on the model of, for example, German-American or Irish-American to give descendants of American slaves and other American blacks who lived through the slavery era a heritage and a cultural base. The term was popularized in black communities around the country via word of mouth and ultimately received mainstream use after Jesse Jackson publicly used the term in front of a national audience. Subsequently, major media outlets adopted its use.
Some such as Maulana Karenga and Owen Alik Shahadah argue African-American is more appropriate, because it accurately articulates geography and historical origin. Thus linking a people to a continent as opposed to an abstract color. Others believe the term black is inaccurate because African Americans have a variety of skin tones. Surveys show that the majority of Black Americans have no preference for "African American" versus "Black," although they have a slight preference for "Black" in personal settings and "African American" in more formal settings.
Many African Americans expressed a preference for the term, as it was formed in the same way as names for others of the many ethnic groups in the nation. Some argued further that, because of the historical circumstances surrounding the capture, enslavement and systematic attempts to de-Africanize blacks in the United States under chattel slavery, most African Americans are unable to trace their ancestry to a specific African nation; hence, the entire continent serves as a geographic marker.
For many, "African American" is more than a name expressive of cultural and historical roots. The term expresses pride in Africa and a sense of kinship and solidarity with others of the African diaspora—an embrace of pan-Africanism as earlier enunciated by prominent African thinkers such as Marcus Garvey, W. E. B. Du Bois and George Padmore. Rarely used terms include Afro-Usonian and African-Usanian,
Identity.
Since 1977, in an attempt to keep up with changing social opinion, the United States government has officially classified black people (revised to "black" or "African American" in 1997) as "having origins in any of the black racial groups of Africa." Other federal offices, such as the United States Census Bureau, adhere to the Office of Management and Budget standards on race in its data collection and tabulations efforts. In preparation for the United States 2010 Census, a marketing and outreach plan, called "2010 Census Integrated Communications Campaign Plan" (ICC) recognized and defined African Americans as black people born in the United States. From the ICC perspective, African Americans are one of three groups of black people in the United States
The ICC plan was to reach the three groups by acknowledging that each group has its own sense of community that is based on geography and ethnicity. The best way to market the census process toward any of the three groups is to reach them through their own unique communication channels and not treat the entire black population of the U.S. as though they are all African Americans with a single ethnic and geographical background. The U.S. Department of Justice Federal Bureau of Investigation categorizes black or African-American people as "A person having origins in any of the black racial groups of Africa" through racial categories used in the UCR Program adopted from the Statistical Policy Handbook (1978) and published by the Office of Federal Statistical Policy and Standards, U.S. Department of Commerce, derived from the 1977 Office of Management and Budget classification.
Admixture.
Historically, "race mixing" between black and white people was taboo in the United States. So-called anti-miscegenation laws, barring blacks and whites from marrying or having sex, were established in colonial America as early as 1691. The taboo among American whites surrounding white-black relations can be seen as a historical consequence of the oppression and racial segregation of African Americans. Historian David Brion Davis notes the racial mixing that occurred during slavery was frequently attributed by the planter class to the "lower-class white males" but Davis concludes that "there is abundant evidence that many slaveowners, sons of slaveowners, and overseers took black mistresses or in effect raped the wives and daughters of slave families." A famous example was Thomas Jefferson's mistress, Sally Hemings.
Harvard University historian Henry Louis Gates, Jr. wrote in 2009, "African Americans ... are a racially mixed or mulatto people—deeply and overwhelmingly so." For example, after the Emancipation Proclamation Chinese American men married African-American women in high proportions to their total marriage numbers due to few Chinese American women being in the United States. African slaves and their descendants have also had a history of cultural exchange and intermarriage with Native Americans although they did not necessarily retain social, cultural or linguistic ties to Native peoples. There are also increasing intermarriages and offspring between non-Hispanic blacks and Hispanics of any race, especially between Puerto Ricans and African Americans (American-born blacks).
Racially mixed marriages have become increasingly accepted in the United States since the Civil Rights movement and up to the present day. Approval in national opinion polls have risen from 36% in 1978, to 48% in 1991, 65% in 2002, 77% in 2007. Scientific analysis indicates that current African Americans inherit about 14–17.7% of their ancestry from Europeans.
The African-American experience.
In her book "The End of Blackness", as well as in an essay on the liberal website "Salon", author Debra Dickerson has argued that the term "black" should refer strictly to the descendants of Africans brought to America as slaves, and not the sons and daughters of black immigrants who lack that ancestry. In her opinion, President Barack Obama, who is the son of a Kenyan immigrant, although technically African-American, is not black. She makes the argument that grouping all people of African descent together regardless of their unique ancestral circumstances would inevitably deny the lingering effects of slavery within the American community of slave descendants, in addition to denying black immigrants recognition of their own unique ancestral backgrounds. "Lumping us all together", Dickerson wrote, "erases the significance of slavery and continuing racism while giving the appearance of progress".
Similar viewpoints have been expressed by Stanley Crouch in a "New York Daily News" piece, Charles Steele, Jr. of the Southern Christian Leadership Conference and African-American columnist David Ehrenstein of the "LA Times" who accused white liberals of flocking to blacks who were "Magic Negros", a term that refers to a black person with no past who simply appears to assist the mainstream white (as cultural protagonists/drivers) agenda. Ehrenstein went on to say "He's there to assuage white 'guilt' they feel over the role of slavery and racial segregation in American history."
Former Secretary of State Condoleezza Rice (who was famously mistaken for a "recent American immigrant" by French President Nicolas Sarkozy), said "descendants of slaves did not get much of a head start, and I think you continue to see some of the effects of that." She has also rejected an immigrant designation for African Americans and instead prefers the term "black" or "white" to denote the African and European U.S. founding populations.
Terms no longer in common use.
The terms mulatto and colored were widely used until the second quarter of the 20th century, when they were considered outmoded and generally gave way to the use of "negro". By the 1940s, the term commonly was capitalized, Negro, but by the mid-1960s it was considered disparaging. By the end of the 20th century "Negro" had come to be considered inappropriate and was rarely used and perceived as a pejorative. The term is rarely used by younger black people, but remained in use by many older African Americans who had grown up with the term, particularly in the southern U.S.
The word "negro" is the Spanish and Portuguese word for the color "black". In regions such as Latin America where these languages are spoken, "negro" (pronounced slightly differently from "Negro" in English), is a normal word used without disparaging intent in relation to black people.
There are many other deliberately insulting terms. Many were in common use ("e.g.", "nigger"), but had become unacceptable in normal discourse before the end of the 20th century.
See also.
Diaspora:
Lists:

</doc>
<doc id="2161" url="http://en.wikipedia.org/wiki?curid=2161" title="Artistic License">
Artistic License

The Artistic License (version 1.0) is a software license used for certain free and open source software packages, most notably the standard implementation of the Perl programming language and most CPAN modules, which are dual-licensed under the Artistic License and the GNU General Public License (GPL). The original Artistic License was written by Larry Wall. The name of the license is a reference to the concept of artistic license.
The terms of the Artistic License 1.0 were at issue in a 2007 federal district court decision in the US, which suggested that FOSS-like licenses could only be enforced through contract law rather than through copyright law, in contexts where contract damages would be difficult to establish. On appeal, a federal appellate court "determined that the terms of the Artistic License are enforceable copyright conditions".
The case was remanded to the District Court which did not apply the superior court's criteria (on the grounds that in the interim, the Supreme Court had changed the applicable law). However, this left undisturbed the finding that a free and open source license nonetheless has economic value.
Artistic License 1.0.
Whether or not the original Artistic License is a free software license is largely unsettled. It was criticized by the Free Software Foundation
as being "too vague; some passages are too clever for their own good, and their meaning is not clear." The Free Software Foundation has also explicitly called the original Artistic License a non-free license. The FSF recommended that the license not be used on its own, but approved the common AL/GPL dual-licensing approach for Perl projects.
In response to this, Bradley Kuhn, who later worked for the Free Software Foundation, made a minimal redraft to clarify the ambiguous passages. This was released as the Clarified Artistic License, and was approved by the FSF. It is used by the SNEeSe emulator, the Paros Proxy, the JavaFBP toolkit and NcFTP.
Artistic License 2.0.
In response to the Request for comments process for improving the licensing position for Perl 6, Kuhn's draft was extensively rewritten by Roberta Cairney and Allison Randal for readability and legal clarity, with input from the Perl community. This resulted in the Artistic License 2.0 which has been approved as both a free software and open source license.
It has been adopted by some of the Perl 6 implementations, and has been used by the Parrot virtual machine since version 0.4.13.
The OSI recommends that all developers and projects licensing their products with the Artistic License adopt Artistic License 2.0.

</doc>
<doc id="2162" url="http://en.wikipedia.org/wiki?curid=2162" title="Afrikaans">
Afrikaans

Afrikaans or is a West Germanic language spoken in South Africa, Namibia and, to a lesser extent, Botswana and Zimbabwe. It is an offshoot of several Dutch dialects spoken by the mainly Dutch settlers of what is now South Africa, where it gradually began to develop independently in the course of the 18th century. Hence, historically, it is a daughter language of Dutch, and was previously referred to as "Cape Dutch" (a term also used to refer collectively to the early Cape settlers) or "kitchen Dutch" (a derogatory term used to refer to Afrikaans in its earlier days).
Although Afrikaans adopted words from languages such as Portuguese, the Bantu languages, Malay, and the Khoisan languages, an estimated 90 to 95% of Afrikaans vocabulary is of Dutch origin.
Therefore, differences with Dutch often lie in the more analytic morphology and grammar of Afrikaans, and a spelling that expresses Afrikaans pronunciation rather than standard Dutch. There is a large degree of mutual intelligibility between the two languages—especially in written form.
With about 7 million native speakers in South Africa, or 13.5% of the population, it is the third-most-spoken mother tongue in the country. It has the widest geographical and racial distribution of all the official languages of South Africa, and is widely spoken and understood as a second or third language. It is the majority language of the western half of South Africa — the provinces of the Northern Cape and Western Cape — and the first language of 75.8% of Coloured South Africans (3.4 million people), 60.8% of White South Africans (2.7 million) and at 4.6% the second most spoken first-language among Asian South Africans (58,000). About 1.5% of black South Africans (600,000 people) speak it as their first language. Large numbers of Bantu-speaking and English-speaking South Africans also speak it as their second language.
In neighbouring Namibia, Afrikaans is widely spoken as a second language and used as "lingua franca", while as a native language it is spoken in 11% of households, mainly concentrated in the capital Windhoek and the southern regions of Hardap and Karas.
Estimates of the total number of Afrikaans-speakers range between 15 and 23 million.
History.
The Afrikaans language arose in the Dutch Cape Colony, through a gradual divergence from European Dutch dialects, during the course of the 18th century. As early as the mid-18th century and as recently as the mid-20th century, Afrikaans was known in standard Dutch as a "kitchen language" (Afr. "kombuistaal"), lacking the prestige accorded, for example even by the educational system in Africa, to languages spoken outside Africa; other early epithets setting apart "Kaaps Hollands" ("Cape Dutch", i.e. Afrikaans) as putatively beneath official Dutch standards included "geradbraakt/gebroken/onbeschaafd Hollands" ("mutilated/broken/uncivilised Dutch"), as well as "verkeerd Nederlands" ("incorrect Dutch"). An estimated 90 to 95% of Afrikaans vocabulary is ultimately of Dutch origin, and there are few lexical differences between the two languages; however, Afrikaans has a considerably more regular morphology, grammar, and spelling. There is a degree of mutual intelligibility between the two languages, particularly in written form.
Afrikaans acquired some lexical and syntactical borrowings from other languages such as Malay, Khoisan languages, Portuguese, and of the Bantu languages, and to a lesser extent, French. Afrikaans has also been significantly influenced by South African English. Nevertheless, Dutch speakers are confronted with fewer noncognates when listening to Afrikaans than the other way round. Mutual intelligibility thus tends to be asymmetrical, as it is easier for Dutch speakers to understand Afrikaans than for Afrikaans speakers to understand Dutch. In general, mutual intelligibility between Dutch and Afrikaans is better than between Dutch and Frisian or between Danish and Swedish. The South African poet writer Breyten Breytenbach, attempting to visualize the language distance to anglophones once remarked that the differences between (Standard) Dutch and Afrikaans are comparable to those between the Received Pronunciation and Southern American English.
Afrikaans was considered a Dutch dialect in South Africa until the early 20th century, when it became recognised as a distinct language under South African law, alongside Standard Dutch, which it eventually replaced as an official language. A relative majority of the first settlers whose descendants today are the Afrikaners were from the United Provinces (now Netherlands and Belgium), though there were also many from Germany, a considerable number from France, and some from Madeira, Norway, Portugal, Scotland, and various other countries.
The workers and slaves who contributed to the development of Afrikaans were Asians (especially Malays) and Malagasys, as well as the Khoi, San, and Bantu peoples who also lived in the area. African creole people in the early 18th century — documented on the cases of Hendrik Bibault and patriarch Oude Ram — were the first to call themselves "Afrikaner" (Africans). Only much later in the second half of the 19th century did the Boers adopt this attribution, too. The Khoi and mixed-race groups became collectively referred to as 'Coloureds'.
Dialects.
Following early dialectical studies of Afrikaans, it was theorised that three main historical dialects probably existed after the Great Trek in the 1830s. These dialects are the "Northern Cape", "Western Cape", and "Eastern Cape" dialects. Northern Cape dialect may have resulted from contact between Dutch settlers and the Khoi-Khoi people between the Great Karoo and the Kunene, and Eastern Cape dialect between the Dutch and the Xhosa. Remnants of these dialects still remain in present-day Afrikaans, although the standardising effect of Standard Afrikaans has contributed to a great levelling of differences in modern times.
There is also a prison cant, known as soebela or sombela, which is based on Afrikaans, yet heavily influenced by Zulu. This language is used as a secret language in prison and is taught to initiates.
Kaapse Afrikaans.
The term "Kaapse Afrikaans" ("Cape Afrikaans") is sometimes erroneously used to refer to the entire Western Cape dialect; it is more commonly used for a particular sociolect spoken in the Cape Peninsula of South Africa. Kaapse Afrikaans was once spoken by all population groups. However, it became increasingly restricted to the Cape Coloured ethnic group in Cape Town and environs.
Kaapse Afrikaans preserves some features more similar to Dutch than to Afrikaans.
Kaapse Afrikaans has some other features not typically found in Afrikaans.
Kaapse Afrikaans is also characterised by much code-switching between English and Afrikaans, especially in the inner-city and lower socio-economic status areas of Cape Town.
An example of characteristic Kaapse Afrikaans
Oranjerivierafrikaans.
The term "Oranjeriverafrikaans" ("Afrikaans of the Orange River") is sometimes erroneously used to refer to the Northern Cape dialect; it is more commonly used for the regional peculiarities of standard Afrikaans spoken in the Upington/Orange River wine district of South Africa.
Some of the characteristics of Oranjerivierafrikaans are the plural form -goed (Ma-goed, meneergoed), variant pronunciation such as in "kjerk" ("Church") and "gjeld" ("money") and the ending "-se", which indicates possession.
Expatriate geolect.
Although Afrikaans is mainly spoken in South Africa and Namibia, smaller Afrikaans-speaking populations live in Argentina, Australia, Botswana, Brazil, Canada, Lesotho, Malawi, the Netherlands, New Zealand, Swaziland, the UAE, the United Kingdom, the United States, Zambia, and Zimbabwe. Most, if not all, Afrikaans-speaking people living outside Africa are emigrants and their descendants. Because of emigration and migrant labour, more than 100,000 Afrikaans speakers may live in the United Kingdom.
Standardisation.
The linguist Paul Roberge suggested the earliest 'truly Afrikaans' texts are doggerel verse from 1795 and a dialogue transcribed by a Dutch traveller in 1825. Printed material among the Afrikaners at first used only standard European Dutch. By the mid-19th century, more and more were appearing in Afrikaans, which was very much still regarded as a set of regional dialects.
In 1861, L.H. Meurant published his ' ("Conversation between Claus Truthsayer and John Doubter"), which is considered by some to be the first authoritative Afrikaans text. Abu Bakr Effendi also compiled his Arabic Afrikaans Islamic instruction book between 1862 and 1869, although this was only published and printed in 1877. The first Afrikaans grammars and dictionaries were published in 1875 by the ' ('Society for Real Afrikaners') in Cape Town.
The First and Second Boer Wars further strengthened the position of Afrikaans. The official languages of the Union of South Africa were English and Dutch until Afrikaans was subsumed under Dutch on 5 May 1925.
The main Afrikaans dictionary is the Woordeboek van die Afrikaanse Taal (WAT) (Dictionary of the Afrikaans Language), which is as yet incomplete owing to the scale of the project, but the one-volume dictionary in household use is the Verklarende Handwoordeboek van die Afrikaanse Taal (HAT). The official orthography of Afrikaans is the "Afrikaanse Woordelys en Spelreëls", compiled by Die Taalkommissie.
The Afrikaans Bible.
A major landmark in the development of the language was the translation of the whole Bible into Afrikaans. Before this, most Cape Dutch-Afrikaans speakers had to rely on the Dutch Statenbijbel. This Statenvertaling had its origins with the Synod of Dordrecht of 1618 and was thus in an archaic form of Dutch. This was hard for Dutch and Cape Dutch speakers to understand, and increasingly unintelligible for Afrikaans speakers.
C. P. Hoogehout, , and Stephanus Jacobus du Toit were the first Afrikaans Bible translators. Important landmarks in the translation of the Scriptures were in 1878 with C. P. Hoogehout's translation of the "Evangelie volgens Markus" (Gospel of Mark, lit. Gospel according to Mark), however this translation was never published. The manuscript is to be found in the South African National Library, Cape Town.
The first official translation of the entire Bible into Afrikaans was in 1933 by J. D. du Toit, E. E. van Rooyen, J. D. Kestell, H. C. M. Fourie, and BB Keet. This monumental work established Afrikaans as "", that is "a pure and proper language" for religious purposes, especially amongst the deeply Calvinist Afrikaans religious community that previously had been rather sceptical of a Bible translation that varied from the Dutch version that they were used to.
In 1983 a fresh translation marked the 50th anniversary of the 1933 version and provided a much needed revision. The final editing of this edition was done by E. P. Groenewald, A. H. van Zyl, P. A. Verhoef, J. L. Helberg and W. Kempen.
Grammar.
In Afrikaans grammar, there is no distinction between the infinitive and present forms of verbs, with the exception of the verbs 'to be' and 'to have':
In addition, verbs do not conjugate differently depending on the subject. For example,
Only a handful of Afrikaans verbs have a preterite, namely the auxiliary "wees" ("to be"), the modal verbs, and the verb "dink" ("to think"). The preterite of "mag" ("may") is rare in contemporary Afrikaans.
All other verbs use the perfect tense ("hê" + past participle) for the past. Therefore there is no distinction in Afrikaans between "I drank" and "I have drunk". (Also in colloquial German, the past tense is also widely replaced with the perfect.)
When telling a longer story, Afrikaans speakers usually avoid the perfect and simply use the present tense instead (as is possible, but less common, in English as well).
A particular feature of Afrikaans is its use of the double negative; it is classified in Afrikaans as "ontkennende vorm" and is something that is absent from the other West Germanic standard languages. For example,
Both French and San origins have been suggested for double negation in Afrikaans. While double negation is still found in Low Franconian dialects in West-Flanders and in some "isolated" villages in the center of the Netherlands (i.e. Garderen), it takes a different form, which is not found in Afrikaans. The following is an example:
The "-ne" was the Middle Dutch way to negate but it has been suggested that since "-ne" became highly non-voiced, nie or niet was needed to complement the "-ne". With time the "-ne" disappeared in most Dutch dialects.
The double negative construction has been fully grammaticalized in standard Afrikaans and its proper use follows a set of fairly complex rules as the examples below show:
The Dutch word "het" ("it" in English) does not correspond to "het" in Afrikaans; the Dutch word "heb" corresponds to "het" in Afrikaans.
A notable exception to this is the use of the negating grammar form that coincides with negating the English present participle. In this case there is only a single negation.
Certain words in Afrikaans arise due to grammar. For example, "moet nie", which literally means "must not", usually becomes "moenie"; although one does not have to write or say it like this, virtually all Afrikaans speakers will change the two words to "moenie" in the same way as "do not" shifts to "don't" in English.
Sounds.
Afrikaans' sound system is similar to that of other West Germanic languages like Dutch or Frisian.
Orthography.
There are many parallels to the Dutch orthography conventions and those used for Afrikaans. There are 26 letters.
In Afrikaans, many consonants are dropped from the earlier Dutch spelling. For example, "slechts" ('only') in Dutch becomes "slegs" in Afrikaans. For example, Afrikaans and some Dutch dialects make no distinction between and , having merged the latter into the former; while the word for "south" is written " in Dutch, it is spelled " in Afrikaans to represent this merger. Similarly, the Dutch digraph "ĳ", normally pronounced as , is written as "y", except where it replaces the Dutch suffix "–lijk" which is pronounced as or , as in " > ".
Another difference is the indefinite article, ' in Afrikaans and in Dutch. 'A book' is ' in Afrikaans, whereas it is either ' or ' in Dutch. This "" is usually pronounced as just a weak vowel, .
The diminutive suffix in Afrikaans is "-tjie", whereas in Dutch it is "-tje", hence a "bit" is in Afrikaans and in Dutch.
The letters "c", "q", "x", and "z" occur almost exclusively in borrowings from French, English, Greek and Latin. This is usually because words that had "c" and "ch" in the original Dutch are spelled with "k" and "g", respectively, in Afrikaans. Similarly original "qu" and "x" are spelt "kw" and "ks" respectively. For example "" instead of "equatoriaal", and "" instead of "excuus".
The vowels with diacritics in non-loanword Afrikaans are: "á, é, è, ê, ë, í, î, ï, ó, ô, ú, û, ý". Diacritics are ignored when alphabetising, though they are still important, even when typing the diacritic forms may be difficult. For example " instead of the 3 e's alongside each other: geeet which can never occur in Afrikaans or " which translates to say, whereas " is a possessive form.
Initial apostrophes.
A few short words in Afrikaans take initial apostrophes. In modern Afrikaans, these words are always written in lower case (except if the entire line is uppercase), and if they occur at the beginning of a sentence, the next word is capitalised. Three examples of such apostrophed words are '. The last (the indefinite article) is the only apostrophed word that is common in modern written Afrikaans, since the other examples are shortened versions of other words (' and " respectively) and are rarely found outside of a poetic context.
Here are a few examples:
The apostrophe and the following letter are regarded as two separate characters, and are never written using a single glyph, although a single character variant of the indefinite article appears in Unicode, .
Table of characters.
For more on the pronunciation of the letters below, see "".
Afrikaans phrases.
Afrikaans is a very centralised language, meaning that most of the vowels are pronounced in a very centralised (or schwa-like) way. Although there are many different dialects and accents, the transcription would be fairly standard.
It should be noted that in the Dutch language the word "Afrikaans" means African, in the general sense. Consequently Afrikaans is commonly but incorrectly denoted as "Zuid-Afrikaans". This ambiguity also exists in Afrikaans itself and is either resolved in the context of its usage, or by using "Afrikaan" for an African person, and "Afrika-" in the adjective sense.
The following Afrikaans sentences, which have the same meaning in English, are also written identically though their pronunciation differs:
Sample text.
Psalm 23 1983 translation:
"Die Here is my Herder, ek kom niks kort nie."<br>
"Hy laat my in groen weivelde rus. Hy bring my by waters waar daar vrede is."<br>
"Hy gee my nuwe krag. Hy lei my op die regte paaie tot eer van Sy naam."<br>
"Selfs al gaan ek deur donker dieptes, sal ek nie bang wees nie, want U is by my. In U hande is ek veilig."
Psalm 23 alternative translation:
"Die Here is my Herder, niks sal my ontbreek nie."<br>
"Hy laat my neerlê in groen weivelde; na waters waar rus is, lei Hy my heen."<br>
"Hy verkwik my siel; Hy lei my in die spore van geregtigheid, om sy Naam ontwil."<br>
"Al gaan ek ook in 'n dal van doodskaduwee, ek sal geen onheil vrees nie; want U is met my: u stok en u staf die vertroos my."
Lord's Prayer (Afrikaans New Living translation)
"Ons Vader in die hemel, laat U Naam geheilig word."<br>
"Laat U koningsheerskappy spoedig kom."<br>
"Laat U wil hier op aarde uitgevoer word soos in die hemel."<br>
"Gee ons die porsie brood wat ons vir vandag nodig het."<br>
"En vergeef ons ons sondeskuld soos ons ook óns skuldenaars vergewe het."<br>
"Bewaar ons sodat ons nie aan verleiding sal toegee nie; en bevry ons van die greep van die Bose."<br>
"Want van U is die koninkryk,"<br>
"en die krag,"<br>
"en die heerlikheid,"<br>
"tot in ewigheid. Amen"
Lord's Prayer (Original translation):
"Onse Vader wat in die hemel is,"<br>
"laat U Naam geheilig word;"<br>
"laat U koninkryk kom;"<br>
"laat U wil geskied op die aarde,"<br>
"net soos in die hemel."<br>
"Gee ons vandag ons daaglikse brood;"<br>
"en vergeef ons ons skulde"<br>
"soos ons ons skuldenaars vergewe"<br>
"en laat ons nie in die versoeking nie"<br>
"maar verlos ons van die Bose"<br>
"Want aan U behoort die koninkryk"<br>
"en die krag"<br>
"en die heerlikheid"<br>
"tot in ewigheid. Amen"
Sociolinguistics.
Some state that instead of "Afrikaners" which refers to an ethnic group, the terms "Afrikaanses" or "Afrikaanssprekendes" (lit. Afrikaans speakers) should be used for people of any ethnic origin who speak Afrikaans. Linguistic identity has not yet established which terms shall prevail, and all three are used in common parlance.
Afrikaans is also widely spoken in Namibia. Before independence, Afrikaans had equal status with German as an official language. Since independence in 1990, Afrikaans has had constitutional recognition as a national, but not official, language. There is a much smaller number of Afrikaans speakers among Zimbabwe's white minority, as most have left the country since 1980. Afrikaans was also a medium of instruction for schools in Bophuthatswana Bantustan.
Many South Africans living and working in Belgium, the Netherlands, the United Kingdom, Australia, New Zealand, Canada, the United States and Kuwait are also Afrikaans-speaking. They have access to Afrikaans websites, news sites such as and , and radio broadcasts over the web, such as those from Radio Sonder Grense and Radio Pretoria.
Afrikaans has been influential in the development of South African English. Many Afrikaans loanwords have found their way into South African English, such as 'bakkie' ("pickup truck"), 'braai' ("barbecue"), 'naartjie' ("tangerine"), 'tekkies' (AE "sneakers"/BE "trainers"/CE "runners"). A few words in standard English are derived from Afrikaans, such as 'aardvark' (lit. "earth pig"), 'trek' ("pioneering journey", in Afrikaans lit. "pull" but used also for "migrate"), "spoor" ("animal track"), "veld" ("Southern African grassland" in Afrikaans lit. "field"), "commando" from Afrikaans "kommando" meaning small fighting unit, "boomslang" ("tree snake") and apartheid ("segregation"; more accurately "apartness" or "the state or condition of being apart").
In 1976, secondary school pupils in Soweto began a rebellion in response to the government's decision that Afrikaans be used as the language of instruction for half the subjects taught in non-White schools (with English continuing for the other half). Although English is the mother tongue of only 8.2% of the population, it is the language most widely understood, and the second language of a majority of South Africans. Afrikaans is more widely spoken than English in the Northern and Western Cape provinces, several hundred kilometers from Soweto. The Black community's opposition to Afrikaans and preference for continuing English instruction was underscored when the government rescinded the policy one month after the uprising: 96% of Black schools chose English (over Afrikaans or native languages) as the language of instruction.
Under South Africa's Constitution of 1996, Afrikaans remains an official language, and has equal status to English and nine other languages. The new policy means that the use of Afrikaans is now often reduced in favour of English, or to accommodate the other official languages. In 1996, for example, the South African Broadcasting Corporation reduced the amount of television airtime in Afrikaans, while South African Airways dropped its Afrikaans name "" from its livery. Similarly, South Africa's diplomatic missions overseas now only display the name of the country in English and their host country's language, and not in Afrikaans.
In spite of these moves, the language has remained strong, and Afrikaans newspapers and magazines continue to have large circulation figures. Indeed, the Afrikaans-language general-interest family magazine "Huisgenoot" has the largest readership of any magazine in the country. In addition, a pay-TV channel in Afrikaans called KykNet was launched in 1999, and an Afrikaans music channel, MK (Musiek kanaal) (lit. 'Music Channel'), in 2005. A large number of Afrikaans books are still published every year, mainly by the publishers Human & Rousseau, Tafelberg Uitgewers, Struik, and Protea Boekhuis.
Afrikaans has two monuments erected in its honour. The first was erected in Burgersdorp, South Africa, in 1893, and the second, better-known Afrikaans Language Monument ("") was built in Paarl, South Africa, in 1975.
When the British design magazine "Wallpaper" described Afrikaans as "one of the world's ugliest languages" in its September 2005 article about the monument, South African billionaire Johann Rupert (chairman of the Richemont Group), responded by withdrawing advertising for brands such as Cartier, Van Cleef & Arpels, Montblanc and Alfred Dunhill from the magazine. The author of the article, Bronwyn Davies, was an English-speaking South African.
Modern Dutch and Afrikaans share over 90 per cent of their vocabulary. Afrikaans speakers are able to learn Dutch within a comparatively short time. Native Dutch speakers pick up written Afrikaans even more quickly, due to its simplified grammar, whereas understanding spoken Afrikaans might need more effort. Afrikaans speakers can learn Dutch pronunciation with little training. This has enabled Dutch and Belgian companies to outsource their call centre operations to South Africa.
Future of Afrikaans.
Post-apartheid South Africa has seen a loss of preferential treatment by the government for Afrikaans, in terms of education, social events, media (TV and radio), and general status throughout the country, given that it now shares its place as official language with ten other languages. Nevertheless, Afrikaans remains more prevalent in the media – radio, newspapers and television – than any of the other official languages, except English. More than 300 book titles in Afrikaans are published annually. South African census figures suggest a growing number of speakers in all 9 provinces, a total of 6.85 million in 2011 compared to 5.98 million a decade earlier. The South African Institute of Race Relations (SAIRR) project that a growing majority will be Coloured Afrikaans speakers. Afrikaans speakers enjoy higher employment rates than other South African language groups, though half a million remain unemployed.
Despite the challenges of demotion and emigration that it faces in South Africa, the Afrikaans vernacular remains competitive, being popular in DSTV pay channels and several internet sites, while generating high newspaper and music CD sales. A resurgence in Afrikaans popular music since the late 1990s has invigorated the language, especially among a younger generation of South Africans. A recent trend is the increased availability of pre-school educational CDs and DVDs. Such media also prove popular with the extensive Afrikaans-speaking expatriate communities who seek to retain language proficiency in a household context.
After years of slumber, Afrikaans language cinema is showing signs of new vigour. The 2007 film "Ouma se slim kind", the first full-length Afrikaans movie since Paljas of 1998, is seen as the dawn of a new era in Afrikaans cinema. Several short films have been created and more feature-length movies, such as "Poena is Koning" and "Bakgat" (both in 2008) have been produced, besides the 2011 Afrikaans-language film "Skoonheid", which was the first Afrikaans film to screen at the Cannes Film Festival. The film "Platteland" was also released in 2011.
Afrikaans seems to be returning to the SABC. SABC3 announced early in 2009 that it would increase Afrikaans programming due to the "growing Afrikaans-language market and [their] need for working capital as Afrikaans advertising is the only advertising that sells in the current South African television market". In April 2009, SABC3 started screening several Afrikaans-language programmes. Further latent support for the language derives from its de-politicised image in the eyes of younger-generation South Africans, who less and less often view it as "the language of the oppressor". Indeed, there is a groundswell movement within Afrikaans to be inclusive, and to promote itself along with the other indigenous official languages.
In Namibia, the percentage of Afrikaans speakers declined from 11.4% (2001 Census) to 10.4% (2011 Census). The major concentrations are in Hardap (41.0%), Karas (36.1%), Erongo (20.5%), Khomas (18.5%), Omaheke (10.0%), Otjozondjupa (9.4%), Kunene (4.2%), and Oshikoto (2.3%).

</doc>
<doc id="2163" url="http://en.wikipedia.org/wiki?curid=2163" title="Aeolus">
Aeolus

Aeolus (; , "Aiolos" , Modern Greek: ), a name shared by three mythical characters, was the ruler of the winds in Greek mythology. These three personages are often difficult to tell apart, and even the ancient mythographers appear to have been perplexed about which Aeolus was which. Diodorus Siculus made an attempt to define each of these three (although it is clear he also became muddled), and his opinion is followed here. Briefly, the first Aeolus was a son of Hellen and eponymous founder of the Aeolian race; the second was a son of Poseidon, who led a colony to islands in the Tyrrhenian Sea; and the third Aeolus was a son of Hippotes who is mentioned in "Odyssey" book 10 as Keeper of the Winds who gives Odysseus a tightly closed bag full of the captured winds so he could sail easily home to Ithaca on the gentle West Wind. But instead his men thought it was filled with riches, so they opened it which is why the journey was extended. All three men named Aeolus appear to be connected genealogically, although the precise relationship, especially regarding the second and third Aeolus, is often ambiguous.
Son of Hellen.
This Aeolus was son of Hellen and the nymph Orseis, and a brother of Dorus, Xuthus and, in some sources, of Amphictyon (who is otherwise a brother of Hellen). Described as the ruler of Aeolia (later called Thessaly) and held to be the founder of the Aeolic branch of the Greek nation, this Aeolus married Enarete, daughter of Deimachus (otherwise unknown). Aeolus and Enarete had many children, although the precise number and identities of these children vary from author to author in the ancient sources. The great extent of country which this race occupied, and the desire of each part of it to trace its origin to some descendant of Aeolus, probably gave rise to the varying accounts about the number of his children. Some scholars contend that the most ancient and genuine story told of only four sons of Aeolus: Sisyphus, Athamas, Cretheus, and Salmoneus, as the representatives of the four main branches of the Aeolic race. Other sons included Deioneus, Perieres, Cercaphas and perhaps Magnes (usually regarded as a brother of Macedon) and Aethlius. Another son is named Mimas, who provides a link to the third Aeolus in a genealogy that seems very contrived. Calyce, Peisidice, Perimede and Alcyone were counted among the daughters of Aeolus and Enarete. This Aeolus also had an illegitimate daughter named Arne, begotten on Melanippe, daughter of the Centaur Chiron. This Arne became the mother of the second Aeolus, by the god Poseidon.
Son of Poseidon.
This Aeolus was a son of Poseidon by Arne, daughter of Aeolus. He had a twin brother named Boeotus. Arne confessed to her father that she was with child by the god Poseidon; her father, however, did not believe her, and handed her over to a man named Metapontus, King of Icaria. When Bœotus and Aeolus were born, they were raised by Metapontus; but their stepmother (Autolyte, wife of Metapontus) quarrelled with their mother Arne, prompting Bœotus and Aeolus to kill Autolyte and flee from Icaria. Bœotus (accompanied by Arne) went to southern Thessaly, and founded Boeotia; but Aeolus went to a group of islands in the Tyrrhenian Sea, which received from him the name of the Aeolian Islands; according to some accounts this Aeolus founded the town of Lipara. Although his home has been traditionally identified as one of the Aeolian Islands (there is little consensus as to which), near Sicily, an alternative location has been suggested at Gramvousa off the northwest coast of Crete. Aeolus had six sons and six daughters, whom in Homer he wed to one another and the family lived happily together. Later writers were shocked by the incest: in Hyginus, the day Aeolus learned that one of his sons, Macareus, had committed incest with his sister Canace he expelled Macareus and threw the child born of this incestuous union to the dogs, and sent his daughter a sword by which she was to kill herself. Other late accounts claim that Macareus had a daughter named Amphissa, beloved by Apollo.
Son of Hippotes.
This Aeolus is most frequently conflated with Aeolus, the son of Poseidon, god of the sea. It is difficult to differentiate this Aeolus from the second Aeolus, as their identities seem to have been merged by many ancient writers. The father of this third Aeolus is given as Hippotes, son of Mimas, a son of the first Aeolus (son of Hellen). According to some accounts, Hippotes married the same Melanippe who was the mother of Arne. This Aeolus lived on the floating island of Aeolia and was visited by Odysseus and his crew in the "Odyssey." He gave hospitality for a month and provided for a west wind to carry them home. He also provided a gift of a bag containing all winds but the west, which Odysseus's crew members unwittingly opened just before they were to reach Ithaca. Unfortunately, they were blown back to Aeolia, where Aeolus refused to provide any further help, because he believed that their short and unsuccessful voyage meant that the gods did not favour them. This Aeolus was perceived by post-Homeric authors as a god, rather than as a mortal and simple Keeper of the Winds (as in the "Odyssey"). 
Like the previous, this Aeolus was said to have had twelve children - six sons and six daughters. According to Diodorus, he was father of six sons by Cyane, daughter of Liparus (the eponym of the island Lipara, whom Aeolus assisted in conquering lands above Surrentum, Italy). The sons' names were Agathyrnus, Astyochus, Androcles, Iocastus, Pheraemon, Xuthus, whereas the daughters are not mentioned at all. The sons were said to have become kings: Iocastus of the region in southern Italy as far as Rhegium; Pheraemon and Androcles of the part of Sicily between the Strait of Messina and Lilybaeum; Xuthus of Leontini; Agathyrnus of what was known as Agathyrnitis, having founded Agathyrnum; and Astyochus of Lipara. All were said to have been remembered as just and pious rulers. Another list of Aeolus' children is found in scholia on the "Odyssey". The latter source gives the sons' names as Androcles, Chrysippus, Iocastus, Phalacrus, Pheraemon, Xuthus, and the daughters' as Aeole, Astycrateia, Dia, Hephaestia, Iphthe, Periboea; their mother in this account is Telepora or Telepatra, daughter of Laestrygon.
Parthenius of Nicaea recorded a love affair between Odysseus and Aeolus' daughter Polymele; the latter was said to have ended up betrothed to her own brother Diores. 
In the "Aeneid" by Virgil, Juno offers Aeolus the nymph Deiopea as a wife if he will release his winds upon the fleet of Aeneas.

</doc>
<doc id="2166" url="http://en.wikipedia.org/wiki?curid=2166" title="ABC">
ABC

ABC are the first three letters of the Latin script.
ABC may refer to:

</doc>
<doc id="2167" url="http://en.wikipedia.org/wiki?curid=2167" title="Alford plea">
Alford plea

An "Alford" plea (also called a Kennedy plea in West Virginia, an
Alford" guilty plea, and the Alford" doctrine) in United States law is a guilty plea in criminal court, whereby a defendant in a criminal case does not admit the criminal act and asserts innocence. In entering an Alford plea, the defendant admits that the evidence the prosecution has would be likely to persuade a judge or jury to find the defendant guilty beyond a reasonable doubt.
Origin.
The "Alford" guilty plea is named after the United States Supreme Court case of "North Carolina v. Alford" (1970). Henry Alford had been indicted on a charge of first-degree murder in 1963. Evidence in the case included testimony from witnesses that Alford had said after the death of the victim that he had killed the individual. Court testimony showed Alford and the victim argued at the victim's house. Alford left the house, and afterwards the victim received a fatal gunshot wound when he opened the door responding to a knock.
Alford was faced with the possibility of capital punishment if convicted by a jury trial. The death penalty was the automatic sentence by North Carolina law at the time, if two requisites in the case were satisfied: the defendant had to have pleaded not guilty, and the jury did not instead recommend a life sentence. Had he pled guilty to first-degree murder, Alford would have had the possibility of a life sentence, but would have avoided the death penalty. The defendant did not want to admit guilt. Alford pled guilty to second-degree murder, and said he was doing so to avoid a death sentence if he had been convicted of first-degree murder after attempting to contest that charge. Alford was sentenced to thirty years in prison, after the trial judge in the case accepted the plea bargain and ruled that the defendant had been adequately informed by his lawyer.
Alford appealed and requested a new trial, arguing he was forced into a guilty plea because he was afraid of receiving a death sentence. The Supreme Court of North Carolina ruled that the defendant had voluntarily entered the guilty plea, with knowledge of what that meant. Following this ruling, Alford petitioned for a writ of habeas corpus in the United States District Court for the Middle District of North Carolina, which upheld the initial ruling, and subsequently to the United States Court of Appeals for the Fourth Circuit which ruled that Alford's plea was not voluntary, because it was made under fear of the death penalty. "I just pleaded guilty because they said if I didn't, they would gas me for it," wrote Alford in one of his appeals.
The case was then appealed to the Supreme Court. Supreme Court Justice Byron White wrote the decision for the majority. The Supreme Court held that for the plea to be accepted, the defendant must have been advised by a competent lawyer who was able to inform the individual that his best decision in the case would be to enter a guilty plea. The Court ruled that the defendant can enter such a plea "when he concludes that his interests require a guilty plea and the record strongly indicates guilt." The Court allowed the guilty plea only with a simultaneous protestation of innocence as there was enough evidence to show that the prosecution had a strong case for a conviction, and the defendant was entering such a plea to avoid this possible sentencing. The Court went on to note that even if the defendant could have shown that he would not have entered a guilty plea "but for" the rationale of receiving a lesser sentence, the plea itself would not have been ruled invalid. As evidence existed that could have supported Alford's conviction, the Supreme Court held that his guilty plea was allowable while the defendant himself still maintained that he was not guilty.
Definition.
The "Dictionary of Politics: Selected American and Foreign Political and Legal Terms" defines the term Alford plea as: "A plea under which a defendant may choose to plead guilty, not because of an admission to the crime, but because the prosecutor has sufficient evidence to place a charge and to obtain conviction in court. The plea is commonly used in local and state courts in the United States." According to "University of Richmond Law Review", "When offering an Alford plea, a defendant asserts his innocence but admits that sufficient evidence exists to convict him of the offense." "A Guide to Military Criminal Law" notes that under the Alford plea, "the defendant concedes that the prosecution has enough evidence to convict, but the defendant still refuses to admit guilt." The book "Plea Bargaining's Triumph: A History of Plea Bargaining in America" published by Stanford University Press defines the plea as one in "which the defendant adheres to his/her claim of innocence even while allowing that the government has enough evidence to prove his/her guilt beyond a reasonable doubt". According to the book "Gender, Crime, and Punishment" published by Yale University Press, "Under the Alford doctrine, a defendant does not admit guilt but admits that the state has sufficient evidence to find him or her guilty, should the case go to trial." "Webster's New World Law Dictionary" defines Alford plea as: "A guilty plea entered as part of a plea bargain by a criminal defendant who denies committing the crime or who does not actually admit his guilt. In federal courts, such plea may be accepted as long as there is evidence that the defendant is actually guilty."
The Alford guilty plea is "a plea of guilty containing a protestation of innocence". The defendant pleads guilty, but does not have to specifically admit to the guilt itself. The defendant maintains a claim of innocence, but agrees to the entry of a conviction in the charged crime. Upon receiving an Alford guilty plea from a defendant, the court may immediately pronounce the defendant guilty and impose sentence as if the defendant had otherwise been convicted of the crime. Sources disagree, as may differing states' laws, as to what category of plea the "Alford" plea falls under: Some sources state that the Alford guilty plea is a form of "nolo contendere", where the defendant in the case states "no contest" to the factual matter of the case as given in the charges outlined by the prosecution. Others hold that an "Alford" plea is simply one form of a guilty plea, and, as with other guilty pleas, the judge must see there is some factual basis for the plea.
Defendants can take advantage of the ability to use the Alford guilty plea, by admitting there is enough evidence to convict them of a higher crime, while at the same time pleading guilty to a lesser charge. Defendants usually enter an Alford guilty plea if they want to avoid a possible worse sentence were they to lose the case against them at trial. It affords defendants the ability to accept a plea bargain, while maintaining innocence.
Court and government usage.
This form of guilty plea has been frequently used in local and state courts in the United States, though it consists of a small percentage of all plea bargains in the U.S. This form of plea is not allowed in courts of the United States military. In 2000 the United States Department of Justice noted, "In an Alford plea the defendant agrees to plead guilty because he or she
realizes that there is little chance to win acquittal because of the strong evidence of guilt. About 17% of State inmates and 5% of Federal inmates submitted either an Alford plea or a no contest plea, regardless of the type of attorney. This difference reflects the relative readiness of State courts, compared to Federal courts, to accept an alternative plea."
In the 1995 case "State of Idaho v. Howry" before the Idaho Court of Appeals, the Court commented on the impact of the Alford guilty plea on later sentencing. The Court ruled, "Although an Alford plea allows a defendant to plead guilty amid assertions of innocence, it does not require a court to accept those assertions. The sentencing court may, of necessity, consider a broad range of information, including the evidence of the crime, the defendant's criminal history and the demeanor of the defendant, including the presence or absence of remorse." In the 1999 South Carolina Supreme Court case "State v. Gaines", the Court held that Alford guilty pleas were to be held valid in the absence of a specific on-the-record ruling that the pleas were voluntary – provided that the sentencing judge acted appropriately in accordance with the rules for acceptance of a plea made voluntarily by the defendant. The Court held that a ruling that the plea was entered into voluntarily is implied by the act of sentencing.
In the 2006 case before the United States Court of Appeals for the Fifth Circuit, "Ballard v. Burton", Judge Carl E. Stewart writing for the Court held that an Alford guilty plea is a "variation of an ordinary guilty plea". In October 2008, the United States Department of Justice defined an Alford plea as: "the defendant maintains his or her innocence with respect to the charge to which he or she offers to plead guilty".
In March 2009, the Minnesota House of Representatives characterized the Alford plea as: "a form of a guilty plea in which the defendant asserts innocence but acknowledges on the record that the prosecutor could present enough evidence to prove guilt." The Minnesota Judicial Branch similarly states: "Alford Plea: A plea of guilty that may be accepted by a court even where the defendant does not admit guilt. In an Alford plea, defendant has to admit that he has reviewed the state's evidence, a reasonable jury could find him guilty, and he wants to take advantage of a plea offer that has been made. Court has discretion as to whether to accept this type of plea."
The U.S. Attorneys' Manual states that in the federal system, Alford pleas "should be avoided except in the most unusual circumstances, even if no plea agreement is involved and the plea would cover all pending charges." U.S. Attorneys are required to obtain the approval of the Assistant Attorney General with supervisory responsibility over the subject matter before accepting such a plea.
Commentary.
In his 1972 book "American Criminal Justice", Jonathan D. Caplan comments on the Supreme Court decision, noting, "The "Alford" decision recognizes the plea-bargaining system, acknowledging that a man may maintain his innocence but still plead guilty in order to minimize his potential loss." Caplan comments on the impact of the Supreme Court's decision making it necessary for there to be evidence of guilt in such a plea, "By requiring that there be some evidence of guilt in such a situation, the decision attempts to protect the 'really' innocent from the temptations to which plea-bargaining and defense attorneys may subject them."
Major Steven E. Walburn argues in a 1998 article in "The Air Force Law Review" that this form of guilty plea should be adopted for usage by the United States military. "In fairness to an accused, if, after consultation with his defense counsel, he knowingly and intelligently determines that his best interest is served by an Alford-type guilty plea, he should be free to choose this path. The system should not force him to lie under oath, nor to go to trial with no promise of the ultimate outcome concerning guilt or punishment. We must trust the accused to make such an important decision for himself. The military provides an accused facing court-martial with a qualified defense attorney. Together, they are in the best position to properly weigh the impact his decision, and the resulting conviction, will have upon himself and his family," writes Walburn. He emphasizes that when allowing these pleas, "trial counsel should establish as strong a factual basis as possible", in order to minimize the possible negative outcomes to "the public's perception of the administration of justice within the military".
Stephanos Bibas writes in a 2003 analysis for "Cornell Law Review" that Judge Frank H. Easterbrook and a majority of scholars "praise these pleas as efficient, constitutional means of resolving cases." Bibas notes that prominent plea bargain critic Albert Alschuler supports the use of this form of plea, writing, "He views them as a lesser evil, a way to empower defendants within a flawed system. As long as we have plea bargaining, he maintains, innocent defendants should be free to use these pleas to enter advantageous plea bargains without lying. And guilty defendants who are in denial should be empowered to use these pleas instead of being forced to stand trial." Bibas instead asserts that this form of plea is "unwise and should be abolished". Bibas argues, "These procedures may be constitutional and efficient, but they undermine key values served by admissions of guilt in open court. They undermine the procedural values of accuracy and public confidence in accuracy and fairness, by convicting innocent defendants and creating the perception that innocent defendants are being pressured into pleading guilty. More basically, they allow guilty defendants to avoid accepting responsibility for their wrongs."
Legal scholar Jim Drennan, an expert on the court system at the Institute of Government at the University of North Carolina at Chapel Hill, told the "Winston-Salem Journal" in a 2007 interview that the ability to use this form of guilty plea as an option in courts had a far-reaching effect throughout the United States. Drennan commented, "We have lots of laws, but human interaction creates unique circumstances and the law has to adapt." He said of the Supreme Court case, "They had to make a decision about what to do. One of the things the court has to do is figure out how to answer new questions, and that is what happened in this case."

</doc>
<doc id="2170" url="http://en.wikipedia.org/wiki?curid=2170" title="ABCD">
ABCD

ABCD is a list of the first four letters in the English alphabet. It may also refer to:

</doc>
<doc id="2171" url="http://en.wikipedia.org/wiki?curid=2171" title="Anti-realism">
Anti-realism

In analytic philosophy, the term anti-realism describes any position involving either the denial of an objective reality or the denial that verification-transcendent statements are either true or false. This latter construal is sometimes expressed by saying "there is no fact of the matter as to whether or not P." Thus, we may speak of anti-realism with respect to other minds, the past, the future, universals, mathematical entities (such as natural numbers), moral categories, the material world, or even thought. The two construals are clearly distinct but often confused. For example, an "anti-realist" who denies that other minds exist (i. e., a solipsist) is quite different from an "anti-realist" who claims that there is no fact of the matter as to whether or not there are unobservable other minds (i. e., a logical behaviorist).
Anti-realism in philosophy.
Michael Dummett.
The term was coined by Michael Dummett, who introduced it in his paper "Realism" to re-examine a number of classical philosophical disputes involving such doctrines as nominalism, conceptual realism, idealism and phenomenalism. The novelty of Dummett's approach consisted in seeing these disputes as analogous to the dispute between intuitionism and Platonism in the philosophy of mathematics.
According to intuitionists (anti-realists with respect to mathematical objects), the truth of a mathematical statement consists in our ability to prove it. According to platonists (realists), the truth of a statement consists in its correspondence to objective reality. Thus, intuitionists are ready to accept a statement of the form "P or Q" as true only if we can prove P or if we can prove Q:
this is called the disjunction property. In particular, we cannot in general claim that "P or not P" is true (the law of Excluded Middle), since in some cases we may not be able to prove the statement "P" nor prove the statement "not P". Similarly, intuitionists object to the existence property for classical logic, where one can prove formula_1, without being able to produce any term formula_2 of which formula_3 holds.
Dummett argues that the intuitionistic notion of truth lies at the bottom of various classical forms of anti-realism. He uses this notion to re-interpret phenomenalism, claiming that it need not take the form of a reductionism (often considered untenable).
Dummett's writings on anti-realism also draw heavily on the later writings of Wittgenstein concerning meaning and rule following. In fact, Dummett's writings on anti-realism can be seen as an attempt to integrate central ideas from the "Philosophical Investigations" into analytical philosophy.
Anti-realism in the sense that Dummett uses the term is also often called semantic anti-realism.
Hilary Putnam's "internal realism".
Despite being at one time a defender of metaphysical realism, Hilary Putnam later abandoned this view in favor of a position he termed "internal realism".
Precursors.
Doubts about the possibility of definite truth have been expressed since ancient times, for instance in the skepticism of Pyrrho. Anti-realism about matter or physical entities also has a long history. It can be found in the idealism of
Berkeley, as well as Hegel and other post-Kantians.
Metaphysical realism vis-à-vis internal realism.
Anti-realist arguments.
Idealists are skeptics about the physical world, maintaining either: 1) that nothing exists outside the mind, or 2) that we would have no access to a mind-independent reality even if it may exist; the latter case often takes the form of a denial of the idea that we can have unconceptualised experiences (see Myth of the Given). Conversely, most realists (specifically, indirect realists) hold that perceptions or sense data are caused by mind-independent objects. But
this introduces the possibility of another kind of skepticism: since our understanding of causality is that the same effect can be produced by multiple causes, there is a lack of determinacy about what one is really perceiving. A concrete example of a situation where an individual's sensory input might be caused by something other than what he thinks is causing it is the brain in a vat scenario.
On a more abstract level, model theoretic arguments hold that a given set of symbols in a theory can be mapped onto any number of sets of real-world objects — each set being a "model" of the theory — providing the interrelationships between the objects are the same. (Compare with symbol grounding.)
Anti-realism in science.
In philosophy of science, anti-realism applies chiefly to claims about the non-reality of "unobservable" entities such as electrons or genes, which are not detectable with human senses. For a brief discussion comparing such anti-realism to its opposite, realism, see (Okasha 2002, ch. 4). Ian Hacking (1999, p. 84) also uses the same definition. One prominent position in the philosophy of science is instrumentalism, which is a non-realist position. Non-realism takes a purely agnostic view towards the existence of unobservable entities: unobservable entity X serves simply as an instrument to aid in the success of theory Y. We need not determine the existence or non-existence of X. Some scientific anti-realists argue further, however, and deny that unobservables exist even as non-truth conditioned instruments.
Anti-realism in mathematics.
Realism in the philosophy of mathematics is the claim that mathematical entities such as number have a mind-independent existence. The main forms are empiricism, which associates numbers with concrete physical objects; and Platonism, according to which numbers are abstract, non-physical entities. 
The "epistemic argument" against Platonism has been made by Paul Benacerraf and Hartry Field. Platonism posits that mathematical objects are "abstract" entities. By general agreement, abstract entities cannot
interact causally with concrete, physical entities. ("the truth-values of our mathematical assertions depend on facts involving platonic entities that reside in a realm outside of space-time") Whilst our knowledge of concrete, physical objects is based on our ability to perceive them, and therefore to causally interact with them, there is no parallel account of how mathematicians come to have knowledge of abstract objects. ("An account of mathematical truth ..must be consistent with the possibility of mathematical knowledge"). Another way of making the point is that if the Platonic world were to disappear, it would make no difference to the ability of mathematicians to generate proofs, etc., which is already fully accountable in terms of physical processes in their brains.
Field developed his views into fictionalism. Benacerraf also developed the philosophy of mathematical structuralism, according to which there are no mathematical objects. Nonetheless, some versions of structuralism are compatible with some versions of realism.
The argument hinges on the idea that a satisfactory naturalistic account of thought processes in terms of brain processes can be given for mathematical reasoning along with everything else. One line of defense is to maintain that this is false, so that mathematical reasoning uses some special intuition that involves contact with the Platonic realm. A modern form of this argument is given by Sir Roger Penrose.
Another line of defense is to maintain that abstract objects are relevant to mathematical reasoning in a way that is non causal, and not analogous to perception. This argument is developed by Jerrold Katz in his book "Realistic Rationalism".
A more radical defense is to deny the separation of physical world and the platonic world, i.e. the mathematical universe hypothesis. In that case, a mathematician's knowledge of mathematics is one mathematical object making contact with another.

</doc>
<doc id="2174" url="http://en.wikipedia.org/wiki?curid=2174" title="Arsenal F.C.">
Arsenal F.C.

Arsenal Football Club are a Premier League football club based in Holloway, London. One of the most successful clubs in English football, they have won 13 First Division and Premier League titles and a joint record 11 FA Cups.
Arsenal's success has been particularly consistent: the club has accumulated the second most points in English top-flight football, holds the ongoing record for the longest uninterrupted period in the top flight, and would be placed first in an aggregated league of the entire 20th century. Arsenal are the second side to complete an English top-flight season unbeaten (in the 2003–04 season), doing so under almost twice the matches of the previous team.
Arsenal were founded in 1886 in Woolwich and in 1893 became the first club from the south of England to join the Football League. In 1913, they moved north across the city to Arsenal Stadium in Highbury. In the 1930s, they won five League Championship titles and two FA Cups. After a lean period in the post-war years they won the League and FA Cup Double, in the 1970–71 season, and in the 1990s and first decade of the 21st century, won two more Doubles and reached the 2006 UEFA Champions League Final. Since neighbouring Tottenham Hotspur, the two clubs have had a fierce rivalry, the North London derby.
Arsenal has one of the highest incomes and largest fanbases in the world. Forbes's 2014 estimate put Arsenal as the fifth most valuable association football club in the world, valued at more than $1.3 billion.
History.
Arsenal Football Club were formed as Dial Square in 1886 by workers at the Royal Arsenal in Woolwich, south-east London, and were renamed Royal Arsenal shortly afterwards. The club was renamed again to Woolwich Arsenal after becoming a limited company in 1893. The club became the first southern member of the Football League in 1893, starting out in the Second Division, and won promotion to the First Division in 1904. The club's relative geographic isolation resulted in lower attendances than those of other clubs, which led to the club becoming mired in financial problems and effectively bankrupt by 1910, when they were taken over by businessmen Henry Norris and William Hall. Norris sought to move the club elsewhere, and in 1913, soon after relegation back to the Second Division, Arsenal moved to the new Arsenal Stadium in Highbury, North London; they dropped "Woolwich" from their name the following year. Arsenal only finished in fifth place in the second division during the last pre-war competitive season of 1914–15, but were nevertheless elected to rejoin the First Division when competitive football resumed in 1919–20, at the expense of local rivals Tottenham Hotspur. Some books have reported that this election to division 1 was achieved by dubious means.
Arsenal appointed Herbert Chapman as manager in 1925. Having already won the league twice with Huddersfield Town in 1923–24 and 1924–25 (see Seasons in English football), Chapman brought Arsenal their first period of major success. His revolutionary tactics and training, along with the signings of star players such as Alex James and Cliff Bastin, laid the foundations of the club's domination of English football in the 1930s. Under his guidance Arsenal won their first major trophies – victory in the 1930 FA Cup Final preceded two League Championships, in 1930–31 and 1932–33. In addition, Chapman was behind the 1932 renaming of the local London Underground station from "Gillespie Road" to "Arsenal", making it the only Tube station to be named specifically after a football club.
Chapman died suddenly of pneumonia in early 1934, leaving Joe Shaw and George Allison to carry on his successful work. Under their guidance, Arsenal won three more titles, in 1933–34, 1934–35 and 1937–38, and the 1936 FA Cup while also becoming known as the "Bank of England club." As key players retired, Arsenal had started to fade by the decade's end, and then the intervention of the Second World War meant competitive professional football in England was suspended.
After the war, Arsenal enjoyed a second period of success under Allison's successor Tom Whittaker, winning the league in 1947–48 and 1952–53, and the FA Cup in 1950. Their fortunes waned thereafter; unable to attract players of the same calibre as they had in the 1930s, the club spent most of the 1950s and 1960s in trophyless mediocrity. Even former England captain Billy Wright could not bring the club any success as manager, in a stint between 1962 and 1966.
Arsenal began winning silverware again with the surprise appointment of club physiotherapist Bertie Mee as manager in 1966. After losing two League Cup finals, they won their first European trophy, the 1969–70 Inter-Cities Fairs Cup. This was followed by an even greater triumph: their first League and FA Cup double in 1970–71. This marked a premature high point of the decade; the Double-winning side was soon broken up and the following decade was characterised by a series of near misses, starting with Arsenal finishing as FA Cup runners up in 1972, and First Division runners-up in 1972–73.
Terry Neill was recruited by the Arsenal board to replace Bertie Mee on 9 July 1976 and at the age of 34 he became the youngest Arsenal manager to date. With new signings like Malcolm Macdonald and Pat Jennings, and a crop of talent in the side such as Liam Brady and Frank Stapleton, the club enjoyed their best form since the 1971 double, reaching a trio of FA Cup finals (1978, 1979 and 1980), and losing the 1980 European Cup Winners' Cup Final on penalties. The club's only success during this time was a last-minute 3–2 victory over Manchester United in the 1979 FA Cup Final, widely regarded as a classic.
The return of former player George Graham as manager in 1986 brought a third period of glory. Arsenal won the League Cup in 1987, Graham's first season in charge. This was followed by a League title win in 1988–89, won with a last-minute goal in the final game of the season against fellow title challengers Liverpool. Graham's Arsenal won another title in 1990–91, losing only one match, won the FA Cup and League Cup double in 1993, and a second European trophy, the European Cup Winners' Cup, in 1994. Graham's reputation was tarnished when he was found to have taken kickbacks from agent Rune Hauge for signing certain players, and he was dismissed in 1995. His replacement, Bruce Rioch, lasted for only one season, leaving the club after a dispute with the board of directors.
The club's success in the late 1990s and first decade of the 21st century owed a great deal to the 1996 appointment of Arsène Wenger as manager. Wenger brought new tactics, a new training regime and several foreign players who complemented the existing English talent. Arsenal won a second League and Cup double in 1997–98 and a third in 2001–02. In addition, the club reached the final of the 1999–2000 UEFA Cup (losing on penalties to Galatasaray), were victorious in the 2003 and 2005 FA Cups, and won the Premier League in 2003–04 without losing a single match, an achievement which earned the side the nickname "The Invincibles". The feat came within a run of 49 league matches unbeaten from 7 May 2003 to 24 October 2004, a national record.
Arsenal finished in either first or second place in the league in eight of Wenger's first eleven seasons at the club, although on no occasion were they able to retain the title. As of July 2013, they were one of only five teams, the others being Manchester United, Blackburn Rovers, Chelsea, and Manchester City, to have won the Premier League since its formation in 1992. Arsenal had never progressed beyond the quarter-finals of the Champions League until 2005–06; in that season they became the first club from London in the competition's fifty-year history to reach the final, in which they were beaten 2–1 by Barcelona. In July 2006, they moved into the Emirates Stadium, after 93 years at Highbury.
Arsenal reached the final of the 2007 and 2011 League Cups, losing 2–1 to Chelsea and Birmingham City respectively. The club had not gained a major trophy since the 2005 FA Cup until 17 May 2014, when Arsenal beat Hull City in the 2014 FA Cup Final, coming back from a 2–0 deficit to win the match 3–2.
Crest.
Unveiled in 1888, Royal Arsenal's first crest featured three cannon viewed from above, pointing northwards, similar to the coat of arms of the Metropolitan Borough of Woolwich. These can sometimes be mistaken for chimneys, but the presence of a carved lion's head and a cascabel on each are clear indicators that they are cannon. This was dropped after the move to Highbury in 1913, only to be reinstated in 1922, when the club adopted a crest featuring a single cannon, pointing eastwards, with the club's nickname, "The Gunners", inscribed alongside it; this crest only lasted until 1925, when the cannon was reversed to point westward and its barrel slimmed down.
In 1949, the club unveiled a modernised crest featuring the same style of cannon below the club's name, set in blackletter, and above the coat of arms of the Metropolitan Borough of Islington and a scroll inscribed with the club's newly adopted Latin motto, "Victoria Concordia Crescit" "victory comes from harmony", coined by the club's programme editor Harry Homer. For the first time, the crest was rendered in colour, which varied slightly over the crest's lifespan, finally becoming red, gold and green. Because of the numerous revisions of the crest, Arsenal were unable to copyright it. Although the club had managed to register the crest as a trademark, and had fought (and eventually won) a long legal battle with a local street trader who sold "unofficial" Arsenal merchandise, Arsenal eventually sought a more comprehensive legal protection. Therefore, in 2002 they introduced a new crest featuring more modern curved lines and a simplified style, which was copyrightable. The cannon once again faces east and the club's name is written in a sans-serif typeface above the cannon. Green was replaced by dark blue. The new crest was criticised by some supporters; the Arsenal Independent Supporters' Association claimed that the club had ignored much of Arsenal's history and tradition with such a radical modern design, and that fans had not been properly consulted on the issue.
Until the 1960s, a badge was worn on the playing shirt only for high-profile matches such as FA Cup finals, usually in the form of a monogram of the club's initials in red on a white background.
The monogram theme was developed into an Art Deco-style badge on which the letters A and C framed a football rather than the letter F, the whole set within a hexagonal border. This early example of a corporate logo, introduced as part of Herbert Chapman's rebranding of the club in the 1930s, was used not only on Cup Final shirts but as a design feature throughout Highbury Stadium, including above the main entrance and inlaid in the floors. From 1967, a white cannon was regularly worn on the shirts, until replaced by the club crest, sometimes with the addition of the nickname "The Gunners", in the 1990s.
In the 2011–2012 season, Arsenal celebrated their 125th year anniversary. The celebrations included a modified version of the current crest worn on their jerseys for the season. The crest was all white, surrounded by 15 oak leaves to the right and 15 laurel leaves to the left. The oak leaves represent the 15 founding members of the club who met at the Royal Oak pub. The 15 laurel leaves represent the design detail on the six pence pieces paid by the founding fathers to establish the club. The laurel leaves also represent strength. To complete the crest, 1886 and 2011 are shown on either sides of the motto "Forward" at the bottom of the crest.
Colours.
For much of Arsenal's history, their home colours have been bright red shirts with white sleeves and white shorts, though this has not always been the case. The choice of red is in recognition of a charitable donation from Nottingham Forest, soon after Arsenal's foundation in 1886. Two of Dial Square's founding members, Fred Beardsley and Morris Bates, were former Forest players who had moved to Woolwich for work. As they put together the first team in the area, no kit could be found, so Beardsley and Bates wrote home for help and received a set of kit and a ball. The shirt was redcurrant, a dark shade of red, and was worn with white shorts and socks with blue and white hoops.
In 1933, Herbert Chapman, wanting his players to be more distinctly dressed, updated the kit, adding white sleeves and changing the shade to a brighter pillar box red. Two possibilities have been suggested for the origin of the white sleeves. One story reports that Chapman noticed a supporter in the stands wearing a red sleeveless sweater over a white shirt; another was that he was inspired by a similar outfit worn by the cartoonist Tom Webster, with whom Chapman played golf.
Regardless of which story is true, the red and white shirts have come to define Arsenal and the team have worn the combination ever since, aside from two seasons. The first was 1966–67, when Arsenal wore all-red shirts; this proved unpopular and the white sleeves returned the following season. The second was 2005–06, the last season that Arsenal played at Highbury, when the team wore commemorative redcurrant shirts similar to those worn in 1913, their first season in the stadium; the club reverted to their normal colours at the start of the next season. In the 2008–09 season, Arsenal replaced the traditional all-white sleeves with red sleeves with a broad white stripe.
Arsenal's home colours have been the inspiration for at least three other clubs. In 1909, Sparta Prague adopted a dark red kit like the one Arsenal wore at the time; in 1938, Hibernian adopted the design of the Arsenal shirt sleeves in their own green and white strip. In 1920, Sporting Clube de Braga's manager returned from a game at Highbury and changed his team's green kit to a duplicate of Arsenal's red with white sleeves and shorts, giving rise to the team's nickname of "Os Arsenalistas". These teams still wear these designs to this day.
For many years Arsenal's away colours were white shirts and either black or white shorts. In the 1969–70 season, Arsenal introduced an away kit of yellow shirts with blue shorts. This kit was worn in the 1971 FA Cup Final as Arsenal beat Liverpool to secure the double for the first time in its history. Arsenal reached the FA Cup final again the following year and wearing the red and white home strip and were beaten by Leeds United. Arsenal then competed in three consecutive FA Cup finals between 1978 and 1980 wearing their "lucky" yellow and blue strip, which remained the club's away strip until the release of a green and navy away kit in 1982–83. The following season, Arsenal returned to the yellow and blue scheme, albeit with a darker shade of blue than before.
When Nike took over from Adidas as Arsenal's kit provider in 1994, Arsenal's away colours were again changed to two-tone blue shirts and shorts. Since the advent of the lucrative replica kit market, the away kits have been changed regularly, with Arsenal usually releasing both away and third choice kits. During this period the designs have been either all blue designs, or variations on the traditional yellow and blue, such as the metallic gold and navy strip used in the 2001–02 season, the yellow and dark grey used from 2005 to 2007, and the yellow and maroon of 2010 to 2013.
As of 2009, the away kit is changed every season, and the outgoing away kit becomes the third-choice kit if a new home kit is being introduced in the same year.
Kit manufacturers and shirt sponsors.
Arsenal's shirts have been made by manufacturers including Bukta (from the 1930s until the early 1970s), Umbro (from the 1970s until 1986), Adidas (1986–1994), Nike (1994–2014), and Puma (from 2014). Like those of most other major football clubs, Arsenal's shirts have featured sponsors' logos since the 1980s; sponsors include JVC (1982–1999), Sega (1999–2002), O2 (2002–2006), and Emirates (from 2006).
Stadiums.
For most of their time in south-east London, Arsenal played at the Manor Ground in Plumstead, apart from a three-year period at the nearby Invicta Ground between 1890 and 1893. The Manor Ground was initially just a field, until the club installed stands and terracing for their first Football League match in September 1893. They played their home games there for the next twenty years (with two exceptions in the 1894–95 season), until the move to north London in 1913.
Widely referred to as Highbury, Arsenal Stadium was the club's home from September 1913 until May 2006. The original stadium was designed by the renowned football architect Archibald Leitch, and had a design common to many football grounds in the UK at the time, with a single covered stand and three open-air banks of terracing. The entire stadium was given a massive overhaul in the 1930s: new Art Deco West and East stands were constructed, opening in 1932 and 1936 respectively, and a roof was added to the North Bank terrace, which was bombed during the Second World War and not restored until 1954.
Highbury could hold more than 60,000 spectators at its peak, and had a capacity of 57,000 until the early 1990s. The Taylor Report and Premier League regulations obliged Arsenal to convert Highbury to an all-seater stadium in time for the 1993–94 season, thus reducing the capacity to 38,419 seated spectators. This capacity had to be reduced further during Champions League matches to accommodate additional advertising boards, so much so that for two seasons, from 1998 to 2000, Arsenal played Champions League home matches at Wembley, which could house more than 70,000 spectators.
Expansion of Highbury was restricted because the East Stand had been designated as a Grade II listed building and the other three stands were close to residential properties. These limitations prevented the club from maximising matchday revenue during the 1990s and first decade of the 21st century, putting them in danger of being left behind in the football boom of that time.
After considering various options, in 2000 Arsenal proposed building a new 60,361-capacity stadium at Ashburton Grove, since named the Emirates Stadium, about 500 metres south-west of Highbury.
The project was initially delayed by red tape and rising costs,
and construction was completed in July 2006, in time for the start of the 2006–07 season.
The stadium was named after its sponsors, the airline company Emirates, with whom the club signed the largest sponsorship deal in English football history, worth around £100 million;
some fans referred to the ground as Ashburton Grove, or the Grove, as they did not agree with corporate sponsorship of stadium names.
The stadium will be officially known as Emirates Stadium until at least 2028, and the airline will be the club's shirt sponsor until the end of the 2018–19 season. From the start of the 2010–11 season on, the stands of the stadium have been officially known as North Bank, East Stand, West Stand and Clock end.
Arsenal's players train at the Shenley Training Centre in Hertfordshire, a purpose-built facility which opened in 1999. Before that the club used facilities on a nearby site owned by the University College of London Students' Union. Until 1961 they had trained at Highbury. Arsenal's Academy under-18 teams play their home matches at Shenley, while the reserves play their games at Meadow Park, which is also the home of Boreham Wood F.C..
Supporters.
Arsenal fans often refer to themselves as "Gooners", the name derived from the team's nickname, "The Gunners". The fanbase is large and generally loyal, and virtually all home matches sell out; in 2007–08 Arsenal had the second-highest average League attendance for an English club (60,070, which was 99.5% of available capacity), and as of 2006, the fourth-highest all-time average attendance. Arsenal has the seventh highest average attendance of European football clubs only behind Borussia Dortmund, FC Barcelona, Manchester United, Real Madrid, Bayern Munich, and Schalke. The club's location, adjoining wealthy areas such as Canonbury and Barnsbury, mixed areas such as Islington, Holloway, Highbury, and the adjacent London Borough of Camden, and largely working-class areas such as Finsbury Park and Stoke Newington, has meant that Arsenal's supporters have come from across the usual class divides.
Like all major English football clubs, Arsenal has a number of domestic supporters' clubs, including the Arsenal Football Supporters Club, which works closely with the club, and the Arsenal Independent Supporters' Association, which maintains a more independent line. The Arsenal Supporters' Trust promotes greater participation in ownership of the club by fans. The club's supporters also publish fanzines such as "The Gooner", "Gunflash" and the satirical "Up The Arse!". In addition to the usual English football chants, supporters sing "One-Nil to the Arsenal" (to the tune of "Go West") and "Boring, Boring Arsenal", which used to be a common taunt from opposition fans but is now sung ironically by Arsenal supporters when the team is playing well.
There have always been Arsenal supporters outside London, and since the advent of satellite television, a supporter's attachment to a football club has become less dependent on geography. Consequently, Arsenal have a significant number of fans from beyond London and all over the world; in 2007, 24 UK, 37 Irish and 49 other overseas supporters clubs were affiliated with the club. A 2005 report by Granada Ventures, which at the time owned a 9.9% stake in the club, estimated Arsenal's global fanbase at 27 million.
Arsenal's longest-running and deepest rivalry is with their nearest major neighbours, Tottenham Hotspur; matches between the two are referred to as North London derbies. Other rivalries within London include those with Chelsea, Fulham and West Ham United. In addition, Arsenal and Manchester United developed a strong on-pitch rivalry in the late 1980s, which intensified in recent years when both clubs were competing for the Premier League title – so much so that a 2003 online poll by the Football Fans Census listed Manchester United as Arsenal's biggest rivals, followed by Tottenham and Chelsea. A 2008 poll listed the Tottenham rivalry as more important.
Ownership and finances.
Arsenal's parent company, Arsenal Holdings plc, operates as a non-quoted public limited company, whose ownership is considerably different from that of other football clubs. Only 62,217 shares in Arsenal have been issued, and they are not traded on a public exchange such as the FTSE or AIM; instead, they are traded relatively infrequently on PLUS (), a specialist market. At 31 August 2010, a single share in Arsenal had a mid price of £10,250, which set the club's market capitalisation value at approximately £637.74m. The club made a pre-tax operating profit (excluding player transfers) of £62.7m in the year ending 31 May 2009, from a turnover of £313.3m.
The largest shareholder on the Arsenal board is American sports tycoon Stan Kroenke, who launched a bid for the club in 2007, and in November 2009 increased his holding to 18,594 shares (29.9%).
A rival bid to Kroenke's came from Red & White Securities, which is co-owned by Russian billionaire Alisher Usmanov and London-based financier Farhad Moshiri. Red & White launched its bid in August 2007, buying the stake held by former Arsenal vice-chairman David Dein, and as at February 2009 owned 15,555 shares (25.0%) in the club. This led to press speculation of a bidding war between Kroenke and Usmanov. However, Kroenke agreed not to purchase more than 29.9% of the club until at least September 2009, while the rest of the board have first option on each other's shares until October 2012.
As of October 2011, Kroenke owns 41,574 shares (66.82%) and Red & White Securities own 18,261 shares (29.35%). Under company law Kroenke, as majority shareholder, is obliged to make an offer for the remaining shares in the club.
Ivan Gazidis has been the club's Chief Executive since 2009.
In popular culture.
Arsenal have appeared in a number of media "firsts". On 22 January 1927, their match at Highbury against Sheffield United was the first English League match to be broadcast live on radio. A decade later, on 16 September 1937, an exhibition match between Arsenal's first team and the reserves was the first football match in the world to be televised live. Arsenal also featured in the first edition of the BBC's "Match of the Day", which screened highlights of their match against Liverpool at Anfield on 22 August 1964. BSkyB's coverage of Arsenal's January 2010 match against Manchester United was the first live public broadcast of a sports event on 3D television.
As one of the most successful teams in the country, Arsenal has often featured when football is depicted in the arts in Britain. They formed the backdrop to one of the earliest football-related films, "The Arsenal Stadium Mystery" (1939). The film centres on a friendly match between Arsenal and an amateur side, one of whose players is poisoned while playing. Many Arsenal players appeared as themselves and manager George Allison was given a speaking part. More recently, the book "Fever Pitch" by Nick Hornby was an autobiographical account of Hornby's life and relationship with football and Arsenal in particular. Published in 1992, it formed part of the revival and rehabilitation of football in British society during the 1990s. The book was twice adapted for the cinema – the 1997 British film focuses on Arsenal's 1988–89 title win, and a 2005 American version features a fan of baseball's Boston Red Sox.
Arsenal has often been stereotyped as a defensive and "boring" side, especially during the 1970s and 1980s; many comedians, such as Eric Morecambe, made jokes about this at the team's expense. The theme was repeated in the 1997 film "The Full Monty", in a scene where the lead actors move in a line and raise their hands, deliberately mimicking the Arsenal defence's offside trap, in an attempt to co-ordinate their striptease routine. Another film reference to the club's defence comes in the film "Plunkett & Macleane", in which two characters are named Dixon and Winterburn after Arsenal's long-serving full backs – the right-sided Lee Dixon and the left-sided Nigel Winterburn.
The 1991 television comedy sketch show "Harry Enfield & Chums" featured a sketch from the characters Mr Cholmondly-Warner and Grayson where the Arsenal team of 1933, featuring exaggerated parodies of fictitious amateur players take on the Liverpool team of 1991.
In the community.
In 1985, Arsenal founded a community scheme, "Arsenal in the Community", which offered sporting, social inclusion, educational and charitable projects. The club support a number of charitable causes directly and in 1992 established The Arsenal Charitable Trust, which by 2006 had raised more than £2 million for local causes. An ex-professional and celebrity football team associated with the club also raised money by playing charity matches.
In the 2009–10 season Arsenal announced that there had raised a record breaking £818,897 for the Great Ormond Street Hospital Children's Charity. The original target was £500,000 but thanks to the overwhelming support from fans, players, directors and staff. They were able to smash the target.
Statistics and records.
Arsenal's tally of 13 League Championships is the third highest in English football, after Manchester United (20) and Liverpool (18), while the total of 11 FA Cups is the joint-highest with Manchester United. Arsenal have achieved three League and FA Cup "Doubles" (in 1971, 1998 and 2002), a feat only previously achieved by Manchester United (in 1994, 1996 and 1999), and in 1993 were the first side in English football to complete the FA Cup and League Cup double. Arsenal were also the first London club to reach the final of the UEFA Champions League, in 2006, losing the final 2–1 to Barcelona.
Arsenal have one of the best top-flight records in history, having finished below fourteenth only seven times. Arsenal also have the highest average league finishing position for the 20th century, with an average league placing of 8.5. In addition, they are one of only six clubs to have won the FA Cup twice in succession, in 2002 and 2003. Arsenal also hold the record for the longest unbeaten run in the Premier League at 49 games, and are the only team to have gone an entire Premier League season unbeaten in 2003–04.
David O'Leary holds the record for Arsenal appearances, having played 722 first-team matches between 1975 and 1993. Fellow centre half and former captain Tony Adams comes second, having played 669 times. The record for a goalkeeper is held by David Seaman, with 564 appearances.
Thierry Henry is the club's top goalscorer with 228 goals in all competitions between 1999 and 2012, having surpassed Ian Wright's total of 185 in October 2005. Wright's record had stood since September 1997, when he overtook the longstanding total of 178 goals set by winger Cliff Bastin in 1939. Henry also holds the club record for goals scored in the League, with 175, a record that had been held by Bastin until February 2006.
Arsenal's record home attendance is 73,707, for a UEFA Champions League match against RC Lens on 25 November 1998 at Wembley Stadium, where the club formerly played home European matches because of the limits on Highbury's capacity. The record attendance for an Arsenal match at Highbury is 73,295, for a 0–0 draw against Sunderland on 9 March 1935, while that at Emirates Stadium is 60,161, for a 2–2 draw with Manchester United on 3 November 2007.
Arsenal have also set records in English football, including the most consecutive seasons spent in the top flight (87 as of 2013–14) and the longest run of unbeaten League matches (49 between May 2003 and October 2004). This included all 38 matches of their title-winning 2003–04 season, when Arsenal became only the second club to finish a top-flight campaign unbeaten, after Preston North End (who played only 22 matches) in 1888–89.
Arsenal also set a Champions League record during the 2005–06 season by going ten matches without conceding a goal, beating the previous best of seven set by A.C. Milan. They went a record total stretch of 995 minutes without letting an opponent score; the streak ended in the final, when Samuel Eto'o scored a 76th-minute equaliser for Barcelona.
Managers.
There have been eighteen permanent and five caretaker managers of Arsenal since the appointment of the club's first professional manager, Thomas Mitchell in 1897. The club's longest-serving manager, in terms of both length of tenure and number of games overseen, is Arsène Wenger, who was appointed in 1996. Wenger is also Arsenal's only manager from outside the United Kingdom. Two Arsenal managers have died in the job – Herbert Chapman and Tom Whittaker.
Arsenal Ladies.
Arsenal Ladies are the women's football club affiliated to Arsenal. Founded in 1987, they turned semi-professional in 2002 and are managed by Laura Harvey. Arsenal Ladies are the most successful team in English women's football. In the 2008–09 season, they won all three major English trophies – the FA Women's Premier League, FA Women's Cup and FA Women's Premier League Cup, and, as of 2009, were the only English side to have won the UEFA Women's Cup, having done so in the 2006–07 season as part of a unique quadruple. The men's and women's clubs are formally separate entities but have quite close ties; Arsenal Ladies are entitled to play once a season at the Emirates Stadium, though they usually play their home matches at Boreham Wood.

</doc>
<doc id="2175" url="http://en.wikipedia.org/wiki?curid=2175" title="Cuisine of the United States">
Cuisine of the United States

The cuisine of the United States reflects its history. The European colonization of the Americas yielded the introduction of a number of ingredients and cooking styles to the latter. The various styles continued expanding well into the 19th and 20th centuries, proportional to the influx of immigrants from many foreign nations; such influx developed a rich diversity in food preparation throughout the country.
Early Native Americans utilized a number of cooking methods in early American Cuisine that have been blended with early European cooking methods to form the basis of American Cuisine. When the colonists came to Virginia, Massachusetts, or any of the other English colonies on the eastern seaboard of North America, they farmed animals for clothing and meat in a similar fashion to what they had done in Europe. They had cuisine similar to their previous British cuisine. The American colonial diet varied depending on the settled region in which someone lived. Commonly hunted game included deer, bear, buffalo and wild turkey. A number of fats and oils made from animals served to cook much of the colonial foods. Prior to the Revolution, New Englanders consumed large quantities of rum and beer, as maritime trade provided them relatively easy access to the goods needed to produce these items: Rum was the distilled spirit of choice, as the main ingredient, molasses, was readily available from trade with the West Indies. In comparison to the northern colonies, the southern colonies were quite diverse in their agricultural diet and did not have a central region of culture. 
During the 18th and 19th centuries, Americans developed many new foods. During the Progressive Era (1890s–1920s) food production and presentation became more industrialized. One characteristic of American cooking is the fusion of multiple ethnic or regional approaches into completely new cooking styles. A wave of celebrity chefs began with Julia Child and Graham Kerr in the 1970s, with many more following after the rise of cable channels like Food Network. 
History.
Pre-Colonial cuisine.
Seafood.
Seafood in the United States originated with the Native Americans, who often ate cod, lemon sole, flounder, herring, halibut, sturgeon, smelt, drum on the East Coast, and olachen and salmon on the West Coast. Whale was hunted by Native Americans off the Northwest coast, especially by the Makah, and used for their meat and oil. Seal and walrus were also eaten, in addition to eel from New York's Finger Lakes region. Catfish was also popular amongst native peoples, including the Modocs. Crustacean included shrimp, lobster, crayfish, and dungeness crabs in the Northwest and blue crabs in the East. Other shellfish include abalone and geoduck on the West Coast, while on the East Coast the surf clam, quahog, and the soft-shell clam. Oysters were eaten on both shores, as were mussels and periwinkles.
Cooking methods.
Early Native Americans utilized a number of cooking methods in early American Cuisine that have been blended with early European cooking methods to form the basis of American Cuisine. Grilling meats was common. Spit roasting over a pit fire was common as well. Vegetables, especially root vegetables were often cooked directly in the ashes of the fire. As early Native Americans lacked pottery that could be used directly over a fire, they developed a technique which has caused many anthropologists to call them "Stone Boilers". They would heat rocks directly in a fire and then add the bricks to a pot filled with water until it came to a boil so that it would cook the meat or vegetables in the boiling water. In what is now the Southwestern United States, they also created adobe ovens called hornos to bake items such as cornmeal breads, and in other parts of America, made ovens of dug pits. These pits were also used to steam foods by adding heated rocks or embers and then seaweed or corn husks placed on top to steam fish and shellfish as well as vegetables; potatoes would be added while still in-skin and corn while in-husk, this would later be referred to as a clambake by the colonists.
Colonial period.
When the colonists came to Virginia, Massachusetts, or any of the other English colonies on the eastern seaboard of North America, their initial attempts at survival included planting crops familiar to them from back home in England. In the same way, they farmed animals for clothing and meat in a similar fashion. Through hardships and eventual establishment of trade with Britain, the West Indies and other regions, the colonists were able to establish themselves in the American colonies with a cuisine similar to their previous British cuisine. There were some exceptions to the diet, such as local vegetation and animals, but the colonists attempted to use these items in the same fashion as they had their equivalents or ignore them entirely if they could. The manner of cooking for the American colonists followed along the line of British cookery up until the Revolution. The British sentiment followed in the cookbooks brought to the New World as well.
There was a general disdain for French cookery, even with the French Huguenots in South Carolina and French-Canadians. One of the cookbooks that proliferated in the colonies was The Art of Cookery Made Plain and Easy written by Hannah Glasse, wrote of disdain for the French style of cookery, stating “the blind folly of this age that would rather be imposed on by a French booby, than give encouragement to a good English cook!” Of the French recipes, she does add to the text she speaks out flagrantly against the dishes as she “… think it an odd jumble of trash.” Reinforcing the anti-French sentiment was the French and Indian War from 1754–1764. This created a large anxiety against the French, which influenced the English to either deport many of the French, or as in the case of many Acadians from Nova Scotia, they forcibly relocated to Louisiana. The Acadian French did create a large French influence in the diet of those settled in Louisiana, but had little or no influence outside of Louisiana - except among the Acadian Francophones who settled eastern Maine at the same time they colonised New Brunswick.
Common ingredients.
The American colonial diet varied depending on the settled region in which someone lived. Local cuisine patterns had established by the mid-18th century. The New England colonies were extremely similar in their dietary habits to those that many of them had brought from England. A striking difference for the colonists in New England compared to other regions was seasonality. While in the southern colonies, they could farm almost year round, in the northern colonies, the growing seasons were very restricted. In addition, colonists’ close proximity to the ocean gave them a bounty of fresh fish to add to their diet, especially in the northern colonies. Wheat, however, the grain used to bake bread back in England was almost impossible to grow, and imports of wheat were far from cost productive. Substitutes in cases such as this included cornmeal. The Johnnycake was a poor substitute to some for wheaten bread, but acceptance by both the northern and southern colonies seems evident.
As many of the New Englanders were originally from England game hunting was often a pastime from back home that paid off when they immigrated to the New World. Much of the northern colonists depended upon the ability either of themselves to hunt, or for others from which they could purchase game. This was the preferred method for protein consumption over animal husbandry, as it required much more work to defend the kept animals against Native Americans or the French.
Livestock and game.
Commonly hunted game included deer, bear, buffalo and wild turkey. The larger muscles of the animals were roasted and served with currant sauce, while the other smaller portions went into soups, stews, sausages, pies, and pasties. In addition to game, colonists' protein intake was supplemented by mutton. The Spanish in Florida originally introduced sheep to the New World, but this development never quite reached the North, and there they were introduced by the Dutch and English. The keeping of sheep was a result of the English non-practice of animal husbandry. The animals provided wool when young and mutton upon maturity after wool production was no longer desirable. The forage-based diet for sheep that prevailed in the Colonies produced a characteristically strong, gamy flavor and a tougher consistency, which required aging and slow cooking to tenderize.
Fats and oils.
A number of fats and oils made from animals served to cook much of the colonial foods. Many homes had a sack made of deerskin filled with bear oil for cooking, while solidified bear fat resembled shortening. Rendered pork fat made the most popular cooking medium, especially from the cooking of bacon. Pork fat was used more often in the southern colonies than the northern colonies as the Spanish introduced pigs earlier to the South. The colonists enjoyed butter in cooking as well, but it was rare prior to the American Revolution, as cattle were not yet plentiful.
Alcoholic drinks.
Prior to the Revolution, New Englanders consumed large quantities of rum and beer, as maritime trade provided them relatively easy access to the goods needed to produce these items: Rum was the distilled spirit of choice, as the main ingredient, molasses, was readily available from trade with the West Indies. Further into the interior, however, one would often find colonists consuming whiskey, as they did not have similar access to sugar cane. They did have ready access to corn and rye, which they used to produce their whiskey. However, until the Revolution, many considered whiskey to be a coarse alcohol unfit for human consumption, as many believed that it caused the poor to become raucous and unkempt drunkards. In addition to these alcohol-based products produced in America, imports were seen on merchant shelves, including wine and brandy.
Southern variations.
In comparison to the northern colonies, the southern colonies were quite diverse in their agricultural diet and did not have a central region of culture. The uplands and the lowlands made up the two main parts of the southern colonies. The slaves and poor of the south often ate a similar diet, which consisted of many of the indigenous New World crops. Salted or smoked pork often supplement the vegetable diet. Rural poor often ate squirrel, possum, rabbit and other woodland animals. Those on the “rice coast” often ate ample amounts of rice, while the grain for the rest of the southern poor and slaves was cornmeal used in breads and porridges. Wheat was not an option for most of those that lived in the southern colonies.
The diet of the uplands often included cabbage, string beans, white potatoes, while most avoided sweet potatoes and peanuts. Well-off whites in the uplands avoided crops imported from Africa because of the perceived inferiority of crops of the African slaves. Those who could grow or afford wheat often had biscuits as part of their breakfast, along with healthy portions of pork. Salted pork was a staple of any meal, as it was used in the preparations of vegetables for flavor, in addition to being eaten directly as a protein.
The lowlands, which included much of the Acadian French regions of Louisiana and the surrounding area, included a varied diet heavily influenced by Africans and Caribbeans, rather than just the French. As such, rice played a large part of the diet as it played a large part of the diets of the Africans and Caribbean. In addition, unlike the uplands, the lowlands subsistence of protein came mostly from coastal seafood and game meats. Much of the diet involved the use of peppers, as it still does today. Interestingly, although the English had an inherent disdain for French foodways, as well as many of the native foodstuff of the colonies, the French had no such disdain for the indigenous foodstuffs. In fact, they had a vast appreciation for the native ingredients and dishes.
Post-colonial cuisine.
During the 18th and 19th centuries, Americans developed many new foods. Some, such as Rocky Mountain oysters, stayed regional; some spread throughout the nation but with little international appeal, such as peanut butter (a core ingredient of the famous peanut butter and jelly sandwich); and some spread throughout the world, such as popcorn, Coca-Cola and its competitors, fried chicken, cornbread, unleavened muffins such as the poppyseed muffin, and brownies.
Modern cuisine.
During the Progressive Era (1890s–1920s) food production and presentation became more industrialized. Major railroads featured upscale cuisine in their dining cars. Restaurant chains emerged with standardized decor and menus, most famously the Fred Harvey restaurants along the route of the Sante Fe Railroad in the Southwest.
At the universities, nutritionists and home economists taught a new scientific approach to food. During World War I the Progressives' moral advice about food conservation was emphasized in large-scale state and federal programs designed to educate housewives. Large-scale foreign aid during and after the war brought American standards to Europe.
Newspapers and magazines ran recipe columns, aided by research by corporate kitchens (for example, General Mills, Campbell's, Kraft Foods). One characteristic of American cooking is the fusion of multiple ethnic or regional approaches into completely new cooking styles. Hamburgers and hot dogs from German cuisine, spaghetti and pizza from Italian cuisine became popular. Since the 1960s Asian cooking has played a particularly large role in American fusion cuisine.
Similarly, some dishes that are typically considered American have their origins in other countries. American cooks and chefs have substantially altered these dishes over the years, to the degree that the dishes now enjoyed around the world are considered to be American. Hot dogs and hamburgers are both based on traditional German dishes, but in their modern popular form they can be reasonably considered American dishes.
Pizza is based on the traditional Italian dish, brought by Italian immigrants to the United States, but varies highly in style based on the region of development since its arrival (a "Chicago" style has focus on a thicker, more bread-like crust, whereas a "New York Slice" is known to have a much thinner crust, for example) and these types can be advertised throughout the country and are generally recognizable/well-known (with some restaurants going so far as to import New York City tap water from a thousand or more miles away to recreate the signature style in other regions).
Many companies in the American food industry develop new products requiring minimal preparation, such as frozen entrees. Many of these recipes have become very popular. For example, the General Mills "Betty Crocker's Cookbook", first published in 1950 and currently in its 10th edition, is commonly found in American homes.
A wave of celebrity chefs began with Julia Child and Graham Kerr in the 1970s, with many more following after the rise of cable channels like Food Network. Trendy food items in the 2000s and 2010s (albeit with long traditions) include doughnuts, cupcakes, macaroons, and meatballs.
New American.
During the 1980s, upscale restaurants introduced a mixing of cuisines that contain Americanized styles of cooking with foreign elements commonly referred as New American cuisine.
Regional cuisines.
Given the United States's large size, numerous regions each have their own distinctive cuisines, all quite diverse.
New England.
New England is a Northeastern region of the United States, including the six states of Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont. The Native American cuisine became part of the cookery style that the early colonists brought with them. The style of New England cookery originated from its colonial roots, that is to say practical, frugal and willing to eat anything other than what they were used to from their British roots. Much of the cuisine started with one-pot cookery, which resulted in such dishes as succotash, chowder, baked beans, and others.
Lobster is an integral ingredient to the cuisine, indigenous to the coastal waters of the region. Other shellfish of the coastal regions include little neck clams, sea scallops, blue mussels, oysters, soft shell clams and razor shell clams. Much of this shellfish contributes to New England tradition, the clambake. The clambake as known today is a colonial interpretation of an American Indian tradition.
The fruits of the region include the "Vitis labrusca" grapes used in grape juice made by companies such as Welch's, along with jelly, Kosher wine by companies like Mogen David and Manischewitz along with other wineries that make higher quality wines. Apples from New England include the original varieties Baldwin, Lady, Mother, Pomme Grise, Porter, Roxbury Russet, Wright, Sops of Wine, Peck's Pleasant, Titus Pippin, Westfield-Seek-No-Further, and Duchess of Oldenburg. Cranberries are another fruit indigenous to the region.
Pacific and Hawaiian cuisine.
Hawaii is often considered to be one of the most culturally diverse U.S. states, as well as being the only state with an Asian majority population. As a result, Hawaiian cuisine borrows elements of a variety of cuisines, particularly those of Asian and Pacific-rim cultures, as well as traditional native Hawaiian. Some notable Hawaiian fare includes seared ahi tuna, opakapaka (snapper) with passionfruit, Hawaiian island-raised lamb, beef and meat products, Hawaiian plate lunch, and Molokai shrimp and seafood caught fresh in Hawaiian waters. Some cuisine also incorporates a broad variety of produce and locally grown agricultural products, including tomatoes, strawberries, mushrooms, sweet maui onions, and tropical fruits including papayas, mangoes, lilikoi (passionfruit) and lychee.
Midwest.
Midwestern cuisine covers everything from barbecue to the Chicago-style hot dog.
The American South.
The cuisine of the American South has been influenced by the many diverse inhabitants of the region, including Americans of European descent, Native Americans and African Americans. The cuisine of the American South, along with the rest of its culture, is one of the most distinct in all of the country.
Cuisine in the West.
Cooking in the American West gets its influence from Native American and Mexican cultures, and other European settlers into the part of the country. Common dishes vary depending on the area. For instance, the Northwest relies on local seafood, while in the Southwest, Mexican flavors are extremely common.
Ethnic and immigrant influence.
The demand for ethnic foods in the United States reflects the nation's changing diversity as well as its development over time. According to the National Restaurant Association, 
Restaurant industry sales are expected to reach a record high of $476 billion in 2005, an increase of 4.9 percent over 2004... Driven by consumer demand, the ethnic food market reached record sales in 2002, and has emerged as the fastest growing category in the food and beverage product sector, according to USBX Advisory Services. Minorities in the U.S. spend a combined $142 billion on food and by 2010, America's ethnic population is expected to grow by 40 percent.
A movement began during the 1980s among popular leading chefs to reclaim America's ethnic foods within its regional traditions, where these trends originated. One of the earliest was Paul Prudhomme, who in 1984 began the introduction of his influential cookbook, "Paul Prodhomme's Louisiana Kitchen", by describing the over 200 year history of Creole and Cajun cooking; he aims to "preserve and expand the Louisiana tradition." Prodhomme's success quickly inspired other chefs. Norman Van Aken embraced a Floridian type cuisine fused with many ethnic and globalized elements in his "Feast of Sunlight" cookbook in 1988. The movement finally gained fame around the world when California became swept up in the movement, then seemingly started to lead the trend itself, in, for example, the popular restaurant Chez Panisse in Berkeley. Examples of the Chez Panisse phenomenon, chefs who embraced a new globalized cuisine, were celebrity chefs like Jeremiah Tower and Wolfgang Puck, both former colleagues at the restaurant. Puck went on to describe his belief in contemporary, new style American cuisine in the introduction to "The Wolfgang Puck Cookbook":
Another major breakthrough, whose originators were once thought to be crazy, is the mixing of ethnic cuisines. It is not at all uncommon to find raw fish listed next to tortillas on the same menu. Ethnic crossovers also occur when distinct elements meet in a single recipe. This country is, after all, a huge melting pot. Why should its cooking not illustrate the American transformation of diversity into unity?
Puck's former colleague, Jeremiah Tower became synonymous with California Cuisine and the overall American culinary revolution. Meanwhile, the restaurant that inspired both Puck and Tower became a distinguished establishment, popularizing its so called "mantra" in its book by Paul Bertolli and owner Alice Waters, "Chez Panisse Cooking", in 1988. Published well after the restaurants' founding in 1971, this new cookbook from the restaurant seemed to perfect the idea and philosophy that had developed over the years. The book embraced America's natural bounty, specifically that of California, while containing recipes that reflected Bertoli and Waters' appreciation of both northern Italian and French style foods.
Early ethnic influences.
While the earliest cuisine of the United States was influenced by indigenous Native Americans, the cuisine of the thirteen colonies or the culture of the antebellum American South; the overall culture of the nation, its gastronomy and the growing culinary arts became ever more influenced by its changing ethnic mix and immigrant patterns from the 18th and 19th centuries unto the present. Some of the ethnic groups that continued to influence the cuisine were here in prior years; while others arrived more numerously during “The Great Transatlantic Migration (of 1870—1914) or other mass migrations.
Some of the ethnic influences could be found in the nation from after the American Civil War and into the History of United States continental expansion during most of the 19th century. Ethnic influences already in the nation at that time would include the following groups and their respective cuisines:
Later ethnic and immigrant influence.
Mass migrations of immigrants to the United States came in several waves. Historians identify several waves of migration to the United States: one from 1815–1860, in which some five million English, Irish, Germanic, Scandinavian, and others from northwestern Europe came to the United States; one from 1865–1890, in which some 10 million immigrants, also mainly from northwestern Europe, settled, and a third from 1890–1914, in which 15 million immigrants, mainly from central, eastern, and southern Europe (many Austrian, Hungarian, Turkish, Lithuanian, Russian, Jewish, Greek, Italian, and Romanian) settled in the United States.
Together with earlier arrivals to the United States (including the indigenous Native Americans, Hispanic and Latino Americans, particularly in the West, Southwest, and Texas; African Americans who came to the United States in the Atlantic slave trade; and early colonial migrants from Britain, France, Germany, Spain, and elsewhere), these new waves of immigrants had a profound impact on national or regional cuisine. Some of these more prominent groups include the following:
"Italian, Mexican and Chinese (Cantonese) cuisines have indeed joined the mainstream. These three cuisines have become so ingrained in the American culture that they are no longer foreign to the American palate. According to the study, more than nine out of 10 consumers are familiar with and have tried these foods, and about half report eating them frequently. The research also indicates that Italian, Mexican and Chinese (Cantonese) have become so adapted to such an extent that "authenticity" is no longer a concern to customers."
Contributions from these ethnic foods have become as common as traditional "American" fares such as hot dogs, hamburgers, beef steak, which are derived from German cuisine, (chicken-fried steak, for example, is a variation on German schnitzel), cherry pie, Coca-Cola, milkshakes, fried chicken (Fried chicken is of Scottish and African influence) and so on. Nowadays, Americans also have a ubiquitous consumption of foods like pizza and pasta, tacos and burritos to "General Tso's chicken" and fortune cookies. Fascination with these and other ethnic foods may also vary with region.
Notable American chefs.
American chefs have been influential both in the food industry and in popular culture. An important 19th Century American chef was Charles Ranhofer of Delmonico's Restaurant in New York City. American cooking has been exported around the world, both through the global expansion of restaurant chains such as T.G.I. Friday's and McDonald's and the efforts of individual restaurateurs such as Bob Payton, credited with bringing American-style pizza to the UK.
The first generation of television chefs such as Robert Carrier and Julia Child tended to concentrate on cooking based primarily on European, especially French and Italian, cuisines. Only during the 1970s and 1980s did television chefs such as James Beard and Jeff Smith shift the focus towards home-grown cooking styles, particularly those of the different ethnic groups within the nation. Notable American restaurant chefs include Thomas Keller, Charlie Trotter, Grant Achatz, Alfred Portale, Paul Prudhomme, Paul Bertolli, Frank Stitt, Alice Waters, Patrick O’Connell and celebrity chefs like Mario Batali, David Chang, Alton Brown, Emeril Lagasse, Cat Cora, Michael Symon, Bobby Flay, Ina Garten, Todd English, Sandra Lee, Anthony Bourdain, and Paula Deen.
Regional chefs are emerging as localized celebrity chefs with growing broader appeal, such as Peter Merriman (Hawaii Regional Cuisine), Jerry Traunfeld, Alan Wong (Pacific Rim cuisine), Norman Van Aken (New World Cuisine – fusion Latin, Caribbean, Asian, African and American), and Mark Miller (American Southwest cuisine).

</doc>
