<doc id="1968" url="http://en.wikipedia.org/wiki?curid=1968" title="Apollo 14">
Apollo 14

Apollo 14 was the eighth manned mission in the United States Apollo program, and the third to land on the Moon. It was the last of the "H missions," targeted landings with two-day stays on the Moon with two lunar EVAs, or moonwalks.
Commander Alan Shepard, Command Module Pilot Stuart Roosa, and Lunar Module Pilot Edgar Mitchell launched on their nine-day mission on January 31, 1971 at 4:04:02 pm local time after a 40 minute, 2 second delay due to launch site weather restrictions, the first such delay in the Apollo program. Shepard and Mitchell made their lunar landing on February 5 in the Fra Mauro formation; this had originally been the target of the aborted Apollo 13 mission. During the two lunar EVAs, of Moon rocks were collected and several surface experiments, including seismic studies, were performed. Shepard famously hit two golf balls on the lunar surface with a makeshift club he had brought from Earth. Shepard and Mitchell spent about 33 hours on the Moon, with about 9½ hours on EVA.
While Shepard and Mitchell were on the surface, Roosa remained in lunar orbit aboard the Command/Service Module "Kitty Hawk", performing scientific experiments and photographing the Moon, including the landing site of the future Apollo 16 mission. He took several hundred seeds on the mission, many of which were germinated on return, resulting in the so-called Moon trees. Shepard, Roosa, and Mitchell landed in the Pacific Ocean on February 9.
Crew.
Shepard was the oldest U.S. astronaut when he made his trip aboard Apollo 14. He is the only astronaut from Project Mercury (the original Mercury Seven astronauts) to reach the Moon. Another of the original seven, Gordon Cooper, had (as Apollo 10's backup commander) tentatively been scheduled to command the mission, but according to author Andrew Chaikin, his casual attitude toward training, along with problems with NASA hierarchy (reaching all the way back to the Mercury-Atlas 9 flight), resulted in his removal.
The mission was a personal triumph for Shepard, who had battled back from Ménière's disease which grounded him from 1964 to 1968. He and his crew were originally scheduled to fly on Apollo 13, but in 1969 NASA officials switched the scheduled crews for Apollos 13 and 14. This was done to allow Shepard more time to train for his flight, as he had been grounded for four years.
As of 2014, Mitchell is the only surviving member of the crew; Roosa died in 1994 from pancreatitis and Shepard in 1998 from leukemia.
Mission highlights.
Launch and flight to lunar orbit.
Apollo 14 launched during heavy cloud cover, and was quickly obscured by the clouds. However, NASA's long-range cameras, based 60 miles south in Vero Beach, had a clear shot of the remainder of the launch. Following the launch, the Launch Control Center at Kennedy Space Center was visited by U.S. Vice President Spiro T. Agnew, Prince Juan Carlos of Spain, and his wife, Princess Sofía.
At the beginning of the mission, the CSM "Kitty Hawk" had difficulty achieving capture and docking with the LM "Antares". Repeated attempts to dock went on for 1 hour and 42 minutes, until it was suggested that Roosa hold "Kitty Hawk" against "Antares" using its thrusters, then the docking probe would be retracted out of the way, hopefully triggering the docking latches. This attempt was successful, and no further docking problems were encountered during the mission.
Lunar descent.
After separating from the Command Module in lunar orbit, the LM "Antares" also had two serious problems. First, the LM computer began getting an ABORT signal from a faulty switch. NASA believed that the computer might be getting erroneous readings like this if a tiny ball of solder had shaken loose and was floating between the switch and the contact, closing the circuit. The immediate solution—tapping on the panel next to the switch—did work briefly, but the circuit soon closed again. If the problem recurred after the descent engine fired, the computer would think the signal was real and would initiate an auto-abort, causing the ascent stage to separate from the descent stage and climb back into orbit. NASA and the software teams at the Massachusetts Institute of Technology scrambled to find a solution, and determined the fix would involve reprogramming the flight software to ignore the false signal. The software modifications were transmitted to the crew via voice communication, and Mitchell manually entered the changes (amounting to over 80 keystrokes on the LM computer pad) just in time.
A second problem occurred during the powered descent, when the LM radar altimeter failed to lock automatically onto the Moon's surface, depriving the navigation computer of vital information on the vehicle altitude and groundspeed. (This was not a result of the modifications to the ABORT command; rather, the post-mission report indicated it was an unrelated bug in the radar's operation.) After the astronauts cycled the landing radar breaker, the unit successfully acquired a signal near , again just in the nick of time. Shepard then manually landed the LM closer to its intended target than any of the other six Moon landing missions. Mitchell believes that Shepard would have continued with the landing attempt without the radar, using the LM inertial guidance system and visual cues. But a post-flight review of the descent data showed the inertial system alone would have been inadequate, and the astronauts probably would have been forced to abort the landing as they approached the surface.
Lunar surface operations.
Shepard and Mitchell named their landing site "Fra Mauro Base", and this designation is recognized by the International Astronomical Union (depicted in Latin on lunar maps as "Statio Fra Mauro").
Shepard's first words, after stepping onto the lunar surface were, "And it's been a long way, but we're here." Unlike Neil Armstrong on Apollo 11 and Pete Conrad on Apollo 12, Shepard had already stepped off the LM footpad and was a few yards (meters) away before he spoke.
Shepard's moonwalking suit was the first to utilize red stripes on the arms and legs and on the top of the lunar EVA sunshade "hood," so as to allow easy identification between the commander and LM pilot on the surface; on the Apollo 12 pictures, it had been almost impossible to distinguish between the two crewmen, causing a great deal of confusion. This feature was included on Jim Lovell's Apollo 13 suit; however, because no landing was made on that mission, Apollo 14 was the first to make use of it. This feature was used for the remaining Apollo missions, and for the EVAs of Space Shuttle flights afterwards, and it is still in use today on both the U.S. and Russian space suits on the International Space Station.
After landing in the Fra Mauro formation—the destination for Apollo 13—Shepard and Mitchell took two moonwalks, adding new seismic studies to the by now familiar Apollo experiment package (ALSEP), and using the Modular Equipment Transporter (MET), a pull cart for carrying equipment and samples, referred to as a "lunar rickshaw." Roosa, meanwhile, took pictures from on board Command Module "Kitty Hawk" in lunar orbit.
The second moonwalk, or EVA, was intended to reach the rim of the wide Cone Crater. However, the two astronauts were not able to find the rim amid the rolling terrain of the crater's slopes. Later analysis, using the pictures that they took, determined that they had come within an estimated of the crater's rim. Images from the Lunar Reconnaissance Orbiter (LRO) show the tracks of the astronauts and the MET come to within 30 m of the rim.
Shepard and Mitchell deployed and activated various scientific instruments and experiments and collected almost of lunar samples for return to earth. Other Apollo 14 achievements included: the only use of MET; longest distance traversed by foot on the lunar surface; first use of shortened lunar orbit rendezvous techniques; and the first extensive orbital science period conducted during CSM solo operations.
The astronauts also engaged in less serious activities on the Moon. Shepard smuggled on board a six iron golf club head which he could attach to the handle of a lunar excavation tool, and two golf balls, and took several one-handed swings (due to the limited flexibility of the EVA suit). He exuberantly exclaimed that the second ball went "miles and miles and miles" in the low lunar gravity, but later estimated the distance as . Mitchell then threw a lunar scoop handle as if it was a javelin.
Return, splashdown and quarantine.
On the way back to Earth, the crew conducted the first U.S. materials processing experiments in space.
The Command Module "Kitty Hawk" splashed down in the South Pacific Ocean on February 9, 1971 at 21:05 [UTC], approximately south of American Samoa. After recovery by the ship USS "New Orleans", the crew was flown to Pago Pago International Airport in Tafuna for a reception before being flown on a C-141 cargo plane to Honolulu. The Apollo 14 astronauts were the last lunar explorers to be quarantined on their return from the Moon.
Roosa, who worked in forestry in his youth, took several hundred tree seeds on the flight. These were germinated after the return to Earth, and widely distributed around the world as commemorative Moon trees.
Mission insignia.
The oval insignia shows a gold NASA Astronaut Pin, given to U.S. astronauts upon completing their first space flight, traveling from the Earth to the Moon. A gold band around the edge includes the mission and astronaut names. The designer was Jean Beaulieu.
The backup crew spoofed the patch with its own version, with revised artwork showing a Wile E. Coyote cartoon character depicted as gray-bearded (for Shepard, who was 47 at the time of the mission and the oldest man on the Moon), pot-bellied (for Mitchell, who had a pudgy appearance) and red furred (for Roosa's red hair), still on the way to the Moon, while Road Runner (for the backup crew) is already on the Moon, holding a U.S. flag and a flag labeled "1st Team." The flight name is replaced by "BEEP BEEP" and the backup crew's names are given. Several of these patches were hidden by the backup crew and found during the flight by the crew in notebooks and storage lockers in both the CSM "Kitty Hawk" and the LM "Antares" spacecraft, and one patch was even stored on the MET lunar hand cart.
Spacecraft location.
The Apollo 14 Command Module "Kitty Hawk" is on display at the Apollo/Saturn V Center building at the Kennedy Space Center after being on display at the Astronaut Hall of Fame near Titusville, Florida, for several years.
The ascent stage of Lunar Module "Antares" impacted the Moon on February 7, 1971 at 00:45:25.7 UT (February 6, 7:45 PM EST) . "Antares"' descent stage and the mission's other equipment remain at Fra Mauro at .
Photographs taken in 2009 by the Lunar Reconnaissance Orbiter were released on July 17, and the Fra Mauro equipment was the most visible Apollo hardware at that time, owing to particularly good lighting conditions. In 2011, the LRO returned to the landing site at a lower altitude to take higher resolution photographs.
External links.
NASA reports
Multimedia

</doc>
<doc id="1969" url="http://en.wikipedia.org/wiki?curid=1969" title="Apollo 15">
Apollo 15

Apollo 15 was the ninth manned mission in the United States' Apollo program, the fourth to land on the Moon, and the eighth successful manned mission. It was the first of what were termed "J missions," long stays on the Moon, with a greater focus on science than had been possible on previous missions. It was also the first mission on which the Lunar Roving Vehicle was used.
The mission began on July 26, 1971, and ended on August 7. At the time, NASA called it the most successful manned flight ever achieved.
Commander David Scott and Lunar Module Pilot James Irwin spent three days on the Moon, including 18½ hours outside the spacecraft on lunar extra-vehicular activity (EVA). The mission landed near Hadley rille, in an area of the Mare Imbrium called "Palus Putredinus" (Marsh of Decay). The crew explored the area using the first lunar rover, which allowed them to travel much farther from the Lunar Module (LM) than had been possible on missions without the rover. They collected of lunar surface material. At the same time, Command Module Pilot Alfred Worden orbited the Moon, using a Scientific Instrument Module (SIM) in the Service Module (SM) to study the lunar surface and environment in great detail with a panoramic camera, a gamma-ray spectrometer, a mapping camera, a laser altimeter, a mass spectrometer, and a lunar sub-satellite deployed at the end of Apollo 15's stay in lunar orbit (an Apollo program first).
Although the mission accomplished its objectives, this success was somewhat overshadowed by negative publicity that accompanied public awareness of postage stamps carried without authorization by the astronauts, who had made plans to sell them upon their return. Ironically, this mission was one of very few that had been honored with the issue of a commemorative stamp, with this first use of a lunar rover happening one decade after the first Mercury astronaut launch.
Crew.
All three astronauts on the all-United States Air Force crew received an honorary degree or Master's degree from the University of Michigan, including Scott's honorary degree, awarded in the spring of 1971, months before the launch. Scott had attended the University of Michigan, but left before graduating to accept an appointment to the United States Military Academy. The crewmen did their undergraduate work at either the United States Military Academy or the United States Naval Academy.
Backup crew.
Schmitt was the first member of Group 4 to be selected as a prime or backup crew member for an Apollo flight; from Group 4 he was the only astronaut to make it to the Moon, with the last Apollo mission at the end of 1972.
Planning and training.
The crew for Apollo 15 had previously served as the backup crew for Apollo 12. There had been a friendly rivalry between that prime and backup crew on that mission, with the prime being all United States Navy, and the backup all United States Air Force.
Originally Apollo 15 would have been an H mission, like Apollos 12, 13 and 14. But on September 2, 1970, NASA announced it was canceling what were to be the current incarnations of the Apollo 15 and Apollo 19 missions. To maximize the return from the remaining missions, Apollo 15 would now fly as a J mission and have the honor of carrying the first lunar rover.
One of the major changes in the training for Apollo 15 was the geology training. Although on previous flights the crews had been trained in field geology, for the first time Apollo 15 would make it a high priority. Scott and Irwin would train with Leon Silver, a Caltech geologist who on Earth was interested in the Precambrian. Silver had been suggested by Harrison Schmitt as an alternative to the classroom lecturers that NASA had previously used. Among other things, Silver had made important refinements to the methods for dating rocks using the decay of uranium into lead in the late 1950s.
At first Silver would take the prime and backup crews to various geological sites in Arizona and New Mexico as if for a normal field geology lesson, but as launch time approached, these trips became more realistic. Crews began to wear mock-ups of the backpacks they would carry, and communicate using walkie-talkies to a CAPCOM in a tent. (During a mission the Capsule Communicators (CAPCOMs), always fellow astronauts, were the only people who normally would speak to the crew.) The CAPCOM was accompanied by a group of geologists unfamiliar with the area who would rely on the astronauts' descriptions to interpret the findings.
The decision to land at Hadley came in September 1970. The Site Selection Committees had narrowed the field down to two sites — Hadley Rille or the crater Marius, near which were a group of low, possibly volcanic, domes. Although not ultimately his decision, the commander of a mission always held great sway. To David Scott the choice was clear, with Hadley, being "exploration at its finest."
Command Module Pilot Alfred Worden undertook a different kind of geology training. Working with an Egyptian-born geologist, Farouk El-Baz, he flew over areas in an airplane simulating the speed at which terrain would pass below him while in the Apollo Command/Service Module (CSM) in orbit. He became quite adept at making observations as the object traveled below.
Mission highlights.
Launch and outbound trip.
Apollo 15 launched on July 26, 1971, at 9:34 AM EDT from the Kennedy Space Center, at Cape Canaveral, Florida. During the launch, the S-IC did not completely shut off following staging for four seconds, creating the possibility of the spent stage banging into the S-II engines, damaging them and forcing an abort (the S-II exhaust also struck a telemetry package on the S-IC and caused it to fail). Despite this, the third stage and spacecraft reached its planned Earth parking orbit. A couple of hours into the mission, the third stage reignited to propel the spacecraft out of Earth orbit and on to the Moon.
A few days after launching from Florida, the spacecraft passed behind the far side of the Moon, where the Service Propulsion System (SPS) engine on the CSM ignited for a six-minute burn, to slow the craft down into an initial lunar orbit. Once the lowest point of altitude in the orbit was reached, the SPS engine was fired again, to place the spacecraft into the proper descent orbit for the Lunar Module landing at Hadley.
Landing.
Most of the first part of the day after arriving in lunar orbit on July 30 was spent in preparing the Lunar Module for descent to the lunar surface later on that day. When preparations were complete, un-docking from the CSM was attempted; it did not occur, because of a faulty seal in the hatch mechanism. The Command Module Pilot, Alfred Worden, re-sealed the hatch; the LM then separated from the CSM. David Scott and James Irwin continued preparations for the descent while Worden remained in the CSM, returning to a higher orbit to perform lunar observations and await his crewmates' return a few days later.
Soon, Scott and Irwin began the descent to the Hadley landing site. Several minutes after descent was initiated, at pitch-over and the beginning of the approach phase of the landing, the LM was six kilometers east of the pre-selected landing target. On learning this, Scott altered the flight path of the LM. They touched down at 22:16:29 UTC on July 30 at Hadley, within a few hundred meters of the planned landing site. While previous crews had exited the Lunar Module shortly after landing, the crew of Apollo 15 elected to spend the rest of the day inside the LM, waiting until the next day to perform the first of three EVAs, or moonwalks, in order to preserve their sleep rhythm on a mission on which they were to spend a significantly longer time on the surface than previous crews had spent. Before they slept, Scott performed a stand-up EVA, during which the LM was depressurized and he photographed their surroundings from the top docking hatch.
Lunar surface.
Throughout the sleep period, Mission Control, in Houston, monitored a slow but steady oxygen leak. The data output of the onboard telemetry computers was limited during the night to conserve energy, so controllers could not determine the exact cause of the leak without awaking the crew. Scott and Irwin eventually were awakened an hour early, and the source of the leak was found to be an open valve on the urine transfer device. After the problem was solved, the crew began preparation for the first Moon walk.
Four hours later, Scott and Irwin became the seventh and eighth humans, respectively, to walk on the Moon. After unloading the Lunar Roving Vehicle (LRV), the two drove to the first moonwalk's primary destination, Elbow Crater, along the edge of Hadley Rille. On returning to the LM "Falcon", Scott and Irwin deployed the Apollo Lunar Surface Experiments Package (ALSEP). The first EVA lasted about 6½ hours.
The target of the second EVA, the next day, was the edge of Mount Hadley Delta, where the pair sampled boulders and craters along the Apennine Front. During this moonwalk, the astronauts recovered what came to be one of the more famous lunar samples collected on the Moon during Apollo, sample #15415, more commonly known as the "Genesis Rock." Once back at the landing site, Scott continued to try to drill holes for an experiment at the ALSEP site, with which he had struggled the day before. After conducting soil-mechanics experiments and erecting a U.S. flag, Scott and Irwin returned to the LM. EVA 2 lasted 7 hours and 12 minutes.
During EVA 3, the third and final moonwalk of the mission, the crew again ventured to the edge of Hadley Rille, this time to the northwest of the immediate landing site. After returning to the LM's location, Scott performed an experiment in view of the television camera, using a feather and hammer to demonstrate Galileo's theory that all objects in a given gravity field fall at the same rate, regardless of mass (in the absence of aerodynamic drag). He dropped the hammer and feather at the same time; because of the negligible lunar atmosphere, there was no drag on the feather, which hit the ground at the same time as the hammer.
Scott then drove the rover to a position away from the LM, where the television camera could be used to observe the lunar liftoff. Scott set up a memorial nearby to the cosmonauts and astronauts who were known to have died up to that time, with a plaque bearing their names and a "Fallen Astronaut" statuette. The EVA lasted 4 hours and 50 minutes.
In total, the two astronauts spent 18½ hours outside the LM and collected approximately of lunar samples.
Return to Earth.
After lifting off from the lunar surface 2 days and 18 hours after landing, the LM ascent stage rendezvoused and re-docked with the CSM with Worden aboard in orbit. After transferring samples and other items from the LM to the CSM, the LM was sealed off, jettisoned, and intentionally crashed into the lunar surface. After completing more observations of the Moon from orbit and releasing the sub-satellite, the three-person crew departed lunar orbit with another burn of the SPS engine.
The next day, on the return trip to Earth, Worden performed a spacewalk in deep space, the first of its kind, to retrieve exposed film from the SIM bay. Later on in the day, the crew set an endurance record for Apollo program, becoming the longest Apollo spaceflight to that point.
On approach to Earth the next day, August 7, the Service Module was jettisoned, and the Command Module (CM) reentered the Earth's atmosphere. Although one of the three parachutes on the CM failed to deploy properly, only two were required for a safe landing (one extra for redundancy). Upon landing in the North Pacific Ocean, the crew were recovered and taken aboard the recovery ship, the USS "Okinawa" after a mission lasting 12 days, 7 hours, 11 minutes, and 53 seconds.
Hardware.
Spacecraft.
Apollo 15 used Command/Service Module CSM-112, which was given the call sign "Endeavour", named after the HMS "Endeavour" and Lunar Module LM-10, call sign "Falcon", named after the United States Air Force Academy mascot. If Apollo 15 had flown as a H mission, it would have been with CSM-111 and LM-9. That CSM was used by the Apollo–Soyuz Test Project in 1975, but the Lunar Module went unused and is now on display at the Kennedy Space Center Visitor Complex.
After re-entry, one of "Endeavour"'s three main parachutes collapsed after opening. Only two of the three parachutes were required for safe splashdown; the third was a contingency. "Endeavour" ultimately splashed down safely to end the mission.
Technicians at the Kennedy Space Center had many problems with the SIM bay in the Service Module. It was the first time it had flown and experienced problems from the start. Problems came from the fact the instruments were designed to operate in zero gravity, but had to be tested in the 1 g on the surface of the Earth. As such, things like the 7.5 m booms for the mass and gamma ray spectrometers could only be tested using railings that tried to mimic the space environment, and so they never worked particularly well. When the technicians tried to integrate the entire bay into the rest of the spacecraft, data streams would not synchronize, and lead investigators of the instruments would want to make last minute checks and changes. When it came time to test the operation of the gamma-ray spectrometer, it was necessary to stop every engine within of the test site.
On the Lunar Module, the fuel and oxidizer tanks were enlarged on both the descent and ascent stages and the engine bell on the descent stage was extended. Batteries and solar cells were added for increased electrical power. In all this increased the weight of the Lunar Module to , heavier than previous models.
"Endeavour" is currently on display at the National Museum of the United States Air Force at Wright-Patterson Air Force Base in Dayton, Ohio.
Lunar Rover.
The Lunar Roving Vehicle had been in development since May 1969, with the contract awarded to Boeing. It could be folded into a space 5 ft by 20 in (1.5 m by 0.5 m). Unloaded it weighed 460 lb (209 kg) and when carrying two astronauts and their equipment, 1500 lb (700 kg). Each wheel was independently driven by a ¼ horsepower (200 W) electric motor. Although it could be driven by either astronaut, the Commander always drove. Travelling at speeds up to 6 to 8 mph (10 to 12 km/h), it meant that for the first time the astronauts could travel far afield from their lander and still have enough time to do some scientific experiments.
Lunar subsatellite.
The Apollo 15 subsatellite (PFS-1) was a small satellite released into lunar orbit from the SIM bay. Its main objectives were to study the plasma, particle, and magnetic field environment of the Moon and map the lunar gravity field. Specifically, it measured plasma and energetic particle intensities and vector magnetic fields, and facilitated tracking of the satellite velocity to high precision. A basic requirement was that the satellite acquire fields and particle data everywhere on the orbit around the Moon. The Moon's roughly circular orbit about the Earth at ~380,000 km (60 Earth radii) carried the subsatellite into both interplanetary space and various regions of the Earth's magnetosphere. The satellite orbited the Moon and returned data from August 4, 1971 until January 1973.
In later years, through a study of many lunar orbiting satellites, scientists came to discover that most low lunar orbits (LLO) are unstable. Fortunately, PFS-1 had been placed, unknown to mission planners at the time, very near to one of only four lunar "frozen orbits", where a lunar satellite may remain indefinitely.
Releasing the subsatellite was the crew's final activity in lunar orbit, occurring an hour before the burn to take them back to Earth. A virtually identical subsatellite was deployed by Apollo 16.
Launch vehicle.
The Saturn V that launched Apollo 15 was designated SA-510, the tenth flight-ready model of the rocket. As the payload of the rocket was greater, changes were made to its launch trajectory and Saturn V itself. The rocket was launched in a more southerly direction (80–100 degrees azimuth) and the Earth parking orbit lowered to above the Earth's surface. These two changes meant more could be launched. The propellant reserves were reduced and the number of retrorockets on the S-IC first stage (used to separate the spent first stage from the S-II second stage) reduced from eight to four. The four outboard engines of the S-IC would be burned longer and the center engine would also burn longer before being shut down (see Saturn V for more information on the launch sequence). Changes were also made to the S-II to stop pogo oscillations.
Once all the various components had been installed on the Saturn V, it was moved to the launch site, Launch Complex 39A. During late June and early July 1971, the rocket and Launch Umbilical Tower (LUT) were struck by lightning at least four times. All was well however, with only minor damage suffered.
Space suits.
The astronauts themselves wore new space suits. On all previous Apollo flights, including the non-lunar flights, the commander and lunar module pilot had worn suits with the life support, liquid cooling, and communications connections in two parallel rows of three. On Apollo 15, the new suits, dubbed the "A7LB," had the connectors situated in triangular pairs. This new arrangement, along with the relocation of the entry zipper (which went in an up-down motion on the old suits), from the right shoulder to the left hip, allowed the inclusion of a new waist joint, allowing the astronauts to bend completely over and to sit on the rover. Upgraded backpacks allowed for longer-duration moonwalks, and the Command Module Pilot, who wore a suit with three connectors, would wear a five-connector version of the old Moon suit — the liquid cooling water connector being removed, as the Command Module Pilot would make a "deep-space EVA" to retrieve film cartridges on the flight home.
Scandals.
After a successful mission, the reputations of the crew and NASA were tarnished by a deal the crew had made with a German stamp dealer. H. Walter Eiermann, who had many professional and social contacts with NASA employees and the astronaut corps, arranged for Scott to carry unauthorized commemorative postal covers in his space suit, in addition to the postal covers NASA had contracted to carry for the United States Postal Service. Eiermann had promised each astronaut $7,000 in the form of savings accounts in return for 100 covers signed after having been on the Moon. He told the astronauts that he would not advertise or sell the covers until the end of the Apollo program. Irwin wrote in his book "To Rule the Night" that the astronauts had agreed to the deal as a way to help finance their children's college tuition.
One final controversial event happened after the flight. The crew had contacted Belgian sculptor Paul Van Hoeydonck to create a small statuette to commemorate those astronauts and cosmonauts that had lost their lives in the furtherance of space exploration. The small aluminum sculpture called "Fallen Astronaut" was left on the Moon next to the lunar rover at the end of EVA 3, along with a plaque bearing the names of 14 American astronauts and Soviet cosmonauts. Unknown at the time, two of the original selection of 20 cosmonauts had also died before Apollo 15: Valentin Bondarenko in a fire during training in March 1961 and Grigori Nelyubov in a train accident/suicide in February 1966. Therefore, their names were not included on the plaque. The memorial was left while the television camera was turned off. Only Irwin knew what Scott was doing at the time. Scott told mission control he was doing some cleanup activities around the rover so they wouldn't know what he was doing. They had agreed with Van Hoeydonck that no replicas were to be made. After mentioning the statuette during their post-flight press conference, the National Air and Space Museum contacted the crew asking for a replica made for the museum, and Van Hoeydonck subsequently advertised replicas for sale to the public. Under pressure from NASA, Van Hoeydonck withdrew the sale offer. NASA ultimately showed the monument on its Apollo 15 mission documentary, with no mention that it was unauthorized.
Mission insignia.
The three astronauts of Apollo 15 were all United States Air Force active duty officers, and their patch carries Air Force motifs (just as the Apollo 12 all-Navy crew's patch had featured a sailing ship). The circular patch features stylized red, white and blue birds flying over the Hadley Rille section of the Moon. Immediately behind the birds, a line of craters form the Roman numeral XV. The artwork is circled in red, with a white band giving the mission and crew names and a blue border. Scott contacted fashion designer Emilio Pucci to design the patch, who came up with the basic idea of the three-bird motif on a square patch. The crew changed the shape to round and the colors from blues and greens to a patriotic red, white and blue. Worden stated that each bird also represented an astronaut, white being his own color (and as Command Module Pilot, uppermost), with Scott the blue bird and Irwin the red. The Roman numeral design was created when NASA insisted that the mission number be displayed in Arabic numerals.
Visibility from space.
The halo area of the Apollo 15 landing site, generated by the LM's exhaust plume, was observed by a camera aboard the Japanese lunar orbiter SELENE and confirmed by comparative analysis of photographs in May 2008. This corresponds well to photographs taken from the Apollo 15 Command Module showing a change in surface reflectivity due to the plume, and was the first visible trace of manned landings on the Moon seen from space since the close of the Apollo program.
External links.
NASA reports
Multimedia

</doc>
<doc id="1970" url="http://en.wikipedia.org/wiki?curid=1970" title="Apollo 16">
Apollo 16

Apollo 16 was the tenth manned mission in the United States Apollo space program, the fifth and penultimate to land on the Moon and the first to land in the lunar highlands. The second of the so-called "J missions," it was crewed by Commander John Young, Lunar Module Pilot Charles Duke and Command Module Pilot Ken Mattingly. Launched from the Kennedy Space Center in Florida at 12:54 PM EST on April 16, 1972, the mission lasted 11 days, 1 hour, and 51 minutes, and concluded at 2:45 PM EST on April 27.
John Young and Charles Duke spent 71 hours—just under three days—on the lunar surface, during which they conducted three extra-vehicular activities or moonwalks, totaling 20 hours and 14 minutes. The pair drove the Lunar Roving Vehicle (LRV), the second produced and used on the Moon, . On the surface, Young and Duke collected of lunar samples for return to Earth, while Command Module Pilot Ken Mattingly orbited in the Command/Service Module (CSM) above to perform observations. Mattingly spent 126 hours and 64 revolutions in lunar orbit. After Young and Duke rejoined Mattingly in lunar orbit, the crew released a subsatellite from the Service Module (SM). During the return trip to Earth, Mattingly performed a one-hour spacewalk to retrieve several film cassettes from the exterior of the Service Module.
Apollo 16's landing spot in the highlands was chosen to allow the astronauts to gather geologically older lunar material than the samples obtained in the first four landings, which were in or near lunar maria. Samples from the Descartes Formation and the Cayley Formation disproved a hypothesis that the formations were volcanic in origin.
Crew.
Mattingly had originally been assigned to the prime crew of Apollo 13, but was exposed to the measles through Duke, at that time on the back-up crew for Apollo 13, who had caught it from one of his children. He never contracted the illness, but was nevertheless removed from the crew and replaced by his backup, Jack Swigert, three days before the launch. Young, a captain in the United States Navy, had flown on three spaceflights prior to Apollo 16: Gemini 3, Gemini 10 and Apollo 10, which orbited the Moon. One of 19 astronauts selected by NASA in April 1966, Duke had never flown in space before Apollo 16. He served on the support crew of Apollo 10 and was a Capsule Communicator (CAPCOM) for Apollo 11.
Backup crew.
Although not officially announced, the original backup crew consisted of Fred W. Haise (CDR), William R. Pogue (CMP) and Gerald P. Carr (LMP), who were targeted for the prime crew assignment on Apollo 19. However, after the cancellations of Apollos 18 and 19 were finalized in September 1970 this crew would not rotate to a lunar mission as planned. Subsequently, Roosa and Mitchell were recycled to serve as members of the backup crew after returning from Apollo 14, while Pogue and Carr were reassigned to the Skylab program where they flew on Skylab 4.
Mission insignia.
The insignia of Apollo 16 is dominated by a rendering of an American eagle and a red, white and blue shield, representing the people of the United States, over a gray background representing the lunar surface. Overlaying the shield is a gold NASA vector, orbiting the Moon. On its gold-outlined blue border, there are 16 stars, representing the mission number, and the names of the crew members: Young, Mattingly, Duke. The insignia was designed from ideas originally submitted by the crew of the mission.
Planning and training.
Landing site selection.
Apollo 16 was to be the second of the J missions, an Apollo mission type featuring the use of the Lunar Roving Vehicle, increased scientific capability, and lunar surface stays of three days. As Apollo 16 was the penultimate mission in the Apollo program and there was no new hardware or procedures to test on the lunar surface, the last two missions (the other being Apollo 17) presented opportunities for astronauts to clear up some uncertainties in understanding the Moon's properties. Although previous Apollo expeditions, including Apollo 14 and Apollo 15 obtained samples of pre-mare lunar material, before lava began to upwell from the Moon's interior and flood the low areas and basins, none had actually visited the lunar highlands.
Apollo 14 had visited and sampled a ridge of material that had been ejected by the impact that created the Mare Imbrium impact basin. Likewise, Apollo 15 had also sampled material in the region of Imbrium, visiting the basin's edge. There remained the possibility, because the Apollo 14 and Apollo 15 landing sites were closely associated with the Imbrium basin, that different geologic processes were prevalent in areas of the lunar highlands far from Mare Imbrium. Several members of the scientific community remarked that the central lunar highlands resembled regions on Earth that were created by volcanic processes and hypothesized the same might be true on the Moon. They had hoped that scientific output from the Apollo 16 mission would provide an answer.
Two locations on the Moon were given primary consideration for exploration by the Apollo 16 expedition: the Descartes Highlands region west of Mare Nectaris and the crater Alphonsus. At Descartes, the Cayley and Descartes formations were the primary areas of interest in that scientists suspected, based on telescopic and orbital imagery, that the terrain found there was formed by magma more viscous than that which formed the lunar maria. The Cayley Formation's age was approximated to be about the same as Mare Imbrium based on the local frequency of impact craters. The considerable distance between the Descartes site and previous Apollo landing sites would be beneficial for the network of geophysical instruments, portions of which were deployed on each Apollo expedition beginning with Apollo 12.
At the Alphonsus, three scientific objectives were determined to be of primary interest and paramount importance: the possibility of old, pre-Imbrium impact material from within the crater's wall, the composition of the crater's interior and the possibility of past volcanic activity on the floor of the crater at several smaller "dark halo" craters. Geologists feared, however, that samples obtained from the crater might have been contaminated by the Imbrium impact, thus preventing Apollo 16 from obtaining samples of pre-Imbrium material. There also remained the distinct possibility that this objective had already been satisfied by the Apollo 14 and Apollo 15 missions, as the Apollo 14 samples had not yet been completely analyzed and samples from Apollo 15 had not yet been obtained.
It was decided to target the Apollo 16 mission for the Descartes site. Following the decision, the Alphonsus site was considered the most likely candidate for Apollo 17, but was eventually rejected. With the assistance of orbital photography obtained on the Apollo 14 mission, the Descartes site was determined to be safe enough for a manned landing. The specific landing site was between two young impact craters, North Ray and South Ray craters – in diameter, respectively – which provided "natural drill holes" which penetrated through the lunar regolith at the site, thus leaving exposed bedrock that could be sampled by the crew.
After selecting the landing site for Apollo 16, sampling the Descartes and Cayley formations, two geologic units of the lunar highlands, was determined by mission planners to be the primary sampling interest of the mission. It was these formations that the scientific community widely suspected were formed by lunar volcanism, but this hypothesis was proven incorrect by the composition of lunar samples from the mission.
Training.
In preparation for their mission, the Apollo 16 astronauts participated in an extensive training program that included several field geology trips to introduce the astronauts to concepts and techniques they would use on the lunar surface. During these trips, the astronauts visited and provided scientific descriptions of geologic features they were likely to encounter. In July 1971, the Apollo 16 astronauts visited Sudbury, Ontario, Canada for geology training exercises, the first time U.S. astronauts did so. Geologists chose the area because of a wide crater created about 1.6 million years ago by a large meteorite. The Sudbury Basin shows evidence of shatter cone geology familiarizing the Apollo crew with geologic evidence of a meteor impact. During the training exercises the astronauts did not wear space suits, but carried radio equipment to converse with each other and a scientist-astronaut, practicing procedures they would use on the lunar surface.
In addition to field geology training, the astronauts also trained to use the space suits, adapt to the reduced lunar gravity, collect samples, maneuver in the Lunar Roving Vehicle, and land and recover after the mission. They also received survival training and preparation for other technical aspects of the mission.
Mission highlights.
Launch and outbound trip.
The launch of Apollo 16 was delayed one month from March 17 to April 16. This was the first launch delay in the Apollo program due to a technical problem. During the delay, the space suits, a spacecraft separation mechanism and batteries in the Lunar Module (LM) were modified and tested. There were concerns that the explosive mechanism designed to separate the docking ring from the Command Module (CM) would not create enough pressure to completely sever the ring. This, along with a dexterity issue in Young's space suit and fluctuations in the capacity of the Lunar Module batteries, required investigation and trouble-shooting. In January 1972, three months before the planned April launch date, a fuel tank in the Command Module was accidentally damaged during a routine test. The rocket was returned to the Vertical Assembly Building (VAB) and the fuel tank replaced, and the rocket returned to the launch pad in February in time for the scheduled launch.
The official mission countdown began on Monday, April 10, 1972, at 8:30 AM, six days before the launch. At this point the Saturn V rocket's three stages were powered up and drinking water was pumped into the spacecraft. As the countdown began, the crew of Apollo 16 was participating in final training exercises in anticipation of a launch on April 16. The astronauts underwent their final preflight physical examination on April 11. On April 15, liquid hydrogen and liquid oxygen propellants were pumped into the spacecraft, while the astronauts rested in anticipation of their launch the next day.
The Apollo 16 mission launched from the Kennedy Space Center in Florida at 12:54 PM EST on April 16, 1972. The launch was nominal; the crew experienced vibration similar to that of previous crews. The first and second stages of the Saturn V rocket performed nominally; the spacecraft entered orbit around Earth just under 12 minutes after lift-off. After reaching orbit, the crew spent time adapting to the zero-gravity environment and preparing the spacecraft for Trans Lunar Injection (TLI), the burn of the third-stage rocket that would propel them to the Moon. In Earth orbit, the crew faced minor technical issues, including a potential problem with the environmental control system and the S-IVB third stage's attitude control system, but eventually resolved or compensated for them as they prepared to depart towards the Moon. After two orbits, the rocket's third stage reignited for just over five minutes, propelling the craft towards the Moon at about . Six minutes after the burn of the S-IVB, the Command/Service Module, containing the crew, separated from the rocket and traveled for before turning around and retrieving the Lunar Module from inside the expended rocket stage. The maneuver, known as transposition, went smoothly and the LM was extracted from the S-IVB. Following transposition and docking, the crew noticed the exterior surface of the Lunar Module was giving off particles from a spot where the LM's skin appeared torn or shredded; at one point, Duke estimated they were seeing about five to ten particles per second. The crew entered the Lunar Module through the docking tunnel connecting it with the Command Module to inspect its systems, at which time they did not spot any major issues. Once on course towards the Moon, the crew put the spacecraft into a rotisserie "barbecue" mode in which the craft rotated along its long axis three times per hour to ensure even heat distribution about the spacecraft from the Sun. After further preparing the craft for the voyage, the crew began the first sleep period of the mission just under 15 hours after launch.
By the time Mission Control issued the wake-up call to the crew for flight day two, the spacecraft was about away from the Earth, traveling at about . As it was not due to arrive in lunar orbit until flight day four, flight days two and three were largely preparatory days, consisting of spacecraft maintenance and scientific research. On day two, the crew performed an electrophoresis experiment, also performed on Apollo 14, in which they attempted to prove the higher purity of particle migrations in the zero-gravity environment. The remainder of day two included a two-second mid-course correction burn performed by the Command/Service Module's Service Propulsion System engine to tweak the spacecraft's trajectory. Later in the day, the astronauts entered the Lunar Module for the second time in the mission to further inspect the landing craft's systems. The crew reported they had observed additional paint peeling from a portion of the LM's outer aluminum skin. Despite this, the crew discovered that the spacecraft's systems were performing nominally. Following the LM inspection, the crew reviewed checklists and procedures for the following days in anticipation of their arrival and the Lunar Orbit Insertion burn. Command Module Pilot Mattingly reported a "gimbal lock" warning light, indicating the craft was not reporting an attitude. Mattingly alleviated this by realigning the guidance system using the Sun and Moon. At the end of day two, Apollo 16 was about away from Earth.
At the beginning of day three, the spacecraft was about away from the Earth. The velocity of the craft steadily decreased, as it had not yet reached the lunar sphere of gravitational influence. The early part of day three was largely housekeeping, spacecraft maintenance and exchanging status reports with Mission Control in Houston. The crew performed the Apollo light flash experiment, or ALFMED, to investigate "light flashes" that were seen by the astronauts when the spacecraft was dark, regardless of whether or not their eyes were open, on Apollo lunar flights. This was thought to be caused by the penetration of the eye by cosmic ray particles. During the second half of the day, Young and Duke again entered the Lunar Module to power it up and check its systems, and perform housekeeping tasks in preparation for lunar landing. The systems were found to be functioning as expected. Following this, the crew donned their space suits and rehearsed procedures that would be used on landing day. Just before the end of flight day three at 59 hours, 19 minutes, 45 seconds after liftoff, while from the Earth and from the Moon, the spacecraft's velocity began increasing as it accelerated towards the Moon after entering the lunar sphere of influence.
After waking up on flight day four, the crew began preparations for the maneuver that would brake the spacecraft into orbit around the Moon, or lunar orbit insertion. At a distance of from the Moon, the Scientific Instrument Module (SIM) bay cover was jettisoned. At just over 74 hours into the mission, the spacecraft passed behind the Moon, losing direct contact with Mission Control. While over the far side of the Moon, the Command/Service Module's Service Propulsion System engine burned for 6 minutes and 15 seconds, braking the spacecraft into an orbit around the Moon with a low point (pericynthion) of 58.3 and a high point (apocynthion) of 170.4 nautical miles (108.0 and 315.6 km, respectively). After entering lunar orbit, the crew began preparations for the Descent Orbit Insertion (DOI) maneuver to further modify the spacecraft's orbital trajectory. The maneuver was successful, decreasing the craft's pericynthion to . The remainder of flight day four was spent making observations and preparing for activation of the Lunar Module, undocking, and landing the next day.
Lunar surface.
The crew continued preparing for Lunar Module activation and undocking shortly after waking up to begin flight day five. The boom that extended the mass spectrometer out from the Command/Service Module's Scientific Instruments Bay was stuck in a semi-deployed position. It was decided that Young and Duke would visually inspect the boom after undocking from the CSM in the LM. They entered the LM for activation and checkout of the spacecraft's systems. Despite entering the LM 40 minutes ahead of schedule, they completed preparations only 10 minutes early due to numerous delays in the process. With the preparations finished, they undocked in the LM "Orion" from Mattingly in the Command/Service Module "Casper" 96 hours, 13 minutes, 13 seconds into the mission. For the rest of the two crafts' passes over the near side of the Moon, Mattingly prepared to shift "Casper" to a circular orbit while Young and Duke prepared "Orion" for the descent to the lunar surface. At this point, during tests of the CSM's steerable rocket engine in preparation for the burn to modify the craft's orbit, a malfunction occurred in the engine's backup system. According to mission rules, "Orion" would have then re-docked with "Casper", in case Mission Control decided to abort the landing and use the Lunar Module's engines for the return trip to Earth. After several hours of analysis, however, mission controllers determined that the malfunction could be worked around and Young and Duke could proceed with the landing. As a result of this, powered descent to the lunar surface began about six hours behind schedule. Because of the delay, Young and Duke began their descent to the surface at an altitude higher than that of any previous mission, at . At an altitude of about , Young was able to view the landing site in its entirety. Throttle-down of the LM's landing engine occurred on time and the spacecraft tilted forward to its landing orientation at an altitude of . The LM landed north and west of the planned landing site at 104 hours, 29 minutes, and 35 seconds into the mission, at 2:23:35 UTC on April 21.
After landing, Young and Duke began powering down some of the LM's systems to conserve battery power. Upon completing their initial adjustments, the pair configured "Orion" for their three-day stay on the lunar surface, removed their space suits and took initial geological observations of the immediate landing site. They then settled down for their first meal on the surface. After eating, they configured the cabin for their first sleep period on the Moon. The landing delay caused by the malfunction in the Command/Service Module's main engine necessitated significant modifications to the mission schedule. Apollo 16 would spend one less day in lunar orbit after surface exploration had been completed to afford the crew contingency time to compensate for any further problems and to conserve expendables. In order to improve Young's and Duke's sleep schedule, the third and final moonwalk of the mission was trimmed from seven hours to five.
The next morning, flight day five, Young and Duke ate breakfast and began preparations for the first extra-vehicular activity (EVA), or moonwalk. After the pair donned and pressurized their space suits and depressurized the Lunar Module cabin, Young climbed out onto the "porch" of the LM, a small platform above the ladder. Duke handed Young a jettison bag full of trash to dispose of on the surface. Young then lowered the equipment transfer bag (ETB), containing equipment for use during the EVA, to the surface. Young descended the ladder and, upon setting foot on the lunar surface, became the ninth human to walk on the Moon. Upon stepping onto the surface, Young expressed his sentiments about being there: "There you are: Mysterious and Unknown Descartes. Highland plains. Apollo 16 is gonna change your image. I'm sure glad they got ol' Brer Rabbit, here, back in the briar patch where he belongs." Duke soon descended the ladder and joined Young on the surface, becoming the tenth and youngest human to walk on the Moon, at age 36. After setting foot on the lunar surface, Duke expressed his excitement, commenting: "Fantastic! Oh, that first foot on the lunar surface is super, Tony!" The pair's first task of the moonwalk was to unload the Lunar Roving Vehicle, the Far Ultraviolet Camera/Spectrograph (UVC), and other equipment, from the Lunar Module. This was done without problems. On first driving the lunar rover, Young discovered that the rear steering was not working. He alerted Mission Control to the problem before setting up the television camera and planting the flag of the United States with Duke. The day's next task was to deploy the Apollo Lunar Surface Experiments Package (ALSEP); while they were parking the lunar rover, on which the TV camera was mounted, to observe the deployment, the rear steering began functioning without explanation. While deploying a heat-flow experiment that had burned up with the Lunar Module "Aquarius" on Apollo 13 and had been attempted without success on Apollo 15, a cable was inadvertently snapped after getting caught around Young's foot. After ALSEP deployment, they collected samples in the vicinity. About four hours after the beginning of EVA-1, they mounted the lunar rover and drove to the first geologic stop, Plum Crater, a crater on the rim of Flag Crater, a crater across. There, at a distance of from the LM, they sampled material from the vicinity of Flag Crater, which scientists believed penetrated through the upper regolith layer to the underlying Cayley Formation. It was there that Young retrieved, at the request of Mission Control, the largest rock returned by an Apollo mission, a breccia nicknamed Big Muley after mission geology principal investigator William R. Muehlberger. The next stop of the day was Buster Crater, about from the LM. There, Duke took pictures of Stone Mountain and South Ray Crater while Young deployed a magnetic field experiment. At that point, scientists began to reconsider their pre-mission hypothesis that Descartes had been the setting of ancient volcanic activity, as the two astronauts had yet to find any volcanic material. Following their stop at Buster, Young did a demonstration drive of the lunar rover while Duke filmed with a 16 mm movie camera. After completing more tasks at the ALSEP, they returned to the LM to close out the moonwalk. They reentered the LM 7 hours, 6 minutes, and 56 seconds after the start of the EVA. Once inside, they pressurized the LM cabin, went through a half-hour briefing with scientists in Mission Control, and configured the cabin for the sleep period.
Shortly after waking up on the morning of flight day six three and a half minutes early, they discussed with Mission Control in Houston the day's timeline of events. The second lunar excursion's primary objective was to visit Stone Mountain to climb up the slope of about 20 degrees to reach a cluster of five craters known as "Cinco Craters." After preparations for the day's moonwalk were completed, the astronauts climbed out of the Lunar Module. After departing the immediate landing site in the lunar rover, they arrived at the day's first destination, the Cinco Craters, from the LM. At above the valley floor, the pair were at the highest elevation above the LM of any Apollo mission. After marveling at the view from the side of Stone Mountain, which Duke described as "spectacular," the astronauts gathered samples in the vicinity. After spending 54 minutes on the slope, they climbed aboard the lunar rover en route to the day's second stop, station five, a crater across. There, they hoped to find Descartes material that had not been contaminated by ejecta from South Ray Crater, a large crater south of the landing site. The samples they collected there, although their origin is still not certain, are, according to geologist Don Wilhelms, "a reasonable bet to be Descartes." The next stop, station six, was a blocky crater, where the astronauts believed they could sample the Cayley Formation as evidenced by the firmer soil found there. Bypassing station seven to save time, they arrived at station eight on the lower flank of Stone Mountain, where they sampled material on a ray from South Ray Crater for about an hour. There, they collected black and white breccias and smaller, crystalline rocks rich in plagioclase. At station nine, an area known as the "Vacant Lot," which was believed to be free of ejecta from South Ray, they spent about 40 minutes gathering samples. Twenty-five minutes after departing station nine, they arrived at the final stop of the day, halfway between the ALSEP site and the LM. There, they dug a double core and conducted several penetrometer tests along a line stretching east of the ALSEP. At the request of Young and Duke, the moonwalk was extended by ten minutes. After returning to the LM to wrap up the second lunar excursion, they climbed back inside the landing craft's cabin, sealing and pressurizing the interior after 7 hours, 23 minutes, and 26 seconds of EVA time, breaking a record that had been set on Apollo 15. After eating a meal and proceeding with a debriefing on the day's activities with Mission Control, they reconfigured the LM cabin and prepared for the sleep period.
Flight day seven was their third and final day on the lunar surface, returning to orbit to rejoin Mattingly in the Command/Service Module following the day's moonwalk. During the third and final lunar excursion, they were to explore North Ray Crater, the largest of any of the craters any Apollo expedition had visited. After exiting "Orion", the pair drove the lunar rover away from the LM before adjusting their heading to travel to North Ray Crater. The drive was smoother than that of the previous day, as the craters were shallower and boulders were less abundant north of the immediate landing site. Boulders gradually became larger and more abundant as they approached North Ray in the lunar rover. Upon arriving at the rim of North Ray Crater, they were away from the LM. After their arrival, the duo took photographs of the wide and deep crater. They visited a large boulder, taller than a four-story building, which became known as 'House Rock'. Samples obtained from this boulder delivered the final blow to the pre-mission volcanic hypothesis, proving it incorrect. House Rock had numerous bullet hole-like marks where micrometeoroids from space had impacted the rock. About 1 hour and 22 minutes after arriving, they departed for station 13, a large boulder field about from North Ray. On the way, they set a lunar speed record, traveling at an estimated downhill. They arrived at a high boulder, which they called 'Shadow Rock'. Here, they sampled permanently shadowed soil. During this time, Mattingly was preparing the Command/Service Module in anticipation their return approximately six hours later. After three hours and six minutes, they returned to the LM, where they completed several experiments and offloaded the rover. A short distance from the LM, Duke placed a photograph of his family and a United States Air Force commemorative medallion on the surface. Young drove the rover to a point about east of the LM, known as the 'VIP site,' so its television camera, controlled remotely by Mission Control, could observe Apollo 16's liftoff from the Moon. They then reentered the LM after a 5 hour and 40 minute final excursion. After pressurizing the LM cabin, the crew began preparing to return to lunar orbit.
Return to Earth.
Eight minutes before departing the lunar surface, CAPCOM James Irwin notified Young and Duke from Mission Control that they were go for liftoff. Two minutes before launch, they activated the "Master Arm" switch and then the "Abort Stage" button, after which they awaited ignition of "Orion"’s ascent stage engine. When the ascent stage ignited, small explosive charges severed the ascent stage from the descent stage and cables connecting the two were severed by a guillotine-like mechanism. Six minutes after liftoff, at a speed of about , Young and Duke reached lunar orbit. Young and Duke successfully rendezvoused and re-docked with Mattingly in the Command/Service Module. To minimize the transfer of lunar dust from the LM cabin into the CSM, Young and Duke cleaned the cabin before opening the hatch separating the two spacecraft. After opening the hatch and reuniting with Mattingly, the crew transferred the samples Young and Duke had collected on the surface into the CSM for transfer to Earth. After transfers were completed, the crew would sleep before jettisoning the empty Lunar Module ascent stage the next day, when it was to be crashed intentionally into the lunar surface.
The next day, after final checks were completed, the expended LM ascent stage was jettisoned. Because of a failure by the crew to activate a certain switch in the LM before sealing it off, it initially tumbled after separation and did not execute the rocket burn necessary for the craft's intentional de-orbit. The ascent stage eventually crashed into the lunar surface nearly a year after the mission. The crew's next task, after jettisoning the Lunar Module ascent stage, was to release a subsatellite into lunar orbit from the CSM's Scientific Instrument Bay. The burn to alter the CSM's orbit to that desired for the subsatellite had been cancelled; as a result, the subsatellite lasted half of its anticipated lifetime. Just under five hours later, on the CSM's 65th orbit around the Moon, its Service Propulsion System main engine was reignited to propel the craft on a trajectory that would return it to Earth. The SPS engine performed the burn flawlessly despite the malfunction that had delayed the lunar landing several days before.
At a distance of about from Earth, Mattingly performed a "deep-space" extra-vehicular activity, or spacewalk, during which he retrieved several film cassettes from the CSM's SIM bay. While outside the spacecraft, Mattingly set up a biological experiment, the Microbial Ecology Evaluation Device (MEED). The MEED experiment was only performed on Apollo 16. The crew carried out various housekeeping and maintenance tasks aboard the spacecraft and ate a meal before concluding the day.
The penultimate day of the flight was largely spent performing experiments, aside from a twenty-minute press conference during the second half of the day. During the press conference, the astronauts answered questions pertaining to several technical and non-technical aspects of the mission prepared and listed by priority at the Manned Spacecraft Center in Houston by journalists covering the flight. In addition to numerous housekeeping tasks, the astronauts prepared the spacecraft for its atmospheric reentry the next day. At the end of the crew's final full day in space, the spacecraft was approximately from Earth and closing at a rate of about .
When the wake-up call was issued to the crew for their final day in space by CAPCOM Tony England, it was about out from Earth, traveling just over . Just over three hours before splashdown in the Pacific Ocean, the crew performed a final course correction burn, changing their velocity by . Approximately ten minutes before reentry into Earth's atmosphere, the cone-shaped Command Module containing the three crewmembers separated from the Service Module, which would burn up during reentry. At 265 hours and 37 minutes into the mission, at a velocity of about , Apollo 16 began atmospheric reentry. At its maximum, the temperature of the heat shield was between . After successful parachute deployment and less than 14 minutes after reentry began, the Command Module splashed down in the Pacific Ocean southeast of the island of Kiritimati (or "Christmas Island"), 290 hours, 37 minutes, 6 seconds after liftoff. The spacecraft and its crew was retrieved by the . They were safely aboard the "Ticonderoga" 37 minutes after splashdown.
Lunar subsatellite PFS-2.
The Apollo 16 subsatellite (PFS-2) was a small satellite released into lunar orbit from the Service Module. Its principal objective was to measure charged particles and magnetic fields all around the Moon as the Moon orbited Earth, similar to its sister spacecraft, PFS-1, released eight months earlier by Apollo 15. "The low orbits of both subsatellites were to be similar ellipses, ranging from above the lunar surface."
"Instead, something bizarre happened. The orbit of PFS-2 rapidly changed shape and distance from the Moon. In 2-1/2 weeks the satellite was swooping to within a hair-raising of the lunar surface at closest approach. As the orbit kept changing, PFS-2 backed off again, until it seemed to be a safe 30 miles away. But not for long: inexorably, the subsatellite's orbit carried it back toward the Moon. And on May 29, 1972—only 35 days and 425 orbits after its release"—PFS-2 crashed into the Lunar surface.
In later years, through a study of many lunar orbiting satellites, scientists came to discover that most low lunar orbits (LLO) are unstable. PFS-2 had been placed, unknown to mission planners at the time, squarely into one of the most unstable of orbits, at 11 degrees orbital inclination, far from the four "frozen lunar orbits" discovered only later at 27º, 50º, 76º, and 86º inclination.
Spacecraft locations.
The aircraft carrier USS "Ticonderoga" delivered the Apollo 16 Command Module to the North Island Naval Air Station, near San Diego, California, on Friday, May 5, 1972. On Monday, May 8, 1972, ground service equipment being used to empty the residual toxic reaction control system fuel in the Command Module tanks exploded in a Naval Air Station hangar. Forty-six people were sent to the hospital for 24 to 48 hours observation, most suffering from inhalation of toxic fumes. Most seriously injured was a technician who suffered a fractured kneecap when the GSE cart overturned on him. A hole was blown in the hangar roof 250 feet above; about 40 windows in the hangar were shattered. The Command Module suffered a three-inch gash in one panel.
The Apollo 16 Command Module "Casper" is on display at the U.S. Space & Rocket Center in Huntsville, Alabama. The Lunar Module ascent stage separated 24 April 1972 but a loss of attitude control rendered it out of control. It orbited the Moon for about a year. Its impact site on the Moon is unknown.
Duke donated some flown items, including a lunar map, to Kennesaw State University in Kennesaw, Georgia. He left two items on the Moon, both of which he photographed. The most famous is a plastic-encased photo portrait of his family (NASA Photo AS16-117-18841). The reverse of the photo is signed by Duke's family and bears this message: "This is the family of Astronaut Duke from Planet Earth. Landed on the Moon, April 1972." The other item was a commemorative medal issued by the United States Air Force, which was celebrating its 25th anniversary in 1972. He took two medals, leaving one on the Moon and donating the other to the Wright-Patterson Air Force Base museum.
In 2006, shortly after Hurricane Ernesto affected Bath, North Carolina, eleven year-old Kevin Schanze discovered a piece of metal debris on the ground near his beach home. Schanze and a friend discovered a "stamp" on the flat metal sheet, which upon further inspection turned out to be a faded copy of the Apollo 16 mission insignia. NASA later confirmed the object to be a piece of the first stage of the Saturn V rocket that launched Apollo 16 into space. In July 2011, after returning the piece of debris at NASA's request, 16-year-old Schanze was given an all-access tour of the Kennedy Space Center and VIP seating for the launch of STS-135, the final mission of the Space Shuttle program.

</doc>
<doc id="1971" url="http://en.wikipedia.org/wiki?curid=1971" title="Apollo 17">
Apollo 17

Apollo 17 was the final mission of the United States' Apollo lunar landing program, and was the sixth and last landing of humans on the Moon. Launched at 12:33 AM Eastern Standard Time (EST) on December 7, 1972, with a three-member crew consisting of Commander Eugene Cernan, Command Module Pilot Ronald Evans, and Lunar Module Pilot Harrison Schmitt, It was the last use of Apollo hardware for its original mission. After Apollo 17, extra Apollo spacecraft were used in the Skylab and Apollo–Soyuz Test Project programs.
Apollo 17 was the sixth Apollo lunar landing, the first night launch of a U.S. human spaceflight and the final crewed launch of a Saturn V rocket. It was a "J-type mission," which included a three-day lunar surface stay, extended scientific capability, and the third Lunar Roving Vehicle (LRV). While Evans remained in lunar orbit above in the Command/Service Module (CSM). Cernan and Schmitt spent just over three days on the lunar surface in the Taurus-Littrow valley, conducting three periods of extra-vehicular activity, or moonwalks, during which they collected lunar samples and deployed scientific instruments. Cernan, Evans, and Schmitt returned to Earth on December 19 after an approximately 12-day mission.
The decision to land in the Taurus-Littrow valley was made with the primary objectives for Apollo 17 in mind: to sample lunar highland material older than the impact that formed Mare Imbrium and investigating the possibility of relatively young volcanic activity in the same vicinity. Taurus-Littrow was selected with the prospects of finding highland material in the valley's north and south walls and the possibility that several craters in the valley surrounded by dark material could be linked to volcanic activity.
Apollo 17 also broke several records set by previous flights, including the longest manned lunar landing flight; the longest total lunar surface extravehicular activities; the largest lunar sample return, and the longest time in lunar orbit.
Apollo 17 remains the most recent manned Moon landing and also the last time humans have travelled beyond low Earth orbit.
Crew.
Eugene Cernan, Ronald Evans, and former X-15 pilot Joe Engle were assigned to the backup crew of Apollo 14. Engle flew sixteen X-15 flights, three of which exceeded the border of space. Following the rotation pattern that a backup crew would fly as the prime crew three missions later, Cernan, Evans, and Engle would have flown Apollo 17. Harrison Schmitt served on the backup crew of Apollo 15 and, following the crew rotation cycle, was slated to fly as Lunar Module Pilot on Apollo 18. However, Apollo 18 was cancelled in September 1970. Following this decision, the scientific community pressured NASA to assign a geologist to an Apollo landing, as opposed to a pilot trained in geology. In light of this pressure, Harrison Schmitt, a professional geologist, was assigned the Lunar Module Pilot position on Apollo 17.
Subsequent to the decision to assign Schmitt to Apollo 17, there remained the question of which crew (the full backup crew of Apollo 15, Dick Gordon, Vance Brand, and Schmitt, or the backup crew of Apollo 14) would become prime crew of the mission. NASA Director of Flight Crew Operations Deke Slayton ultimately assigned the backup crew of Apollo 14 (Cernan and Evans), along with Schmitt, to the prime crew of Apollo 17.
Backup crew.
Replacement.
The Apollo 15 prime crew received the backup assignment since this was to be the last lunar mission and the backup crew would not rotate to another mission. However, when the Apollo 15 postage stamp incident became public in early 1972 the crew was reprimanded by NASA and the United States Air Force (they were active duty officers). Director of Flight Crew Operations Deke Slayton removed them from flight status and replaced them with Young and Duke from the Apollo 16 prime crew and Roosa from the Apollo 14 prime and Apollo 16 backup crews.
Mission insignia.
The insignia's most prominent feature is an image of the Greek sun god Apollo backdropped by a rendering of an American eagle, the red bars on the eagle mirroring those on the flag of the United States. Three white stars above the red bars represent the three crewmen of the mission. The background includes the Moon, the planet Saturn and a galaxy or nebula. The wing of the eagle partially overlays the Moon, suggesting man's established presence there. The gaze of Apollo and the direction of the eagle's motion embody man's intention to explore further destinations in space.
The patch includes, along with the colors of the U.S. flag (red, white, and blue), the color gold, representative of a "golden age" of spaceflight that was to begin with Apollo 17. The image of Apollo in the mission insignia is a rendering of the "Apollo Belvedere" sculpture. The insignia was designed by Robert McCall, with input from the crew.
Planning and training.
Like Apollo 15 and Apollo 16, Apollo 17 was slated to be a "J-mission," an Apollo mission type that featured lunar surface stays of three days, higher scientific capability, and the usage of the Lunar Roving Vehicle. Since Apollo 17 was to be the final lunar landing of the Apollo program, high-priority landing sites that had not been visited previously were given consideration for potential exploration. A landing in the crater Copernicus was considered, but was ultimately rejected because Apollo 12 had already obtained samples from that impact, and three other Apollo expeditions had already visited the vicinity of Mare Imbrium. A landing in the lunar highlands near the crater Tycho was also considered, but was rejected because of the rough terrain found there and a landing on the lunar far side in the crater Tsiolkovskiy was rejected due to technical considerations and the operational costs of maintaining communication during surface operations. A landing in a region southwest of Mare Crisium was also considered, but rejected on the grounds that a Soviet spacecraft could easily access the site; Luna 20 eventually did so shortly after the Apollo 17 site selection was made.
After the elimination of several sites, three sites made the final consideration for Apollo 17: Alphonsus crater, Gassendi crater, and the Taurus-Littrow valley. In making the final landing site decision, mission planners took into consideration the primary objectives for Apollo 17: obtaining old highlands material from a substantial distance from Mare Imbrium, sampling material from young volcanic activity (i.e., less than three billion years), and having minimal ground overlap with the orbital ground tracks of Apollo 15 and Apollo 16 to maximize the amount of new data obtained.
The Taurus-Littrow site was selected with the prediction that the crew would be able to obtain samples of old highland material from the remnants of a landslide event that occurred on the south wall of the valley and the possibility of relatively young, explosive volcanic activity in the area. Although the valley is similar to the landing site of Apollo 15 in that it is on the border of a lunar mare, the advantages of Taurus-Littrow were believed to outweigh the drawbacks, thus leading to its selection as the Apollo 17 landing site.
Apollo 17 was the only lunar landing mission to carry the Traverse Gravimeter Experiment (TGE), an experiment built by Draper Laboratory at the Massachusetts Institute of Technology designed to provide relative gravity measurements throughout the landing site at various locations during the mission's moonwalks. Scientists would then use this data to gather information about the geological substructure of the landing site and the surrounding vicinity.
As with previous lunar landings, the Apollo 17 astronauts underwent an extensive training program that included training to collect samples on the surface, usage of the spacesuits, navigation in the Lunar Roving Vehicle, field geology training, survival training, splashdown and recovery training, and equipment training.
Mission hardware and experiments.
Traverse Gravimeter.
Apollo 17 was the only Apollo lunar landing mission to carry the Traverse Gravimeter Experiment. As gravimeters have proven to be useful in the geologic investigation of the Earth, the objective of this experiment was to determine the feasibility of using the same techniques on the Moon to learn about its internal structure. The gravimeter was used to obtain readings at the landing site in the immediate vicinity of the Lunar Module (LM), as well as various locations on the mission's traverse routes. The TGE was carried on the Lunar Roving Vehicle; measurements were taken by the astronauts while the LRV was not in motion or after the gravimeter was placed on the surface.
A total of twenty-six measurements were taken with the TGE during the mission's three moonwalks, with productive results. As part of the Apollo Lunar Surface Experiments Package (ALSEP), the astronauts also deployed the Lunar Surface Gravimeter, a similar experiment, which ultimately failed to function properly.
Scientific Instrument Module.
Sector one of the Apollo 17 Service Module (SM) contained the Scientific Instrument Module (SIM) bay. The SIM bay housed three experiments for use in lunar orbit: a lunar sounder, an infrared scanning radiometer, and a far-ultraviolet spectrometer. A mapping camera, panoramic camera, and a laser altimeter were also included in the SIM bay.
The lunar sounder beamed electromagnetic impulses toward the lunar surface, which were designed with the objective of obtaining data to assist in developing a geological model of the interior of the Moon to an approximate depth of .
The Infrared Scanning Radiometer was designed with the objective of generating a temperature map of the lunar surface to aid in locating surface features such as rock fields, structural differences in the lunar crust, and volcanic activity.
The Far-Ultraviolet Spectrometer was to be used to obtain data pertaining to the composition, density, and constituency of the lunar atmosphere. The spectrometer was also designed to detect far-UV radiation emitted by the Sun that has been reflected off the lunar surface.
The Laser Altimeter was designed with the intention of measuring the altitude of the spacecraft above the lunar surface within approximately two meters (6.5 feet), and providing altitude information to the panoramic and mapping cameras.
Light flash phenomenon.
Throughout the Apollo lunar missions, the crew members observed light flashes that penetrated closed eyelids. These flashes, described as "streaks" or "specks" of light, were usually observed by astronauts while the spacecraft was darkened during a sleep period. These flashes, while not observed on the lunar surface, would average about two per minute and were observed by the crew members during the trip out to the Moon, back to Earth, and in lunar orbit.
The Apollo 17 crew conducted an experiment, also conducted on Apollo 16, with the objective of linking these light flashes with cosmic rays. As part of an experiment conducted by NASA and the University of Houston, one astronaut wore a device that recorded the time, strength, and path of high-energy atomic particles that penetrated the device. Analysis of the results concluded that the evidence supported the hypothesis that the flashes occurred when charged particles travelled through the retina in the eye.
Surface Electrical Properties Experiment.
Apollo 17 was the only lunar surface expedition to include the Surface Electrical Properties (SEP) experiment. The experiment included two major components: a transmitting antenna deployed near the Lunar Module and a receiving antenna located on the Lunar Roving Vehicle. At different stops during the mission's traverses, electrical signals traveled from the transmitting device, through the ground, and received at the LRV. The electrical properties of the lunar soil could be determined by comparison of the transmitted and received electrical signals. The results of this experiment, which are consistent with lunar rock composition, show that the top of the Moon are extremely dry.
Lunar Roving Vehicle.
Apollo 17 was the third mission (the others being Apollo 15 and Apollo 16) to make use of a Lunar Roving Vehicle. The LRV, in addition to being used by the astronauts for transport from station to station on the mission's three moonwalks, was used to transport the astronauts' tools, communications equipment, and samples. The Apollo 17 LRV was also used to carry experiments unique to the mission, such as the Traverse Gravimeter and Surface Electrical Properties experiment. The Apollo 17 LRV traveled a cumulative distance of approximately in a total drive time of about four hours and twenty-six minutes; the greatest distance Eugene Cernan and Harrison Schmitt traveled from the Lunar Module was about .
Biological cosmic ray experiment.
Apollo 17 included a biological cosmic ray experiment (BIOCORE), carrying mice that had been implanted with radiation monitors to see whether they suffered damage from cosmic rays.
Five pocket mice ("Perognathus longimembris") were implanted with radiation monitors under their scalps and flown on the mission. The species was chosen because it was well-documented, small, easy to maintain in an isolated state (not requiring drinking water for the duration of the mission and with highly concentrated waste), and for its ability to withstand environmental stress. Four of the five mice survived the flight; the cause of death of the fifth mouse was not determined.
The study found lesions in the scalp itself and liver. The scalp lesions and liver lesions appeared to be unrelated to one another, and were not thought to be the result of cosmic rays. No damage was found in the mice's retinas or viscera. At the time of the publication of the Apollo 17 Preliminary Science Report, the mouse brains had not yet been examined. However, subsequent studies showed no significant effect on the brains.
Mission highlights.
Launch and outbound trip.
Apollo 17 launched at 12:33 AM EST on December 7, 1972, from launch pad 39-A at the Kennedy Space Center. It was the last manned Saturn V launch and the only night launch. The launch was delayed two hours and forty minutes due to an automatic cutoff in the launch sequencer at the T-30 second mark in the countdown. The issue was quickly determined to be a minor technical error. The clock was reset and held at the T-22 minute mark while technicians worked around the malfunction in order to continue with the launch. This pause was the only launch delay in the Apollo program caused by this type of hardware failure. The count resumed and a normal low Earth orbit was achieved.
Approximately 500,000 people were estimated to have observed the launch in the immediate vicinity of Kennedy Space Center, despite the early morning hour. The launch was visible as far away as ; observers in Miami, Florida, saw a "red streak" crossing the northern sky.
At 3:46 AM EST, the S-IVB third stage was re-ignited to propel the spacecraft towards the Moon.
At approximately 2:47 PM EST on December 10, the Service Propulsion System engine on the Command/Service Module ignited to slow down the CSM/Lunar Module stack into lunar orbit. Following orbit insertion and orbital stabilization, the crew began preparations for landing in the Taurus-Littrow valley.
Landing.
After separating from the Command/Service Module, the Lunar Module "Challenger" and its crew of two, Eugene Cernan and Harrison Schmitt, adjusted their orbit and began preparations for the descent to Taurus-Littrow. While Cernan and Schmitt prepared for landing, Command Module Pilot Ron Evans remained in orbit to take observations, perform experiments and await the return of his crew-mates a few days later.
Soon after completing their preparations for landing, Cernan and Schmitt began their descent to the Taurus-Littrow valley on the lunar surface. Several minutes after the descent phase was initiated, the Lunar Module pitched over, giving the crew their first look at the landing site during the descent phase and allowing Cernan to guide the spacecraft to a desirable landing target while Schmitt provided data from the flight computer essential for landing. The LM touched down on the lunar surface at 2:55 PM EST on December 11. Shortly thereafter, the two astronauts began re-configuring the LM for their stay on the surface and began preparations for the first moonwalk of the mission, or EVA-1.
Lunar surface.
The first moonwalk of the mission began approximately four hours after landing, at about 6:55 PM on December 11. The first task of the first lunar excursion was to offload the Lunar Roving Vehicle and other equipment from the Lunar Module. While working near the rover, a fender was accidentally broken off when Gene Cernan brushed up against it, his hammer getting caught under the right-rear fender, breaking off the rear extension. The same incident had also occurred on Apollo 16 as Commander John Young maneuvered around the rover. Although this was not a mission-critical issue, the loss of the fender caused Cernan and Schmitt to be covered with dust thrown up when the rover was in motion. The crew used duct tape to fix the problem, but the dust picked up on the surface prevented the tape from sticking for the length of the exploration. The crew then deployed the Apollo Lunar Surface Experiments Package west of the immediate landing site. After completing this, Cernan and Schmitt departed on the first geologic traverse of the mission, during which they gathered of samples; took seven gravimeter measurements; and deployed two explosive packages, which were later detonated remotely to test geophones that had been placed by the astronauts and seismometers that had been placed on previous Apollo missions. The EVA ended after seven hours and twelve minutes.
On December 12, at 6:28 PM EST, Cernan and Schmitt began their second lunar excursion. One of the first tasks of the EVA was repairing the right-rear fender on the LRV, the rearward extension of which had been broken off the previous day. The pair did this by taping together four cronopaque maps with duct tape and clamping the replacement fender extension to the fender, thus providing a means of preventing dust from raining down upon them while in motion. During this EVA, the pair sampled several different types of geologic deposits found in the valley, including orange-colored soil. The crew completed this moonwalk after seven hours and thirty-seven minutes. They collected of samples, deployed three more explosive packages and took seven gravimeter measurements.
The third moonwalk, the last of the Apollo program, began at 5:26 PM EST on December 13. During this excursion, the crew collected of lunar samples and took nine gravimeter measurements. Before ending the moonwalk, the crew collected a rock, a breccia, and dedicated it to several different nations which were represented in Mission Control Center in Houston, Texas, at the time. A plaque located on the Lunar Module, commemorating the achievements made during the Apollo program, was then unveiled. Before reentering the LM for the final time, Gene Cernan expressed his thoughts:
Cernan then followed Schmitt into the Lunar Module after spending approximately seven hours and 15 minutes outside during the mission's final lunar excursion.
Return to Earth.
Eugene Cernan and Harrison Schmitt successfully lifted off from the lunar surface in the ascent stage of the Lunar Module on December 14, at 5:55 PM EST. After a successful rendezvous and docking with Ron Evans in the Command/Service Module in orbit, the crew transferred equipment and lunar samples between the LM and the CSM for return to Earth. Following this, the LM ascent stage was sealed off and jettisoned at 1:31 AM on December 15. The ascent stage was then deliberately crashed into the Moon in a collision recorded by seismometers deployed on Apollo 17 and previous Apollo expeditions.
On December 17, during the trip back to Earth, at 3:27 PM EST, Ron Evans successfully conducted a one hour and seven minute spacewalk to retrieve exposed film from the instrument bay on the exterior of the CSM.
On December 19, the crew jettisoned the no-longer-needed Service Module, leaving only the Command Module for return to Earth. The Apollo 17 spacecraft reentered Earth's atmosphere and landed safely in the Pacific Ocean at 2:25 PM, from the recovery ship, the USS "Ticonderoga". Cernan, Evans and Schmitt were then retrieved by a recovery helicopter and were safely aboard the recovery ship 52 minutes after landing.
Spacecraft locations.
The Command Module "America" is currently on display at Space Center Houston at the Lyndon B. Johnson Space Center in Houston, Texas.
The ascent stage of lunar module "Challenger" impacted the Moon December 15, 1972 at 06:50:20.8 UT (1:50 AM EST), at . The descent stage remains on the Moon at the landing site, .
In 2009 and again in 2011, the Lunar Reconnaissance Orbiter photographed the landing site from increasingly low orbits.
Depiction of mission in fiction.
Portions of the Apollo 17 mission are dramatized in the 1998 HBO miniseries "From the Earth to the Moon" episode entitled "Le Voyage dans la Lune."
The prologue to the 1999 novel "Back to the Moon", by Homer Hickam, begins with a dramatized depiction of the end of the second Apollo 17 EVA. The orange soil then becomes the major driver of the plot of the rest of the story.
The 2005 novel "Tyrannosaur Canyon" by Douglas Preston opens with a depiction of the Apollo 17 moonwalks using quotes taken from the official mission transcript.
Additionally, there have been fictional astronauts in film, literature and television who have been described as "the last man to walk on the Moon," implying they were crew members on Apollo 17. One such character was Steve Austin in the television series "The Six Million Dollar Man". In the 1972 novel "Cyborg", upon which the series was based, Austin remembers watching the Earth "fall away during Apollo XVII." In the 1998 film "Deep Impact" fictional astronaut Spurgeon "Fish" Tanner, portrayed by Robert Duvall, was described at a Presidential press conference as the "last man to walk on the moon" by the President of the United States, portrayed by Morgan Freeman.
In the Anime Aldnoah.Zero, the Apollo 17 mission locates an ancient transporter gate leading to Mars left by an unknown, extinct alien race. This discovery is the divergence point for the story's alternate history.

</doc>
<doc id="1973" url="http://en.wikipedia.org/wiki?curid=1973" title="American Revolution">
American Revolution

The American Revolution was a political upheaval that took place between 1765 and 1783 during which the Thirteen American Colonies broke from the British Empire and formed an independent nation, the United States of America. The American Revolution was the result of a series of social, political, and intellectual transformations in American society, government and ways of thinking. Starting in 1765 the Americans rejected the authority of Parliament to tax them without elected representation; protests continued to escalate, as in the Boston Tea Party of 1773, and the British imposed punitive laws—the Intolerable Acts—on Massachusetts in 1774. 
The Patriots fought the British in the American Revolutionary War (1775–1783). Formal acts of rebellion against British authority began in 1774 when the Patriot Suffolk Resolves effectively replaced the royal government of the Massachusetts, and confined British control to the city of Boston. Tensions escalated to the outbreak of fighting between Patriot militia and British regulars at the at Lexington and Concord in April 1775. 
Each colony now had a new government that took control. The British responded by sending combat troops to re-establish royal control and resistance was coordinated through the Second Continental Congress.
The British sent invasion armies and used their powerful navy to blockade the coast. Former Virginia militia officer George Washington became the Commander-in-Chief of the Continental Army, working with Congress and the states to raise armies and neutralize the influence of Loyalists. While precise proportions are not known, about 40% of the colonists were Patriots, 20% were Loyalists and the rest were neutral or did not reveal loyalties. As the war continued some changed their loyalties. Claiming British rule was tyrannical]] and violated the rights of Englishmen, the Patriot leadership professed the political philosophies of liberalism and republicanism to reject monarchy and aristocracy, and proclaimed that all men are created equal. The Continental Congress declared independence in July 1776, when Thomas Jefferson as the primary author, and the Congress unanimously approved an edited version, of the United States Declaration of Independence. Congress rejected British proposals for compromise that would keep them under the king. The British were forced out of Boston in 1776, but then captured and held New York City for the duration of the war, nearly capturing General Washington and his army. The British blockaded the ports and captured other cities for brief periods, but 90% of the inhabitants were in rural areas.
In early 1778, after an invading British army from Canada was captured by the Americans, the French entered the war as allies of the United States. The naval and military power of the two sides were about equal, and France had allies in the Netherlands and Spain, while Britain had no major allies in this large-scale war. The war later turned to the American South, where the British captured an army at South Carolina, but failed to enlist enough volunteers from Loyalist civilians to take effective control. A combined American–French force captured a second British army at Yorktown in 1781, effectively ending the war in the United States. A peace treaty in 1783 confirmed the new nation's complete separation from the British Empire. The United States took possession of nearly all the territory east of the Mississippi River and south of the Great Lakes, with the British retaining control of Canada and Spain taking Florida. Among the significant results of the revolution was the creation of a democratically-elected representative government responsible to the will of the people.
The period after the peace treaty came in 1783 involved debates between nationally-minded men like Washington who wanted a strong national government, and leaders who wanted strong states but a weak national government. The former group won out the ratification of a new United States Constitution in 1788. It replaced the weaker "Articles of Confederation and Perpetual Union". The new Constitution established a relatively strong federal national government that included a strong elected president, national courts, a bicameral Congress that represented both states in the Senate and population in the House of Representatives. Congress had powers of taxation that were lacking under the old Articles. The United States Bill of Rights of 1791 comprised the first ten amendments to the Constitution, guaranteeing many "natural rights" that were influential in justifying the revolution, and attempted to balance a strong national government with strong state governments and broad personal liberties. The American shift to liberal republicanism, and the gradually increasing democracy, caused an upheaval of traditional social hierarchy and gave birth to the ethic that has formed a core of political values in the United States.
Origins.
1764–1766: Taxes imposed and withdrawn.
The issue in the 1760s was whether Parliament had the authority to levy taxes, or whether only the colonial legislatures could do so. The extra revenue was slated to pay pensions to British veterans. The issue was not the small total of tax money involved, but the question of who had the power to levy taxes. In 1765 under British Prime Minister George Grenville the Parliament passed the Stamp Act, instituting the first direct tax levied on the colonies. All official documents, newspapers, almanacs and pamphlets—even decks of playing cards—were required to have the stamps. The colonists objected chiefly on the grounds not that the taxes were high (they were low), but because they had no representation in the Parliament. Benjamin Franklin testified in Parliament in 1766 that Americans already contributed heavily to the defense of the Empire. He said local governments had raised, outfitted and paid 25,000 soldiers to fight France--as many as Britain itself sent--and spent many millions from American treasuries doing so in the French and Indian War alone. Stationing a standing army in Great Britain during peacetime was politically unacceptable. London had to deal with 1,500 politically well-connected British officers who became redundant; it would have to discharge them or station them in North America.
In 1765 the Sons of Liberty formed. They used public demonstrations, violence and threats of violence to ensure that the British tax laws were unenforceable. While openly hostile to what they considered an oppressive Parliament acting illegally, colonists persisted in sending numerous petitions and pleas for intervention from a monarch to whom they still claimed loyalty. In Boston, the Sons of Liberty burned the records of the vice-admiralty court and looted the home of the chief justice, Thomas Hutchinson. Several legislatures called for united action, and nine colonies sent delegates to the Stamp Act Congress in New York City in October 1765. Moderates led by John Dickinson drew up a "Declaration of Rights and Grievances" stating that taxes passed without representation violated their rights as Englishmen. Colonists emphasized their determination by boycotting imports of British merchandise.
The Parliament at Westminster saw itself as the supreme lawmaking authority throughout all British possessions and thus entitled to levy any tax without colonial approval. Parliament insisted that the colonies effectively enjoyed a "virtual representation". Americans such as James Otis maintained the Americans were not in fact virtually represented.
In London, the Rockingham government came to power (July 1765) and Parliament debated whether to repeal the stamp tax or to send an army to enforce it. Benjamin Franklin made the case for repeal, explaining the colonies had spent heavily in manpower, money, and blood in defense of the empire in a series of wars against the French and Indians, and that further taxes to pay for those wars were unjust and might bring about a rebellion. Parliament agreed and repealed the tax (February 21, 1766), but in the Declaratory Act of March 1766 insisted that parliament retained full power to make laws for the colonies "in all cases whatsoever".
1767–1773: Townshend Acts and the Tea Act.
In 1767 the Parliament passed the Townshend Acts, which placed a tax on a number of essential goods including paper, glass, and tea. Angered at the tax increases, colonists organized a boycott of British goods. Meanwhile, riots against trade regulations led to the deployment of British troops to Boston in 1768. On March 5, 1770 a large mob gathered around a group of British soldiers. The mob grew more and more threatening, throwing snowballs, rocks and debris at the soldiers. One soldier was clubbed and fell.
All but one of the soldiers fired into the crowd. They hit 11 people; three civilians died at the scene of the shooting, and two died after the incident. The event quickly came to be called the Boston Massacre. Although the soldiers were tried and acquitted (defended by John Adams), the widespread descriptions soon became propaganda to turn colonial sentiment against the British. This in turn began a downward spiral in the relationship between Britain and the Province of Massachusetts.
Responding to protests, in 1770 Parliament withdrew all taxes except the tax on tea, giving up its efforts to raise revenue. This temporarily resolved the crisis and the boycott of British goods largely ceased, with only the more radical patriots such as Samuel Adams continuing to agitate.
In June 1772, in what became known as the "Gaspée" Affair, American patriots including John Brown burned a British warship that had been vigorously enforcing unpopular trade regulations. About a year later, private letters were published in which Massachusetts Governor Thomas Hutchinson called for the abridgement of colonial rights, and Lieutenant Governor Andrew Oliver called for the direct payment of colonial officials (until then the purview of the colonial assembly, and a means by which it controlled the governor). The furor over the affair contributed to Hutchinson's recall, and brought a conciliatory Benjamin Franklin firmly to the side of the colonists.
In late 1772 Samuel Adams in Boston set about creating new Committees of Correspondence, which linked Patriots in all 13 colonies and eventually provided the framework for a rebel government. In early 1773 Virginia, the largest colony, set up its Committee of Correspondence, on which Patrick Henry and Thomas Jefferson served.
A total of about 7000 to 8000 Patriots served on "Committees of Correspondence" at the colonial and local levels, comprising most of the leadership in their communities — Loyalists were excluded. The committees became the leaders of the American resistance to British actions, and largely determined the war effort at the state and local level. When the First Continental Congress decided to boycott British products, the colonial and local Committees took charge, examining merchant records and publishing the names of merchants who attempted to defy the boycott by importing British goods.
In 1773 Parliament decided to lower the price of tea in order to undersell smuggled Dutch tea. Special consignees were appointed to sell the tea in order to bypass colonial merchants. In most instances the consignees were forced to resign and the tea was turned back, but Massachusetts governor Thomas Hutchinson refused to give into pressure. In Boston on December 16, 1773 a group of men, led by Samuel Adams and dressed to evoke American Indians, boarded the ships of the government-favored British East India Company and dumped an estimated £10,000 worth of tea from their holds (approximately £636,000 in 2008) into Boston Harbor. This event became known as the Boston Tea Party and remains a significant part of American patriotic lore.
1774–1775: Intolerable Acts and the Quebec Act.
The British government responded by passing several Acts which came to be known as the Intolerable Acts, which further darkened colonial opinion towards the British. They consisted of four laws enacted by the British parliament. The first, the Massachusetts Government Act, altered the Massachusetts charter and restricted town meetings. The second Act, the Administration of Justice Act, ordered that all British soldiers to be tried were to be arraigned in Britain, not in the colonies. The third Act was the Boston Port Act, which closed the port of Boston until the British had been compensated for the tea lost in the Boston Tea Party. The fourth Act was the Quartering Act of 1774, which allowed royal governors to house British troops in the homes of citizens without requiring permission of the owner.
In response, Massachusetts patriots issued the Suffolk Resolves and formed an alternative shadow government known as the "Provincial Congress" which began training militia outside British-occupied Boston. In September 1774, the First Continental Congress convened, consisting of representatives from each of the colonies, to serve as a vehicle for deliberation and collective action. During secret debates conservative Joseph Galloway proposed the creation of a colonial Parliament that would be able to approve or disapprove of acts of the British Parliament but his idea was not accepted. The Congress instead endorsed the proposal of John Adams that Americans would obey Parliament voluntarily but would resist all taxes in disguise. Congress called for a boycott beginning on 1 December 1774 of all British goods; it was enforced by new committees authorized by the Congress.
The Quebec Act of 1774 extended Quebec's boundaries to the Ohio River, shutting out the claims of the 13 colonies. By then, however, the Americans had little regard for new laws from London; they were drilling militia and organizing for war.
The British retaliated by confining all trade of the New England colonies to Britain and excluding them from the Newfoundland fisheries. Lord North advanced a compromise proposal in which Parliament would not tax so long as the colonies made fixed contributions for defense and to support civil government. This would also be rejected.
Creating new state constitutions.
Following the Battle of Bunker Hill in June 1775, the Patriots had control of most of Massachusetts; the Loyalists suddenly found themselves on the defensive. In all 13 colonies, Patriots had overthrown their existing governments, closing courts and driving British governors, agents and supporters from their homes. They had elected conventions and "legislatures" that existed outside any legal framework; new constitutions were used in each state to supersede royal charters. They declared they were states now, not colonies.
On January 5, 1776, New Hampshire ratified the first state constitution, six months before the signing of the Declaration of Independence. Then, in May 1776, Congress voted to suppress all forms of crown authority, to be replaced by locally created authority. Virginia, South Carolina, and New Jersey created their constitutions before July 4. Rhode Island and Connecticut simply took their existing royal charters and deleted all references to the crown.
The new states had to decide not only what form of government to create, they first had to decide how to select those who would craft the constitutions and how the resulting document would be ratified. In states where the wealthy exerted firm control over the process, such as Maryland, Virginia, Delaware, New York and Massachusetts - the last-mentioned of these state's constitutions still being in force in the 21st century, continuously since its ratification on June 15, 1780 - the results were constitutions that featured:
In states where the less affluent had organized sufficiently to have significant power—especially Pennsylvania, New Jersey, and New Hampshire—the resulting constitutions embodied
Whether conservatives or radicals held sway in a state did not mean that the side with less power accepted the result quietly. The radical provisions of Pennsylvania's constitution lasted only 14 years. In 1790, conservatives gained power in the state legislature, called a new constitutional convention, and rewrote the constitution. The new constitution substantially reduced universal white-male suffrage, gave the governor veto power and patronage appointment authority, and added an upper house with substantial wealth qualifications to the unicameral legislature. Thomas Paine called it a constitution unworthy of America.
Military hostilities begin.
Massachusetts was declared in a state of rebellion in February 1775 and the British garrison received orders to disarm the rebels and arrest their leaders, leading to the Battles of Lexington and Concord on 19 April 1775. The Patriots set siege to Boston, expelled royal officials from all the colonies, and took control through the establishment of Provincial Congresses. The Battle of Bunker Hill followed on June 17, 1775. While a British victory, it was at a great cost; about 1,000 British casualties from a garrison of about 6,000, as compared to 500 American casualties from a much larger force. First ostensibly loyal to the king and desiring to govern themselves while remaining in the empire, the repeated pleas by the First Continental Congress for royal intervention on their behalf with Parliament resulted in the declaration by the King that the states were "in rebellion", and the members of Congress were traitors.
In the winter of 1775, the Americans invaded Canada. General Richard Montgomery captured Montreal but a joint attack on Quebec was a total failure; many Americans were captured or died of smallpox.
In March 1776, with George Washington as the commander of the new army, the Continental Army forced the British to evacuate Boston. The revolutionaries were now in full control of all 13 colonies and were ready to declare independence. While there still were many Loyalists, they were no longer in control anywhere by July 1776, and all of the Royal officials had fled.
Prisoners.
In August 1775, George III declared Americans in arms against royal authority to be traitors to the Crown. Although Lord Germain took a hard line, the British generals on the scene never held treason trials; they treated captured enemy soldiers as prisoners of war. The dilemma was that tens of thousands of Loyalists were under American control and American retaliation would have been easy. The British built much of their strategy around using these Loyalists.
Following their surrender at the Battles of Saratoga in October 1777, there were thousands of British and Hessian soldiers in American hands. Therefore, no Americans were put on trial for treason. The British maltreated the prisoners they held, resulting in more deaths to American sailors and soldiers than from combat operations. At the end of the war, both sides released their surviving prisoners.
Independence and Union.
In April 1776 the North Carolina Provincial Congress issued the Halifax Resolves, explicitly authorizing its delegates to vote for independence. In May Congress called on all the states to write constitutions, and eliminate the last remnants of royal rule.
By June nine colonies were ready for independence; one by one the last four —Pennsylvania, Delaware, Maryland and New York — fell into line. Richard Henry Lee was instructed by the Virginia legislature to propose independence, and he did so on June 7, 1776. On the 11th a committee was created to draft a document explaining the justifications for separation from Britain. After securing enough votes for passage, independence was voted for on July 2. The Declaration of Independence, drafted largely by Thomas Jefferson and presented by the committee, was slightly revised and unanimously adopted by the entire Congress on July 4, marking the formation of a new sovereign nation, which called itself the United States of America.
The Second Continental Congress approved a new constitution, the "Articles of Confederation," for ratification by the states on November 15, 1777, and immediately began operating under their terms. The Articles were formally ratified on March 1, 1781. At that point, the Continental Congress was dissolved and on the following day a new government of the United States in Congress Assembled took its place, with Samuel Huntington as presiding officer.
Defending the Revolution.
British return: 1776–1777.
After Washington forced the British out of Boston in spring 1776, neither the British nor the Loyalists controlled any significant areas. The British, however, were massing forces at their naval base at Halifax, Nova Scotia. They returned in force in July 1776, landing in New York and defeating Washington's Continental Army at the Battle of Brooklyn in August, one of the largest engagements of the war. After the Battle of Brooklyn, the British requested a meeting with representatives from Congress to negotiate an end to hostilities.
A delegation including John Adams and Benjamin Franklin met Howe on Staten Island in New York Harbor on September 11, in what became known as the Staten Island Peace Conference. Howe demanded a retraction of the Declaration of Independence, which was refused, and negotiations ended until 1781. The British then quickly seized New York City and nearly captured General Washington. They made the city their main political and military base of operations in North America, holding it until November 1783. New York City consequently became the destination for Loyalist refugees, and a focal point of Washington's intelligence network.
The British also took New Jersey, pushing the Continental Army into Pennsylvania. In a surprise attack in late December 1776 Washington crossed the Delaware River back into New Jersey and defeated Hessian and British armies at Trenton and Princeton, thereby regaining New Jersey. The victories gave an important boost to pro-independence supporters at a time when morale was flagging, and have become iconic events of the war.
In 1777, as part of a grand strategy to end the war, the British sent an invasion force from Canada to seal off New England, which the British perceived as the primary source of agitators. In a major case of mis-coordination, the British army in New York City went to Philadelphia which it captured from Washington. The invasion army under Burgoyne waited in vain for reinforcements from New York, and became trapped in northern New York state. It surrendered after the Battle of Saratoga in October 1777. From early October 1777 until November 15 a pivotal siege at Fort Mifflin, Philadelphia, Pennsylvania distracted British troops and allowed Washington time to preserve the Continental Army by safely leading his troops to harsh winter quarters at Valley Forge.
American alliances after 1778.
The capture of a British army at Saratoga encouraged the French to formally enter the war in support of Congress, as Benjamin Franklin negotiated a permanent military alliance in early 1778, significantly becoming the first country to officially recognize the Declaration of Independence. On February 6, 1778, a Treaty of Amity and Commerce and a Treaty of Alliance were signed between the United States and France. William Pitt spoke out in parliament urging Britain to make peace in America, and unite with America against France, while other British politicians who had previously sympathised with colonial grievances now turned against the American rebels for allying with Britain's international rival and enemy.
Later Spain (in 1779) and the Dutch (1780) became allies of the French, leaving the British Empire to fight a global war alone without major allies, and requiring it to slip through a combined blockade of the Atlantic. The American theater thus became only one front in Britain's war. The British were forced to withdraw troops from continental America to reinforce the valuable sugar-producing Caribbean colonies, which were considered more important.
Because of the alliance with France and the deteriorating military situation, Sir Henry Clinton, the British commander, evacuated Philadelphia to reinforce New York City. General Washington attempted to intercept the retreating column, resulting in the Battle of Monmouth Court House, the last major battle fought in the north. After an inconclusive engagement, the British successfully retreated to New York City. The northern war subsequently became a stalemate, as the focus of attention shifted to the smaller southern theater.
The British move South, 1778–1783.
The British strategy in America now concentrated on a campaign in the southern colonies. With fewer regular troops at their disposal, the British commanders saw the "southern strategy" as a more viable plan, as the south was perceived as being more strongly Loyalist, with a large population of recent immigrants as well as large numbers of slaves who might be captured or run away to join the British.
Beginning in late December 1778, the British captured Savannah and controlled the Georgia coastline. In 1780 they launched a fresh invasion and took Charleston as well. A significant victory at the Battle of Camden meant that royal forces soon controlled most of Georgia and South Carolina. The British set up a network of forts inland, hoping the Loyalists would rally to the flag.
Not enough Loyalists turned out, however, and the British had to fight their way north into North Carolina and Virginia, with a severely weakened army. Behind them much of the territory they had already captured dissolved into a chaotic guerrilla war, fought predominantly between bands of Loyalist and American militia, which negated many of the gains the British had previously made.
Yorktown 1781.
The British army under Cornwallis marched to Yorktown, Virginia where they expected to be rescued by a British fleet. The fleet showed up but so did a larger French fleet, so the British fleet after the Battle of the Chesapeake returned to New York for reinforcements, leaving Cornwallis trapped. In October 1781 under a combined siege by the French and Continental armies under Washington, the British surrendered their second invading army of the war.
The end of the war.
Historians continue to debate whether the odds for American victory were long or short. John E. Ferling says the odds were so long that the American victory was "Almost A Miracle." On the other hand, Joseph Ellis says the odds favored the Americans, and asks whether there ever was any realistic chance for the British to win. He argues that this opportunity came only once, in the summer of 1776 and the British failed that test. Admiral Howe and his brother General Howe, "missed several opportunities to destroy the Continental Army...Chance, luck, and even the vagaries of the weather played crucial roles." Ellis's point is that the strategic and tactical decisions of the Howes were fatally flawed because they underestimated the challenges posed by the Patriots. Ellis concludes that once the Howe brothers failed, the opportunity for a British victory "would never come again."
Support for the conflict had never been strong in Britain, where many sympathized with the rebels, but now it reached a new low. Although King George III personally wanted to fight on, his supporters lost control of Parliament, and no further major land offensives were launched in the American Theater.
Washington could not know that after Yorktown the British would not reopen hostilities. They still had 26,000 troops occupying New York City, Charleston and Savannah, together with a powerful fleet. The French army and navy departed, so the Americans were on their own in 1782–83. The treasury was empty, and the unpaid soldiers were growing restive, almost to the point of mutiny or possible "coup d'état". The unrest among officers of the Newburgh Conspiracy was personally dispelled by Washington in 1783, and Congress subsequently created the promise of a five years bonus for all officers.
Peace treaty.
The peace treaty with Britain, known as the Treaty of Paris, gave the U.S. all land east of the Mississippi River and south of the Great Lakes, though not including Florida (On September 3, 1783, Britain entered into a separate agreement with Spain under which Britain ceded Florida back to Spain.) The British abandoned the Indian allies living in this region; they were not a party to this treaty and did not recognize it until they were defeated militarily by the United States. Issues regarding boundaries and debts were not resolved until the Jay Treaty of 1795. Since the blockade was lifted and the old imperial restrictions were gone, American merchants were free to trade with any nation anywhere in the world, and their businesses flourished.
Impact on Britain.
Losing the war and the 13 colonies was a shock to Britain. The war revealed the limitations of Britain's fiscal-military state when it discovered it suddenly faced powerful enemies, with no allies, and dependent on extended and vulnerable transatlantic lines of communication. The defeat heightened dissension and escalated political antagonism to the King's ministers. Inside parliament, the primary concern changed from fears of an over-mighty monarch to the issues of representation, parliamentary reform, and government retrenchment. Reformers sought to destroy what they saw as widespread institutional corruption.
The result was a powerful crisis, 1776–1783. The peace in 1783 left France financially prostrate, while the British economy boomed thanks to the return of American business. The crisis ended after 1784 thanks to the King's shrewdness in outwitting Charles James Fox (the leader of the Fox-North Coalition), and renewed confidence in the system engendered by the leadership of the new Prime Minister, William Pitt. Historians conclude that loss of the American colonies enabled Britain to deal with the French Revolution with more unity and better organization than would otherwise have been the case. Britain turned towards Asia, the Pacific and later Africa with subsequent exploration leading to the rise of the Second British Empire.
Finance.
Britain's war against the Americans, French and Spanish cost about £100 million. The Treasury borrowed 40% of the money it needed. Heavy spending brought France to the verge of bankruptcy and revolution, while the British had relatively little difficulty financing their war, keeping their suppliers and soldiers paid, and hiring tens of thousands of German soldiers.
Britain had a sophisticated financial system based on the wealth of thousands of landowners, who supported the government, together with banks and financiers in London. The efficient British tax system collected about 12 percent of the GDP in taxes during the 1770s.
In sharp contrast, Congress and the American states had no end of difficulty financing the war. In 1775 there was at most 12 million dollars in gold in the colonies, not nearly enough to cover current transactions, let alone finance a major war. The British made the situation much worse by imposing a tight blockade on every American port, which cut off almost all imports and exports. One partial solution was to rely on volunteer support from militiamen, and donations from patriotic citizens.
Another was to delay actual payments, pay soldiers and suppliers in depreciated currency, and promise it would be made good after the war. Indeed, in 1783 the soldiers and officers were given land grants to cover the wages they had earned but had not been paid during the war. Not until 1781, when Robert Morris was named Superintendent of Finance of the United States, did the national government have a strong leader in financial matters.
Morris used a French loan in 1782 to set up the private Bank of North America to finance the war. Seeking greater efficiency, Morris reduced the civil list, saved money by using competitive bidding for contracts, tightened accounting procedures, and demanded the national government's full share of money and supplies from the confederated states.
Congress used four main methods to cover the cost of the war, which cost about 66 million dollars in specie (gold and silver). Congress made two issues of paper money, in 1775–1780, and in 1780–81. The first issue amounted to 242 million dollars. This paper money would supposedly be redeemed for state taxes, but the holders were eventually paid off in 1791 at the rate of one cent on the dollar. By 1780, the paper money was "not worth a Continental", as people said.
The skyrocketing inflation was a hardship on the few people who had fixed incomes—but 90 percent of the people were farmers, and were not directly affected by that inflation. Debtors benefited by paying off their debts with depreciated paper.The greatest burden was borne by the soldiers of the Continental Army, whose wages—usually in arrears—declined in value every month, weakening their morale and adding to the hardships suffered by their families.
Beginning in 1777, Congress repeatedly asked the states to provide money. But the states had no system of taxation either, and were little help. By 1780 Congress was making requisitions for specific supplies of corn, beef, pork and other necessities—an inefficient system that kept the army barely alive.
Starting in 1776, the Congress sought to raise money by loans from wealthy individuals, promising to redeem the bonds after the war. The bonds were in fact redeemed in 1791 at face value, but the scheme raised little money because Americans had little specie, and many of the rich merchants were supporters of the Crown. Starting in 1776, the French secretly supplied the Americans with money, gunpowder, and munitions in order to weaken its arch enemy, Great Britain. When France officially entered the war in 1778, the subsidies continued, and the French government, as well as bankers in Paris and Amsterdam loaned large sums to the American war effort. These loans were repaid in full in the 1790s.
Concluding the Revolution.
Creating a "more perfect union" and guaranteeing rights.
After the war finally ended in 1783, there was a period of prosperity. The national government, still operating under the Articles of Confederation, was able to settle the issue of the western territories, which were ceded by the states to Congress. American settlers moved rapidly into those areas, with Vermont, Kentucky and Tennessee becoming states in the 1790s.
However, the national government had no money to pay either the war debts owed to European nations and the private banks, or to pay Americans who had been given millions of dollars of promissory notes for supplies during the war. Nationalists, led by Washington, Alexander Hamilton and other veterans, feared that the new nation was too fragile to withstand an international war, or even internal revolts such as the Shays' Rebellion of 1786 in Massachusetts.
Calling themselves "Federalists," the nationalists convinced Congress to call the Philadelphia Convention in 1787. It adopted a new Constitution that provided for a much stronger federal government, including an effective executive in a check-and-balance system with the judiciary and legislature. After a fierce debate in the states over the nature of the proposed new government, the Constitution was ratified in 1788. The new government under President George Washington took office in New York in March 1789. As assurances to those who were cautious about federal power, amendments to the Constitution guaranteeing many of the inalienable rights that formed a foundation for the revolution were spearheaded in Congress by James Madison, and later ratified by the states in 1791.
National debt.
The national debt after the American Revolution fell into three categories. The first was the $12 million owed to foreigners—mostly money borrowed from France. There was general agreement to pay the foreign debts at full value. The national government owed $40 million and state governments owed $25 million to Americans who had sold food, horses, and supplies to the revolutionary forces. There were also other debts that consisted of promissory notes issued during the Revolutionary War to soldiers, merchants, and farmers who accepted these payments on the premise that the new Constitution would create a government that would pay these debts eventually.
The war expenses of the individual states added up to $114 million compared to $37 million by the central government. In 1790, at the recommendation of first Secretary of the Treasury Alexander Hamilton, Congress combined the remaining state debts with the foreign and domestic debts into one national debt totaling $80 million. Everyone received face value for wartime certificates, so that the national honor would be sustained and the national credit established.
Ideology and Factions.
The population of the 13 Colonies was far from homogeneous, particularly in their political views and attitudes. Loyalties and allegiances varied widely not only within regions and communities, but also within families and sometimes shifted during the course of the Revolution.
Ideology behind the Revolution.
The ideological movement known as the American Enlightenment was a critical precursor to the American Revolution. Chief among the ideas of the American Enlightenment were the concepts of liberalism, republicanism and fear of corruption. Collectively, the acceptance of these concepts by a growing number of American colonists began to foster an intellectual environment which would lead to a new sense of political and social identity.
Natural rights and republicanism.
John Locke's (1632–1704) ideas on liberty greatly influenced the political thinking behind the revolution, especially through his indirect influence on English writers. He is often referred to as "the philosopher of the American Revolution," and is credited with leading Americans to the critical concepts of social contract, natural rights, and "born free and equal." Locke's Two Treatises of Government, published in 1689, was especially influential; Locke in turn was influenced by Protestant theology. He argued that, as all humans were created equally free, governments needed the consent of the governed. Both Lockean concepts were central to the United States Declaration of Independence, which deduced human equality, "life, liberty, and the pursuit of happiness" from the biblical belief in creation: "All men are "created" equal, ... they are endowed by their "Creator" with certain unalienable Rights."
The Declaration also referred to the "Laws of Nature and of Nature's God" as justification for the Americans' separation from the British monarchy. Most eighteenth-century Americans believed that nature, the entire universe, was God's creation. Therefore he was "Nature's God." Everything, including man, was part of the "universal order of things", which began with God and was pervaded and directed by his providence. Accordingly, the signers of the Declaration professed their "firm reliance on the Protection of divine Providence." And they appealed to "the Supreme Judge [God] for the rectitude of [their] intentions." Like most of his countrymen, George Washington was firmly convinced that he was an instrument of providence, to the benefit not only of the American people but of all of humanity.
The theory of the "social contract" influenced the belief among many of the Founders that among the "natural rights" of man was the right of the people to overthrow their leaders, should those leaders betray the historic rights of Englishmen. In terms of writing state and national constitutions, the Americans heavily used Montesquieu's analysis of the wisdom of the "balanced" British Constitution.
A motivating force behind the revolution was the American embrace of a political ideology called "republicanism", which was dominant in the colonies by 1775, but of minor importance back in Britain. The republicanism was inspired by the "country party" in Britain, whose critique of British government emphasized that corruption was a terrible reality in Britain. Americans feared the corruption was crossing the Atlantic; the commitment of most Americans to republican values and to their rights, energized the revolution, as Britain was increasingly seen as hopelessly corrupt and hostile to American interests. Britain seemed to threaten the established liberties that Americans enjoyed. The greatest threat to liberty was depicted as corruption—not just in London but at home as well. The colonists associated it with luxury and, especially, inherited aristocracy, which they condemned.
The Founding Fathers were strong advocates of republican values, particularly Samuel Adams, Patrick Henry, John Adams, Benjamin Franklin, Thomas Jefferson, Thomas Paine, George Washington, James Madison and Alexander Hamilton, which required men to put civic duty ahead of their personal desires. Men had a civic duty to be prepared and willing to fight for the rights and liberties of their countrymen and countrywomen. John Adams, writing to Mercy Otis Warren in 1776, agreed with some classical Greek and Roman thinkers in that "Public Virtue cannot exist without private, and public Virtue is the only Foundation of Republics." He continued: 
"There must be a positive Passion for the public good, the public Interest, Honour, Power, and Glory, established in the Minds of the People, or there can be no Republican Government, nor any real Liberty. And this public Passion must be Superior to all private Passions. Men must be ready, they must pride themselves, and be happy to sacrifice their private Pleasures, Passions, and Interests, nay their private Friendships and dearest connections, when they Stand in Competition with the Rights of society."
 For women, "republican motherhood" became the ideal, exemplified by Abigail Adams and Mercy Otis Warren; the first duty of the republican woman was to instill republican values in her children and to avoid luxury and ostentation.
Fusing republicanism and liberalism.
While some republics had emerged throughout history, such as the Roman Republic of the ancient world, one based on liberal principles had never existed. Thomas Paine's best-seller pamphlet "Common Sense" appeared in January 1776, after the Revolution had started. It was widely distributed and loaned, and often read aloud in taverns, contributing significantly to spreading the ideas of republicanism and liberalism together, bolstering enthusiasm for separation from Britain, and encouraging recruitment for the Continental Army.
Paine provided a new and widely accepted argument for independence, by advocating a complete break with history. "Common Sense" is oriented to the future in a way that compels the reader to make an immediate choice. It offered a solution for Americans disgusted and alarmed at the threat of tyranny.
Impact of Great Awakening.
Dissenting (i.e. Protestant, non-Church of England) churches of the day were the "school of democracy." President John Witherspoon of the College of New Jersey (now Princeton University) wrote widely circulated sermons linking the American Revolution to the teachings of the Hebrew Bible. Throughout the colonies, dissenting Protestant ministers (Congregationalist, Baptist, and Presbyterian) preached Revolutionary themes in their sermons, while most Church of England clergymen preached loyalty to the King. Religious motivation for fighting tyranny reached across socioeconomic lines to encompass rich and poor, men and women, frontiersmen and townsmen, farmers and merchants.
Historian Bernard Bailyn argues that the evangelicalism of the era challenged traditional notions of natural hierarchy by preaching that the Bible taught all men are equal, so that the true value of a man lies in his moral behavior, not his class. Kidd argues that religious disestablishment, belief in a God as the guarantor of human rights, and shared convictions about sin, virtue, and divine providence worked together to unite rationalists and evangelicals and thus encouraged American defiance of the Empire, whereas Bailyn denied that religion played such a critical role. Alan Heimert argued, however, that New Light antiauthoritarianism was essential to the further democratization of colonial American society, and set the stage for a confrontation with British monarchical and aristocratic rule.
Class and psychology of the factions.
Looking back, John Adams concluded in 1818:
In terms of class, Loyalists tended to have longstanding social and economic connections to British merchants and government; for instance, prominent merchants in major port cities such as New York, Boston and Charleston tended to be Loyalists, as did men involved with the fur trade along the northern frontier. In addition, officials of colonial government and their staffs, those who had established positions and status to maintain, favored maintaining relations with Great Britain. They often were linked to British families in England by marriage as well.
By contrast, Patriots by number tended to be yeomen farmers, especially in the frontier areas of New York and the backcountry of Pennsylvania, Virginia and down the Appalachian mountains. They were craftsmen and small merchants. Leaders of both the Patriots and the Loyalists were men of educated, propertied classes. The Patriots included many prominent men of the planter class from Virginia and South Carolina, for instance, who became leaders during the Revolution, and formed the new government at the national and state levels.
To understand the opposing groups, historians have assessed evidence of their hearts and minds. In the mid-20th century, historian Leonard Woods Labaree identified eight characteristics of the Loyalists that made them essentially conservative; traits to those characteristic of the Patriots. Older and better established men, Loyalists tended to resist innovation. They thought resistance to the Crown—which they insisted was the only legitimate government—was morally wrong, while the Patriots thought morality was on their side.
Loyalists were alienated when the Patriots resorted to violence, such as burning houses and tarring and feathering. Loyalists wanted to take a centrist position and resisted the Patriots' demand to declare their opposition to the Crown. Many Loyalists, especially merchants in the port cities, had maintained strong and long-standing relations with Britain (often with business and family links to other parts of the British Empire).
Many Loyalists realized that independence was bound to come eventually, but they were fearful that revolution might lead to anarchy, tyranny or mob rule. In contrast, the prevailing attitude among Patriots, who made systematic efforts to use mob violence in a controlled manner, was a desire to seize the initiative. Labaree also wrote that Loyalists were pessimists who lacked the confidence in the future displayed by the Patriots.
Historians in the early 20th century, such as J. Franklin Jameson, examined the class composition of the Patriot cause, looking for evidence of a class war inside the revolution. In the last 50 years, historians have largely abandoned that interpretation, emphasizing instead the high level of ideological unity. Just as there were rich and poor Loyalists, the Patriots were a 'mixed lot', with the richer and better educated more likely to become officers in the Army.
Ideological demands always came first: the Patriots viewed independence as a means to gain freedom from British oppression and taxation and, above all, to reassert what they considered to be their rights as English subjects. Most yeomen farmers, craftsmen, and small merchants joined the Patriot cause to demand more political equality. They were especially successful in Pennsylvania but less so in New England, where John Adams attacked Thomas Paine's "Common Sense" for the "absurd democratical notions" it proposed.
King George III.
The war became a personal issue for the king, fueled by his growing belief that British leniency would be taken as weakness by the Americans. The king also sincerely believed he was defending Britain's constitution against usurpers, rather than opposing patriots fighting for their natural rights.
Patriots.
At the time, revolutionaries were called "Patriots", "Whigs", "Congress-men", or "Americans". They included a full range of social and economic classes, but were unanimous regarding the need to defend the rights of Americans and uphold the principles of republicanism in terms of rejecting monarchy and aristocracy, while emphasizing civic virtue on the part of the citizens. Newspapers were strongholds of patriotism (although there were a few Loyalist papers), and printed many pamphlets, announcements, patriotic letters and pronouncements.
According to historian Robert Calhoon, the consensus of historians is that 40–45% of the white population in the Thirteen Colonies supported the Patriots' cause, 15–20% supported the Loyalists, and the remainder were neutral or kept a low profile. Mark Lender explores why ordinary folk became insurgents against the British even though they were unfamiliar with the ideological rationales being offered. They held very strongly a sense of "rights" that they felt the British were violating – rights that stressed local autonomy, fair dealing, and government by consent. They were highly sensitive to the issue of tyranny, which they saw manifested in the British response to the Boston Tea Party. The arrival in Boston of the British Army heightened their sense of violated rights, leading to rage and demands for revenge. They had faith that God was on their side.
Loyalists.
The consensus of scholars is that about 15–20% of the white population remained loyal to the British Crown. Those who actively supported the king were known at the time as "Loyalists", "Tories", or "King's men". The Loyalists never controlled territory unless the British Army occupied it. Loyalists were typically older, less willing to break with old loyalties, often connected to the Church of England, and included many established merchants with strong business connections across the Empire, as well as royal officials such as Thomas Hutchinson of Boston. There were 500 to 1000 black loyalists who were held as slaves by patriots, escaped to British lines and joined the British army. Most died of disease but Britain took the survivors to Canada as free men.
The revolution could divide families. The most dramatic example was when William Franklin, son of Benjamin Franklin and royal governor of the Province of New Jersey, remained loyal to the Crown throughout the war; they never spoke again. Recent immigrants who had not been fully Americanized were also inclined to support the King, such as recent Scottish settlers in the back country; among the more striking examples of this, see Flora MacDonald.
After the war, the great majority of the 450,000–500,000 Loyalists remained in America and resumed normal lives. Some, such as Samuel Seabury, became prominent American leaders. Estimates vary, but about 62,000 Loyalists relocated to Canada, and others to Britain (7,000) or to Florida or the West Indies (9,000). The exiles represented approximately 2% of the total population of the colonies. Nearly all black loyalists left for Nova Scotia, Florida, or England, where they could remain free. When Loyalists left the South in 1783, they took thousands of their slaves with them to be slaves in the British West Indies.
Neutrals.
A minority of uncertain size tried to stay neutral in the war. Most kept a low profile, but the Quakers, especially in Pennsylvania, were the most important group to speak out for neutrality. As Patriots declared independence, the Quakers, who continued to do business with the British, were attacked as supporters of British rule, "contrivers and authors of seditious publications" critical of the revolutionary cause.
Role of women.
Women contributed to the American Revolution in many ways, and were involved on both sides. While formal Revolutionary politics did not include women, ordinary domestic behaviors became charged with political significance as Patriot women confronted a war that permeated all aspects of political, civil, and domestic life. They participated by boycotting British goods, spying on the British, following armies as they marched, washing, cooking, and tending for soldiers, delivering secret messages, and in a few cases like Deborah Samson, fighting disguised as men. Also, Mercy Otis Warren held meetings in her house and cleverly attacked Loyalists with her creative plays and histories. Above all, they continued the agricultural work at home to feed their families and the armies. They maintained their families during their husbands' absences and sometimes after their deaths.
American women were integral to the success of the boycott of British goods, as the boycotted items were largely household items such as tea and cloth. Women had to return to knitting goods, and to spinning and weaving their own cloth — skills that had fallen into disuse. In 1769, the women of Boston produced 40,000 skeins of yarn, and 180 women in Middletown, Massachusetts wove of cloth.
A crisis of political loyalties could disrupt the fabric of colonial America women's social worlds: whether a man did or did not renounce his allegiance to the King could dissolve ties of class, family, and friendship, isolating women from former connections. A woman's loyalty to her husband, once a private commitment, could become a political act, especially for women in America committed to men who remained loyal to the King. Legal divorce, usually rare, was granted to Patriot women whose husbands supported the King.
Other participants.
France.
In early 1776, France set up a major program of aid to the Americans, and the Spanish secretly added funds. Each country spent one million "livres tournaises" to buy munitions. A dummy corporation run by Pierre Beaumarchais concealed their activities. American rebels obtained some munitions through the Dutch Republic as well as French and Spanish ports in the West Indies.
Spain.
Spain did not officially recognize the U.S. but became an informal ally when it declared war on Britain on June 21, 1779. Bernardo de Gálvez y Madrid, general of the Spanish forces in New Spain, also served as governor of Louisiana. He led an expedition of colonial troops to force the British out of Florida and keep open a vital conduit for supplies.
Native Americans.
Most Native Americans rejected pleas that they remain neutral and supported the British Crown, both because of trading relationships and its efforts to prohibit colonial settlement west of the Appalachian Mountains. The great majority of the 200,000 Native Americans east of the Mississippi distrusted the colonists and supported the British cause, hoping to forestall continued colonial encroachment on their territories. Those tribes that were more closely involved in colonial trade tended to side with the revolutionaries, although political factors were important as well.
Although there was limited participation by Native American warriors except for those associated with four of the Iroquois nations in New York and Pennsylvania, the British provided Indians with funding and weapons to attack American outposts. Some Indians tried to remain neutral, seeing little value in joining a European conflict and fearing reprisals from whichever side they opposed. The Oneida and Tuscarora peoples of western New York supported the American cause.
The British provided arms to Indians, who were led by Loyalists in war parties to raid frontier settlements from the Carolinas to New York. They killed many scattered settlers, especially in Pennsylvania. In 1776 Cherokee war parties attacked American colonists all along the southern frontier of the uplands. While the Chickamauga Cherokee could launch raids numbering a couple hundred warriors, as seen in the Chickamauga Wars, they could not mobilize enough forces to fight a major invasion without the help of allies, most often the Creek.
Joseph Brant of the powerful Mohawk nation, part of the Iroquois Confederacy based in New York, was the most prominent Native American leader against the rebel forces. In 1778 and 1780, he led 300 Iroquois warriors and 100 white Loyalists in multiple attacks on small frontier settlements in New York and Pennsylvania, killing many settlers and destroying villages, crops and stores. The Seneca, Onondaga and Cayuga of the Iroquois Confederacy also allied with the British against the Americans.
In 1779 the Continentals retaliated with an American army under John Sullivan, which raided and destroyed 40 empty Iroquois villages in central and western New York. Sullivan's forces systematically burned the villages and destroyed about 160,000 bushels of corn that comprised the winter food supply. Facing starvation and homeless for the winter, the Iroquois fled to the Niagara Falls area and to Canada, mostly to what became Ontario. The British resettled them there after the war, providing land grants as compensation for some of their losses.
At the peace conference following the war, the British ceded lands which they did not really control, and did not consult their Indian allies. They "transferred" control to the Americans of all the land east of the Mississippi and north of Florida. The historian Calloway concludes:
The British did not give up their forts in the West (what is now the Ohio to Wisconsin) until 1796; they kept alive the dream of forming a satellite Indian nation there, which they called a Neutral Indian Zone. That goal was one of the causes of the War of 1812.
African Americans.
Free blacks in the North and South fought on both sides of the Revolution, but most fought for the patriots. Gary Nash reports that recent research concludes there were about 9000 black Patriot soldiers, counting the Continental Army and Navy, and state militia units, as well as privateers, wagoneers in the Army, servants to officers, and spies. Ray Raphael notes that while thousands did join the Loyalist cause, "A far larger number, free as well as slave, tried to further their interests by siding with the patriots." Crispus Attucks, who was shot dead by British soldiers in the Boston Massacre in 1770, is an iconic martyr to Patriots. Both sides offered freedom and re-settlement to slaves who were willing to fight for them, especially targeting slaves whose owners supported the opposing cause.
Many African-American slaves sided with the Loyalists. Tens of thousands used the turmoil of war to escape, and the southern plantation economies of South Carolina and Georgia especially were disrupted. During the Revolution, the British tried to turn slavery against the Americans, but historian David Brion Davis explains the difficulties with a policy of wholesale arming of the slaves: 
Davis underscored the British dilemma: "Britain, when confronted by the rebellious American colonists, hoped to exploit their fear of slave revolts while also reassuring the large number of slave-holding Loyalists and wealthy Caribbean planters and merchants that their slave property would be secure". The colonists accused the British of encouraging slave revolts.
American advocates of independence were commonly lampooned in Britain for what was termed their hypocritical calls for freedom, at the same time that many of their leaders were planters who held hundreds of slaves. Samuel Johnson snapped, "how is it we hear the loudest yelps for liberty among the [slave] drivers of the Negroes?" Benjamin Franklin countered by criticizing the British self-congratulation about "the freeing of one Negro" (Somersett) while they continued to permit the Slave Trade.
Phyllis Wheatley, a black poet who popularized the image of Columbia to represent America, came to public attention when her "Poems on Various Subjects, Religious and Moral" appeared in 1773.
During the war, slaves escaped from across New England and the mid-Atlantic area to British-occupied cities, such as New York. The effects of the war were more dramatic in the South. In Virginia the royal governor Lord Dunmore recruited black men into the British forces with the promise of freedom, protection for their families, and land grants. Tens of thousands of slaves escaped to British lines throughout the South, causing dramatic losses to slaveholders and disrupting cultivation and harvesting of crops. For instance, South Carolina was estimated to lose about 25,000 slaves, or one third of its slave population, to flight, migration or death. From 1770 to 1790, the black proportion of the population (mostly slaves) in South Carolina dropped from 60.5 percent to 43.8 percent; and in Georgia from 45.2 percent to 36.1 percent.
When the British evacuated its forces from Savannah and Charleston, it also gave transportation to 10,000 slaves, carrying through on its commitment to them. They evacuated and resettled more than 3,000 "Black Loyalists" from New York to Nova Scotia, Upper and Lower Canada. Others sailed with the British to England or were resettled in the West Indies of the Caribbean. More than 1200 of the Black Loyalists of Nova Scotia later resettled in the British colony of Sierra Leone, where they became leaders of the Krio ethnic group of Freetown and the later national government. Many of their descendants still live in Sierra Leone, as well as other African countries.
Effects of the Revolution.
Loyalist expatriation.
About 60,000 to 70,000 Loyalists left the newly founded republic; some left for Britain and the remainder, called United Empire Loyalists, received British subsidies to resettle in British colonies in North America, especially Quebec (concentrating in the Eastern Townships), Prince Edward Island, and Nova Scotia. The new colonies of Upper Canada (now Ontario) and New Brunswick were created by Britain for their benefit. However, about 80% of the Loyalists stayed and became loyal citizens of the United States, and some of the exiles later returned to the U.S.
Interpretations.
Interpretations about the effect of the Revolution vary. Contemporary participants referred to the events as "the revolution." Greene argues that the events were not "revolutionary," as the colonial society was not transformed but replaced a distant government with a local one. Historians such as Bernard Bailyn, Gordon Wood, and Edmund Morgan accept the contemporary view of the participants that the American Revolution was a unique and radical event that produced deep changes and had a profound effect on world affairs, based on an increasing belief in the principles of the Enlightenment as reflected in how liberalism was understood during the period, and republicanism. These were demonstrated by a leadership and government that espoused protection of natural rights, and a system of laws chosen by the people. However, what was then considered the people was still restricted to free white males who were able to pass a property-qualification, about 1/9 of the population. Such a restriction made a significant gain of the revolution irrelevant to women, African-Americans and slaves, poor white men, young adults, and Native Americans. Only with the development of the American system over the following centuries would a government by the people promised by the revolution be won for a greater inclusion of the population.
As an example or inspiration.
After the Revolution, genuinely democratic politics became possible. The rights of the people were incorporated into state constitutions. Concepts of liberty, individual rights, equality among men and hostility toward corruption became incorporated as core values of liberal republicanism. The greatest challenge to the old order in Europe was the challenge to inherited political power and the democratic idea that government rests on the consent of the governed. The example of the first successful revolution against a European empire, and the first successful establishment of a republican form of democratically elected government, provided a model for many other colonial peoples who realized that they too could break away and become self-governing nations with directly elected representative government.
The Dutch Republic, also at war with Britain at that time, was the next country after France to sign a treaty with the United States, on October 8, 1782. On April 3, 1783, Ambassador Extraordinary Gustaf Philip Creutz, representing King Gustav III of Sweden, and Benjamin Franklin, Minister Plenipotentiary of the United States of America, signed a Treaty of Amity and Commerce with the U.S.
The American Revolution was the first wave of the Atlantic Revolutions: the French Revolution, the Haitian Revolution, and the Latin American wars of independence. Aftershocks reached Ireland in the Irish Rebellion of 1798, in the Polish-Lithuanian Commonwealth, and in the Netherlands.
The Revolution had a strong, immediate influence in Great Britain, Ireland, the Netherlands, and France. Many British and Irish Whigs spoke in favor of the American cause. The Revolution, along with the Dutch Revolt (end of the 16th century) and the English Civil War (in the 17th century), was among the examples of overthrowing an old regime for many Europeans who later were active during the era of the French Revolution, such as Marquis de Lafayette. The American Declaration of Independence influenced the French Declaration of the Rights of Man and the Citizen of 1789.
The spirit of the Declaration of Independence led to laws ending slavery in all the Northern states and the Northwest Territory, with New Jersey the last in 1804—long before the British Parliament acted in 1833 to abolish slavery in its colonies. States such as New Jersey and New York adopted gradual emancipation, which kept some people as slaves for more than two decades longer.
Status of American women.
The democratic ideals of the Revolution inspired changes in the roles of women.
The concept of republican motherhood was inspired by this period and reflects the importance of Republicanism as the dominant American ideology. It assumed that a successful republic rested upon the virtue of its citizens. Women were considered to have the essential role of instilling their children with values conducive to a healthy republic. During this period, the wife's relationship with her husband also became more liberal, as love and affection instead of obedience and subservience began to characterize the ideal marital relationship. In addition, many women contributed to the war effort through fundraising and running family businesses in the absence of husbands.
The traditional constraints gave way to more liberal conditions for women. Patriarchy faded as an ideal; young people had more freedom to choose their spouses and more often used birth control to regulate the size of their families. Society emphasized the role of mothers in child rearing, especially the patriotic goal of raising republican children rather than those locked into aristocratic value systems. There was more permissiveness in child-rearing. Patriot women married to Loyalists who left the state could get a divorce and obtain control of the ex-husband's property.
Whatever gains they had made, however, women still found themselves subordinated, legally and socially, to their husbands, disfranchised and usually with only the role of mother open to them. But, some women earned livelihoods as midwives and in other roles in the community, which were not originally recognized as significant by men.
Abigail Adams expressed to her husband, the president, the desire of women to have a place in the new republic:
Zagarri (2007) argues the Revolution created a continuing debate on the rights of woman and an environment favorable to women's participation in politics. She asserts that for a brief decade, a "comprehensive transformation in women's rights, roles, and responsibilities seemed not only possible but perhaps inevitable." But, the changes also engendered a backlash that set back the cause of women's rights and led to a greater rigidity that marginalized women from political life.
Memory.
The American Revolution has a central place in the American memory. It is the founding story, and is covered not only in the schools but in innumerable monuments. Thus Independence Day (the "Fourth of July") is a major national holiday celebrated ubiquitously annually. Besides local sites such as Bunker Hill, one of the first national pilgrimages for memorial tourists was Mount Vernon, George Washington's estate (near Washington DC), which attracted ten thousand visitors a year by the 1850s.
Crider points out that in the 1850s editors and orators both North and South claimed their region was the true custodian of the legacy of 1776, as they used the Revolution symbolically in their rhetoric. Ryan, noting that the Bicentennial was celebrated only a year after the humiliating 1975 withdrawal from Vietnam, says the Ford administration stressed the themes of renewal and rebirth based on a restoration of traditional values, and presented a nostalgic approach to 1776 that made it seem eternally young and fresh.
Albanese argues that the Revolution became the main source of the non-denominational "American civil religion" that has shaped patriotism and the memory and meaning of the nation's birth ever since. She says that specific battles are not central (as they are for the Civil War) but rather certain events and people have been celebrated as icons of certain virtues (or vices). Thus she points out the Revolution produced a Moses-like leader (George Washington), prophets (Thomas Jefferson, Tom Paine), disciples (Alexander Hamilton, James Madison) and martyrs (Boston Massacre, Nathan Hale), as well as devils (Benedict Arnold), sacred places (Valley Forge, Bunker Hill), rituals (Boston Tea Party), emblems (the new flag), sacred holidays (Independence Day) and a holy scripture whose every sentence is carefully studied and applied in current law cases (The Declaration of Independence, the Constitution and the Bill of Rights).

</doc>
<doc id="1974" url="http://en.wikipedia.org/wiki?curid=1974" title="April 17">
April 17


</doc>
<doc id="1975" url="http://en.wikipedia.org/wiki?curid=1975" title="Alan Ayckbourn">
Alan Ayckbourn

Sir Alan Ayckbourn, CBE (born 12 April 1939) is a prolific English playwright. He has written and produced more than seventy full-length plays in Scarborough and London and was, between 1972 and 2009, the artistic director of the Stephen Joseph Theatre in Scarborough, where all but four of his plays have received their first performance. More than 40 have subsequently been produced in the West End, at the Royal National Theatre or by the Royal Shakespeare Company since his first hit "Relatively Speaking" opened at the Duke of York's Theatre in 1967.
Major successes include "Absurd Person Singular" (1975), "The Norman Conquests" trilogy (1973), "Bedroom Farce" (1975), "Just Between Ourselves" (1976), "A Chorus of Disapproval" (1984), "Woman in Mind" (1985), "A Small Family Business" (1987), "Man Of The Moment" (1988), "House" & "Garden" (1999) and "Private Fears in Public Places" (2004). His plays have won numerous awards, including seven London "Evening Standard" Awards. They have been translated into over 35 languages and are performed on stage and television throughout the world. Ten of his plays have been staged on Broadway, attracting two Tony nominations, and one Tony award.
Life.
Childhood.
Ayckbourn was born in Hampstead, London. His mother Irene Worley ("Lolly") was a writer of short stories who published under the name "Mary James". His father, Horace Ayckbourn, was an orchestral violinist, at one time deputy leader of the London Symphony Orchestra. His parents, who separated shortly after World War II, never married, and Ayckbourn's mother divorced her "first" husband to marry again in 1948.
Ayckbourn wrote his first play at Wisborough Lodge (a preparatory school in the village of Wisborough Green) when he was about 10. Whilst at prep school as a boarder, his mother wrote to tell him she was marrying Cecil Pye, a bank manager. When he went home for the holidays his new family consisted of his mother, his stepfather and Christopher, his stepfather's son by an earlier marriage. This relationship too, reportedly ran into difficulties early on.
Ayckbourn attended Haileybury and Imperial Service College, in the village of Hertford Heath, and whilst there toured Europe and America with the school's Shakespeare company.
Adult life.
After leaving school at 17, Ayckbourn's career took several temporary jobs in various places before starting a temporary job at the Scarborough Library Theatre, where he was introduced to the artistic director, Stephen Joseph. It is said that Joseph became both a mentor and father figure for Ayckbourn until his untimely death in 1967, and he has consistently spoken highly of him.
Ayckbourn's career was briefly interrupted when he was called for National Service. He was swiftly discharged, officially on medical grounds, but it is suggested that a doctor who noticed his reluctance to join the Armed Forces deliberately failed the medical as a favour. Although Ayckbourn continued to move where his career took him, he settled in Scarborough, eventually buying Longwestgate House, the house formerly owned by Stephen Joseph.
In 1957, Ayckbourn married Christine Roland, another member of the Library Theatre company, and indeed Ayckbourn's first two plays were written jointly with her under the pseudonym of "Roland Allen". They had two sons, Steven and Philip. However, the marriage had difficulties which eventually led to their separation in 1971. Alan Ayckbourn said that his relationship with Christine became easy once they agreed their marriage was over. Around this time, he started to share a home with Heather Stoney, an actress he had first met ten years earlier. Like his mother, neither he nor Christine sought a divorce for the next thirty years and it was only in 1997 that they formally divorced; Ayckbourn married Heather Stoney. One side-effect of the timing is that, as Alan was awarded a knighthood a few months before the divorce, both his first and second wife are entitled to take the title of Lady Ayckbourn.
In February 2006, he suffered a stroke in Scarborough, and stated: "I hope to be back on my feet, or should I say my left leg, as soon as possible, but I know it is going to take some time. In the meantime I am in excellent hands and so is the Stephen Joseph Theatre." He left hospital after eight weeks and returned to directing after six months, but the following year he announced he would step down as artistic director of the Stephen Joseph Theatre. Ayckbourn, however, continues to write and direct his own work at the theatre.
Influence on plays.
Since Alan Ayckbourn's plays started becoming established in the West End, interviewers have raised the question of whether his work is autobiographical. There is no clear answer to this question. There has only been one biography, written by Paul Allen, and this primarily covers his career in the theatre. Ayckbourn has frequently said he sees aspects of himself in all his characters. For example, in "Bedroom Farce" (1975), he admitted to being, in some respects, all four of the men in the play. It has been suggested that, after Ayckbourn himself, the person who is used the most in his plays is his mother, particularly as Susan in "Woman in Mind" (1985).
What is less clear is how much influence events in Ayckbourn's life have had on his writing. It is true that the theme of marriages in various difficulties was heavily present throughout his plays in the early seventies, around the time his own marriage was coming to an end. However, by this time, he had also witnessed the failures of his parents' relationships as well as those of some of his friends. Which relationships, if any, he drew on for his plays, is unclear. In Paul Allen’s biography, Ayckbourn is briefly compared to Dafydd and Guy in "A Chorus of Disapproval" (1984). Both characters feel themselves in trouble, and there was speculation that Alan Ayckbourn himself may have felt himself to be in trouble. At the time, he had reportedly become seriously involved with another actress, which threatened his relationship with Heather Stoney. But again, it is unclear whether this had any effect on the writing, and Paul Allen's view is that it is not current experience that Ayckbourn uses for his plays.
It could be that Ayckbourn had written plays with himself and his own issues in mind, but as Ayckbourn is portrayed as a guarded and private man, it is hard to imagine him exposing his own life in his plays to any great degree. In the biography, Paul Allen wrote, regarding a suggestion in "Cosmopolitan" that his plays were becoming autobiographical: "If we take that to mean that his plays tell his own life story, he still hasn't started."
Career.
Early career and acting.
On leaving school his theatrical career started immediately, with an introduction to Sir Donald Wolfit by his French master. Ayckbourn joined Wolfit on tour to the Edinburgh Festival Fringe as an acting assistant stage manager (meaning a role that involved both acting and stage management) for three weeks, with his first role on the professional stage being various parts in "The Strong are Lonely" by Fritz Hochwälder. In the following year, Ayckbourn appeared in six other plays at the Connaught Theatre, Worthing, and the Thorndyke theatre, Leatherhead.
In 1957, Ayckbourn was employed by the director Stephen Joseph at the Library Theatre, Scarborough, the predecessor to the modern Stephen Joseph Theatre. His role, again, was initially an acting stage manager. This employment led to Ayckbourn's first professional script commission, in 1958. When he complained about the quality of a script he was performing, Joseph challenged him to write a better one. The result was "The Square Cat", written under the pseudonym Roland Allen and first performed in 1959. In this play, Ayckbourn himself played the character Jerry Watiss.
After thirty-four appearances in plays at the Library Theatre, including four of his own, in 1962 Ayckbourn moved to Stoke-on-Trent to help set up the Victoria Theatre, (now the New Vic), where he appeared in a further eighteen plays. His final appearance in one of his own plays was as the Crimson Gollywog in the disastrous children's play "Christmas v Mastermind". He left the Stoke company in 1964, officially to commit his time to the London production of "Mr. Whatnot", but reportedly because was having trouble working with the artistic director, Peter Cheeseman. By now, his career as a writer was coming to fruition, and his acting career was sidelined.
His final role on stage was as Jerry in "Two for the Seesaw" by William Gibson, at the Civic Theatre in Rotherham. He was left stranded on stage because Heather Stoney was unable to re-appear because the props had been left unpacked, and this led him to decide acting was more trouble than it was worth. The assistant stage manager on the production, Bill Kenwright, would become one of the UK's most successful producers.
Writing.
Alan Ayckbourn's earliest plays were written and produced at a time when the Scarborough Library theatre, like most regional theatres, regularly commissioned work from their own actors to keep costs down (the other notable actor whose work was being commissioned being David Campton). His first play, "The Square Cat", was sufficiently popular locally to secure further commissions, but neither this nor the following three plays had any major impact outside of Scarborough. But, after his transfer to Victoria Theatre in Stoke-on-Trent, there came "Christmas v Mastermind", which flopped and is now universally regarded as Ayckbourn's greatest disaster.
His fortunes began to revive in 1963 with "Mr. Whatnot", again premièring at the Victoria Theatre. This was the first play that Ayckbourn was sufficiently happy with to allow performances by day, and the first play to receive a West End performance. However, the West End production flopped, in part down to misguided casting. After this, Ayckbourn experimented by collaborating with comedians, first writing a monologue for Tommy Cooper, and later with Ronnie Barker, who played Lord Slingsby-Craddock in the London production of "Mr Whatnot" in 1964, for the scripts of for LWT's "Hark at Barker". Ayckbourn used the pseudonym 'Peter Caulfield' because he was under exclusive contract to the BBC at the time.
Then, in 1965, back at the Scarborough Library Theatre, "Meet my Father" was produced, later retitled "Relatively Speaking". This time, the play was a massive success, both in Scarborough and the West End, making Alan Ayckbourn rich and earning him a congratulatory telegram from Noël Coward. This was not quite the end of Ayckbourn's hit-and-miss record, because his following play, "The Sparrow" only ran for three weeks at Scarborough. However, the following play, "How the Other Half Loves", secured his runaway success as a playwright.
The height of Ayckbourn's commercial success included "Absurd Person Singular" (1975), "The Norman Conquests" trilogy (1973), "Bedroom Farce" (1975) and "Just Between Ourselves" (1976), all plays that focused heavily on marriage in the British middle classes. The only failure during this period was a 1975 musical with Andrew Lloyd Webber, "Jeeves", and even this did little to dent Ayckbourn's popularity. Although his plays have received major West End productions almost from the beginning of his writing career, and hence have been reviewed in British newspapers, Ayckbourn's work was for years routinely dismissed as being too slight for serious study. Recently, scholars have begun to view Ayckbourn as an important commentator on the lifestyles of the British suburban middle class, and as a stylistic innovator who experiments with theatrical styles within the boundaries set by popular tastes.
From the 1980s, Ayckbourn began to move away from the recurring themes of marriage and explore other contemporary themes, one example being "Woman in Mind", a play performed entirely from the perspective of a Woman going through a nervous breakdown. He also experimented with several more unconventional ways of writing plays, such as "Intimate Exchanges", which has one beginning and sixteen possible endings, and "House & Garden", where two plays take place simultaneously of two different stages, as well as diversifying into children's theatre (such as "Mr A's Amazing Maze Plays" and musical plays, such as "By Jeeves" (a more successful rewrite of the original "Jeeves").
With a résumé of over seventy plays, of which more than forty have played at the National Theatre or in the West End, Alan Ayckbourn is one of England’s most successful living playwrights. Despite his success, honours and awards (which include a prestigious Laurence Olivier Award), Alan Ayckbourn remains a relatively anonymous figure dedicated to regional theatre. Throughout his writing career, all but four of his plays were premièred at the Stephen Joseph Theatre in Scarborough in its three different locations.
Alan Ayckbourn received the CBE in 1987 and was knighted in 1997. It is frequently claimed (but not proven) that Alan Ayckbourn is the most performed living English playwright, and the second most performed of all time after Shakespeare.
Although Alan Ayckbourn's plays no longer dominate the theatrical scene on the scale of his earlier works, he continues to write, his most recent major success being "Private Fears in Public Places" that had a hugely successful Off-Broadway run at 59E59 Theaters, and in 2006 was made into a film "Cœurs", directed by Alain Resnais. After suffering a stroke, there was uncertainly as to whether he could continue to write (the Ayckbourn play premièred immediately after the stroke, "If I Were You", was written before his illness), but his first play written afterwards, "Life and Beth", was premièred in the summer of 2008. Ayckbourn continues to write for the Stephen Joseph Theatre on invitation of his successor as artistic director, Chris Monks, with the first new play under this arrangement, "My Wonderful Day", performed in October 2009. His latest play, "Roundelay" is scheduled to open in September 2014; the order in which each of the five acts is played in each performance is to be left to chance (allowing 120 possible permutations), with members of the audience being invited to extract five coloured ping pong balls from a bag beforehand.
Many of Ayckbourn's plays have had their New York premiere at 59E59 Theaters as part of their annual Brits Off Broadway Festitval including "Private Fears in Public Places", "Intimate Exchanges", "My Wonderful Day" and "Neighbourhood Watch" among others.
Directing.
Although Alan Ayckbourn is best known as a writer, it is said that he only spends 10% of his time writing plays. Most of the rest of his time is spent directing.
Alan Ayckbourn began directing at the Scarborough Library Theatre in 1961, with a production of "Gas Light" by Patrick Hamilton. He directed five other plays that year and the following year in Scarborough, and after transferring to the Victoria Theatre, directed a further six plays in 1963. Between 1964 and 1967 (when much of his time was taken up by various productions of his early successes "Mr. Whatnot" and "Relatively Speaking") he only directed one play ("The Sparrow", written by himself, later withdrawn), but in 1968 he resumed regularly directing plays, mostly at Scarborough. At this time he also worked as a radio drama producer for the BBC, based in Leeds.
At first, his directing career was separate from his writing career. It was not until 1963 that Ayckbourn directed a play of his own (a revival of "Standing Room Only"), 1967 that Ayckbourn directed a première of his own ("The Sparrow"). The London premières remained in the hands of other directors for longer, with the first play of his both written and directed by him in London ("Bedroom Farce") waiting until 1977.
After the death of Stephen Joseph in 1967, the position of Director of Productions was appointed on an annual basis. Alan Ayckbourn was offered this position in 1969 and 1970, succeeding Rodney Wood, but he handed the position over to Caroline Smith in 1971 (having spent most of his time that year in the USA with "How the Other Half Loves"). He became Director of Productions again in 1972, and this time, on 12 November that same year, he was made the permanent artistic director of the theatre.
In mid-1986, Ayckbourn accepted an invitation to work as a visiting director for two years at the Royal National Theatre in London, form his own company, and perform a play in each of the three auditoria provided at least one was a new play of his own. Using a stock company that included established performers like Michael Gambon, Polly Adams and Simon Cadell. The three plays became four, and were: "Tons of Money" by Will Evans and Valentine, with adaptations by Ayckbourn (Lyttelton), Arthur Miller's "A View From the Bridge" (Cottesloe), his own "A Small Family Business" (Olivier) and John Ford's "'Tis Pity She's a Whore" (Olivier again). During this time, Alan Ayckbourn shared his role of artistic director of the Stephen Joseph Theatre with Robin Herford and returned in 1987 to direct the première of "Henceforward...".
He announced in 1999 that he would step back from directing the work of other playwrights, in order to concentrate on his own plays, the last one being Rob Shearman's "Knights in Plastic Armour" in 1999; the exception being in 2002 when he directed the world première of Tim Firth's "The Safari Party".
In 2002, following a dispute over the Duchess Theatre's handling of "Damsels in Distress", Ayckbourn sharply criticised both this and the West End's treatment of theatre in general, in particular their casting of celebrities. Although he did not explicitly say he would boycott the West End, he did not return to direct in the West End again until 2009 with a revival of "Woman in Mind" (although he did allow other West End producers to revive "Absurd Person Singular" in 2007 and "The Norman Conquests" in 2008).
After Ayckbourn suffered a stroke in February 2006, he returned to work in September and premièred his 70th play "If I Were You" at the Stephen Joseph Theatre the following month.
He announced in June 2007 that he would retire as artistic director of the Stephen Joseph Theatre after the 2008 season. His successor, Chris Monks, took over at the start of the 2009–2010 season, but Ayckbourn remained to direct premières and revivals of his work at the theatre, beginning with "How the Other Half Loves" in June 2009.
In March 2010 he directed an in-the-round revival of his play "Taking Steps" at the Orange Tree Theatre, winning universal press acclaim.
In July 2014, Ayckbourn directed a of "The Boy Who Fell Into A Book", with musical adaptation and lyrics by Paul James and music by Eric Angus and Cathy Shostak. The show ran in The Stephen Joseph Theatre and received critical acclaim.
Works.
One-act plays.
There are seven one-act plays written by Alan Ayckbourn. Five of them ("Mother Figure", "Drinking Companion", "Between Mouthfuls", "Gosforth’s Fete" and "Widows Might") were written for "Confusions", first performed in 1974.
The other two one-act plays were:
Film adaptations of Ayckbourn plays.
Plays adapted as films include:

</doc>
<doc id="1979" url="http://en.wikipedia.org/wiki?curid=1979" title="Alpha Centauri">
Alpha Centauri

Alpha Centauri (α Centauri, α Cen; also known as Rigil Kent —see Names) or Toliman is the brightest star in the southern constellation of Centaurus and the third brightest star in the night sky. The Alpha Centauri system is located 1.34 parsecs or 4.37 light years from the Sun, making it the closest star system to our Solar System. Although it appears to the unaided eye as a single object, Alpha Centauri is actually a binary star system (designated Alpha Centauri AB or α Cen AB) whose combined visual magnitude of −0.27 makes it the third brightest star (other than the Sun) seen from Earth after the −1.46 magnitude Sirius and the −0.72 magnitude Canopus.
Its component stars are named Alpha Centauri A (α Cen A), with 110% of the mass and 151.9% the luminosity of the Sun, and Alpha Centauri B (α Cen B), at 90.7% of the Sun's mass and 44.5% of its luminosity. During the pair's 79.91-year orbit about a common center, the distance between them varies from about that between Pluto and the Sun to that between Saturn and the Sun.
A third star, known as Proxima Centauri, Proxima, or Alpha Centauri C (α Cen C), is probably gravitationally associated with Alpha Centauri AB. Proxima is at the slightly smaller distance of 1.29 parsecs or 4.24 light years from the Sun, making it the closest star to the Sun even though it is not visible to the naked eye. The separation of Proxima from Alpha Centauri AB is about 0.06 parsecs, 0.2 light years or 13,000 astronomical units (AU); equivalent to 400 times the size of Neptune's orbit.
The system may also contain at least one planet, the Earth-sized Alpha Centauri Bb, which, if confirmed, will be the closest known exoplanet to Earth. The planet has a mass at least 13% more than Earth's and orbits Alpha Centauri B with a period of 3.236 days. Orbiting at a distance of 6 million kilometers from the star, 4% of the distance of the Earth to the Sun and a tenth of the distance between Mercury and the Sun, the planet has an estimated surface temperature of 1500 K (roughly 1200 °C), too hot to be habitable. On June 10, 2013, scientists reported that the earlier claims of an Earth-like exoplanet orbiting Alpha Centauri B may not be supported.
Nature and components.
"Alpha Centauri" is the name given to what appears as a single star to the naked eye and the brightest star in the southern constellation of Centaurus. At −0.27v visual magnitude, it is fainter only than Sirius and Canopus. The next brightest star in the night sky is Arcturus. Actually a multiple star system, its two main stars are Alpha Centauri A and Alpha Centauri B , usually defined to identify them as the different components of the binary . A third companion—Proxima Centauri (or Proxima or )—has a distance much greater than the observed separation between stars A and B and is probably gravitationally associated with the AB system. As viewed from Earth, it is located at an angular separation of 2.2° from the two main stars. If it were bright enough to be seen without a telescope, Proxima Centauri would appear to the naked eye as a star separate from . Alpha Centauri AB and Proxima Centauri form a "visual double" star. Direct evidence that Proxima Centauri has an elliptical orbit typical of binary stars has yet to be found. Together all three components make a triple star system, referred to by double-star observers as the triple star (or multiple star), .
Alpha Centauri A is the principal member, or "primary", of the binary system, being slightly larger and more luminous than the Sun. It is a solar-like main-sequence star with a similar yellowish color, whose stellar classification is spectral type G2 V. From the determined mutual orbital parameters, Alpha Centauri A is about 10% more massive than the Sun, with a radius about 23% larger. The projected rotational velocity of this star is , resulting in an estimated rotational period of 22 days, which gives it a slightly faster rotational period than the Sun's 25 days. When considered among the individual brightest stars in the sky (excluding the Sun), Alpha Centauri A is the fourth brightest at −0.01 magnitude, being fractionally fainter than Arcturus at −0.04v magnitude.
Alpha Centauri B is the companion star, or "secondary", of the binary system, and is slightly smaller and less luminous than the Sun. It is a main-sequence star of spectral type K1 V, making it more an orange color than the primary star. Alpha Centauri B is about 90% the mass of the Sun and 14% smaller in radius. The projected rotational velocity is , resulting in an estimated rotational period of 41 days. (An earlier, 1995 estimate gave a similar rotation period of 36.8 days.) Although it has a lower luminosity than component A, star B emits more energy in the X-ray band. The light curve of B varies on a short time scale and there has been at least one observed flare. Alpha Centauri B at 1.33v magnitude would be twenty-first in brightness if it could be seen independently of Alpha Centauri A.
Alpha Centauri C, also known as Proxima Centauri, is of spectral class M5 Ve or M5 VIe, suggesting this is either a small main-sequence star (Type V) or subdwarf (VI) with emission lines. Its B−V color index is +1.90 and its mass is about 0.123 M☉, or 129 Jupiter masses.
Together, the bright visible components of the binary star system are called Alpha Centauri AB . This "AB" designation denotes the apparent gravitational centre of the main binary system relative to other companion star(s) in any multiple star system. "AB-C" refers to the orbit of Proxima around the central binary, being the distance between the centre of gravity and the outlying companion. Some older references use the confusing and now discontinued designation of A×B. Since the distance between the Sun and Alpha Centauri AB does not differ significantly from either star, gravitationally this binary system is considered as if it were one object.
Asteroseismic studies, chromospheric activity, and stellar rotation (gyrochronology), are all consistent with the α Cen system being similar in age to, or slightly older than, the Sun, with typical ages quoted between 4.5 and 7 billion years (Gyr). Asteroseismic analyses that incorporate the tight observational constraints on the stellar parameters for α Cen A and/or B have yielded age estimates of 4.85 ± 0.5 Gyr, 5.0 ± 0.5 Gyr, 5.2–7.1 Gyr, 6.4 Gyr, and 6.52 ± 0.3 Gyr. Age estimates for stars A and B based on chromospheric activity (Calcium H & K emission) yield 4.4–6.5 Gyr, while gyrochronology yields 5.0 ± 0.3 Gyr.
Observation.
The two Alpha Centauri AB binary stars are too close together to be resolved by the naked eye, because the angular separation varies between 2 and 22 arcsec, but through much of the orbit, both are easily resolved in binoculars or small telescopes.
In the southern hemisphere, Alpha Centauri forms the outer star of "The Pointers" or "The Southern Pointers", so called because the line through Beta Centauri (Hadar/Agena),
some 4.5° west, points directly to the constellation Crux — the Southern Cross. The Pointers easily distinguish the true Southern Cross from the fainter asterism known as the False Cross.
South of about 29° S latitude, Alpha Centauri is circumpolar and never sets below the horizon. Both stars, including Crux, are too far south to be visible for mid-latitude northern observers. Below about 29° N latitude to the equator (roughly Hermosillo, Chihuahua in Mexico, Galveston, Texas, Ocala, Florida and Lanzarote, the Canary Islands of Spain) during the northern summer, Alpha Centauri lies close to the southern horizon. The star culminates each year at midnight on 24 April or 9 p.m. on 8 June.
As seen from Earth, Proxima Centauri lies 2.2° southwest from Alpha Centauri AB. This is about four times the angular diameter of the Full Moon, and almost exactly half the distance between Alpha Centauri AB and Beta Centauri. Proxima usually appears as a deep-red star of 13.1v visual magnitude in a poorly populated star field, requiring moderately sized telescopes to see. Listed as V645 Cen in the "General Catalogue of Variable Stars (G.C.V.S.) Version 4.2", this UV Ceti-type flare star can unexpectedly brighten rapidly to about 11.0v or 11.09V magnitude. Some amateur and professional astronomers regularly monitor for outbursts using either optical or radio telescopes.
Observational history.
English explorer Robert Hues brought Alpha Centauri to the attention of European observers in his 1592 work "Tractatus de Globis", along with Canopus and Achernar, noting "Now, therefore, there are but three Stars of the first magnitude that I could perceive in all those parts which are never seene here in England. The first of these is that bright Star in the sterne of Argo which they call Canobus. The second is in the end of Eridanus. The third [Alpha Centauri] is in the right foote of the Centaure."
The binary nature of Alpha Centauri AB was first recognized in December 1689 by astronomer and Jesuit priest Jean Richaud. The finding was made incidentally while observing a passing comet from his station in Puducherry. Alpha Centauri was only the second binary star system to be discovered, preceded only by Alpha Crucis.
By 1752, French astronomer Abbé Nicolas Louis de Lacaille made astrometric positional measurements using a meridian circle while John Herschel, in 1834, made the first micrometrical observations. Since the early 20th century, measures have been made with photographic plates.
By 1926, South African astronomer William Stephen Finsen calculated the approximate orbit elements close to those now accepted for this system. All future positions are now sufficiently accurate for visual observers to determine the relative places of the stars from a binary star ephemeris. Others, like the Belgian astronomer D. Pourbaix (2002), have regularly refined the precision of any new published orbital elements.
Alpha Centauri is the closest star system to the Solar System. It lies about 4.37 light-years in distance, or about 41.5 trillion kilometres, 25.8 trillion miles or 277,600 AU. Scottish astronomer Thomas Henderson made the original discovery from many exacting observations of the trigonometric parallaxes of the AB system between April 1832 and May 1833. He withheld the results because he suspected they were too large to be true, but eventually published in 1839 after Friedrich Wilhelm Bessel released his own accurately determined parallax for 61 Cygni in 1838. For this reason, Alpha Centauri is considered as the second star to have its distance measured because it was not formally recognized first. Alpha Centauri is inside the G-cloud, and the nearest known system to it is Luhman 16 at 3.6 light years.
Scottish astronomer Robert Innes discovered Proxima Centauri in 1915 by blinking photographic plates taken at different times during a dedicated proper motion survey. This showed the large proper motion and parallax of the star was similar in both size and direction to those of Alpha Centauri AB, suggesting immediately it was part of the system and slightly closer to us than Alpha Centauri AB. Lying 4.24 light-years away, Proxima Centauri is the nearest star to the Sun. All current derived distances for the three stars are from the parallaxes obtained from the Hipparcos star catalog (HIP).
Binary system.
With the orbital period of 79.91 years, the A and B components of this binary star can approach each other to 11.2 astronomical units, equivalent to 1.67 billion km or about the mean distance between the Sun and Saturn, or may recede as far as 35.6 AU (5.3 billion km—approximately the distance from the Sun to Pluto). This is a consequence of the binary's moderate orbital eccentricity "e" = 0.5179. From the orbital elements, the total mass of both stars is about 2.0 "M"☉—or twice that of the Sun. The average individual stellar masses are 1.09 "M"☉ and 0.90 "M"☉, respectively, though slightly higher masses have been quoted in recent years, such as 1.14 "M"☉ and 0.92 "M"☉, or totalling 2.06 "M"☉. Alpha Centauri A and B have absolute magnitudes of +4.38 and +5.71, respectively. Stellar evolution theory implies both stars are slightly older than the Sun at 5 to 6 billion years, as derived by both mass and their spectral characteristics.
Viewed from Earth, the "apparent orbit" of this binary star means that the separation and position angle (P.A.) are in continuous change throughout the projected orbit. Observed stellar positions in 2010 are separated by 6.74 arcsec through the P.A. of 245.7°, reducing to 6.04 arcsec through 251.8° in 2011. Next closest approach will be in February 2016, at 4.0 arcsec through 300°. Observed maximum separation of these stars is about 22 arcsec, while the minimum distance is 1.7 arcsec. Widest separation occurred during February 1976 and the next will be in January 2056.
In the "true orbit", closest approach or periastron was in August 1955, and next in May 2035. Furthest orbital separation at apastron last occurred in May 1995 and the next will be in 2075. The apparent distance between the two stars is rapidly decreasing, at least until 2019.
Companion: Proxima Centauri.
The much fainter red dwarf named Proxima Centauri, or simply Proxima, is about 15,000 AU away from Alpha Centauri AB. This is equivalent to 0.24 light years or 2.2 trillion kilometres—about 5% the distance between Alpha Centauri AB and the Sun. Proxima is likely gravitationally bound to Alpha Centauri AB, orbiting it with a period between 100,000 and 500,000 years. However, it is also possible that Proxima is not gravitationally bound and thus moving along a hyperbolic trajectory with respect to Alpha Centauri AB. The main evidence for a bound orbit is that Proxima's association with Alpha Centauri AB is unlikely to be accidental, since they share approximately the same motion through space. Theoretically, Proxima could leave the system after several million years. It is not yet certain whether Proxima and Alpha are truly gravitationally bound.
Proxima is an M5.5 V spectral class red dwarf with an absolute magnitude of +15.53, which is only a small fraction of the Sun's luminosity. By mass, Proxima is calculated as (rounded to 0.12 "M"☉) or about one-eighth that of the Sun.
High-proper-motion star.
All components of Alpha Centauri display significant proper motions against the background sky, similar to the first magnitude stars Sirius and Arcturus. Over the centuries, this causes the apparent stellar positions to slowly change. Such motions define the "high-proper-motion stars". These stellar motions were unknown to ancient astronomers. Most assumed that all stars were immortal and permanently fixed on the celestial sphere, as stated in the works of the philosopher Aristotle.
Edmond Halley in 1718 found that some stars had significantly moved from their ancient astrometric positions. For example, the bright star Arcturus (α Boo) in the constellation of Boötes showed an almost 0.5° difference in 1800 years, as did the brightest star, Sirius, in Canis Major (α CMa). Halley's positional comparison was Ptolemy's catalogue of stars contained in the Almagest whose original data included portions from an earlier catalog by Hipparchos during the . Halley's proper motions were mostly for northern stars, so the southern star Alpha Centauri was not determined until the early 19th century.
Scottish-born observer Thomas James Henderson in the 1830s at the Royal Observatory at the Cape of Good Hope discovered the true distance to Alpha Centauri. He soon realised this system displayed an unusually high proper motion, and therefore its observed true velocity through space should be much larger. In this case, the apparent stellar motion was found using Abbé Nicolas Louis de Lacaille's astrometric observations of 1751–1752, by the observed differences between the two measured positions in different epochs. Using the Hipparcos Star Catalogue (HIP) data, the mean individual proper motions are −3678 mas/yr or −3.678 arcsec per year in right ascension and +481.84 mas/yr or 0.48184 arcsec per year in declination. As proper motions are cumulative, the motion of Alpha Centauri is about 6.1 arcmin each century, and 61.3 arcmin or 1.02° each millennium. These motions are about one-fifth and twice, respectively, the diameter of the full moon. Using spectroscopy the mean radial velocity has been determined to be towards the Solar System.
As the stars of Alpha Centauri approach us, the measured proper motion and trigonometric parallax slowly increase. Changes are also observed in the size of the semi-major axis of the orbital ellipse, increasing by 0.03 arcsec per century. This change slightly shortens the observed orbital period of by some 0.006 years per century. This small effect is gradually decreasing until the star system is at its closest to us, and is then reversed as the distance increases again. Consequently, the observed position angles of the stars are subject to changes in the orbital elements over time, as first determined by W. H. van den Bos in 1926. Some slight differences of about 0.5% in the measured proper motions are caused by Alpha Centauri AB's orbital motion.
Based on these observed proper motions and radial velocities, Alpha Centauri will continue to gradually brighten, passing just north of the Southern Cross or Crux, before moving northwest and up towards the celestial equator and away from the galactic plane. By about 29,700 AD, in the present-day constellation of Hydra, Alpha Centauri will be 1.00 pc or 3.26 ly away. Then it will reach the stationary radial velocity (RVel) of 0.0 km/s and the maximum apparent magnitude of −0.86V (which is comparable to present-day magnitude of Canopus). However, even during the time of this nearest approach, the apparent magnitude of Alpha Centauri will still not surpass that of Sirius (which will brighten incrementally over the next 60,000 years, and will continue to be the brightest star as seen from Earth for the next 210,000 years).
The Alpha Centauri system will then begin to move away from the Solar System, showing a positive radial velocity. Due to visual perspective, about 100,000 years from now, these stars will reach a final vanishing point and slowly disappear among the countless stars of the Milky Way. Here this once bright yellow star will fall below naked-eye visibility somewhere in the faint present day southern constellation of Telescopium (this unusual location results from the fact that Alpha Centauri's orbit around the galactic centre is highly tilted with respect to the plane of the Milky Way galaxy).
Apparent movement.
In about 4000 years, the proper motion of Alpha Centauri will mean that from the point of view of Earth it will appear close enough to Beta Centauri to form an optical double star. Beta Centauri is in reality far more distant than Alpha Centauri.
Planets.
Until the 1990s, technologies did not exist that could detect planets outside the Solar System. However, some exoplanets may be orbiting the Alpha Centauri system.
Alpha Centauri Bb.
On 16 October 2012, researchers, mainly from the Observatory of Geneva and from the Centre for Astrophysics of the University of Porto, announced that an Earth-mass planet had been detected in orbit around Alpha Centauri B using the radial velocity technique. Over three years of observations had been needed for the difficult analysis. The planet has a minimum mass of 1.13 times Earth's mass. It is not in the habitable zone, orbiting very close to the host star at just 0.04 AU and completing one orbit every 3.236 days. Its surface temperature is estimated to be 1200 °C (about 1500 K), far too hot for liquid water and also above the melting temperatures of many silicate magmas. For comparison, the surface temperature of Venus, the hottest planet in the Solar System, is 462 °C (735 K).
Alpha Centauri ABb.
On 24 September 2014, astronomers from Saint Petersburg, Russia, announced a planet orbiting the binary Alpha Centauri AB system. It was announced at Journees-2014, a scientific conference, held at the Pulkovo Observatory in Saint Petersburg. The planet may be located at a distance of 80 AU and is orbiting with an orbital period of about 100 years.
Possibility of additional planets.
The discovery of planets orbiting other star systems, including similar binary systems (Gamma Cephei), raises the possibility that additional planets may exist in the Alpha Centauri system. Such planets could orbit Alpha Centauri A or Alpha Centauri B individually, or be on large orbits around the binary Alpha Centauri AB. Since both the principal stars are fairly similar to the Sun (for example, in age and metallicity), astronomers have been especially interested in making detailed searches for planets in the Alpha Centauri system. Several established planet-hunting teams have used various radial velocity or star transit methods in their searches around these two bright stars. All the observational studies have so far failed to find any evidence for brown dwarfs or gas giants.
In 2009, computer simulations (then unaware of the close-in planet Bb) showed that a planet might have been able to form near the inner edge of Alpha Centauri B's habitable zone, which extends from 0.5 to 0.9 AU from the star. Certain special assumptions, such as considering that Alpha Centauri A and B may have initially formed with a wider separation and later moved closer to each other (as might be possible if they formed in a dense star cluster) would permit an accretion-friendly environment farther from the star. Bodies around A would be able to orbit at slightly farther distances due to A's stronger gravity. In addition, the lack of any brown dwarfs or gas giants in close orbits around A or B make the likelihood of terrestrial planets greater than otherwise. Theoretical studies on the detectability via radial velocity analysis have shown that a dedicated campaign of high-cadence observations with a 1–m class telescope can reliably detect a hypothetical planet of 1.8 Earth masses in the habitable zone of B within three years.
Radial velocity measurements of Alpha Centauri B with HARPS spectrograph ruled out planets of more than 4 Earth masses to the distance of the habitable zone of the star (orbital period P = 200 days).
Alpha Centauri is envisioned as the first target for unmanned interstellar exploration. Crossing the huge distance between the Sun and Alpha Centauri using current spacecraft technologies would take several millennia, though the possibility of solar sail or nuclear pulse propulsion technology could cut this down to a matter of decades.
Theoretical planets.
Early computer-generated models of planetary formation predicted the existence of terrestrial planets around both Alpha Centauri A and B, but most recent numerical investigations have shown that the gravitational pull of the companion star renders the accretion of planets very difficult. Despite these difficulties, given the similarities to the Sun in spectral types, star type, age and probable stability of the orbits, it has been suggested that this stellar system could hold one of the best possibilities for harbouring extraterrestrial life on a potential planet.
Some astronomers speculated that any possible terrestrial planets in the Alpha Centauri system may be bone dry or lack significant atmospheres. In the Solar System both Jupiter and Saturn were probably crucial in perturbing comets into the inner Solar System. Here the comets provided the inner planets with their own source of water and various other ices but Proxima Centauri may have influenced the planetary disk as the Alpha Centauri system was forming enriching the area around Alpha Centauri A and B with volatile materials. This would be discounted if, for example, Alpha Centauri B happened to have gas giants orbiting Alpha Centauri A (or conversely, Alpha Centauri A for Alpha Centauri B), or if the stars B and A themselves were able to successfully perturb comets into each other's inner system as Jupiter and Saturn presumably have done in the Solar System. Because icy bodies probably also reside in Oort clouds of other planetary systems, when they are influenced gravitationally by either the gas giants or disruptions by passing nearby stars many of these icy bodies then travel starwards. There is no direct evidence yet of the existence of such an Oort cloud around Alpha Centauri AB, and theoretically this may have been totally destroyed during the system's formation.
To be in the star's habitable zone, any suspected Earth-like planet around Alpha Centauri A would have to be placed about 1.25 AU away – about halfway between the distances of Earth's orbit and Mars's orbit in the Solar System – so as to have similar planetary temperatures and conditions for liquid water to exist. For the slightly less luminous and cooler Alpha Centauri B, the habitable zone would lie closer at about 0.7 AU , approximately the distance that Venus is from the Sun.
With the goal of finding evidence of such planets, both Proxima Centauri and Alpha Centauri AB were among the listed "Tier 1" target stars for NASA's Space Interferometry Mission (SIM). Detecting planets as small as three Earth-masses or smaller within two astronomical units of a "Tier 1" target would have been possible with this new instrument. The SIM mission, however, was cancelled due to financial issues in 2010.
View from this system.
Viewed from near the Alpha Centauri system, the sky would appear very much as it does for earthbound observers, except that Centaurus would be missing its brightest star. The Sun would be a yellow +0.5 visual magnitude star in eastern Cassiopeia at the antipodal point of Alpha Centauri's current RA and Dec. at (2000). This place is close to the 3.4 magnitude star ε Cassiopeiae. An interstellar or alien observer would find the \/\/ of Cassiopeia had become a /\/\/ shape nearly in front of the Heart Nebula in Cassiopeia. Sirius lies less than a degree from Betelgeuse in the otherwise unmodified Orion and is with −1.2 a little fainter than from Earth but still the brightest star in the Alpha Centauri sky. Procyon is also displaced into the middle of Gemini, outshining Pollux, while both Vega and Altair are shifted northwestward relative to Deneb (which barely moves, due to its great distance)- giving the Summer Triangle a more equilateral appearance.
From Proxima itself, Alpha Centauri AB would appear like two close bright stars with the combined magnitude of −6.8. Depending on the binary's orbital position, the bright stars would appear noticeably divisible to the naked eye, or occasionally, but briefly, as single unresolved star. Based on the calculated absolute magnitudes, the visual magnitudes of Alpha Centauri A and B would be −6.5 and −5.2, respectively.
View from a hypothetical planet.
An observer on a hypothetical planet orbiting around either Alpha Centauri A or Alpha Centauri B would see the other star of the binary system as an intensely bright object in the night sky, showing a small but discernible disk.
For example, some theoretical Earth-like planet orbiting about 1.25 AU from Alpha Centauri A (so that the star appears roughly as bright as the Sun viewed from the Earth) would see Alpha Centauri B orbit the entire sky once roughly every one year and three months (or 1.3(4) a), the planet's own orbital period. Added to this would be the changing apparent position of Alpha Centauri B during its long eighty-year elliptical orbit with respect to Alpha Centauri A (comparable in speed to Uranus here). Depending on the position on its orbit, Alpha Centauri B would vary in apparent magnitude between −18.2 (dimmest) and −21.0 (brightest). These visual magnitudes are much dimmer than the observed −26.7 magnitude for the Sun as viewed from the Earth. The difference of 5.7 to 8.6 magnitudes means Alpha Centauri B would appear, on a linear scale, 2500 to 190 times dimmer than Alpha Centauri A (or the Sun viewed from the Earth), but also 190 to 2500 times brighter than the −12.5 magnitude full Moon as seen from the Earth.
Also, if another similar Earth-like planet orbited at 0.71 AU from Alpha Centauri B (so that in turn Alpha Centauri B appeared as bright as the Sun seen from the Earth), this hypothetical planet would receive slightly more light from the more luminous Alpha Centauri A, which would shine 4.7 to 7.3 magnitudes dimmer than Alpha Centauri B (or the Sun seen from the Earth), ranging in apparent magnitude between −19.4 (dimmest) and −22.1 (brightest). Thus Alpha Centauri A would appear between 830 and 70 times dimmer than the Sun but some 580 to 6900 times brighter than the full Moon. During such planet's orbital period of 0.6(3) a, an observer on the planet would see this intensely bright companion star circle the sky just as we see with the Solar System's planets. Furthermore, Alpha Centauri A sidereal period of approximately eighty years means that this star would move through the local ecliptic as slowly as Uranus with its eighty-four year period, but as the orbit of Alpha Centauri A is more elliptical, its apparent magnitude will be far more variable. Although intensely bright to the eye, the overall illumination would not significantly affect climate nor influence normal plant photosynthesis.
An observer on the hypothetical planet would notice a change in orientation to VLBI reference points commensurate with the binary orbit periodicity plus or minus any local effects such as precession or nutation.
Assuming this hypothetical planet had a low orbital inclination with respect to the mutual orbit of Alpha Centauri A and B, then the secondary star would start beside the primary at 'stellar' conjunction. Half the period later, at 'stellar' opposition, both stars would be opposite each other in the sky. Then, for about half the planetary year the appearance of the night sky would be a darker blue – similar to the sky during totality at any total solar eclipse. Humans could easily walk around and clearly see the surrounding terrain, and reading a book would be quite possible without any artificial light. After another half period in the stellar orbit, the stars would complete their orbital cycle and return to the next stellar conjunction, and the familiar Earth-like day and night cycle would return.
Names.
The colloquial name of Alpha Centauri is "Rigel Kent" or "Rigil Kent", short for "Rigil/Rigel Kentaurus", the romanization of the Arabic name رجل القنطورس "Rijl Qanṭūris", from the phrase "Rijl al-Qanṭūris" "the foot of the Centaur". This is sometimes further abbreviated to "Rigel", though that is ambiguous with Beta Orionis, which is also called Rigel. Although the short form "Rigel Kent" is common in English, the stars are most often referred to by their Bayer designation "Alpha Centauri."
A medieval name is "Toliman", whose etymology may be Arabic الظلمان "al-Ẓulmān" "the ostriches". During the 19th century, the northern amateur popularist Elijah H. Burritt used the now-obscure name Bungula, possibly coined from "β" and the Latin "ungula" ("hoof"). Together, Alpha and Beta Centauri form the "Southern Pointers" or "The Pointers", as they point towards the Southern Cross, the asterism of the constellation of Crux.
In Chinese, "Nán Mén", meaning "Southern Gate", refers to an asterism consisting of α Centauri and ε Centauri. Consequently, α Centauri itself is known as "Nán Mén Èr", the Second Star of the Southern Gate.
To the Australian aboriginal Boorong people of northwestern Victoria, Alpha and Beta Centauri are "Bermbermgle", two brothers noted for their courage and destructiveness, who speared and killed "Tchingal" "The Emu" (the Coalsack Nebula). The form in Wotjobaluk is "Bram-bram-bult".
Use in modern fiction.
Alpha Centauri's relative proximity makes it in some ways the logical choice as "first port of call". Speculative fiction about interstellar travel often predicts eventual human exploration, and even the discovery and colonization of planetary systems. These themes are common to many works of science fiction and video games.

</doc>
<doc id="1980" url="http://en.wikipedia.org/wiki?curid=1980" title="Amiga">
Amiga

The Amiga is a family of personal computers sold by Commodore in the 1980s and 1990s. The first model was launched in 1985 as a high-end home computer and became popular for its graphical, audio and multi-tasking abilities. The Amiga provided a significant upgrade from 8-bit computers, such as the Commodore 64, and the platform quickly grew in popularity among computer enthusiasts. The name "Amiga" was chosen because it is the Spanish word for "(female) friend", and alphabetically it appears before Apple in lists of computer makers. It originated as a project called Lorraine, therefore the female was used instead of the male and general version "Amigo".
The best selling model, the Amiga 500, was introduced in 1987 and became the leading home computer of the late 1980s and early 1990s in much of Western Europe. In North America success was more modest. The Amiga went on to sell approximately six million units. As the second generation of Amiga systems, the A1200 and the A4000 were released in 1992. However, poor marketing and failure to repeat the technological advances of the first systems meant that the Amiga quickly lost its market share to competing platforms, such as the fourth generation game consoles, Apple Macintosh and IBM PC compatibles.
Based on the Motorola 68000 family of microprocessors, the machine has a custom chipset with graphics and sound capabilities that were unprecedented for the price, and a pre-emptive multitasking operating system called AmigaOS. The original operating system, partly based on TRIPOS and written in BCPL, was called AmigaDOS and the GUI was called Workbench. When it was eventually renamed AmigaOS, the BCPL parts were rewritten in C language.
Although early Commodore advertisements attempted to cast the computer as an all-purpose business machine, the Amiga was most commercially successful as a home computer, with a wide range of games and creative software. It was also a less expensive alternative to the Apple Macintosh and IBM PC as a general-purpose business or home computer. Initially, the Amiga was developed alongside various PC Compatible Systems by Commodore but later Commodore left the PC market. The platform became particularly popular for gaming and programming demos. It also found a prominent role in the desktop video, video production, and show control business, leading to affordable video editing systems such as the Video Toaster. The Amiga's native ability to simultaneously play back multiple digital sound samples made it a popular platform for early "tracker" music software. The relatively powerful processor and ability to access several megabytes of memory led to the development of several 3D rendering packages, including LightWave 3D and Aladdin 4D.
Since the demise of Commodore, various groups have marketed successors to the original Amiga line, including Genesi, Eyetech, ACube Systems and A-EON Technology. Likewise, AmigaOS has influenced replacements, clones and compatible systems such as MorphOS, AmigaOS 4 and AROS. The demise of Commodore has been commonly attributed to numerous factors such as poor marketing, a lack of sufficient third party developers, and a failure to compete with cheaper PC clones with "multimedia" features and low-cost color-capable Macintosh models such as the Macintosh LC.
History.
Development of the Amiga began in 1982 with Jay Miner, developer of the Atari 800 chip set, as the principal hardware designer of Amiga Corporation. It was initially intended to be a next generation video game machine, but was redesigned as a general purpose computer after the North American video game crash of 1983. A prototype of the full computer was shown to the public for the first time at the Summer Consumer Electronics Show in 1984. In order to bring the design to market Commodore International bought Amiga Corporation and funded development. The first model was released in 1985 as simply "The Amiga from Commodore", later to be retroactively dubbed the Amiga 1000. The following year the Amiga product line was expanded with the introduction of two new models: the Amiga 2000 for high-end graphics and business use, and the Amiga 500 for home use. Commodore later released other Amiga models, both for low-end gaming use and high-end productivity use.
In 1994, Commodore filed for bankruptcy and its assets were purchased by Escom, a German PC manufacturer, who created the subsidiary company Amiga Technologies. They re-released the A1200 and A4000T, and introduced a new 68060 version of the A4000T. However, Escom in turn went bankrupt in 1997. The Amiga brand was then sold to another PC manufacturer, Gateway 2000, which had announced grand plans for it. However, in 2000, Gateway sold the Amiga brand without having released any products. The current owner of the trademark, Amiga, Inc, licensed the rights to sell hardware using the Amiga or AmigaOne brand to computer vendors Commodore USA, Eyetech Group, Ltd. and A-Eon Technology CVBA. Unofficial AmigaOne clones were developed by Italian hardware company, Acube.
Hardware.
At its core, the Amiga has a custom chipset consisting of several coprocessors, which handle audio, video and direct memory access independently of the Central Processing Unit (CPU). This architecture freed up the Amiga's processor for other tasks and gave the Amiga a performance edge over its competitors, particularly in terms of video-intensive applications and games.
The general Amiga architecture uses two distinct bus subsystems, namely, the chipset bus and the CPU bus. The chipset bus allows the custom coprocessors and CPU to address "Chip RAM". The CPU bus provides addressing to other subsystems, such as conventional RAM, ROM and the Zorro II or Zorro III expansion subsystems. This architecture enables independent operation of the subsystems; the CPU "Fast" bus can be much faster than the chipset bus. CPU expansion boards may provide additional custom buses. Additionally, "busboards" or "bridgeboards" may provide ISA or PCI buses.
Central processing unit.
The Motorola 68000 series of microprocessors was used in all Amiga models from Commodore. While the 68000 family has a 32-bit design, the 68000 used in several early models is generally referred to as 16-bit. The 68000 has a 16-bit external data bus so must transfer 32 bits of data in two consecutive steps, a technique called multiplexing: all this is transparent to the software, which was 32-bit from the beginning. The 68000 could address 16 MB of physical memory. Later Amiga models featured full 32-bit CPUs with a larger address space and instruction pipeline facilities. Commodore's design choice to remain with the 68000 architecture ensured that code was backward-compatible across the Amiga line.
CPU upgrades were offered by both Commodore and third-party manufacturers. Most Amiga models can be upgraded either by direct CPU replacement or through expansion boards. Such boards often featured faster and higher capacity memory interfaces and hard disk controllers.
Towards the end of Commodore's time in charge of Amiga development there were suggestions that Commodore intended to move away from the 68000 series to higher performance RISC processors, such as the PA-RISC. However, these ideas were never developed before Commodore filed for bankruptcy. Despite this, third-party manufacturers designed upgrades featuring a combination of 68000 series and PowerPC processors along with a PowerPC native microkernel and software. Later Amiga clones featured PowerPC processors only.
Custom chipset.
The custom chipset at the core of the Amiga design appeared in three distinct generations, with a large degree of backward-compatibility. The Original Chip Set (OCS) appeared with the launch of the A1000 in 1985. OCS was eventually followed by the modestly improved Enhanced Chip Set (ECS) in 1990 and finally by the partly 32-bit Advanced Graphics Architecture (AGA) in 1992. Each chipset consists of several coprocessors which handle graphics acceleration, digital audio, direct memory access and communication between various peripherals (e.g., CPU, memory and floppy disks). In addition, some models featured auxiliary custom chips which performed tasks such as SCSI control and display de-interlacing.
Graphics.
All Amiga systems can display full-screen animated graphics with 2, 4, 8, 16, 32, 64 (EHB Mode) or 4096 colors (HAM Mode). Models with the AGA chipset (A1200 and A4000) also have non-EHB 64, 128, 256 and (HAM Mode) color modes and a palette expanded from 4096 to 16.8 million colors.
The Amiga chipset can "genlock", which is the ability to adjust its own screen refresh timing to match an NTSC or PAL video signal. When combined with setting transparency, this allows an Amiga to overlay an external video source with graphics. This ability made the Amiga popular for many applications, and provides the ability to do character generation and CGI effects far more cheaply than earlier systems. This ability has been frequently utilized by wedding videographers, TV stations and their weather forecasting divisions (for weather graphics and radar), advertising channels, music video production, and desktop videographers. The NewTek Video Toaster was made possible by the genlock ability of the Amiga.
In 1988, the release of the Amiga A2024 fixed-frequency monochrome monitor with built-in framebuffer and flicker fixer hardware provided the Amiga with a choice of high-resolution graphic modes (1024×800 for NTSC and 1024×1024 for PAL).
ReTargetable Graphics.
ReTargetable Graphics is an API for device drivers mainly used by 3rd party graphics hardware to interface with AmigaOS via a set of libraries. The software libraries may include software tools to adjust resolution, screen colors, pointers and screenmodes. It uses available hardware and does not extend the capabilities in any way. Amiga intuition.library is limited to display depths of 8-bits but RTG libraries makes is possible to handle higher depths like 24-bits.
Sound.
The sound chip, named Paula, supports four PCM-sample-based sound channels (two for the left speaker and two for the right) with 8-bit resolution for each channel and a 6-bit volume control per channel. The analog output is connected to a low-pass filter, which filters out high-frequency aliases when the Amiga is using a lower sampling rate (see Nyquist limit). The brightness of the Amiga's power LED is used to indicate the status of the Amiga's low-pass filter. The filter is active when the LED is at normal brightness, and deactivated when dimmed (or off on older A500 Amigas). On Amiga 1000 (and first Amiga 500 and Amiga 2000 model), the power LED had no relation to the filter's status, and a wire needed to be manually soldered between pins on the sound chip to disable the filter. Paula can read directly from the system's RAM, using direct memory access (DMA), making sound playback without CPU intervention possible.
Although the hardware is limited to four separate sound channels, software such as "OctaMED" uses software mixing to allow eight or more virtual channels, and it was possible for software to mix two hardware channels to achieve a single 14-bit resolution channel by playing with the volumes of the channels in such a way that one of the source channels contributes the most significant bits and the other the least.
The quality of the Amiga's sound output, and the fact that the hardware is ubiquitous and easily addressed by software, were standout features of Amiga hardware unavailable on PC platforms for years. Third-party sound cards exist that provide DSP functions, multi-track direct-to-disk recording, multiple hardware sound channels and 16-bit and beyond resolutions. A retargetable sound API called AHI was developed allowing these cards to be used transparently by the OS and software.
Kickstart firmware.
Kickstart is the firmware upon which AmigaOS is bootstrapped. Its purpose is to initialize the Amiga hardware and core components of AmigaOS and then attempt to boot from a bootable volume, such as a floppy disk or hard disk drive. Most models (excluding the Amiga 1000) come equipped with Kickstart on an embedded ROM-chip.
Keyboard and mouse.
The keyboard on Amiga computers was similar to that found on a mid 80s IBM PC: 10 function keys, a numeric keypad, and 4 separate directional arrow keys. Caps Lock and Control shared space to the left of A. Missing were the Home, End, Page Up, and Page Down keys: these were accomplished on Amigas by pressing shift and the appropriate arrow key. The Amiga keyboard added a Help key, the lack of which made it necessary to use a function key for this purpose on PCs (usually F1). In addition to the Control and Alt modifier keys, the Amiga had 2 'Amiga' keys, rendered as 'Open Amiga' and 'Closed Amiga' similar to the Open/Closed Apple logo keys on Apple II keyboards. The left was used to manipulate the operating system (moving screens and the like) and the right delivered commands to the application. The absence of Num lock freed space for more math symbols around the number pad. Contemporary Macintosh computers, for comparison, lacked function keys completely.
The mouse had two buttons like Windows, but unlike Windows pressing and holding the right button replaced the system status line at the top of the screen with a Maclike menu bar. As with Apple's Mac OS prior to Mac OS 8, menu options were selected by releasing the button over that option, not by left clicking.
Other peripherals and expansions.
The Amiga was one of the first home computers for which inexpensive sound sampling and video digitization accessories were available. As a result of this and the Amiga's audio and video capabilities, the Amiga became a popular system for editing and producing both music and video.
Many expansion boards were produced for Amiga computers to improve the performance and capability of the hardware, such as memory expansions, SCSI controllers, CPU boards, and graphics boards. Other upgrades include genlocks, network cards for Ethernet, modems, sound cards and samplers, video digitizers, extra serial ports, and IDE controllers. Additions after the demise of Commodore company are USB cards. The most popular upgrades were memory, SCSI controllers and CPU accelerator cards. These were sometimes combined into the one device.
Early CPU accelerator cards feature full 32-bit CPUs of the 68000 family such as the Motorola 68020 and Motorola 68030, almost always with 32-bit memory and usually with FPUs and MMUs or the facility to add them. Later designs feature the Motorola 68040 or Motorola 68060. Both CPUs feature integrated FPUs and MMUs. Many CPU accelerator cards also had integrated SCSI controllers.
Phase5 designed the PowerUP boards (Blizzard PPC and CyberStorm PPC) featuring both a 68k (a 68040 or 68060) and a PowerPC (603 or 604) CPU, which are able to run the two CPUs at the same time and share the system memory. The PowerPC CPU on PowerUP boards is usually used as a coprocessor for heavy computations; a powerful CPU is needed to run MAME for example, but even decoding JPEG pictures and MP3 audio was considered heavy computation at the time. It is also possible to ignore the 68k CPU and run Linux on the PPC via project Linux APUS, but a PowerPC-native AmigaOS promised by Amiga Technologies GmbH was not available when the PowerUP boards first appeared.
24-bit graphics cards and video cards were also available. Graphics cards are designed primarily for 2D artwork production, workstation use, and later, gaming. Video cards are designed for inputting and outputting video signals, and processing and manipulating video.
Perhaps the most famous video card in the North American market was the "NewTek Video Toaster". This was a powerful video effects board which turned the Amiga into an affordable video processing computer which found its way into many professional video environments. One particularly well-known use was to create the special effects in early series of Babylon 5. Due to its NTSC-only design, it did not find a market in countries that used the PAL standard, such as in Europe. In PAL countries, the "OpalVision" card was popular, although less featured and supported than the Video Toaster. Low-cost timebase correctors (TBC) specifically designed to work with the Toaster quickly came to market, most of which were designed as standard Amiga bus cards.
Various manufacturers started producing PCI busboards for the A1200 and A4000, allowing standard Amiga computers to use PCI cards such as Voodoo graphic cards, Sound Blaster sound cards, 10/100 Ethernet cards, and TV tuner cards. Other manufacturers produced hybrid boards which contained an Intel x86 series chip, allowing the Amiga to emulate a PC.
PowerPC upgrades with Wide SCSI controllers, PCI busboards with Ethernet, sound and 3D graphics cards, and tower cases allowed the A1200 and A4000 to survive well into the late nineties.
Expansion boards were made by Richmond Sound Design that allow their show control and sound design software to communicate with their custom hardware frames either by ribbon cable or fiber optic cable for long distances, allowing the Amiga to control up to eight million digitally controlled external audio, lighting, automation, relay and voltage control channels spread around a large theme park, for example. See Amiga software for more information on these applications.
Other popular devices included the following:
Serial ports.
The Commodore A2232 provides serial ports. Each port can be driven independently at speeds of There is however a driver available on Aminet that allows two of the serial ports to be driven at The serial card made use of the 65CE02 CPU clocked at . This CPU were also part of the CSG 4510 CPU core that were used in the Commodore 65 computer.
Networking.
Amiga has three networking interface APIs:
Different network media were used:
Models and variants.
The original Amiga models were produced from 1985 to 1996. They are, in order of appearance: 1000, 2000, 500, 1500, 2500, 3000, 3000UX, 3000T, CDTV, 500+, 600, 4000, 1200, CD32, and 4000T. The PowerPC based AmigaOne was later produced from 2002 to 2005, and again in 2012. Several companies and private persons have also released Amiga clones and still do so today.
Commodore Amiga.
The first Amiga model, the Amiga 1000, was launched in 1985 as a high-end home computer and became popular for its impressive graphics, video and audio capabilities. In 2006, PC World rated the Amiga 1000 as the seventh greatest PC of all time, stating "Years ahead of its time, the Amiga was the world's first multimedia, multitasking personal computer".
Following the A1000, Commodore updated the desktop line of Amiga computers with the Amiga 2000 in 1987, the Amiga 3000 in 1990, and the Amiga 4000 in 1992, each offering improved capabilities and expansion options. However, the best selling models were the budget models, particularly the highly successful Amiga 500 (1987) and the Amiga 1200 (1992). The Amiga 500+ (1991) was the shortest lived model, replacing the Amiga 500 and lasting only six months until it was phased out and replaced with the Amiga 600 (1992), which in turn was also quickly replaced by the Amiga 1200.
The CDTV, launched in 1991, was a CD-ROM based all-in-one multimedia system. It was an early attempt at a multi-purpose multimedia appliance in an era before multimedia consoles and CD-ROM drives were common. Unfortunately for Commodore, the system never achieved any real commercial success. Like the Commodore 64GS that was a video game console based on a computer, the CDTV was designed as a video game console and multimedia platform. It had existed before the Sony Playstation and Sega Saturn, but had influenced them. It competed with the Turbo-Grafx-16 CD and Sega Mega-CD systems when it was being sold.
Commodore's last Amiga offering before filing for bankruptcy was an attempt to capture a portion of the highly competitive 1990s console market with the Amiga CD32 (1993), a 32-bit CD-ROM games console. Though discontinued after Commodore's demise it met with moderate commercial success in Europe. The CD32 was a next generation CDTV, and it was designed to save Commodore by entering the growing video game console market.
Following purchase of Commodore's assets by Escom in 1995, the A1200 and A4000T continued to be sold in small quantities until 1996, though the ground lost since the initial launch and the prohibitive expense of these units meant that the Amiga line never regained any real popularity.
Several Amiga models contained references to songs by the rock band The B-52s. Early A500 units, at least, had the words "B52/ROCK LOBSTER" silk-screen printed onto their printed circuit board, a reference to the popular song "Rock Lobster" The Amiga 600 referenced "JUNE BUG" (after the song "Junebug") and the Amiga 1200 had "CHANNEL Z" (after "Channel Z").
Most original casing was made from ABS plastics which may become brown with time. This can be reversed by using the public domain chemical mix "Retr0bright".
AmigaOS 4 systems.
AmigaOS 4 (OS4) is designed for PowerPC Amiga systems. It is mainly based on AmigaOS 3.1 source code, with some parts of version 3.9. Currently runs on both Amigas equipped with CyberstormPPC or BlizzardPPC accelerator boards, on the Teron series based AmigaOne computers built by Eyetech under license by Amiga Inc, on the Pegasos II from Genesi/bPlan GmbH, on the Acube Systems Sam440ep / Sam460ex / AmigaOne 500 systems and on the A-EON AmigaOne X1000.
AmigaOS 4.0 had been available only in developer pre-releases for numerous years until it was officially released in December 2006. Due to the nature of some provisions of the contract between Amiga Inc. and Hyperion Entertainment (the Belgian company which is developing the OS), the commercial AmigaOS 4 had been available only to licensed buyers of AmigaOne motherboards.
AmigaOS 4.0 for Amigas equipped with PowerUP accelerator boards was released in November 2007. Version 4.1 was released in August 2008 for AmigaOne systems, and in May 2011 for Amigas equipped with PowerUP accelerator boards. The most recent release of AmigaOS for all supported platforms is 4.1 update 5. Starting with release 4.1 update 4 there is an Emulation drawer containing official AmigaOS 3.x ROMs (all classic Amiga models including CD32) and relative Workbench files.
Acube Systems entered an agreement with Hyperion under which it has ported AmigaOS 4 to its Sam440ep and Sam460ex line of PowerPC-based motherboards. In 2009 a version for Pegasos II from Genesi/bPlan GmbH]was released in co-operation with Acube Systems. In 2012, A-EON Technology Ltd manufactured and released the AmigaOne X1000 to consumers through their distributor, AmigaKit.com.
Amiga hardware clones.
Long-time Amiga developer MacroSystem entered the Amiga-clone market with their DraCo non-linear video editing system. It appears in two versions, initially a tower model and later a cube. DraCo expanded upon and combined a number of earlier expansion cards developed for Amiga (VLabMotion, Toccata, WarpEngine, RetinaIII) into a true Amiga-clone powered by the Motorola 68060 processor. The DraCo can run AmigaOS 3.1 up through AmigaOS 3.9. It is the only Amiga-based system to support FireWire for video I/O. DraCo also offers an Amiga-compatible Zorro-II expansion bus and introduced a faster custom DraCoBus, capable of transfer rates (faster than Commodore's Zorro-III). The technology was later used in the Casablanca system, a set-top-box also designed for non-linear video editing.
In 1998, Index Information released the Access, an Amiga-clone similar to the Amiga 1200, but on a motherboard which could fit into a standard 5¼" drive bay. It features either a 68020 or 68030 CPU, with a redesigned AGA chipset, and runs AmigaOS 3.1.
In 1998, former Amiga employees (John Smith, Peter Kittel, Dave Haynie and Andy Finkel to mention few) formed a new company called PIOS. Their hardware platform, PIOS One, was aimed at Amiga, Atari and Macintosh users. The company was renamed to Met@box in 1999 until it folded.
The NatAmi (short for "Native Amiga") hardware project began in 2005 with the aim of designing and building an Amiga clone motherboard that is enhanced with modern features. The NatAmi motherboard is a standard Mini-ITX-compatible form factor computer motherboard, powered by a Motorola/Freescale 68060 and its chipset. It is compatible with the original Amiga chipset, which has been inscribed on a programmable FPGA Altera chip on the board. The NatAmi is the second Amiga clone project after the Minimig motherboard, and its history is very similar to that of the C-One mainboard developed by Jeri Ellsworth and Jens Schönfeld. From a commercial point of view, Natami's circuitry and design are currently closed source. One goal of the NatAmi project is to design an Amiga-compatible motherboard that includes up-to-date features but that does not rely on emulation (as in WinUAE), modern PC Intel components, or a modern PowerPC mainboard. As such, NatAmi is not intended to become another evolutionary heir to classic Amigas, such as with AmigaOne or Pegasos computers. This "purist" philosophy essentially limits the resulting processor speed but puts the focus on bandwidth and low latencies. The developers also recreated the entire Amiga chipset, freeing it from legacy Amiga limitations such as two megabytes of audio and video graphics RAM as in the AGA chipset, and rebuilt this new chipset by programming a modern FPGA Altera Cyclone IV chip. Later, the developers decided to create from scratch a new software-form processor chip, codenamed "N68050" that resides in the physical Altera FPGA programmable chip.
In 2006, two new Amiga clones were announced, both using FPGA based hardware synthesis to replace the Amiga OCS custom chipset. The first, the Minimig, is a personal project of Dutch engineer Dennis van Weeren. Referred to as "new Amiga hardware", the original model was built on a Xilinx Spartan-3 development board, but soon a dedicated board was developed. The minimig uses the FPGA to reproduce the custom Denise, Agnus, Paula and Gary chips as well as both 8520 CIAs and implements a simple version of Amber. The rest of the chips are an actual 68000 CPU, ram chips, and a PIC microcontroller for BIOS control. The design for Minimig was released as open source on July 25, 2007. In February 2008, an Italian company Acube Systems began selling Minimig boards. A third party upgrade replaces the PIC microcontroller with a more powerful ARM processor, providing more functionality such as write access and support for hard disk images. The Minimig core has been ported to the FPGArcade "Replay" board. The Replay uses an FPGA with about more capacity and which does support the AGA chipset and a 68020 soft core with 68030 capabilities. The Replay board is designed to implement many older computers and classic arcade machines.
The second is the Clone-A system announced by Individual Computers. As of mid 2007 it has been shown in its development form, with FPGA-based boards replacing the Amiga chipset and mounted on an Amiga 500 motherboard.
In 2011, by ArcadeRetroGaming, called the Multiple Classic Computer, which emulates the Commodore 64. Support for Amiga software is planned.
Emulation.
Like many popular but discontinued platforms, the Amiga has been the target of various emulation projects so that software developed for the Amiga can be run on other computer platforms without the original hardware. Such emulators attempt to replicate the functionality of the Amiga architecture in software. As mentioned above, attempts have also been made to replicate the Amiga chipset in FPGA chips.
One of the most challenging aspects of emulation is the design of the Amiga chipset, which relies on cycle-critical timings. As a result, early emulators did not always achieve the intended results though later emulator versions can now accurately reproduce the behavior of Amiga systems.
Operating systems.
AmigaOS.
AmigaOS is a single-user multitasking operating system. It was developed first by Commodore International, and initially introduced in 1985 with the Amiga 1000. Original versions run on the Motorola 68000 series of microprocessors, while AmigaOS 4 runs only on PowerPC microprocessors. At the time of release AmigaOS put an operating system that was well ahead of its time into the hands of the average consumer. It was one of the first commercially available consumer operating systems for personal computers to implement preemptive multitasking.
Another notable feature was the combined use of both a command-line interface and graphical user interface. AmigaDOS was the disk operating system and command line portion of the OS and Workbench the native graphical windowing, icons, menu and pointer environment for file management and launching applications. Notably, AmigaDOS allowed long filenames (up to 107 characters) with whitespace and did not require file extensions. The windowing system and user interface engine which handles all input events is called Intuition.
The multi-tasking kernel is called Exec. It acts as a scheduler for tasks running on the system, providing pre-emptive multitasking with prioritised round-robin scheduling. It enabled true pre-emptive multitasking in as little as 256 KB of free memory.
AmigaOS is one of the few microkernel-based operating systems not to implement memory protection, though this lack is common amongst many of its contemporary operating systems. The lack of memory protection is because the 68000 CPU does not include a memory management unit and therefore there is no way to enforce protection of memory. Although this speeds and eases inter-process communication because programs can communicate by simply passing a pointer back and forth, the lack of memory protection made the AmigaOS more vulnerable to crashes from badly behaving programs than other multitasking systems that did implement memory protection, and Amiga OS is fundamentally incapable of enforcing any form of security model since any program had full access to the system. A co-operational memory protection feature was implemented in AmigaOS 4 and could be retrofitted to old AmigaOS systems using Enforcer or CyberGuard tools.
The problem was somewhat exacerbated by Commodore's initial decision to release documentation relating not only to the OS's underlying software routines, but also to the hardware itself, enabling intrepid programmers who had developed their skills on the Commodore 64 to POKE the hardware directly, as was done on the older platform. While the decision to release the documentation was a popular one and allowed the creation of fast, sophisticated sound and graphics routines in games and demos, it also contributed to system instability as some programmers lacked the expertise to program at this level. For this reason, when the new AGA chipset was released, Commodore declined to release low-level documentation in an attempt to force developers into using the approved software routines.
Influence on other operating systems.
AmigaOS directly or indirectly inspired the development of various operating systems. MorphOS and AROS clearly inherit heavily from the structure of AmigaOS as explained directly in articles regarding these two operating systems. AmigaOS also influenced BeOS, which featured a centralized system of Datatypes, similar to that present in AmigaOS. Likewise, DragonFlyBSD was also inspired by AmigaOS as stated by Dragonfly developer Matthew Dillon who is a former Amiga developer. WindowLab and amiwm are among several window managers for the X Window System seek to mimic the Workbench interface. IBM licensed the Amiga GUI from Commodore in exchange for the REXX language license. This allowed OS/2 to have the WPS (Work Place Shell) GUI shell for OS/2 2.0 a 32-bit operating system.
Unix and Unix-like systems.
Commodore-Amiga produced Amiga Unix, informally known as Amix, based on AT&T SVR4. It supports the Amiga 2500 and Amiga 3000 and is included with the Amiga 3000UX. Among other unusual features of Amix is a hardware-accelerated windowing system which can scroll windows without copying data. Amix is not supported on the later Amiga systems based on 68040 or 68060 processors.
Other, still maintained, operating systems are available for the classic Amiga platform, including Linux and NetBSD. Both require a CPU with MMU such as the 68020 with 68851 or full versions of the 68030, 68040 or 68060. There is also a version of Linux for Amigas with PowerPC accelerator cards. Debian and Yellow Dog Linux can run on the AmigaOne.
There is an official, older version of OpenBSD. The last Amiga release is 3.2. Minix 1.5.10 also runs on Amiga.
Emulating other systems.
The Amiga is able to emulate other computer platforms ranging from many 8-bit systems such as the Sinclair ZX Spectrum, Commodore 64, Nintendo Game Boy, Nintendo Entertainment System, Apple II and the TRS-80. The Commodore PC-Transformer software emulated an IBM 5150 at 1 MHz in Monochrome mode. Later PC-Bridgecards were a full hardware PC on a card with 8086/80286/80386 Intel chips running MS-DOS and Windows in an Amiga window. A-Max emulated an Apple Macintosh using a serial port dongle that had a Macintosh ROM on it. The Amiga had the same 68000 CPU as the Macintosh and, using a Macintosh emulator, could run Mac 68K operating systems and programs. However, the Amiga could not directly read Macintosh 3.5" floppies due to their proprietary form. Further, it required a compatible Macintosh for a copy of its ROM. The Atari ST was also emulated. MAME (the arcade machine emulator) is also available for Amiga systems with PPC accelerator card upgrades.
Amiga software.
In the late 1980s and early 1990s the platform became particularly popular for gaming, demoscene activities and creative software uses. During this time commercial developers marketed a wide range of games and creative software, often developing titles simultaneously for the Atari ST due to the similar hardware architecture. Popular creative software included, 3D rendering (ray-tracing) packages, bitmap graphics editors, desktop video software, software development packages and "tracker" music editors.
Until the late 1990s the Amiga remained a popular platform for non-commercial software, often developed by enthusiasts, and much of which was freely redistributable. An on-line archive, Aminet, was created in 1992 and until around 1996 was the largest public archive of software, art and documents for any platform.
Marketing.
The name "Amiga" was chosen by the developers from the Spanish word for a female friend, because they knew Spanish, and because it occurred before Apple and Atari alphabetically. It also conveyed the message that the Amiga computer line was "user friendly" as a pun or play on words.
The first official Amiga logo was a rainbow-colored double checkmark. In later marketing material Commodore largely dropped the checkmark and used logos styled with various typefaces. Though it was never adopted as a trademark by Commodore, the "Boing Ball" has been synonymous with Amiga since its launch. It became an unofficial and enduring theme after a visually impressive animated demonstration at the 1984 Winter Consumer Electronics Show in January 1984 showing a checkered ball bouncing and rotating. Following Escom's purchase of Commodore in 1996, the Boing Ball theme was incorporated into a new logo.
Early Commodore advertisements attempted to cast the computer as an all-purpose business machine, though the Amiga was most commercially successful as a home computer. Throughout the 1980s and early 1990s Commodore primarily placed advertising in computer magazines and occasionally in national newspapers and on television.
Legacy.
Since the demise of Commodore, various groups have marketed successors to the original Amiga line:
AmigaOS and MorphOS are commercial proprietary operative systems. AmigaOS 4, based on AmigaOS 3.1 source code with some parts of version 3.9, is developed by Hyperion Entertainment and runs on PowerPC based hardware. MorphOS is developed by MorphOS Team and is continued on Apple PowerPC based hardware.
There is also AROS, a free and open source operative system (re-implementation of the AmigaOS 3.1 APIs), for Amiga 68k, x86 and ARM hardware (one version runs Linux-hosted on the Raspberry Pi). In particular, AROS for Amiga 68k hardware aims to create an open source Kickstart ROM replacement for emulation purpose and/or for use on real "classic" hardware.
Amiga community.
After Commodore went bankrupt in 1994, there remained a very active Amiga community, which continued to support the platform long after mainstream commercial vendors abandoned it. The most popular Amiga magazine, "Amiga Format", continued to publish editions until 2000, some six years after Commodore filed for bankruptcy. Another magazine, "Amiga Active", was launched in 1999 and was published until 2001. Several notable magazines are in publication today: "Amiga Future", which is available in both English and German; "Bitplane.it", a bi-monthly magazine in Italian; and "AmigaPower", a long-running French magazine.
In spite of declining interest in the platform there was a bi-weekly specialist column in the UK weekly magazine Micro Mart. There is also a fan website, that has served as a community discussion and support resource since the 1994 bankruptcy. Other popular English-language "forums" also exist, particularly amiga.org since 1994 and amigaworld.net and English Amiga Board.
Notable historic uses.
The Amiga series of computers found a place in early computer graphic design and television presentation. Below are some examples of notable uses and users:
In addition, many other celebrities and notable individuals have made use of the Amiga:
Other uses.
The Amiga was also used in a number of special purpose applications:

</doc>
<doc id="1985" url="http://en.wikipedia.org/wiki?curid=1985" title="Absorption">
Absorption

Absorption may refer to:

</doc>
<doc id="1986" url="http://en.wikipedia.org/wiki?curid=1986" title="Actinophryid">
Actinophryid

The actinophryids are small, familiar group of heliozoan protists. They are the most common heliozoa in fresh water, and are especially frequent in lakes and rivers, but a few are found in marine and soil habitats as well. Each actinophryid are unicellular and roughly spherical in shape, without any shell or test, and with many pseudopodia supported by axopods radiating outward from the cell body, which adhere to passing prey and allows it to roll or float about. The outer portion of the cell, or ectoplasm, is distinct and is filled with many tiny vacuoles, which assist in flotation. This is very similar to the process of osmosis. The movement of water from inside the cell to the outside is not because of water concentration in this case. It is the cell pushing the excess water out. A few contractile vacuoles around the periphery of the cell expel excess water, and are visible as clear bulges when full.
There are two genera included here. "Actinophrys" have a single, central nucleus. Most are around 40-50 μm in diameter, with axopods up to 100 μm in length, though this varies. "Actinosphaerium" are several times larger, from 200-1000 μm in diameter, with many nuclei, and are found exclusively in fresh water. Two other genera, "Echinosphaerium" and "Camptonema", have been described but appear to be synonyms.
Reproduction takes place by fission, with open mitosis. Under unfavourable conditions, the organism will form a cyst, which is multi-walled and covered in spikes. While encysted it may undergo a peculiar process of autogamy or self-fertilization, where it goes through meiosis and divides to form two gametes, which then fuse together again. This is the only form of sexual reproduction that occurs within the group, though it is really more genetic reorganization than reproduction.
The axopods are supported by microtubules arranged in a unique and characteristic double-coil pattern. In "Actinophrys", these arise from the nuclear membrane, while in "Actinosphaerium" some do and others don't. Other heliozoa where the microtubules arise from the nucleus have been considered possible relatives, and it now appears that the actinophryids developed from axodines such as "Pedinella". These are specialized heterokont algae, related to golden algae, diatoms, brown algae, and the like, which have microtubule-supported tentacles.
As far as the diet of the Actinophyrys goes, the protist feeds on small flagellates, diminutive cilates, microscopic algae, etc.

</doc>
<doc id="1988" url="http://en.wikipedia.org/wiki?curid=1988" title="Abel Tasman">
Abel Tasman

Abel Janszoon Tasman (; 1603 – 10 October 1659) was a Dutch seafarer, explorer, and merchant, best known for his voyages of 1642 and 1644 in the service of the Dutch East India Company (VOC). He was the first known European explorer to reach the islands of Van Diemen's Land (now Tasmania) and New Zealand, and to sight the Fiji islands. His navigator François Visscher and his merchant Isaack Gilsemans mapped substantial portions of Australia, New Zealand, and some Pacific Islands.
First Pacific voyage.
Abel Tasman was born in 1603 in Lutjegast in what is now the province of Groningen, the Netherlands. In 1633, Tasman went to Batavia in service of the VOC; four years later he was back in Amsterdam. Tasman signed on for another ten years and took his wife along to Batavia. In 1639 Tasman was sent as second in command of an exploring expedition in the north Pacific under Matthijs Quast. His fleet included the ships "Engel" and "Gracht" and reached Fort Zeelandia (Dutch Formosa) and Deshima.
In August 1642, the Council of the Indies, consisting of Antonie van Diemen, Cornelis van der Lijn, Joan Maetsuycker, Justus Schouten, Salomon Sweers, Cornelis Witsen, and Pieter Boreel in Batavia despatched Abel Tasman and Franchoijs Visscher on a voyage of which one of the objects was to obtain knowledge of "all the totally unknown provinces of Beach".
Beach and Terra Australis.
"Beach" appeared on maps of the time, notably that of Abraham Ortelius of 1570 and that of Jan Huygen van Linschoten of 1596, as the northernmost part of the southern continent, the "Terra Australis", along with "Locach". According to Marco Polo, "Locach" was a kingdom where gold was “so plentiful that no one who did not see it could believe it”. "Beach" was in fact a mistranscription of "Locach". Locach was Marco Polo’s name for the southern Thai kingdom of Lavo, or Lop Buri, the “city of Lavo”, (ลพบร, after Lavo, the son of Rama in Hindu mythology). In Chinese (Cantonese), Lavo was pronounced “Lo-huk” (羅斛), from which Marco Polo took his rendition of the name. In the German cursive script, “Locach” and “Boeach” look similar, and in the 1532 edition of Marco Polo’s "Travels" his Locach was changed to "Boëach", later shortened to "Beach". They seem to have drawn on the map of the world published in Florence in 1489 by Henricus Martellus, in which "provincia boëach" appears as the southern neighbour of "provincia ciamba". Book III of Marco Polo’s "Il Milione" described his journey by sea from China to India by way of Champa (= Southern Vietnam), Java (which he called "Java Major"), Locach and Sumatra (called "Java Minor"). After a chapter describing the kingdom of Champa there follows a chapter describing Java (which he did not visit himself). The narrative then resumes, describing the route southward from Champa toward Sumatra, but by a slip of the pen the name “Java” was substituted for “Champa” as the point of departure, locating Sumatra 1,300 miles to the south of Java instead of Champa. Locach, located between Champa and Sumatra, was likewise misplaced far to the south of Java, by some geographers on or near an extension of the "Terra Australis". As explained by Sir Henry Yule, the editor of an English edition of Marco Polo’s "Travels": “Some geographers of the 16th century, following the old editions which carried the travellers south-east of Java to the land of “Boeach” (or Locac), introduced in their maps a continent in that situation”. Gerard Mercator did just that on his 1541 globe, placing "Beach provincia aurifera" (“Beach the gold-bearing province”) in the northernmost part of the "Terra Australis" in accordance with the faulty text of Marco Polo’s "Travels". It remained in this location on his world map of 1569, with the amplified description, quoting Marco Polo, "Beach provincia aurifera quam pauci ex alienis regionibus adeunt propter gentis inhumanitatem" (“Beach the gold-bearing province, wither few go from other countries because of the inhumanity of its people”) with "Lucach regnum" shown somewhat to its south west. Following Mercator, Abraham Ortelius also showed "BEACH" and "LVCACH" in these locations on his world map of 1571. Likewise, Linschoten’s very popular 1596 map of the East Indies showed "BEACH" projecting from the map’s southern edge, leading (or misleading) Visscher and Tasman in their voyage of 1642 to seek Beach with its plentiful gold in a location to the south of the Solomon Islands somewhere between Staten Land near Cape Horn and the Cape of Good Hope. Confirmation that land existed where the maps showed "Beach" to be had come from Dirk Hartog’s landing in October 1616 on its west coast, which he called Eendrachtsland after the name of his ship. Abel Tasman endured a very rough journey from Tasmania to New Zealand. In one of his diary entries Tasman credits his compass, claiming it was the only thing that kept him alive.
Mauritius.
In accordance with Visscher's directions, Tasman sailed first to Mauritius and arrived on 5 September 1642. The reason for this was the crew could be fed well on the island; there was plenty of fresh water and timber to repair the ships. Tasman got the assistance of the governor Adriaan van der Stel. Because of the prevailing winds Mauritius was chosen as a turning point. After a four week stay on the island both ships left on 8 October. After a month's travel, snow and hail influenced Tasman to alter course to a more northern direction. Part of the western shore of the continent was already known to the Dutch, but no one had gone as far as Pieter Nuyts, who years earlier had mapped a huge stretch of the southern coast as far as what is today South Australia.
Tasmania.
On 24 November 1642 Abel Tasman sighted the west coast of Tasmania, north of Macquarie Harbour. He named his discovery Van Diemen's Land after Antonio van Diemen, Governor-General of the Dutch East Indies. Proceeding south he skirted the southern end of Tasmania and turned north-east, Tasman then tried to work his two ships into Adventure Bay on the east coast of South Bruny Island where he was blown out to sea by a storm, this area he named Storm Bay. Two days later Tasman anchored to the North of Cape Frederick Hendrick just North of the Forestier Peninsula. Tasman then landed in Blackman Bay – in the larger Marion Bay. The next day, an attempt was made to land in North Bay; however, because the sea was too rough the carpenter swam through the surf and planted the Dutch flag in North Bay. Tasman then claimed formal possession of the land on 3 December 1642.
New Zealand.
After some exploration, Tasman had intended to proceed in a northerly direction but as the wind was unfavourable he steered east. On 13 December they sighted land on the north-west coast of the South Island, New Zealand, becoming the first Europeans to do so. Tasman named it "Staten Landt" on the assumption that it was connected to an island (Staten Island, Argentina) at the south of the tip of South America. He sailed north, then east and 5 days later anchored about 7 km from the coast. He sent ship's boats to gather water, but one of his boats was attacked by Māori in a double hulled waka (canoes) and four of his men were attacked and killed by mere. As Tasman sailed out of the bay he was again attacked, this time by 11 waka . The waka approached the Zeehan which fired and hit one Maori who fell down. Canister shot hit the side of a waka. Archeological research has shown the Dutch had tried to land at a major agricultural area, which the Māori may have been trying to protect. Tasman named the bay "Murderers' Bay" (now known as Golden Bay) and sailed north, but mistook Cook Strait for a bight (naming it "Zeehaen's Bight"). Two names he gave to New Zealand landmarks still endure, Cape Maria van Diemen and Three Kings Islands, but "Kaap Pieter Boreels" was renamed by Cook 125 years later to Cape Egmont.
The return voyage.
On route back to Batavia, Tasman came across the Tongan archipelago on 20 January 1643. While passing the Fiji Islands Tasman's ships came close to being wrecked on the dangerous reefs of the north-eastern part of the Fiji group. He charted the eastern tip of Vanua Levu and Cikobia before making his way back into the open sea. He eventually turned north-west to New Guinea, and arrived at Batavia on 15 June 1643.
Second Pacific voyage.
With three ships on his second voyage ("Limmen", "Zeemeeuw" and the tender "Braek") in 1644, he followed the south coast of New Guinea eastwards. He missed the Torres Strait between New Guinea and Australia, and continued his voyage along the Australian coast. He mapped the north coast of Australia making observations on the land, called New Holland, and its people.
From the point of view of the Dutch East India Company Tasman's explorations were a disappointment: he had neither found a promising area for trade nor a useful new shipping route. Although received modestly, the company was upset to a degree that Tasman didn't fully explore the lands he found, and decided that a more "persistent explorer" should be chosen for any future expeditions. For over a century, until the era of James Cook, Tasmania and New Zealand were not visited by Europeans – mainland Australia was visited, but usually only by accident.
Later life.
On 2 November 1644 Abel Tasman was appointed a member of the Council of Justice at Batavia. He went to Sumatra in 1646, and in August 1647 to Siam (now Thailand) with letters from the company to the King. In May 1648 he was in charge of an expedition sent to Manila to try to intercept and loot the Spanish silver ships coming from America, but he had no success and returned to Batavia in January 1649. In November 1649 he was charged and found guilty of having in the previous year hanged one of his men without trial, was suspended from his office of commander, fined, and made to pay compensation to the relatives of the sailor. On 5 January 1651 he was formally reinstated in his rank and spent his remaining years at Batavia. He was in good circumstances, being one of the larger landowners in the town. He died at Batavia on 10 October 1659 and was survived by his second wife and a daughter by his first wife. The poor in Lutjegast received the small amount of only 25 guilders (about a month wage for one craftsman).
Legacy.
Multiple places have been named after Tasman, including:
Also named after Tasman are:
His portrait has been on 4 New Zealand postage stamp issues, on a 1992 5 NZD coin, and on one 1985 Australian postage stamp
Tasman Map.
The original Tasman Map is held in the collection of the State Library of New South Wales. The map shows a general outline of some parts of the coastline of Australia. The map is also reproduced in the marble floor of the Mitchell Library entry foyer.

</doc>
<doc id="1990" url="http://en.wikipedia.org/wiki?curid=1990" title="August 5">
August 5

References.
f

</doc>
<doc id="1991" url="http://en.wikipedia.org/wiki?curid=1991" title="Angula">
Angula

The word Angula may refer to one of the following:

</doc>
<doc id="1994" url="http://en.wikipedia.org/wiki?curid=1994" title="ASP">
ASP

ASP may refer to:

</doc>
<doc id="1997" url="http://en.wikipedia.org/wiki?curid=1997" title="Algebraic geometry">
Algebraic geometry

Algebraic geometry is a branch of mathematics, classically studying zeros of polynomial equations. Modern algebraic geometry is based on more abstract techniques of abstract algebra, especially commutative algebra, with the language and the problems of geometry.
The fundamental objects of study in algebraic geometry are algebraic varieties, which are geometric manifestations of solutions of systems of polynomial equations. Examples of the most studied classes of algebraic varieties are: plane algebraic curves, which include lines, circles, parabolas, ellipses, hyperbolas, cubic curves like elliptic curves and quartic curves like lemniscates, and Cassini ovals. A point of the plane belongs to an algebraic curve if its coordinates satisfy a given polynomial equation. Basic questions involve the study of the points of special interest like the singular points, the inflection points and the points at infinity. More advanced questions involve the topology of the curve and relations between the curves given by different equations.
Algebraic geometry occupies a central place in modern mathematics and has multiple conceptual connections with such diverse fields as complex analysis, topology and number theory. Initially a study of systems of polynomial equations in several variables, the subject of algebraic geometry starts where equation solving leaves off, and it becomes even more important to understand the intrinsic properties of the totality of solutions of a system of equations, than to find a specific solution; this leads into some of the deepest areas in all of mathematics, both conceptually and in terms of technique.
In the 20th century, algebraic geometry has split into several subareas.
Much of the development of the main stream of algebraic geometry in the 20th century occurred within an abstract algebraic framework, with increasing emphasis being placed on "intrinsic" properties of algebraic varieties not dependent on any particular way of embedding the variety in an ambient coordinate space; this parallels developments in topology, differential and complex geometry. One key achievement of this abstract algebraic geometry is Grothendieck's scheme theory which allows one to use sheaf theory to study algebraic varieties in a way which is very similar to its use in the study of differential and analytic manifolds. This is obtained by extending the notion of point: In classical algebraic geometry, a point of an affine variety may be identified, through Hilbert's Nullstellensatz, with a maximal ideal of the coordinate ring, while the points of the corresponding affine scheme are all prime ideals of this ring. This means that a point of such a scheme may be either a usual point or a subvariety. This approach also enables a unification of the language and the tools of classical algebraic geometry, mainly concerned with complex points, and of algebraic number theory. Wiles's proof of the longstanding conjecture called Fermat's last theorem is an example of the power of this approach.
Basic notions.
Zeros of simultaneous polynomials.
In classical algebraic geometry, the main objects of interest are the vanishing sets of collections of polynomials, meaning the set of all points that simultaneously satisfy one or more polynomial equations. For instance, the two-dimensional sphere in three-dimensional Euclidean space R3 could be defined as the set of all points ("x","y","z") with
A "slanted" circle in R3 can be defined as the set of all points ("x","y","z") which satisfy the two polynomial equations
Affine varieties.
First we start with a field "k". In classical algebraic geometry, this field was always the complex numbers C, but many of the same results are true if we assume only that "k" is algebraically closed. We consider the affine space of dimension "n" over "k", denoted An("k") (or more simply A"n", when "k" is clear from the context). When one fixes a coordinates system, one may identify An("k") with "k""n". The purpose of not working with "k""n" is to emphasize that one "forgets" the vector space structure that "k"n carries.
A function "f" : A"n" → A1 is said to be "polynomial" (or "regular") if it can be written as a polynomial, that is, if there is a polynomial "p" in "k"["x"1...,"x""n"] such that "f"("M") = "p"("t"1...,"t""n") for every point "M" with coordinates ("t"1...,"t""n") in A"n". The property of a function to be polynomial (or regular) does not depend on the choice of a coordinate system in A"n".
When a coordinate system is chosen, the regular functions on the affine "n"-space may be identified with the ring of polynomial functions in "n" variables over "k". Therefore the set of the regular functions on A"n" is a ring, which is denoted "k"[A"n"].
We say that a polynomial "vanishes" at a point if evaluating it at that point gives zero. Let "S" be a set of polynomials in "k"[An]. The "vanishing set of S" (or "vanishing locus" or "zero set") is the set "V"("S") of all points in A"n" where every polynomial in "S" vanishes. In other words,
A subset of A"n" which is "V"("S"), for some "S", is called an "algebraic set". The "V" stands for "variety" (a specific type of algebraic set to be defined below).
Given a subset "U" of A"n", can one recover the set of polynomials which generate it? If "U" is "any" subset of A"n", define "I"("U") to be the set of all polynomials whose vanishing set contains "U". The "I" stands for ideal: if two polynomials "f" and "g" both vanish on "U", then "f"+"g" vanishes on "U", and if "h" is any polynomial, then "hf" vanishes on "U", so "I"("U") is always an ideal of the polynomial ring "k"[A"n"].
Two natural questions to ask are:
The answer to the first question is provided by introducing the Zariski topology, a topology on A"n" whose closed sets are the algebraic sets, and which directly reflects the algebraic structure of "k"[A"n"]. Then "U" = "V"("I"("U")) if and only if "U" is an algebraic set or equivalently a Zariski-closed set. The answer to the second question is given by Hilbert's Nullstellensatz. In one of its forms, it says that "I"("V"("S")) is the radical of the ideal generated by "S". In more abstract language, there is a Galois connection, giving rise to two closure operators; they can be identified, and naturally play a basic role in the theory; the example is elaborated at Galois connection.
For various reasons we may not always want to work with the entire ideal corresponding to an algebraic set "U". Hilbert's basis theorem implies that ideals in "k"[A"n"] are always finitely generated.
An algebraic set is called "irreducible" if it cannot be written as the union of two smaller algebraic sets. Any algebraic set is a finite union of irreducible algebraic sets and this decomposition is unique. Thus its elements are called the "irreducible components" of the algebraic set. An irreducible algebraic set is also called a "variety". It turns out that an algebraic set is a variety if and only if it may be defined as the vanishing set of a prime ideal of the polynomial ring.
Some authors do not make a clear distinction between algebraic sets and varieties and use "irreducible variety" to make the distinction when needed.
Regular functions.
Just as continuous functions are the natural maps on topological spaces and smooth functions are the natural maps on differentiable manifolds, there is a natural class of functions on an algebraic set, called "regular functions" or "polynomial functions". A regular function on an algebraic set "V" contained in An is the restriction to "V" of a regular function on An. For an algebraic set defined on the field of the complex numbers, the regular functions are smooth and even analytic.
It may seem unnaturally restrictive to require that a regular function always extend to the ambient space, but it is very similar to the situation in a normal topological space, where the Tietze extension theorem guarantees that a continuous function on a closed subset always extends to the ambient topological space.
Just as with the regular functions on affine space, the regular functions on "V" form a ring, which we denote by "k"["V"]. This ring is called the "coordinate ring of V".
Since regular functions on V come from regular functions on An, there is a relationship between the coordinate rings. Specifically, if a regular function on "V" is the restriction of two functions "f" and "g" in "k"[An], then "f" − "g" is a polynomial function which is null on "V" and thus belongs to "I"("V"). Thus "k"["V"] may be identified with "k"[An]/"I"("V").
Morphism of affine varieties.
Using regular functions from an affine variety to A1, we can define regular maps from one affine variety to another. First we will define a regular map from a variety into affine space: Let "V" be a variety contained in An. Choose "m" regular functions on "V", and call them "f"1, ..., "f""m". We define a "regular map" "f" from "V" to Am by letting "f" = ("f"1, ..., "f""m"). In other words, each "f""i" determines one coordinate of the range of "f".
If "V"' is a variety contained in Am, we say that "f" is a "regular map" from "V" to "V"' if the range of "f" is contained in "V"'.
The definition of the regular maps apply also to algebraic sets.
The regular maps are also called "morphisms", as they make the collection of all affine algebraic sets into a category, where the objects are the affine algebraic sets and the morphisms are the regular maps. The affine varieties is a subcategory of the category of the algebraic sets.
Given a regular map "g " from "V" to "V"' and a regular function "f" of "k"["V"'], then "f"∘"g"∈"k"["V"]. The map "f"→"f"∘"g" is a ring homomorphism from "k"["V"'] to "k"["V"]. Conversely, every ring homomorphism from "k"["V"'] to "k"["V"] defines a regular map from "V" to "V"'. This defines an equivalence of categories between the category of algebraic sets and the opposite category of the finitely generated reduced "k"-algebras. This equivalence is one of the starting points of scheme theory.
Rational function and birational equivalence.
Contrarily to the preceding ones, this section concerns only varieties and not algebraic sets. On the other hand the definitions extend naturally to projective varieties (next section), as an affine variety and its projective completion have the same field of functions.
If "V" is an affine variety, its coordinate ring is an integral domain and has thus a field of fractions which is denoted "k"("V") and called the "field of the rational functions" on "V" or, shortly, the "function field" of "V". Its elements are the restrictions to "V" of the rational functions over the affine space containing "V". The domain of a rational function "f" is not "V" but the complement of the subvariety (a hypersurface) where the denominator of "f" vanishes.
Like for regular maps, one may define a "rational map" from a variety "V" to a variety "V"'. Like for the regular maps, the rational maps from "V" to "V"' may be identified to the field homomorphisms from "k"("V"') to "k"("V").
Two affine varieties are "birationally equivalent" if there two rational functions between them which are inverse one to the other in the regions where both are defined. Equivalently, they are birationally equivalent if their function fields are isomorphic.
An affine variety is a "rational variety" if it is birationally equivalent to an affine space. This means that the variety admits a rational parameterization. For example, the circle of equation "x"^2 + "y"^2 − 1 = 0 is a rational curve, as it has the parameterization
which may also be viewed as a rational map from the line to the circle.
The problem of resolution of singularities is to know if every algebraic variety is birationally equivalent to a variety whose projective completion is nonsingular (see also smooth completion). It has been positively solved in characteristic 0 by Heisuke Hironaka in 1964 and is yet unsolved in finite characteristic.
Projective variety.
Just as the formulas for the roots of 2nd, 3rd and 4th degree polynomials suggest extending real numbers to the more algebraically complete setting of the complex numbers, many properties of algebraic varieties suggest extending affine space to a more geometrically complete projective space. Whereas the complex numbers are obtained by adding the number i, a root of the polynomial x^2 + 1, projective space is obtained by adding in appropriate points "at infinity", points where parallel lines may meet.
To see how this might come about, consider the variety "V"("y" − "x"2). If we draw it, we get a parabola. As "x" goes to positive infinity, the slope of the line from the origin to the point ("x", "x"2) also goes to positive infinity. As "x" goes to negative infinity, the slope of the same line goes to negative infinity.
Compare this to the variety "V"("y" − "x"3). This is a cubic curve. As "x" goes to positive infinity, the slope of the line from the origin to the point ("x", "x"3) goes to positive infinity just as before. But unlike before, as "x" goes to negative infinity, the slope of the same line goes to positive infinity as well; the exact opposite of the parabola. So the behavior "at infinity" of "V"("y" − "x"3) is different from the behavior "at infinity" of "V"("y" − "x"2).
The consideration of the "projective completion" of the two curves, which is their prolongation "at infinity" in the projective plane, allows to quantify this difference: the point at infinity of the parabola is a regular point, whose tangent is the line at infinity, while the point at infinity of the cubic curve is a cusp. Also, both curves are rational, as they are parameterized by "x", and Riemann-Roch theorem implies that the cubic curve must have a singularity, which must be at infinity, as all its points in the affine space are regular.
Thus many of the properties of algebraic varieties, including birational equivalence and all the topological properties, depends on the behavior "at infinity" and so it is natural to study the varieties in projective space. Furthermore, the introduction of projective techniques made many theorems in algebraic geometry simpler and sharper: For example, Bézout's theorem on the number of intersection points between two varieties can be stated in its sharpest form only in projective space. For these reasons, projective space plays a fundamental role in algebraic geometry.
Nowadays, the "projective space" P"n" of dimension "n" is usually defined as the set of the lines passing through a point, considered as the origin, in the affine space of dimension "n"+1, or equivalently to the set of the vector lines in a vector space of dimension "n"+1. When a coordinate system has been chosen in the space of dimension "n"+1, all the points of a line have the same set of coordinates, up to the multiplication by an element of "k". This defines the homogeneous coordinates of a point of P"n" as a sequence of "n"+1 elements of the base field "k", defined up to the multiplication by a nonzero element of "k" (the same for the whole sequence).
Given a polynomial in "n"+1 variables, it vanishes at all the point of a line passing through the origin if and only if it is homogeneous. In this case, one says that the polynomial "vanishes" at the corresponding point of P"n". This allows to define a "projective algebraic set" in P"n" as the set "V"("f"1, ..., "f""k") where vanishes a finite set of homogeneous polynomials {"f"1, ..., "f""k"}. Like for affine algebraic sets, there is a bijection between the projective algebraic sets and the reduced homogeneous ideals which define them. The "projective varieties" are the projective algebraic sets whose defining ideal is prime. In other words, a projective variety is a projective algebraic set, whose homogeneous coordinate ring is an integral domain, the "projective coordinates ring" being defined as the quotient of the graded ring or the polynomials in "n"+1 variables by the homogeneous (reduced) ideal defining the variety. Every projective algebraic set may be uniquely decomposed into a finite union of projective varieties.
The only regular functions which may be defined properly on a projective variety are the constant functions. Thus this notion is not used in projective situations. On the other hand the "field of the rational functions" or "function field " is a useful notion, which, similarly as in the affine case, is defined as the set of the quotients of two homogeneous elements of the same degree in the homogeneous coordinate ring.
Real algebraic geometry.
The real algebraic geometry is the study of the real points of the algebraic geometry.
The fact that the field of the reals number is an ordered field may not be occulted in such a study. For example, the curve of equation formula_7 is a circle if formula_8, but does not have any real point if formula_9. It follows that real algebraic geometry is not only the study of the real algebraic varieties, but has been generalized to the study of the "semi-algebraic sets", which are the solutions of systems of polynomial equations and polynomial inequalities. For example, a branch of the hyperbola of equation formula_10 is not an algebraic variety, but is a semi-algebraic set defined by formula_11 and formula_12 or by formula_11 and formula_14.
One of the challenging problems of real algebraic geometry is the unsolved Hilbert's sixteenth problem: Decide which respective positions are possible for the ovals of a nonsingular plane curve of degree 8.
Computational algebraic geometry.
One may date the origin of computational algebraic geometry to meeting EUROSAM'79 (International Symposium on Symbolic and Algebraic Manipulation) held at Marseille, France in June 1979. At this meeting,
Since then, most results in this area are related to one or several of these items either by using or improving one of these algorithms, or by finding algorithms whose complexity is simply exponential in the number of the variables.
Gröbner basis.
A Gröbner basis is a system of generators of a polynomial ideal whose computation allows the deduction of many properties of the affine algebraic variety defined by the ideal.
Given an ideal "I" defining an algebraic set "V":
Gröbner basis computations do not allow to compute directly the primary decomposition of "I" nor the prime ideals defining the irreducible components of "V", but most algorithms for this involve Gröbner basis computation. The algorithms which are not based on Gröbner bases use regular chains but may need Gröbner bases in some exceptional situations.
Gröbner base are deemed to be difficult to compute. In fact they may contain, in the worst case, polynomials whose degree is doubly exponential in the number of variables and a number of polynomials which is also doubly exponential. However, this is only a worst case complexity, and the complexity bound of Lazard's algorithm of 1979 may frequently apply. Faugère's F4 and F5 algorithms realize this complexity, as F5 algorithm may be viewed as an improvement of Lazard's 1979 algorithm. It follows that the best implementations allow to compute almost routinely with algebraic sets of degree more than 100. This means that, presently, the difficulty of computing a Gröbner basis is strongly related to the intrinsic difficulty of the problem.
Cylindrical Algebraic Decomposition (CAD).
CAD is an algorithm which had been introduced in 1973 by G. Collins to implement with an acceptable complexity the Tarski–Seidenberg theorem on quantifier elimination over the real numbers.
This theorem concerns the formulas of the first-order logic whose atomic formulas are polynomial equalities or inequalities between polynomials with real coefficients. These formulas are thus the formulas which may be constructed from the atomic formulas by the logical operators "and" (∧), "or" (∨), "not" (¬), "for all" (∀) and "exists" (∃). Tarski's theorem asserts that, from such a formula, one may compute an equivalent formula without quantifier (∀, ∃).
The complexity of CAD is doubly exponential in the number of variables. This means that CAD allow, in theory, to solve every problem of real algebraic geometry which may be expressed by such a formula, that is almost every problem concerning explicitly given varieties and semi-algebraic sets.
While Gröbner basis computation has doubly exponential complexity only in rare cases, CAD has almost always this high complexity. This implies that, unless if most polynomials appearing in the input are linear, it may not solve problems with more than four variables.
Since 1973, most of the research on this subject is devoted either to improve CAD or to find alternate algorithms in special cases of general interest.
As an example of the state of art, there are efficient algorithms to find at least a point in every connected component of a semi-algebraic set, and thus to test if a semi-algebraic set is empty. On the other hand CAD is yet, in practice, the best algorithm to count the number of connected components.
Asymptotic complexity vs. practical efficiency.
The basic general algorithms of computational geometry have a double exponential worst case complexity. More precisely, if "d" is the maximal degree of the input polynomials and "n" the number of variables, their complexity is at most formula_15 for some constant "c", and, for some inputs, the complexity is at least formula_16 for another constant "c"′.
During the last 20 years of 20th century, various algorithms have been introduced to solve specific subproblems with a better complexity. Most of these algorithms have a complexity formula_17.
Among these algorithms which solve a sub problem of the problems solved by Gröbner bases, one may cite "testing if an affine variety is empty" and "solving nonhomogeneous polynomial systems which have a finite number of solutions." Such algorithms are rarely implemented because, on most entries Faugère's F4 and F5 algorithms have a better practical efficiency and probably a similar or better complexity ("probably" because the evaluation of the complexity of Gröbner basis algorithms on a particular class of entries is a difficult task which has be done only in few special cases).
The main algorithms of real algebraic geometry which solve a problem solved by CAD are related to the topology of semi-algebraic sets. One may cite "counting the number of connected components", "testing if two points are in the same components" or "computing a Whitney stratification of a real algebraic set". They have a complexity of
formula_17, but the constant involved by "O" notation is so high that using them to solve any nontrivial problem effectively solved by CAD, is impossible even if one could use all the existing computing power in the world. Therefore these algorithms have never been implemented and this is an active research area to search for algorithms with have together a good asymptotic complexity and a good practical efficiency.
Abstract modern viewpoint.
The modern approaches to algebraic geometry redefine and effectively extend the range of basic objects in various levels of generality to schemes, formal schemes, ind-schemes, algebraic spaces, algebraic stacks and so on. The need for this arises already from the useful ideas within theory of varieties, e.g. the formal functions of Zariski can be accommodated by introducing nilpotent elements in structure rings; considering spaces of loops and arcs, constructing quotients by group actions and developing formal grounds for natural intersection theory and deformation theory lead to some of the further extensions.
Most remarkably, in late 1950s, algebraic varieties were subsumed into Alexander Grothendieck's concept of a scheme. Their local objects are affine schemes or prime spectra which are locally ringed spaces which form a category which is antiequivalent to the category of commutative unital rings, extending the duality between the category of affine algebraic varieties over a field "k", and the category of finitely generated reduced "k"-algebras. The gluing is along Zariski topology; one can glue within the category of locally ringed spaces, but also, using the Yoneda embedding, within the more abstract category of presheaves of sets over the category of affine schemes. The Zariski topology in the set theoretic sense is then replaced by a Grothendieck topology. Grothendieck introduced Grothendieck topologies having in mind more exotic but geometrically finer and more sensitive examples than the crude Zariski topology, namely the étale topology, and the two flat Grothendieck topologies: fppf and fpqc; nowadays some other examples became prominent including Nisnevich topology. Sheaves can be furthermore generalized to stacks in the sense of Grothendieck, usually with some additional representability conditions leading to Artin stacks and, even finer, Deligne-Mumford stacks, both often called algebraic stacks.
Sometimes other algebraic sites replace the category of affine schemes. For example, Nikolai Durov has introduced commutative algebraic monads as a generalization of local objects in a generalized algebraic geometry. Versions of a tropical geometry, of an absolute geometry over a field of one element and an algebraic analogue of Arakelov's geometry were realized in this setup.
Another formal generalization is possible to Universal algebraic geometry in which every variety of algebras has its own algebraic geometry. The term "variety of algebras" should not be confused with "algebraic variety".
The language of schemes, stacks and generalizations has proved to be a valuable way of dealing with geometric concepts and became cornerstones of modern algebraic geometry.
Algebraic stacks can be further generalized and for many practical questions like deformation theory and intersection theory, this is often the most natural approach. One can extend the Grothendieck site of affine schemes to a higher categorical site of derived affine schemes, by replacing the commutative rings with an infinity category of differential graded commutative algebras, or of simplicial commutative rings or a similar category with an appropriate variant of a Grothendieck topology. One can also replace presheaves of sets by presheaves of simplicial sets (or of infinity groupoids). Then, in presence of an appropriate homotopic machinery one can develop a notion of derived stack as such a presheaf on the infinity category of derived affine schemes, which is satisfying certain infinite categorical version of a sheaf axiom (and to be algebraic, inductively a sequence of representability conditions). Quillen model categories, Segal categories and quasicategories are some of the most often used tools to formalize this yielding the "derived algebraic geometry", introduced by the school of Carlos Simpson, including Andre Hirschowitz, Bertrand Toën, Gabrielle Vezzosi, Michel Vaquié and others; and developed further by Jacob Lurie, Bertrand Toën, and Gabrielle Vezzosi. Another (noncommutative) version of derived algebraic geometry, using A-infinity categories has been developed from early 1990-s by Maxim Kontsevich and followers.
History.
Prehistory: before the 19th century.
Some of the roots of algebraic geometry date back to the work of the Hellenistic Greeks from the 5th century BC. The Delian problem, for instance, was to construct a length "x" so that the cube of side "x" contained the same volume as the rectangular box "a"2"b" for given sides "a" and "b". Menechmus (circa 350 BC) considered the problem geometrically by intersecting the pair of plane conics "ay" = "x"2 and "xy" = "ab". The later work, in the 3rd century BC, of Archimedes and Apollonius studied more systematically problems on conic sections, and also involved the use of coordinates. The Arab mathematicians were able to solve by purely algebraic means certain cubic equations, and then to interpret the results geometrically. This was done, for instance, by Ibn al-Haytham in the 10th century AD. Subsequently, Persian mathematician Omar Khayyám (born 1048 A.D.) discovered the general method of solving cubic equations by intersecting a parabola with a circle. Each of these early developments in algebraic geometry dealt with questions of finding and describing the intersections of algebraic curves.
Such techniques of applying geometrical constructions to algebraic problems were also adopted by a number of Renaissance mathematicians such as Gerolamo Cardano and Niccolò Fontana "Tartaglia" on their studies of the cubic equation. The geometrical approach to construction problems, rather than the algebraic one, was favored by most 16th and 17th century mathematicians, notably Blaise Pascal who argued against the use of algebraic and analytical methods in geometry. The French mathematicians Franciscus Vieta and later René Descartes and Pierre de Fermat revolutionized the conventional way of thinking about construction problems through the introduction of coordinate geometry. They were interested primarily in the properties of "algebraic curves", such as those defined by Diophantine equations (in the case of Fermat), and the algebraic reformulation of the classical Greek works on conics and cubics (in the case of Descartes).
During the same period, Blaise Pascal and Gérard Desargues approached geometry from a different perspective, developing the synthetic notions of projective geometry. Pascal and Desargues also studied curves, but from the purely geometrical point of view: the analog of the Greek "ruler and compass construction". Ultimately, the analytic geometry of Descartes and Fermat won out, for it supplied the 18th century mathematicians with concrete quantitative tools needed to study physical problems using the new calculus of Newton and Leibniz. However, by the end of the 18th century, most of the algebraic character of coordinate geometry was subsumed by the "calculus of infinitesimals" of Lagrange and Euler.
19th and early 20th century.
It took the simultaneous 19th century developments of non-Euclidean geometry and Abelian integrals in order to bring the old algebraic ideas back into the geometrical fold. The first of these new developments was seized up by Edmond Laguerre and Arthur Cayley, who attempted to ascertain the generalized metric properties of projective space. Cayley introduced the idea of "homogeneous polynomial forms", and more specifically quadratic forms, on projective space. Subsequently, Felix Klein studied projective geometry (along with other types of geometry) from the viewpoint that the geometry on a space is encoded in a certain class of transformations on the space. By the end of the 19th century, projective geometers were studying more general kinds of transformations on figures in projective space. Rather than the projective linear transformations which were normally regarded as giving the fundamental Kleinian geometry on projective space, they concerned themselves also with the higher degree birational transformations. This weaker notion of congruence would later lead members of the 20th century Italian school of algebraic geometry to classify algebraic surfaces up to birational isomorphism.
The second early 19th century development, that of Abelian integrals, would lead Bernhard Riemann to the development of Riemann surfaces.
In the same period began the algebraization of the algebraic geometry through commutative algebra. The prominent results in this direction are David Hilbert's basis theorem and Nullstellensatz, which are the basis of the connexion between algebraic geometry and commutative algebra, and Francis Sowerby Macaulay's multivariate resultant, which is the basis of elimination theory. Probably because of the size of the computation which is implied by multivariate resultants, elimination theory was forgotten during the middle of the 20th century until it was renewed by singularity theory and computational algebraic geometry.
20th century.
B. L. van der Waerden, Oscar Zariski and André Weil developed a foundation for algebraic geometry based on contemporary commutative algebra, including valuation theory and the theory of ideals. One of the goals was to give a rigorous framework for proving the results of Italian school of algebraic geometry. In particular, this school used systematically the notion of generic point without any precise definition, which was first given by these authors during the 1930s.
In the 1950s and 1960s Jean-Pierre Serre and Alexander Grothendieck recast the foundations making use of sheaf theory. Later, from about 1960, and largely lead by Grothendieck, the idea of schemes was worked out, in conjunction with a very refined apparatus of homological techniques. After a decade of rapid development the field stabilized in the 1970s, and new applications were made, both to number theory and to more classical geometric questions on algebraic varieties, singularities and moduli.
An important class of varieties, not easily understood directly from their defining equations, are the abelian varieties, which are the projective varieties whose points form an abelian group. The prototypical examples are the elliptic curves, which have a rich theory. They were instrumental in the proof of Fermat's last theorem and are also used in elliptic curve cryptography.
In parallel with the abstract trend of the algebraic geometry, which is concerned with general statements about varieties, methods for effective computation with concretely-given varieties have also been developed, which lead to the new area of computational algebraic geometry. One of the founding methods of this area is the theory of Gröbner bases, introduced by Bruno Buchberger in 1965. Another founding method, more specially devoted to real algebraic geometry, is the cylindrical algebraic decomposition, introduced by George E. Collins in 1973.
Applications.
Algebraic geometry now finds applications in statistics, control theory, robotics, error-correcting codes, phylogenetics and geometric modelling. There are also connections to string theory, game theory, graph matchings, solitons and integer programming.

</doc>
<doc id="1998" url="http://en.wikipedia.org/wiki?curid=1998" title="Austin, Texas">
Austin, Texas

Austin () ( or ) is the capital of Texas and the seat of Travis County. Located in and the , it is the city in the United States of America and the city in the state of Texas. It was the third-fastest-growing large city in the nation from 2000 to 2006. Austin is also the second largest state capital in the United States. Austin had a July 1, 2013 population of 885,400 (U.S. Census Bureau estimate). The city is the cultural and economic center of the metropolitan area, which had an estimated population of 1,883,051 as of July 1, 2013.
In the 1830s, pioneers began to settle the area in central Austin along the Colorado River. After Republic of Texas Vice President Mirabeau B. Lamar visited the area during a buffalo-hunting expedition between 1837 and 1838, he proposed that the republic's capital then located in Houston, be relocated to the area situated on the north bank of the Colorado River near the present-day Congress Avenue Bridge. In 1839, the site was officially chosen as the republic's new capital (the republic's seventh and final location) and was incorporated under the name Waterloo. Shortly thereafter, the name was changed to Austin in honor of Stephen F. Austin, the "Father of Texas" and the republic's first secretary of state.
The city grew throughout the 19th century and became a center for government and education with the construction of the Texas State Capitol and the University of Texas at Austin. After a lull in growth from the Great Depression, Austin resumed its development into a major city and, by the 1980s, it emerged as a center for technology and business. A number of Fortune 500 companies have headquarters or regional offices in Austin including Advanced Micro Devices, Apple Inc., eBay, Google, IBM, Intel, Texas Instruments, 3M, and Whole Foods Market. Dell's worldwide headquarters is located in nearby Round Rock, a suburb of Austin.
Residents of Austin are known as "Austinites". They include a diverse mix of government employees (e.g., university faculty and staff, law enforcement, political staffers); foreign and domestic college students; musicians; high-tech workers; blue-collar workers and businesspeople. The city is home to development centers for many technology corporations; it adopted the "Silicon Hills" nickname in the 1990s. However, the current official slogan promotes Austin as "The Live Music Capital of the World", a reference to the many musicians and live music venues within the area, and the long-running PBS TV concert series "Austin City Limits". In recent years, some Austinites have also adopted the unofficial slogan "Keep Austin Weird". This interpretation of the classic, "Texas-style" sense of independence refers to: a desire to protect small, unique, local businesses from being overrun by large corporations. In the late 1800s, Austin also became known as the City of the "Violet Crown" for the wintertime violet glow of color across the hills just after sunset. Even today, many Austin businesses use the term "violet crown" in their name. Austin is known as a "clean air city" for the city's stringent no-smoking ordinances that apply to all public places and buildings, including restaurants and bars.
The FBI ranked Austin as the second safest major city in the U.S. for the year 2012.
History.
Austin, Travis County, and Williamson County have been the site of human habitation since at least 9200 BC. The earliest known inhabitants of the area lived during the late Pleistocene (Ice Age) and are linked to the Clovis culture around 9200 BC (11,200 years ago), based on evidence found throughout the area and documented at the much-studied Gault Site, midway between Georgetown and Fort Hood.
When settlers first arrived from Europe, the area was inhabited by the Tonkawa tribe, and the Comanches and Lipan Apaches were known to travel through the area as well. Spanish colonists, including the Espinosa-Olivares-Aguirre expedition, traveled through the area for centuries, though few permanent settlements were created for some time. In 1730, three missions from East Texas were combined and reestablished as one mission on the south side of the Colorado River, in what is now Zilker Park, in Austin. The mission was in this area for only about seven months, and then was moved to San Antonio de Béxar and split into three missions. In the mid-18th century, the San Xavier missions were located along the Colorado River, in what is now western Milam County, to facilitate exploration.
Early in the 19th century, Spanish forts were established in what are now Bastrop and San Marcos. Following the independence of Mexico, new settlements were established in Central Texas, but growth in the region was stagnant because of conflicts with the regional Native Americans.
In 1835–1836, Texans fought and won independence from Mexico. Texas thus became its own independent country with its own president, congress, and monetary system. In 1839, the Texas Congress formed a commission to seek a site for a new capital to be named for Stephen F. Austin. Mirabeau B. Lamar, second president of the newly formed Republic of Texas, advised the commissioners to investigate the area named Waterloo, noting the area's hills, waterways, and pleasant surroundings. Waterloo was selected and the name "Austin" was chosen as the town's new name. The location was seen as a convenient crossroads for trade routes between Santa Fe and Galveston Bay, as well as routes between northern Mexico and the Red River. Austin is also the site where the southern leg of the Chisholm Trail leads to the Colorado River.
Edwin Waller was picked by Lamar to survey the village and draft a plan laying out the new capital. The original site was narrowed to that fronted the Colorado River between two creeks, Shoal Creek and Waller Creek, which was later named in his honor. The 14-block grid plan was bisected by a broad north-south thoroughfare, Congress Avenue, running up from the river to Capital Square, where the new Texas State Capitol was to be constructed. A temporary one-story capitol was erected on the corner of Colorado and 8th Streets. On August 1, 1839, the first auction of 217 out of 306 lots total was held. The grid plan Waller designed and surveyed now forms the basis of downtown Austin.
In 1840, a series of conflicts between the Texas Rangers and the Comanches, known as the Council House Fight and the Battle of Plum Creek, finally pushed the Comanches westward, mostly ending conflicts in Central Texas. Settlement in the area began to expand quickly. Travis County was established in 1840, and the surrounding counties were mostly established within the next two decades.
Initially, the new capital thrived. But Lamar's political enemy, Sam Houston, used two Mexican army incursions to San Antonio as an excuse to move the government. Sam Houston fought bitterly against Lamar's decision to establish the capital in such a remote wilderness. The men and women who traveled mainly from Houston to conduct government business were intensely disappointed as well. By 1840, the population had risen to 856, of whom nearly half fled from Austin when Congress recessed. The resident Black population listed in January of this same year was 176. The fear of Austin's proximity to the Indians and Mexico, which still considered Texas a part of their land, created an immense motive for Sam Houston, the first and third President of the Republic of Texas, to relocate the capital once again in 1841. Upon threats of Mexican troops in Texas, Houston raided the Land Office to transfer all official documents to Houston for safe keeping in what was later known as the Archive War, but the people of Austin would not allow this unaccompanied decision to be executed. The documents stayed, but the capital would temporarily move from Austin to Houston to Washington-on-the-Brazos. Without the governmental body, Austin's population declined to a low of only a few hundred people throughout the early 1840s. The voting by the fourth President of the Republic, Anson Jones, and Congress, who reconvened in Austin in 1845, settled the issue to keep Austin the seat of government as well as annex the Republic of Texas into the United States.
In 1860, 38% of Travis County residents were slaves. In 1861, with the outbreak of the American Civil War, voters in Austin and other Central Texas communities voted against secession. However, as the war progressed and fears of attack by Union forces increased, Austin contributed hundreds of men to the Confederate forces. The African American population of Austin swelled dramatically after the enforcement of the Emancipation Proclamation in Texas by Union General Gordon Granger at Galveston in an event commemorated as Juneteenth. Black communities such as Wheatville, Pleasant Hill, and Clarksville were established with Clarksville being the oldest surviving freedomtown ‒ the original post-Civil War settlements founded by former African-American slaves ‒ west of the Mississippi River. In 1870, blacks made up 36.5% of Austin's population. The postwar period saw dramatic population and economic growth. The opening of the Houston and Texas Central Railway (H&TC) in 1871 turned Austin into the major trading center for the region with the ability to transport both cotton and cattle. The Missouri, Kansas, and Texas (MKT) line followed close behind. Austin was also the terminus of the southernmost leg of the Chisholm Trail and "drovers" pushed cattle north to the railroad. Cotton was one of the few crops produced locally for export and a cotton gin engine was located downtown near the trains for "ginning" cotton of its seeds and turning the product into bales for shipment. However, as other new railroads were built through the region in the 1870s, Austin began to lose its primacy in trade to the surrounding communities. In addition, the areas east of Austin took over cattle and cotton production from Austin, especially in towns like Hutto and Taylor that sit over the blackland prairie, with its deep, rich soils for producing cotton and hay.
In September 1881, Austin public schools held their first classes. The same year, Tillotson Collegiate and Normal Institute (now part of Huston-Tillotson University) opened its doors. The University of Texas at Austin held its first classes in 1883, although classes had been held in the original wooden state Capitol for four years before.
During the 1880s, Austin gained new prominence as the state capitol building was completed in 1888 and claimed as the seventh largest building in the world. In the late 19th century, Austin expanded its city limits to more than three times its former area, and the first granite dam was built on the Colorado River to power a new street car line and the new "moon towers". Unfortunately, the first dam washed away in a flood on April 7, 1900.
In the 1920s and 1930s, Austin launched a series of civic development and beautification projects that created much of the city's infrastructure and many of its parks. In addition, the state legislature established the Lower Colorado River Authority (LCRA) that, along with the city of Austin, created the system of dams along the Colorado River to form the Highland Lakes. These projects were enabled in large part because the Public Works Administration provided Austin with greater funding for municipal construction projects than other Texas cities.
During the early twentieth century, a three-way system of social segregation emerged in Austin, with Anglos, African Americans, and Mexicans being separated by custom or law in most aspects of life, including housing, health care, and education. Many of the municipal improvement programs initiated during this period—such as the construction of new roads, schools, and hospitals—were deliberately designed to institutionalize this system of segregation. Racial segregation actually increased in Austin during the first half of the twentieth century, with African Americans and Mexicans experiencing high levels of discrimination and social marginalization.
In 1940, the destroyed granite dam on the Colorado River was finally replaced by a hollow concrete dam that formed Lake McDonald (now called Lake Austin) and which has withstood all floods since. In addition, the much larger Mansfield Dam was built by the LCRA upstream of Austin to form the flood-control lake, Lake Travis. In the early 20th century, the Texas Oil Boom took hold, creating tremendous economic opportunities in Southeast Texas and North Texas. The growth generated by this boom largely passed by Austin at first, with the city slipping from fourth largest to 10th largest in Texas between 1880 and 1920.
After the mid-20th century, Austin became established as one of Texas' major metropolitan centers. In 1970, the Census Bureau reported Austin's population as 14.5% Hispanic, 11.9% black, and 73.4% non-Hispanic white. In the late 20th century, Austin emerged as an important high tech center for semiconductors and software. The University of Texas at Austin emerged as a major university.
The 1970s saw Austin's emergence in the national music scene, with local artists such as Willie Nelson, Asleep at the Wheel, and Stevie Ray Vaughan and iconic music venues such as the Armadillo World Headquarters. Over time, the long-running television program "Austin City Limits", its namesake Austin City Limits Festival, and the South by Southwest music festival solidified the city's place in the music industry.
Geography.
The most southerly of the capitals of the contiguous forty-eight states, Austin is located in Central Texas, along the Balcones Escarpment and Interstate 35, 150 miles northwest of Houston. It is also 160 miles south of Dallas and 75 miles north of San Antonio. Its elevation varies from to approximately above sea level. In 2010, the city occupied a total area of . Approximately of this area is water.
Austin is situated on the Colorado River, with three man-made (artificial) lakes within the city limits: Lady Bird Lake (formerly known as Town Lake), Lake Austin (both created by dams along the Colorado River), and Lake Walter E. Long that is partly used for cooling water for the Decker Power Plant. Mansfield Dam and the foot of Lake Travis are located within the city's limits. Lady Bird Lake, Lake Austin, and Lake Travis are each on the Colorado River. As a result of its straddling the Balcones Fault, much of the eastern part of the city is flat, with heavy clay and loam soils, whereas, the western part and western suburbs consist of rolling hills on the edge of the Texas Hill Country. Because the hills to the west are primarily limestone rock with a thin covering of topsoil, portions of the city are frequently subjected to flash floods from the runoff caused by thunderstorms. To help control this runoff and to generate hydroelectric power, the Lower Colorado River Authority operates a series of dams that form the Texas Highland Lakes. The lakes also provide venues for boating, swimming, and other forms of recreation within several parks on the lake shores.
Austin is located at the intersection of four major ecological regions, and is consequently a temperate-to-hot green oasis with a highly variable climate having some characteristics of the desert, the tropics, and a wetter climate. The area is very diverse ecologically and biologically, and is home to a variety of animals and plants. Notably, the area is home to many types of wildflowers that blossom throughout the year but especially in the spring, including the popular bluebonnets, some planted in an effort by "Lady Bird" Johnson, wife of former President Lyndon Johnson.
A popular point of prominence in Austin is Mount Bonnell. At about above sea level, it is a natural limestone formation overlooking Lake Austin on the Colorado River, with an observation deck about below its summit.
The soils of Austin range from shallow, gravelly clay loams over limestone in the western outskirts to deep, fine sandy loams, silty clay loams, silty clays or clays in the city's eastern part. Some of the clays have pronounced shrink-swell properties and are difficult to work under most moisture conditions. Many of Austin's soils, especially the clay-rich types, are slightly to moderately alkaline and have free calcium carbonate.
Cityscape.
Buildings that make up most of Austin's skyline are modest in height and somewhat spread out. The latter characteristic is partly due to a restriction that preserves the view of the Texas State Capitol building from various locations around Austin (known as the Capitol View Corridor). However, many new highrise towers have been constructed and the downtown area is looking more modern and dense. The city's tallest building, The Austonian, was topped out on September 17, 2009. Austin is currently undergoing a skyscraper boom, which includes recent construction on the now complete 360 Condominiums at , Spring (condominiums), the Austonian at , and several others that are mainly for residential use.
At night, parts of Austin are lit by "artificial moonlight" from Moonlight Towers built to illuminate the central part of the city. The moonlight towers were built in the late 19th century and are now recognized as historic landmarks. Only 15 of the 31 original innovative towers remain standing in Austin, and none remain in any of the other cities where they were installed. The towers are featured in the 1993 film "Dazed and Confused".
Downtown.
The central business district of Austin is home to some of the tallest condo towers in the state, with The Austonian topping out at 56 floors (the tallest residential building in the U.S. west of the Mississippi River) and 360 at 44 floors. Former Mayor Will Wynn set out a goal for having up to 25,000 people living Downtown by 2015, and the city provided incentives for building residential units in the urban core. Because of this, the city has been driven to increase density in Austin's urban core. The skyline has drastically changed in recent years, and the residential real estate market has remained relatively strong.
Downtown growth has been aided by the presence of a popular live music and nightlife scene, museums, restaurants, and Lady Bird Lake, considered one of the city's best recreational spots. The 2nd Street District consists of several new residential projects, restaurants, upscale boutiques and other entertainment venues, as well as Austin's City Hall. Across 2nd Street from Austin's City Hall is the new ACL Live @ the Moody Theatre where the long-running PBS program Austin City Limits, is filmed. It is located at the base of the new W Hotel. The annual South by Southwest (SXSW) Music, Film and Interactive Festival is located in downtown Austin and includes one of the world's largest music festivals; with more than 3,000 acts from every continent except Antarctica, playing in more than 100 venues, over five days, in March.
Climate.
Austin has a humid subtropical climate (Köppen: Cfa), characterized by hot summers and mild winters. Austin is usually at least partially sunny, receiving nearly 2650 hours, or 60.3% of the possible total, of bright sunshine per year.
Austin summers are usually hot, with average July and August highs in the high-90s °F (34–36 °C). Highs reach on 116 days per year, and on 18. The highest recorded temperature was occurring on September 5, 2000 and August 28, 2011.
Winters in Austin are mild and relatively dry. For the entire year, Austin averages 88 days below and 13 days when the minimum temperature falls below freezing. The lowest recorded temperature was on January 31, 1949. About every two years or so, Austin experiences an ice storm that freezes roads over and affects much of the city for 24 to 48 hours. Snowfall is rare in Austin; a snowstorm brought the city to a near standstill in 1985.
Monthly averages for Austin's weather data are shown in a graphical format to the right, and in a more detailed tabular format below.
2011 drought.
From October 2010 through September 2011, both major reporting stations in Austin, Camp Mabry and Bergstrom Int'l, had the least rainfall of a water year on record, receiving less than a third of normal precipitation. This was a result of La Niña conditions in the eastern Pacific Ocean where water was significantly cooler than normal. David Brown, a regional official with the National Oceanic and Atmospheric Administration, has explained that "these kinds of droughts will have effects that are even more extreme in the future, given a warming and drying regional climate."
Demographics.
According to the 2010 Census, the racial composition of Austin is:
At the census of 2000, there were 656,562 people, 265,649 households, and 141,590 families residing in the city (roughly comparable in size to San Francisco, Leeds, UK; and Ottawa). The population density was 2,610.4 people per square mile (1,007.9/km²). There were 276,842 housing units at an average density of 1,100.7 per square mile (425.0/km²). There were 265,648 households out of which 26.8% had children under the age of 18 living with them, 38.1% were married couples living together, 10.8% had a female householder with no husband present, and 46.7% were non-families. 32.8% of all households were made up of individuals and 4.6% had someone living alone who was 65 years of age or older. The average household size was 2.40 and the average family size was 3.14.
In the city the population was spread out with 22.5% under the age of 18, 16.6% from 18 to 24, 37.1% from 25 to 44, 17.1% from 45 to 64, and 6.7% who were 65 years of age or older. The median age was 30 years. For every 100 females there were 105.8 males.
The median income for a household in the city was $42,689, and the median income for a family was $54,091. Males had a median income of $35,545 vs. $30,046 for females. The per capita income for the city was $24,163. About 9.1% of families and 14.4% of the population were below the poverty line, including 16.5% of those under age 18 and 8.7% of those age 65 or over. The median house price was $185,906 in 2009, and it has increased every year since 2004.
A 2014 University of Texas at Austin study stated that Austin was the only U.S. city with a fast growth rate that was losing African-Americans.
Economy.
Austin is the anchor city of the Austin-Round Rock-San Marcos MSA, which had a Gross Domestic Product of $86 billion in 2010. Austin is considered to be a major center for high tech. Thousands of graduates each year from the engineering and computer science programs at the University of Texas at Austin provide a steady source of employees that help to fuel Austin's technology and defense industry sectors. The region's rapid growth has led "Forbes" to rank the Austin metropolitan area number one among all big cities for jobs for 2012 in their annual survey and WSJ Marketwatch to rank the area number one for growing businesses. By 2013, Austin ranked No. 14 on "Forbes"' list of the Best Places for Business and Careers (directly below Dallas, No. 13 on the list). As a result of the high concentration of high-tech companies in the region, Austin was strongly affected by the dot-com boom in the late 1990s and subsequent bust. Austin's largest employers include the Austin Independent School District, the City of Austin, Dell, the U.S. Federal Government, Freescale Semiconductor (spun off from Motorola in 2004), IBM, St. David's Healthcare Partnership, Seton Family of Hospitals, the State of Texas, the Texas State University, and the University of Texas at Austin.
Other high-tech companies with operations in Austin include 3M, Apple, Hewlett-Packard, Google, Qualcomm, Inc., AMD, Applied Materials, Cirrus Logic, ARM Holdings, Cisco Systems, Electronic Arts, Flextronics, Facebook, eBay/PayPal, Bioware, Blizzard Entertainment, Hoover's, Intel Corporation, National Instruments, Rackspace, RetailMeNot, Rooster Teeth, Spansion, Buffalo Technology, Silicon Laboratories, Xerox, Oracle, Hostgator, Samsung Group, HomeAway, and United Devices. In 2010, Facebook accepted a grant to build a downtown office that could bring as many as 200 jobs to the city. The proliferation of technology companies has led to the region's nickname, "the Silicon Hills", and spurred development that greatly expanded the city.
Austin is also emerging as a hub for pharmaceutical and biotechnology companies; the city is home to about 85 of them. The city was ranked by the Milken Institute as the No.12 biotech and life science center in the United States. Companies such as Hospira, Pharmaceutical Product Development, and ArthroCare Corporation are located there.
Whole Foods Market (often called just "Whole Foods") is an upscale, international grocery store chain specializing in fresh and packaged food products—many having an organic-/local-/"natural"-theme. It was founded and is headquartered in Austin.
Other companies based in Austin include Freescale Semiconductor, Temple-Inland, Sweet Leaf Tea Company, Keller Williams Realty, GSD&M, Dimensional Fund Advisors, Golfsmith, Forestar Group, and EZCorp.
In addition to national and global corporations, Austin features a strong network of independent, unique, locally owned firms and organizations.
Arts and culture.
"Keep Austin Weird" has been a local motto for years, featured on bumper stickers and T-shirts. This motto has not only been used in promoting Austin's eccentricity and diversity, but is also meant to bolster support of local independent businesses. According to the 2010 book, "Weird City", the phrase was begun by a local Austin Community College librarian, Red Wassenich, and his wife, Karen Pavelka, who were concerned about Austin's "rapid descent into commercialism and over-development." The slogan has been interpreted many ways since its inception, but remains an important symbol for many Austinites who wish to voice concerns over rapid growth and irresponsible development. Austin has a long history of vocal citizen resistance to development projects perceived to degrade the environment, or to threaten the natural and cultural landscapes.
According to the Nielsen Company, adults in Austin read and contribute to blogs more than those in any other U.S. metropolitan area. Austin residents have the highest internet usage in all of Texas. Austin was selected as the No. 2 Best Big City in "Best Places to Live" by "Money" magazine in 2006, and No. 3 in 2009, and also the "Greenest City in America" by MSN. According to "Travel & Leisure" magazine, Austin ranks No. 1 on the list of cities with the best people, referring to the personalities and attributes of the citizens. In 2012, the city was listed among the 10 best places to retire in the U.S. by CBS Money Watch.
SoCo is a shopping district stretching down South Congress Avenue from Downtown. This area is home to coffee shops, eccentric stores, restaurants, food trucks, trailers and festivals. It prides itself on "Keeping Austin Weird", especially with development in the surrounding area(s).
Annual cultural events.
The O. Henry House Museum hosts the annual O. Henry Pun-Off, a pun contest where the successful contestants exhibit wit akin to that of the author William Sydney Porter.
Other annual events include Eeyore's Birthday Party, Spamarama, the Austin Reggae Festival, Art City Austin in April, East Austin Studio Tour in November, and Carnaval Brasileiro in February. Sixth Street features annual festivals such as the Pecan Street Festival and Halloween night. The three-day Austin City Limits Music Festival has been held in Zilker Park every year since 2002. Every year around the end of March and the beginning of April, Austin is home to "Texas Relay Weekend."
Austin's Zilker Park Tree is a Christmas display made of lights strung from the top of a Moonlight tower in Zilker Park. The Zilker Tree is lit in December along with the "Trail of Lights," an Austin Christmas tradition. In 2010 and 2011, the Trail of Lights was canceled due to budget shortfalls, but the trail was turned back on for the 2012 holiday season.
Music.
As Austin's official slogan is "The Live Music Capital of the World", the city has a vibrant live music scene with more music venues per capita than any other U.S. city. Austin's music revolves around the many nightclubs on 6th Street and an annual film/music/interactive festival known as South by Southwest (SXSW). The concentration of restaurants, bars, and music venues in the city's downtown core is a major contributor to Austin's live music scene, as the zip code encompassing the downtown entertainment district hosts the most bar or alcohol-serving establishments in the U.S.
The longest-running concert music program on American television, "Austin City Limits", is recorded at ACL Live at The Moody Theater. "Austin City Limits" and C3 Presents produce the Austin City Limits Music Festival, an annual music and art festival held at Zilker Park in Austin. Other music events include the Urban Music Festival, Fun Fun Fun Fest, Chaos In Tejas and Old Settler's Music Festival. Austin Lyric Opera performs multiple operas each year (including the 2007 opening of Philip Glass's "Waiting for the Barbarians", written by University of Texas at Austin alumnus J. M. Coetzee). The Austin Symphony Orchestra performs a range of classical, pop and family performances and is led by Music Director and Conductor Peter Bay.
Film.
Austin hosts the annual Austin Film Festival, which draws films of many different types from all over the world. In 2004 the city was first in "MovieMaker Magazine's" annual top ten cities to live and make movies.
Austin has been the location for a number of motion pictures, partly due to the influence of The University of Texas at Austin Department of Radio-Television-Film. Films produced in Austin include "The Texas Chain Saw Massacre" (1974), "Songwriter" (1984), "Man of the House", "Secondhand Lions", "Waking Life", "Spy Kids", "Dazed and Confused", "Wild Texas Wind", "Office Space", "The Life of David Gale", "Miss Congeniality", "Doubting Thomas", "Slacker", "Idiocracy", "The New Guy", "Hope Floats", "The Alamo", "Blank Check", "The Wendall Baker Story", "School of Rock", "A Slipping-Down Life", "A Scanner Darkly", "Saturday Morning Massacre", and most recently, the Coen brothers' "True Grit", "Grindhouse", "Machete", "How to Eat Fried Worms" and "Bandslam". In order to draw future film projects to the area, the Austin Film Society has converted several airplane hangars from the former Mueller Airport into filmmaking center Austin Studios. Projects that have used facilities at Austin Studios include music videos by The Flaming Lips and feature films such as "25th Hour" and "Sin City". Austin also hosted the MTV series, "" in 2005. The film review websites Spill.com and Ain't It Cool News are based in Austin. Rooster Teeth Productions, creator of popular web series such as "Red vs. Blue", and "RWBY" is also located in Austin.
Theater.
Austin has a strong theater culture, with dozens of itinerant and resident companies producing a variety of work. The city also has live performance theater venues such as the Zachary Scott Theatre Center, Vortex Repertory Company, Salvage Vanguard Theater, Rude Mechanicals' the Off Center, Austin Playhouse, Scottish Rite Children's Theater, Hyde Park Theatre, the Blue Theater, The Hideout Theatre, and Esther's Follies. The Victory Grill was a renowned venue on the Chitlin' circuit. Public art and performances in the parks and on bridges are popular. Austin hosts the Fuse Box Festival each April featuring international, leading-edge theater artists.
The Paramount Theatre, opened in downtown Austin in 1915, contributes to Austin's theater and film culture, showing classic films throughout the summer and hosting regional premieres for films such as "Miss Congeniality". The Zilker Park Summer Musical is a long-running outdoor musical.
The Long Center for the Performing Arts is a 2,300-seat theater built partly with materials reused from the old Lester E. Palmer Auditorium.
Ballet Austin is the fourth largest ballet academy in the country. Each year Ballet Austin's 20-member professional company performs ballets from a wide variety of choreographers, including their international award winning artistic director, Stephen Mills. The city is also home to the Ballet East Dance Company, a modern dance ensemble, and the Tapestry Dance Company which performs a variety of dance genres.
The Austin improvisational theatre scene has several theaters: ColdTowne Theater, The Hideout Theater, The New Movement Theater, and The Institution Theater. Austin also hosts the Out of Bounds Improv Festival, which draws comedic artists in all disciplines to Austin.
Museums and other points of interest.
Museums in Austin include the Texas Memorial Museum, the Blanton Museum of Art (reopened in 2006), the Bob Bullock Texas State History Museum across the street (which opened in 2000), the Austin Museum of Art (AMOA), the Elisabet Ney Museum and the galleries at the Harry Ransom Center. The Texas State Capitol itself is also a major tourist attraction. The Driskill Hotel built in 1886, once owned by George W. Littlefield, and located at 6th and Brazos streets, was finished just before the construction of the Capitol building. Sixth Street is a musical hub for the city. The Enchanted Forest, a multi-acre outdoor music, art, and performance art space in South Austin hosts events such as fire-dancing and circus-like-acts. Austin is also home to the Lyndon Baines Johnson Library and Museum, which houses documents and artifacts related to the Johnson administration, including LBJ's limousine and a re-creation of the Oval Office.
Locally produced art is featured at the South Austin Museum of Popular Culture. The Mexic-Arte Museum is a Latin American art museum founded in 1983. Austin is also home to the O. Henry House Museum, which served as the residence of O. Henry from 1893 to 1895. Farmers' markets are popular attractions, providing a variety of locally grown and often organic foods.
Austin also has many odd statues and landmarks, such as the Stevie Ray Vaughan statue, the Willie Nelson statue, the Mangia dinosaur, the Loca Maria lady at Taco Xpress, the Hyde Park Gym's giant flexed arm, and Daniel Johnston's "Hi, How are You?" Jeremiah the Innocent frog mural.
The Ann W. Richards Congress Avenue Bridge houses the world's largest urban population of Mexican Free-tailed Bats. Starting in March, up to 1.5 million bats take up residence inside the bridge's expansion and contraction zones as well as in long horizontal grooves running the length of the bridge's underside, an environment ideally suited for raising their young. Every evening around sunset, the bats emerge in search of insects, an exit visible on weather radar. Watching the bat emergence is an event that is popular with locals and tourists, with more than 100,000 viewers per year. The bats migrate to Mexico each winter.
The Austin Zoo, located in unincorporated western Travis County, is a rescue zoo that provides sanctuary to displaced animals from a variety of situations, including those involving neglect.
Sports.
Many Austinites support the athletic programs of the University of Texas at Austin known as the Texas Longhorns. During the 2005–06 academic term, Longhorns football team was named the NCAA Division I FBS National Football Champion, and Longhorns baseball team won the College World Series. The Texas Longhorns play home games in the state's second-largest sports stadium, Darrell K Royal-Texas Memorial Stadium, seating over 101,000 fans. Baseball games are played at UFCU Disch–Falk Field.
Austin is the most populous city in the United States without a club in a major professional sports league.
Minor-league professional sports came to Austin in 1996, when the Austin Ice Bats began playing at the Travis County Expo Center. Since then, the Austin Ice Bats have been replaced by the Texas Stars of the American Hockey League, and many other teams have come to Austin including the ] of the NBA Development League. The Austin Aztex of the USL PDL also call Austin home and have since been promoted to the USL Pro, which is the 3rd tier of professional soccer in the United States, and will begin playing in that league starting in 2015.
Natural features like the bicycle-friendly Texas Hill Country and generally mild climate make Austin the home of several endurance and multi-sport races and communities. The Capitol 10,000 is the largest race in Texas, and approximately fifth largest in the United States. The Austin Marathon has been run in the city every year since 1992.
The Austin-founded American Swimming Association hosts several swim races around town. Austin is also the hometown of several cycling groups and the former seven-time Tour de France champion cyclist Lance Armstrong. Combining these three disciplines is a growing crop of triathlons, including the Capital of Texas Triathlon held every Memorial Day on and around Lady Bird Lake, Auditorium Shores, and Downtown Austin.
In June 2010 it was announced that the Austin area would host the Formula One, United States Grand Prix, from 2012 until 2021. The State pledged $25 million in public funds annually for 10 years to pay the sanctioning fees for the race. A Formula One circuit will need to be built at an estimated cost of $250 to $300 million, and is expected to be located just east of the Austin Bergstrom International Airport. Circuit of the Americas will also play host to MotoGP World Championships from 2013.
The summer of 2014 marked the inaugural season for World TeamTennis team Austin Aces, formerly Orange County Breakers of the southern California region. Austin Aces play their matches at the Cedar Park Center northwest of Austin, and feature former professionals Andy Roddick and Marion Bartoli, as well as current WTA tour player Vera Zvonareva.
Parks and recreation.
The Austin Parks and Recreation Department received the Excellence in Aquatics award in 1999 and the Gold Medal Awards in 2004 from the National Recreation and Park Association. Home to more than 50 public swimming pools, Austin has parks and pools throughout the city. There are several well-known swimming locations. These include Deep Eddy Pool, Texas' oldest man-made swimming pool, and Barton Springs Pool, the nation's largest natural swimming pool in an urban area. Barton Springs Pool is spring-fed while Deep Eddy is well-fed. Both range in temperature from about during the winter to about during the summer. Hippie Hollow Park, a county park situated along Lake Travis, is the only officially sanctioned clothing-optional public park in Texas. Activities include rockclimbing, kayaking, swimming, mountain biking, exploring, and hiking along the greenbelt, a long-spanning area that runs through the city. Zilker Park, a large green area close to downtown, forms part of the greenbelt along the Colorado River. Hamilton Pool is a pool and wildlife park located about 30 minutes from the city.
Government and law.
City government.
Austin is currently administered by a seven-member city council (six council members plus a mayor), each of them elected at large. The council is accompanied by a hired city manager under the manager-council system of municipal governance. Council and mayoral elections are non-partisan, with a runoff in case there is no majority winner. Due to a referendum approved by voters on November 6, 2012, the current composition with council members elected on an at-large basis will change in 2014 to a new system of ten single member districts and a citywide election for mayor.
Austin formerly operated its city hall at 128 West 8th Street. Antoine Predock and Cotera Kolar Negrete & Reed Architects designed a new city hall building, which was intended to reflect what "The Dallas Morning News" referred to as a "crazy-quilt vitality, that embraces everything from country music to environmental protests and high-tech swagger." The new city hall, built from recycled materials, has solar panels in its garage. The city hall, at 301 West Second Street, opened in November 2004. The mayor of Austin is Lee Leffingwell. His second term ends in 2015.
Law enforcement in Austin is provided by the Austin Police Department, except for state government buildings, which are patrolled by the Texas Department of Public Safety. The University of Texas Police operate from the University of Texas.
Fire protection within the city limits is provided by the Austin Fire Department, while the surrounding county is divided into twelve geographical areas known as Emergency Services Districts, which are covered by separate regional fire departments. Emergency Medical Services are provided for the whole county by "Austin-Travis County Emergency Medical Services".
State and federal representation.
The Texas Department of Transportation operates the Austin District Office in Austin.
The Texas Department of Criminal Justice (TDCJ) operates the Austin I and Austin II district parole offices in Austin.
The United States Postal Service operates several post offices in Austin.
Politics.
Austin is known as an enclave of liberal politics in a generally conservative state—so much so, that the city is sometimes sarcastically called the "People's Republic of Austin" by residents of other parts of Texas, and conservatives in the Texas Legislature.
As a result of the major party realignment that began in the 1970s, central Austin became a stronghold of the Democratic Party, while the suburbs tend to vote Republican. A controversial turning point in the political history of the Austin area was the 2003 Texas redistricting. Opponents characterized the resulting district layout as excessively partisan gerrymandering, and the plan was challenged in court by Democratic and minority activists; of note, the Supreme Court of the United States has never struck down a redistricting plan for being excessively partisan. The plan was subsequently upheld by a three-judge federal panel in late 2003, and on June 28, 2006, the matter was largely settled when the Supreme Court, in a 7–2 decision, upheld the entire congressional redistricting plan with the exception of a Hispanic-majority district in southwest Texas. This affected Austin's districting, as U.S. Rep. Lloyd Doggett's district (U.S. Congressional District 25) was found to be insufficiently compact to compensate for the reduced minority influence in the southwest district; it was redrawn so that it now takes in most of southeastern Travis County and several counties to its south and east.
Overall, the city is a blend of downtown liberalism and suburban conservatism but leans to the political left as a whole. The city last went to a Republican candidate in 2000 when Texan resident George W. Bush successfully ran for President. This was helped in part by Ralph Nader of the Green Party splitting the center-left vote by winning a sizeable 10.4%, which was largely at the expense of the Democrats. In 2004, the Democrats rebounded strongly as John Kerry enjoyed a 14.0% margin over Bush, who once again won Texas.
In 2003, the city adopted a resolution against the USA PATRIOT Act that reaffirmed constitutionally guaranteed rights. Of Austin's six state legislative districts, three are strongly Democratic and three are swing districts, two of which are held by Democrats and one of which is held by a Republican. However, two of its three congressional districts (the 10th and the 21st) are presently held by Republicans, with only the 25th held by a Democrat. This is largely due to the 2003 redistricting, which left downtown Austin without an exclusive congressional seat of its own. Travis County was also the only county in Texas to reject Texas Constitutional Amendment Proposition 2 that effectively outlawed gay marriage and status equal or similar to it and did so by a wide margin (40% for, 60% against).
Two of the candidates for president in the 2004 race called Austin home. Michael Badnarik, the Libertarian Party candidate, and David Cobb of the Green Party both had lived in Austin. During the run up to the election in November, a presidential debate was held at the University of Texas at Austin student union involving the two minor party candidates. While the Commission on Presidential Debates only invites Democrats and Republicans to participate in televised debates, the debate at UT was open to all presidential candidates. Austin also hosted one of the last presidential debates between Barack Obama and Hillary Clinton during their heated race for the Democratic nomination in 2008.
In the 2012 Presidential election, Travis County, which contains the majority of Austin, voted to re-elect President Barack H. Obama (D) by a 24-point margin (60.1% to 36.2%).
Environmental movement.
The distinguishing political movement of Austin politics has been that of the environmental movement, which spawned the parallel neighborhood movement, then the more recent conservationist movement (as typified by the Hill Country Conservancy), and eventually the current on-going debate about "sense of place" and preserving the Austin quality of life. Much of the so-called environmental movement has matured into a debate on issues related to saving and creating an Austin "sense of place."
Education.
Researchers at Central Connecticut State University ranked Austin the 16th most literate city in the United States for 2008. The Austin Public Library operates the John Henry Faulk Library and various library branches. In addition, the University of Texas at Austin operates the seventh-largest academic library in the nation.
Austin was voted "America's No.1 College Town" by the Travel Channel. Over 43 percent of Austin residents age 25 and over hold a bachelor's degree, while 16 percent hold a graduate degree. In 2009, greater Austin ranked eighth among metropolitan areas in the United States for bachelor's degree attainment with nearly 39 percent of area residents over 25 holding a bachelor's degree.
Higher education.
Austin is home to the University of Texas at Austin, the flagship institution of the University of Texas System with over 38,000 undergraduate students and 12,000 graduate students. In 2015 rankings, the university was ranked 53rd among "National Universities" (17th among public universities) by "U.S. News & World Report." UT has annual research expenditures of over $595 million and has the highest-ranked business, engineering, and law programs of any university in the state of Texas.
Other institutions of higher learning in Austin include St. Edward's University, Austin Community College, Concordia University, Huston-Tillotson University, the Seminary of the Southwest, the Acton School of Business, Austin Graduate School of Theology, Austin Presbyterian Theological Seminary, Virginia College's Austin Campus, The Art Institute of Austin, Southern Careers Institute of Austin, Austin Conservatory and a branch of Park University.
Public primary and secondary education.
The Austin area has 29 public school districts, 17 charter schools and 69 private schools. Most of the city is served by the Austin Independent School District. This district includes notable schools such as the magnet Liberal Arts and Science Academy High School of Austin, Texas (LASA), which, by test scores, has consistently been within the top thirty high schools in the nation, as well as The Ann Richards School for Young Women Leaders. Some parts of Austin are served by other districts, including Round Rock, Pflugerville, Leander, Manor, Del Valle, Lake Travis, Dripping Springs, Hays, and Eanes ISDs. Four of the metro's major public school systems, representing 54% of area enrollment, are included in "Expansion Management" magazine's latest annual education quality ratings of nearly 2,800 school districts nationwide. Two districts—Eanes and Round Rock—are rated "gold medal", the highest of the magazine's cost-performance categories.
Private and alternative education.
Private and alternative education institutions for children in preschool-12th grade include ACE Academy, Regents School of Austin, Redeemer Lutheran School, Garza (public), Austin Discovery School (public charter), Austin Jewish Academy, Austin Peace Academy, The Austin School for the Performing and Visual Arts, The Austin Waldorf School, The Griffin School, The Khabele School, Concordia Academy, Kirby Hall School, St. Ignatius Martyr Catholic School,Holy Family Catholic School, San Juan Diego Catholic High School, Brentwood Christian School, Renaissance Academy, St. Austin Catholic School, St. Stephen's Episcopal School, St. Mary's, St. Theresa's, St. Michael's Catholic Academy, St. Gabriel's Catholic School, St. Andrew's Episcopal School, St. Francis Episcopal School, St. Paul Lutheran School, Trinity Episcopal School, Huntington-Surrey, Cleaview Sudbury School, Inside Outside School, Paragon Preparatory Middle School, Austin International School, Progress School, Bronze Doors Academy, and a number of Montessori schools.
Along with homeschooling & "unschooling" communities, Austin is home to a number of part-time learning environments designed to offer basic academics and inspired mentoring. Such current resources include the Whole Life Learning Center and AHB Community School.
Austin is also home to child developmental institutions including the Center for Autism and Related Disorders, the Central Texas Autism Center, Johnson Center for Child Health and Development and many more.
Media.
Austin's main daily newspaper is the "Austin American-Statesman". "The Austin Chronicle" is Austin's alternative weekly, while "The Daily Texan" is the student newspaper of the University of Texas at Austin. Austin's business newspaper is the weekly "Austin Business Journal". Austin also has numerous smaller special interest or sub-regional newspapers such as the "Oak Hill Gazette", "Westlake Picayune", "Hill Country News", "Round Rock Leader", "NOKOA", and "The Villager" among others. "Texas Monthly", a major regional magazine, is also headquartered in Austin. The "Texas Observer", a muckraking biweekly political magazine, has been based in Austin for over five decades. The weekly "Community Impact Newspaper" newspaper published by John Garrett, former publisher of the "Austin Business Journal" has five regional editions and is delivered to every house and business within certain zip codes and all of the news is specific to those zip codes. The most recent entrant on the Austin news scene is "The Texas Tribune", an on-line publication focused on Texas and Austin politics. The "Tribune" is "user-supported" through donations, a business model similar to public radio. The Editor is Evan Smith, former Editor of "Texas Monthly". Smith co-founded the "Texas Tribune", a nonprofit, non-partisan public media organization, with Austin venture capitalist John Thornton and veteran journalist Ross Ramsey.
Commercial radio stations include KASE-FM (country), KVET (sports), KVET-FM (country), KKMJ-FM (adult contemporary), KLBJ (talk), KLBJ-FM (classic rock), KTAE (Christian talk), KFMK (contemporary Christian), KOKE-FM (progressive country) and KPEZ (rhythmic contemporary). KUT is the leading public radio station in Texas and produces the majority of its content locally. KOOP (FM) is a volunteer-run radio station with more than 60 locally produced programs. KVRX is the student-run college radio station of the University of Texas at Austin with a focus on local and non-mainstream music and community programming. Other listener-supported stations include KAZI (urban contemporary), and KMFA (classical)
Network television stations (affiliations in parentheses) include KTBC (Fox), KVUE (ABC), KXAN (NBC), KEYE-TV (CBS), KLRU (PBS), KNVA (The CW), KBVO (My Network TV), and KAKW (Univision). KLRU produces several award winning locally produced programs such as "Austin City Limits".
Alex Jones, journalist, radio show host and filmmaker, produces his talk show The Alex Jones Show in Austin which broadcasts nationally on more than 60 AM and FM radio stations in the United States, WWCR Radio shortwave and XM Radio: Channel 166.
Transportation.
Of all the people who work in Austin, 73% drive alone, 10% carpool, 6% work from home, 5% take the bus, 2% walk, and 1% bicycle.
Highways.
Central Austin lies between two major north-south freeways: Interstate 35 to the east and the Mopac Expressway (Loop 1) to the west. U.S. Highway 183 runs from northwest to southeast, and State Highway 71 crosses the southern part of the city from east to west, completing a rough "box" around central and north-central Austin. Austin is the largest city in the United States to be served by only one Interstate Highway.
U.S. Highway 290 enters Austin from the east and merges into Interstate 35. Its highway designation continues south on I-35 and then becomes part of Highway 71, continuing to the west. Highway 290 splits from Highway 71 in southwest Austin, in an interchange known as "The Y." Highway 71 continues to Brady, Texas, and Highway 290 continues west to intersect Interstate 10 near Junction. Interstate 35 continues south through San Antonio to Laredo on the Texas-Mexico border. Interstate 35 is the highway link to the Dallas-Fort Worth metroplex in northern Texas. There are two links to Houston, Texas (Highway 290 and State Highway 71/Interstate 10). Highway 183 leads northwest of Austin toward Lampasas.
In the mid-1980s, construction was completed on Loop 360, a scenic highway that curves through the hill country from near the 71/Mopac interchange in the south to near the 183/Mopac interchange in the north. The iconic Pennybacker Bridge, also known as the "360 Bridge", crosses Lake Austin to connect the northern and southern portions of Loop 360.
Tollways.
State Highway 130 is a bypass route designed to relieve traffic congestion, starting from Interstate 35 just north of Georgetown and running along a parallel route to the east, where it bypasses Round Rock, Austin, San Marcos and New Braunfels before ending at Interstate 10 east of Seguin, where drivers could drive west to return to Interstate 35 in San Antonio. The first segment was opened in November 2006, which was located east of Austin-Bergstrom International Airport at Austin's southeast corner on State Highway 71. Highway 130 runs concurrently with Highway 45 from Pflugerville on the north until it reaches US 183 well south of Austin, where it splits off and goes west. The entire route of State Highway 130 is now complete with last leg, which opened on November 1, 2012. The highway is noted for having the entire route with a speed limit of at least . The 41-mile section of the toll road between Mustang Ridge and Seguin has a posted speed limit of , the highest posted speed limit in the United States.
State Highway 45 runs east-west from just south of Highway 183 in Cedar Park to 130 inside Pflugerville (just east of Round Rock). A tolled extension of State Highway Loop 1 was also created. A new southeast leg of Highway 45 has recently been completed, running from US 183 and the south end of Segment 5 of TX-130 south of Austin due west to I-35 at the FM 1327/Creedmoor exit between the south end of Austin and Buda. The 183A Toll Road opened March 2007, providing a tolled alternative to U.S. 183 through the cities of Leander and Cedar Park. Currently under construction is a change to East US 290 from US 183 to the town of Manor. Officially, the tollway will be dubbed Tollway 290 with the Manor Expressway as a nickname.
Despite the overwhelming initial opposition to the toll road concept when it was first announced, all three toll roads have exceeded revenue projections.
Airports.
Austin's airport is Austin-Bergstrom International Airport (ABIA) ( AUS), located southeast of the city. The airport is on the site of the former Bergstrom Air Force Base, which was closed in 1993 as part of the Base Realignment and Closure process. Previously, Robert Mueller Municipal Airport was the commercial airport of Austin. Austin Executive Airport serves the general aviation coming into the city, as well as other smaller airports outside of the city centre.
Intercity bus service.
Greyhound Lines operates the Austin Station at 916 East Koenig Lane, just east of Airport Boulevard and adjacent to Highland Mall. Turimex Internacional operates bus service from Austin to Nuevo Laredo and on to many destinations in Mexico. The Turimex station is located at 5012 East 7th Street, near Shady Lane.
Megabus offers daily service to San Antonio, Dallas/Fort Worth and Houston.
Public transportation.
Capital Metropolitan Transportation Authority Capital Metro provides public transportation to the city, primarily by bus. Capital Metro is planning to change some routes to "Rapid Lines." The lines will feature long, train-like, high-tech buses. This addition is going to be implemented to help reduce congestion. Capital Metro opened a commuter rail system known as Capital MetroRail on March 22, 2010. The system was built on existing freight rail lines and serves downtown Austin, East Austin, North Central Austin, Northwest Austin, and Leander in its first phase. Future expansion could include a line to Manor and another to Round Rock. Capital Metro is also looking into a light rail system to connect most of Downtown, the University of Texas at Austin, and the Mueller Airport Redevelopment. The light rail system would help connect the MetroRail line to key destinations in Central Austin. On August 7, 2014, the Austin City Council unanimously voted to place a $600 million light rail bond proposal on the November 4, 2014 ballot. Implementation of this package is contingent on matching funding from Federal transit grants. If Federal funding is available, then Austin would begin construction of a light rail line that would run from Riverside Drive to the Highland Austin Community College Campus. An Amtrak "Texas Eagle" station is located west of downtown. Segments of the Amtrak route between Austin and San Antonio are under evaluation for a future regional passenger rail corridor as an alternative to the traffic congestion of Interstate 35. This is a multi jurisdictional project called . Austin is also home to Car2Go, a carsharing program. Austin was chosen as the first city in the western hemisphere to host this company's business, which is based in Germany.
Cycling.
Austin is known as the most bike-friendly city in Texas and has a Silver-level rating from the League of American Bicyclists. There are over 80 miles of bike lanes in Austin. Over 2% of commuters get to work by bike and many more Austinites ride for daily transportation needs, according to the American Community Survey. The North Loop neighborhood along with the Manor Road area have the highest bike commuting rates, with over 13% of residents biking to work in 2012. Biking is also very popular recreationally with the extensive network of trails in the city.
The city's bike advocacy organization is Bike Austin. Bike Texas, a state-level advocacy also has its main office in Austin.
Bicycles are a popular transportation choice among students, faculty, and staff at the University of Texas. According to a survey done at UT, 9% of commuters bike to campus.
Walkability.
A 2013 study by Walk Score ranked Austin 35th most walkable of the 50 largest U.S. cities. This is considered a medium low ranking.
Sister cities.
List of sister cities of Austin, Texas, designated by Sister Cities International.
The cities of Belo Horizonte, Brazil and Elche, Spain were formerly sister cities, but upon a vote of the Austin City Council in 1991, their status was de-activated.

</doc>
<doc id="2003" url="http://en.wikipedia.org/wiki?curid=2003" title="Argument from morality">
Argument from morality

The argument from morality is an argument for the existence of God. Arguments from morality tend to be based on moral normativity or moral order. Arguments from moral normativity observe some aspect of morality and argue that God is the best or only explanation for this, concluding that God must exist. Argument from moral order are based on the asserted need for moral order to exist in the universe. They claim that, for this moral order to exist, God must exist to support it.
German philosopher Immanuel Kant devised an argument from morality based on practical reason. Kant argued that the goal of humanity is to achieve perfect happiness and virtue (the summum bonum) and believed that an afterlife must exist in order for this to be possible, and that God must exist to provide this. In his book "Mere Christianity", C. S. Lewis argued that "conscience reveals to us a moral law whose source cannot be found in the natural world, thus pointing to a supernatural Lawgiver." Lewis argued that accepting the validity of human reason as a given must include accepting the validity of practical reason, which could not be valid without reference to a higher cosmic moral order which could not exist without a God to create and/or establish it. A related argument is from conscience; John Henry Newman argued that the conscience supports the claim that objective moral truths exist because it drives people to act morally even when it is not in their own interest. Newman argued that, because the conscience suggests the existence of objective moral truths, God must exist to give authority to these truths.
General form.
All variations of the argument from morality begin with an observation about moral thought or experiences and conclude with the existence of God. Some of these arguments propose moral facts which they claim evident through human experience, arguing that God is the best explanation for these. Other versions describe some end which humans should strive to attain, only possible if God exists.
Many arguments from morality are based on morality normativity, which suggest that objective moral truths exist and require God's existence to give them authority. Often, they consider that morality seems to be binding – obligations are seen to convey more than just a preference, but imply that the obligation will stand, regardless of other factors or interests. For morality to be binding, God must exist. In its most general form, the argument from moral normativity is:
Some arguments from moral order suggest that morality is based on rationality and that this can only be the case if there is a moral order in the universe. The arguments propose that only the existence of God as orthodoxly conceived could support the existence of moral order in the universe, so God must exist. Alternative arguments from moral order have proposed that we have an obligation to attain the perfect good of both happiness and moral virtue. They attest that whatever we are obliged to do must be possible, and achieving the perfect good of both happiness and moral virtue is only possible if a natural moral order exists. A natural moral order requires the existence of God as orthodoxly conceived, so God must exist.
Variations.
Practical Reason.
In his "Critique of Pure Reason", German philosopher Immanuel Kant stated that no successful argument for God's existence arises from reason alone. In his "Critique of Practical Reason" he went on to argue that, despite the failure of these arguments, morality requires that God's existence is assumed, owing to practical reason. Rather than proving the existence of God, Kant was attempting to demonstrate that all moral thought requires the assumption that God exists. Kant argued that humans are obliged to bring about the "summum bonum": the two central aims of moral virtue and happiness, where happiness arises out of virtue. As ought implies can, Kant argued, it must be possible for the "summum bonum" to be achieved. He accepted that it is not within the power of humans to bring the "summum bonum" about, because we cannot ensure that virtue always leads to happiness, so there must be a higher power who has the power to create an afterlife where virtue can be rewarded by happiness.
Philosopher G. H. R. Parkinson notes a common objection to Kant's argument: that what ought to be done does not necessarily entail that it is possible. He also argues that alternative conceptions of morality exist which do not rely on the assumptions that Kant makes – he cites utilitarianism as an example which does not require the "summum bonum". Nichola Everitt argues that much moral guidance is unattainable, such as the Biblical command to be Christ-like. She proposes that Kant's first two premises only entail that we must try to achieve the perfect good, not that it is actually attainable.
Argument from objective moral truths.
Both theists and non-theists have accepted that the existence of objective moral truths might entail the existence of God. Atheist philosopher J. L. Mackie accepted that, if objective moral truths existed, they would warrant a supernatural explanation. Scottish philosopher W. R. Sorley presented the following argument:
Many critics have challenged the second premise of this argument, by offering a biological and sociological account of the development of human morality which suggests that it is neither objective nor absolute. This account, supported by biologist E. O. Wilson and philosopher Michael Ruse, proposes that the human experience of morality is a by-product of natural selection, a theory philosopher Mark D. Linville calls evolutionary naturalism. According to the theory, the human experience of moral obligations was the result of evolutionary pressures, which attached a sense of morality to human psychology because it was useful for moral development; this entail that moral values do not exist independently of the human mind. Morality might be better understood as an evolutionary imperative in order to propagate genes and ultimately reproduce. No human society today advocates immorality, such as theft or murder, because it would undoubtedly lead to the end of that particular society and any chance for future survival of offspring. Scottish empiricist David Hume made a similar argument, that belief in objective moral truths is unwarranted and to discuss them is meaningless.
Because evolutionary naturalism proposes an empirical account of morality, it does not require morality to exist objectively; Linville considers the view that this will lead to moral scepticism or antirealism. C. S. Lewis argued that, if evolutionary naturalism is accepted, human morality cannot be described as absolute and objective because moral statements cannot be right or wrong. Despite this, Lewis argued, those who accept evolutionary naturalism still act as if objective moral truths exist, leading Lewis to reject naturalism as incoherent. As an alternative ethical theory, Lewis offered a form of divine command theory which equated God with goodness and treated goodness as an essential part of reality, thus asserting God's existence.
J.C.A. Gaskin challenges the first premise of the argument from moral objectivity, arguing that it must be shown why absolute and objective morality entails that morality is commanded by God, rather than simply a human invention. It could be the consent of humanity that gives it moral force, for example. American philosopher Michael Martin argues that it is not necessarily true that objective moral truths must entail the existence of God, suggesting that there could be alternative explanations: he argues that naturalism may be an acceptable explanation and, even if a supernatural explanation is necessary, it does not have to be God (polytheism is a viable alternative). Martin also argues that a non-objective account of ethics might be acceptable and challenges the view that a subjective account of morality would lead to moral anarchy.
Conscience.
Related to the argument from morality is the argument from conscience, associated with eighteenth-century bishop Joseph Butler and nineteenth-century cardinal John Henry Newman. Newman proposed that the conscience, as well as giving moral guidance, provides evidence of objective moral truths which must be supported by the divine. He argued that emotivism is an inadequate explanation of the human experience of morality because people avoid acting immorally, even when it might be in their interests. Newman proposed that, to explain the conscience, God must exist.
British philosopher John Locke argued that moral rules cannot be established from conscience because the differences in people's consciences would lead to contradictions. Locke also noted that the conscience is influenced by "education, company, and customs of the country", a criticism mounted by J. L. Mackie, who argued that the conscience should be seen as an "introjection" of other people into an agent's mind. Michael Martin challenges the argument from conscience with a naturalistic account of conscience, arguing that naturalism provides as adequate explanation for the conscience with the need for God's existence. He uses the example of the internalisation by humans of social pressures, which leads to the fear of going against these norms. Even if a supernatural cause is required, he argues, it could be something other than God; this would mean that the phenomena of the conscience is no more supportive of monotheism than polytheism.

</doc>
<doc id="2004" url="http://en.wikipedia.org/wiki?curid=2004" title="ASL (disambiguation)">
ASL (disambiguation)

ASL is a common initialism for American Sign Language, the sign language of the United States and Canada, and may also refer to:

</doc>
<doc id="2006" url="http://en.wikipedia.org/wiki?curid=2006" title="Auschwitz concentration camp">
Auschwitz concentration camp

Auschwitz concentration camp ( ) was a network of German Nazi concentration camps and extermination camps built and operated by the Third Reich in Polish areas annexed by Nazi Germany during World War II. It consisted of Auschwitz I (the original camp), Auschwitz II–Birkenau (a combination concentration / extermination camp), Auschwitz III–Monowitz (a labor camp to staff an IG Farben factory), and 45 satellite camps.
Auschwitz I was first constructed to hold Polish political prisoners, who began to arrive in May 1940. The first extermination of prisoners took place in September 1941, and Auschwitz II–Birkenau went on to become a major site of the Nazi "Final Solution to the Jewish question". From early 1942 until late 1944, transport trains delivered Jews to the camp's gas chambers from all over German-occupied Europe, where they were killed with the pesticide Zyklon B. At least 1.1 million prisoners died at Auschwitz, around 90 percent of them Jewish; approximately 1 in 6 Jews killed in the Holocaust died at the camp. Others deported to Auschwitz included 150,000 Poles, 23,000 Romani and Sinti, 15,000 Soviet prisoners of war, 400 Jehovah's Witnesses, homosexuals, and tens of thousands of people of diverse nationalities. Living conditions were brutal, and many of those not killed in the gas chambers died of starvation, forced labor, infectious diseases, individual executions, and medical experiments.
In the course of the war, the camp was staffed by 6,500 to 7,000 members of the German "Schutzstaffel" (SS), approximately 15 percent of whom were later convicted of war crimes. Some, including camp commandant Rudolf Höss, were executed. The Allied Powers refused to believe early reports of the atrocities at the camp, and their failure to bomb the camp or its railways remains controversial. One hundred and forty-four prisoners are known to have escaped from Auschwitz successfully, and on October 7, 1944, two "Sonderkommando" units—prisoners assigned to staff the gas chambers—launched a brief, unsuccessful uprising.
As Soviet troops approached Auschwitz in January 1945, most of its population was evacuated and sent on a death march. The prisoners remaining at the camp were liberated on January 27, 1945, a day now commemorated as International Holocaust Remembrance Day. In the following decades, survivors such as Primo Levi, Viktor Frankl, and Elie Wiesel wrote memoirs of their experiences in Auschwitz, and the camp became a dominant symbol of the Holocaust. In 1947, Poland founded a museum on the site of Auschwitz I and II, and in 1979, it was named a UNESCO World Heritage Site.
History.
Background.
Discrimination against Jews began immediately after the Nazi seizure of power in Germany on January 30, 1933. The Law for the Restoration of the Professional Civil Service, passed on April 7 that year, excluded most Jews from the legal profession and the civil service. Similar legislation soon deprived Jewish members of other professions of the right to practise. Violence and economic pressure were used by the regime to encourage Jews to leave the country voluntarily. Jewish businesses were denied access to markets, forbidden to advertise in newspapers, and deprived of access to government contracts. Citizens were harassed and subjected to violent attacks and boycotts of their businesses.
In September 1935 the Nuremberg Laws were enacted. These laws prohibited marriages between Jews and people of Germanic extraction, extramarital relations between Jews and Germans, and the employment of German women under the age of 45 as domestic servants in Jewish households. The Reich Citizenship Law stated that only those of Germanic or related blood were defined as citizens. Thus Jews and other minority groups were stripped of their German citizenship. By the start of World War II in 1939, around 250,000 of Germany's 437,000 Jews emigrated to the United States, Palestine, Great Britain, and other countries.
The ideology of Nazism brought together elements of antisemitism, racial hygiene, and eugenics, and combined them with pan-Germanism and territorial expansionism with the goal of obtaining more "Lebensraum" (living space) for the Germanic people. Nazi Germany attempted to obtain this new territory by attacking Poland and the Soviet Union, intending to deport or kill the Jews and Slavs living there, who were viewed as being inferior to the Aryan master race. After the invasion of Poland in September 1939, German dictator Adolf Hitler ordered that the Polish leadership and intelligentsia should be destroyed. Approximately 65,000 civilians were killed by the end of 1939. In addition to leaders of Polish society, the Nazis killed Jews, prostitutes, Romani, and the mentally ill. SS-"Obergruppenführer" (Senior Group Leader) Reinhard Heydrich, then head of the Gestapo, ordered on September 21 that Jews should be rounded up and concentrated into cities with good rail links. Initially the intention was to deport the Jews to points further east, or possibly to Madagascar.
Auschwitz I.
After this part of Poland was annexed by Nazi Germany, Oświęcim (Auschwitz) was located administratively in Germany, Province of Upper Silesia, Regierungsbezirk Kattowitz, Landkreis Bielitz. It was first suggested as a site for a concentration camp for Polish prisoners by "SS-Oberführer" Arpad Wigand, an aide to Higher SS and Police Leader for Silesia, Erich von dem Bach-Zelewski. Bach-Zelewski had been searching for a site to house prisoners in the Silesia region, as the local prisons were filled to capacity. Richard Glücks, head of the Concentration Camps Inspectorate, sent former Sachsenhausen concentration camp commandant Walter Eisfeld to inspect the site, which already held sixteen dilapidated one-story buildings that had once served as an army barracks and a camp for transient workers. "Reichsführer-SS" Heinrich Himmler, head of the "Schutzstaffel" (SS), approved the site in April 1940, intending to use the facility to house political prisoners. SS-"Obersturmbannführer" (lieutenant colonel) Rudolf Höss oversaw the development of the camp and served as the first commandant. SS-"Obersturmführer" (senior lieutenant) Josef Kramer was appointed Höss's deputy. Auschwitz I, the original camp, became the administrative center for the whole complex.
Local residents were evicted, including 1,200 people who lived in shacks around the barracks. Around 300 Jewish residents of Oświęcim were brought in to lay foundations. From 1940 to 1941, 17,000 Polish and Jewish residents of the western districts of Oświęcim were expelled from places adjacent to the camp. The Germans also ordered expulsions from the villages of Broszkowice, Babice, Brzezinka, Rajsko, Pławy, Harmęże, Bór, and Budy. German citizens were offered tax concessions and other benefits if they would relocate to the area. By October 1943, more than 6,000 Reich Germans had arrived. The Nazis planned to build a model modern residential area for incoming Germans, including schools, playing fields, and other amenities. Some of the plans went forward, including the construction of several hundred apartments, but many were never fully implemented. Basic amenities such as water and sewage disposal were inadequate, and water-borne illnesses were commonplace.
The first prisoners (30 German criminal prisoners from the Sachsenhausen camp) arrived in May 1940, intended to act as functionaries within the prison system. The first transport of 728 Polish prisoners, which included 20 Jews, arrived on June 14, 1940, from the prison in Tarnów, Poland. They were interned in the former building of the Polish Tobacco Monopoly, adjacent to the site, until the camp was ready. The inmate population grew quickly as the camp absorbed Poland's intelligentsia and dissidents, including the Polish underground resistance. By March 1941, 10,900 were imprisoned there, most of them Poles. By the end of 1940, the SS had confiscated land in the surrounding area to create a "zone of interest" about in area surrounded by a double ring of electrified barbed wire fences and watchtowers. Like other Nazi concentration camps, the gates to Auschwitz I displayed the motto "Arbeit macht frei" ("Work brings freedom").
Auschwitz II-Birkenau.
Construction on Auschwitz II-Birkenau began in October 1941 to ease congestion at the main camp. "Reichsführer-SS" Heinrich Himmler, head of the "Schutzstaffel" (SS), intended the camp to house 50,000 prisoners of war, who would be interned as forced laborers. Plans called for the expansion of the camp first to house 150,000 and eventually as many as 200,000 inmates. An initial contingent of 10,000 Soviet prisoners of war arrived at Auschwitz I in October 1941, but by March 1942 only 945 were still alive, and these were transferred to Birkenau, where most of them died from disease or starvation by May. By this time Hitler had decided that the Jews of Europe were to be exterminated, so Birkenau was repurposed as a combination labor camp / extermination camp.
The chief of construction of Auschwitz II-Birkenau was Karl Bischoff. Unlike his predecessor, he was a competent and dynamic bureaucrat who, in spite of the ongoing war, carried out the construction deemed necessary. The Birkenau camp, the four crematoria, the technically complicated central sauna, a new reception building, and hundreds of other buildings were planned and realized. Bischoff's plans initially called for each barrack to have an occupancy of 550 prisoners (one-third of the space allotted in other Nazi concentration camps). He later changed this to 744 prisoners per barrack. The SS designed the barracks not so much to house people as to destroy them.
The first gas chamber at Birkenau was the "red house" (called Bunker 1 by SS staff), a brick cottage converted into a gassing facility by tearing out the inside and bricking up the walls. It was operational by March 1942. A second brick cottage, the "white house" or Bunker 2, was converted some weeks later. These structures were in use for mass killings until early 1943. Himmler visited the camp in person on July 17 and 18, 1942. He was given a demonstration of a mass killing using the gas chamber in Bunker 2 and toured the building site of the new IG Farben plant being constructed at the nearby town of Monowitz.
In early 1943, the Nazis decided to increase greatly the gassing capacity of Birkenau. Crematorium II, originally designed as a mortuary, with morgues in the basement and ground-level incinerators, was converted into a killing factory by installing gas-tight doors, vents for the Zyklon B (a highly lethal cyanide-based pesticide) to be dropped into the chamber, and ventilation equipment to remove the gas thereafter. It went into operation in March. Crematorium III was built using the same design. Crematoria IV and V, designed from the start as gassing centers, were also constructed that spring. By June 1943, all four crematoria were operational. Most of the victims were killed using these four structures.
The Gypsy camp.
On December 10, 1942, Himmler issued an order to send all Sinti and Roma (Gypsies) to concentration camps, including Auschwitz. A separate camp for Roma was set up at Auschwitz II-Birkenau known as the "Zigeunerfamilienlager" (Gypsy Family Camp). The first transport of German Gypsies arrived on February 26, 1943, and was housed in Section B-IIe of Auschwitz II. Approximately 23,000 Gypsies had been brought to Auschwitz by 1944, 20,000 of whom died there. One transport of 1,700 Polish Sinti and Roma was killed upon arrival, as they were suspected to be ill with spotted fever.
Gypsy prisoners were used primarily for construction work. Thousands died of typhus and noma due to overcrowding, poor sanitary conditions, and malnutrition. Anywhere from 1,400 to 3,000 prisoners were transferred to other concentration camps before the murder of the remaining population.
On August 2, 1944, the SS cleared the Gypsy camp. A witness in another part of the camp later told of the Gypsies unsuccessfully battling the SS with improvised weapons before being loaded into trucks. The surviving population of 2,897 was then killed en masse in the gas chambers. The murder of the Romani people by the Nazis during World War II is known in the Romani language as the Porajmos (devouring).
Auschwitz III.
After examining several sites for a new plant to manufacture buna, a type of synthetic rubber essential to the war effort, chemicals manufacturer IG Farben chose a site near the towns of Dwory and Monowice (Monowitz in German), about east of Auschwitz I and east of the town of Oświęcim. Financial support in the form of tax exemptions was available to corporations prepared to develop industries in the frontier regions under the Eastern Fiscal Assistance Law, passed in December 1940. In addition to its proximity to the concentration camp, which could be used as a source of cheap labor, the site had good railway connections and access to raw materials. In February 1941, Himmler ordered that the Jewish population of Oświęcim should be expelled to make way for skilled laborers that would be brought in to work at the plant. All Poles able to work were to remain in the town and were forced to work building the factory. Himmler visited in person in March and decreed an immediate expansion of the parent camp to house 30,000 persons. Development of the camp at Birkenau began about six months later. Construction of IG Auschwitz began in April, with an initial force of 1,000 workers from Auschwitz I assigned to work on the construction. This number increased to 7,000 in 1943 and 11,000 in 1944. Over the course of its history, about 35,000 inmates in total worked at the plant; 25,000 died as a result of malnutrition, disease, and the physically impossible workload. In addition to the concentration camp inmates, who comprised a third of the work force, IG Auschwitz employed slave laborers from all over Europe.
Initially the laborers walked the seven kilometers from Auschwitz I to the plant each day, but as this meant they had to rise at 3:00 am, many arrived exhausted and unable to work. The camp at Monowitz (also called Monowitz-Buna or Auschwitz III) was constructed and began housing inmates on October 30, 1942, the first concentration camp to be financed and built by private industry. In January 1943 the "ArbeitsausbildungLager" (labor education camp) was moved from the parent camp to Monowitz. These prisoners were also forced to work on the building site. The SS charged IG Farben three Reichsmarks per hour for unskilled workers, four for skilled workers. Although the camp administrators expected the prisoners to work at 75 percent of the capacity of a free worker, the inmates were only able to perform 20 to 50 percent as well. Site managers constantly threatened inmates with transportation to Birkenau for death in the gas chambers as a way to try to increase productivity. Deaths and transfers to the gas chambers at Birkenau reduced the prisoner population of Monowitz by nearly a fifth each month; numbers were made up with new arrivals. Life expectancy of inmates at Monowitz averaged about three months. Though the factory was initially expected to begin production in 1943, shortages of labor and raw materials meant start-up had to be postponed repeatedly. The plant was almost ready to commence production when it was overrun by Soviet troops in 1945.
Subcamps.
Various other German industrial enterprises, such as Krupp and Siemens-Schuckert, built factories with their own subcamps. There were 45 such satellite camps, 28 of which served corporations involved in the armanents industry. Prisoner populations ranged from several dozen to several thousand. Subcamps were built at Blechhammer, Jawiszowice, Jaworzno, Lagisze, Mysłowice, Trzebinia, and other centers as far afield as the Protectorate of Bohemia and Moravia. Satellite camps were designated as "Aussenlager" (external camp), "Nebenlager" (extension or subcamp), or "Arbeitslager" (labor camp). Industries with satellite camps included coal mines, foundries and other metal works, chemical plants, and other industries. Prisoners were also made to work in forestry and farming.
Evacuation, death marches, and liberation.
In November 1944, with the Soviet Red Army approaching through Poland, Himmler ordered gassing operations to cease across the Reich. Crematoria II, III, and IV were dismantled, while Crematorium I was transformed into an air raid shelter. The "Sonderkommando" were ordered to remove other evidence of the killings, including the mass graves. The SS destroyed written records, and in the final week before the camp's liberation, burned or demolished many of its buildings.
Himmler ordered the evacuation of all camps in January 1945, charging camp commanders with "making sure that not a single prisoner from the concentration camps falls alive into the hands of the enemy." On January 17, 58,000 Auschwitz detainees were evacuated under guard, largely on foot; thousands of them died in the subsequent death march west towards Wodzisław Śląski. Approximately 20,000 Auschwitz prisoners made it to Bergen-Belsen concentration camp in Germany, where they were liberated by the British in April 1945.
Those too weak or sick to walk were left behind. When the 322nd Rifle Division of the Red Army arrived at the camp on January 27 they found around 7,500 prisoners and about 600 corpses had been left behind. Among the items found by the Russians were 370,000 men's suits, 837,000 women's garments, and of human hair.
The camp's liberation received little press attention at the time. Rees attributes this to three factors: the previous discovery of similar crimes at Majdanek concentration camp, competing news from the Allied summit at Yalta, and the Soviet Union's interest, for propaganda purposes, in minimizing attention to Jewish suffering.
After the war.
After liberation, parts of Auschwitz I served first as a hospital for liberated prisoners. Soviet and Polish investigators worked in the initial months to document the war crimes of the SS. In the two years that followed, the Soviets dismantled and exported the IG Farben factories, and the Birkenau barracks were looted by Polish civilians. Area residents sifted the mass graves and ashes for gold. Until 1947, some of the facilities were used as a prison camp of the Soviet NKVD.
After the site became a museum in 1947, exhumation work lasted for more than a decade. Antoni Dobrowolski, the oldest known survivor of Auschwitz, died aged 108 on October 21, 2012, in Dębno, Poland.
Camp commandant Rudolf Höss was pursued by the British Intelligence Corps, who arrested him at a farm near Flensburg, Germany, on March 11, 1946. Höss confessed to his role in the mass killings at Auschwitz in his memoirs and in his trial before the Supreme National Tribunal in Warsaw, Poland. He was convicted of murder and hanged at the camp on April 16, 1947.
Around 15 percent of Auschwitz's 6,500 staff were eventually convicted of war crimes. Poland was more active than other nations in investigating war crimes, prosecuting 673 of the total 789 Auschwitz staff ever brought to trial. On November 25, 1947, the Auschwitz Trial began in Kraków, when Poland's Supreme National Tribunal brought to court 40 former Auschwitz staff. The trial's defendants included commandant Arthur Liebehenschel, women's camp leader Maria Mandel, and camp leader Hans Aumeier. The trials ended on December 22, 1947, with 23 death sentences, 7 life sentences, and 9 prison sentences ranging from three to fifteen years. Hans Münch, an SS doctor who had several former prisoners testify on his behalf, was the only person to be acquitted.
Other former staff were hanged for war crimes in the Dachau Trials and the Belsen Trial, including camp leaders Josef Kramer, Franz Hössler, and Vinzenz Schöttl; doctor Friedrich Entress; and guards Irma Grese and Elisabeth Volkenrath. The Frankfurt Auschwitz Trials, held in West Germany from December 20, 1963 to August 20, 1965, convicted 17 of 22 defendants, giving them prison sentences ranging from life to three years and three months. Bruno Tesch and Karl Weinbacher, the owner and the chief executive officer of the firm Tesch & Stabenow, one of the suppliers of Zyklon B, were executed for knowingly supplying the chemical for use on humans.
Command and control.
Around 6,500 to 7,000 SS personnel in total were posted to Auschwitz during the war. Of these, 4 percent were officers and 26 percent were non-commissioned officers, while the remainder were rank-and-file members. Approximately three in four SS personnel worked in security. Others worked in the medical or political departments, in the camp headquarters, or in the economic administration, which was responsible for the property of dead prisoners. SS personnel at the camp included 200 women, who worked as guards, nurses, or messengers. The overall command authority for the entire camp was Department D (the Concentration Camps Inspectorate) of the "SS-Wirtschafts-Verwaltungshauptamt" (SS Economics Main Office; SS-WVHA).
Auschwitz was considered a comfortable posting by many SS members, due to many amenities and the abundance of slave labor. Of the various prisoner groups, SS officers preferred Jehovah's Witnesses for household slaves because of their nonviolent behavior. Höss lived with his wife and children in a villa just outside the camp grounds. Other SS personnel were also initially allowed to bring fiancees, wives, and children to live at the camp, but when the SS camp grew more crowded, Höss restricted further arrivals. Facilities for the SS personnel and their families included a library, swimming pool, coffee house, and a theater that hosted regular performances.
One prisoner in each work detail or prisoner block—usually an Aryan—was appointed as a "Kapo" ("head" or "overseer"). The "Kapos" received better rations and lodging and wielded tremendous power over other prisoners, whom they often abused. Very few "Kapos" were prosecuted after the war, however, due to the difficulty in determining which "Kapo" atrocities had been performed under SS orders and which had been individual actions.
About 120 SS personnel were assigned to the gas chambers and lived on site at the crematoria. Several SS personnel oversaw the killings at each gas chamber, while the bulk of the work was done by the mostly Jewish prisoners known as "Sonderkommando" (special squad). "Sonderkommando" responsibilities included guiding victims to the gas chambers and removing, looting, and cremating the corpses.
The "Sonderkommado" were housed separately from other prisoners, in somewhat better conditions. Their quality of life was further improved by access to the goods taken from murdered prisoners, which "Sonderkommando" were sometimes able to steal for themselves and to trade on Auschwitz's black market. Hungarian doctor Miklós Nyiszli reported that the "Sonderkommando" numbered around 860 prisoners when the Hungarian Jews were being killed in 1944. Many "Sonderkommando" committed suicide due to the horrors of their work; those who did not generally were shot by the SS in a matter of weeks, and new "Sonderkommando" units were then formed from incoming transports. Almost none of the 2,000 prisoners placed in these units survived to the camp's liberation.
Life in the camps.
The prisoners' day began at 4:30 am (an hour later in winter) with morning roll call. Dr. Miklos Nyiszli describes roll call as beginning 3:00 am and lasting four hours. The weather was cold in Auschwitz at that time of day, even in summer. The prisoners were ordered to line up outdoors in rows of five and had to stay there until 7:00 am, when the SS officers arrived. Meanwhile the guards would force the prisoners to squat for an hour with their hands above their heads or levy punishments such as beatings or detention for infractions such as having a missing button or an improperly cleaned food bowl. The inmates were counted and re-counted. Nyiszli describes how even the dead had to be present at roll call, standing supported by their fellow inmates until the ordeal was over. When he was a prisoner in 1944–45, five to ten men were found dead in the barracks each night. The prisoners assigned to Mengele's staff slept in a separate barracks and were awoken at 7:00 am for a roll call that only took a few minutes.
After roll call, the "Kommando", or work details, walked to their place of work, five abreast, wearing striped camp fatigues, no underwear, and ill-fitting wooden shoes without socks. A prisoner's orchestra (such as the Women's Orchestra of Auschwitz) was forced to play cheerful music as the workers left the camp. "Kapos" were responsible for the prisoners' behavior while they worked, as was an SS escort. The working day lasted 12 hours during the summer and a little less in the winter. Much of the work took place outdoors at construction sites, gravel pits, and lumber yards. No rest periods were allowed. One prisoner was assigned to the latrines to measure the time the workers took to empty their bladders and bowels. Sunday was not a work day, but the prisoners did not rest; they were required to clean the barracks and take their weekly shower. Prisoners were allowed to write (in German) to their families on Sundays. Inmates who did not speak German would trade some of their bread to another inmate for help composing their letters. Members of the SS censored the outgoing mail.
A second mandatory roll call took place in the evening. If a prisoner was missing, the others had to remain standing in place until he was either found or the reason for his absence discovered, regardless of the weather conditions, even if it took hours. After roll call, individual and collective punishments were meted out, depending on what had happened during the day, before the prisoners were allowed to retire to their blocks for the night and receive their bread rations and water. Curfew was two or three hours later. The prisoners slept in long rows of wooden bunks, lying in and on their clothes and shoes to prevent them from being stolen.
According to Nyiszli, "Eight hundred to a thousand people were crammed into the superimposed compartments of each barracks. Unable to stretch out completely, they slept there both lengthwise and crosswise, with one man's feet on another's head, neck, or chest. Stripped of all human dignity, they pushed and shoved and bit and kicked each other in an effort to get a few more inches' space on which to sleep a little more comfortably. For they did not have long to sleep".
The types of prisoners were distinguishable by triangular pieces of cloth, called "Winkel", sewn onto on their jackets below their prisoner number. Political prisoners had a red triangle, Jehovah's Witnesses had purple, criminals had green, and so on. The nationality of the inmate was indicated by a letter stitched onto the "Winkel". Jews had a yellow triangle, overlaid by a second "Winkel" if they also fit into a second category. Uniquely at Auschwitz, prisoners were tattooed with their prisoner number, on the chest for Soviet prisoners of war and on the left arm for civilians.
Prisoners received a hot drink in the morning, but no breakfast, and a thin meatless vegetable soup at noon. In the evening they received a small ration of moldy bread. Most prisoners saved some of the bread for the following morning. Nyiszli notes the daily intake did not exceed 700 calories, except for prisoners being subjected to live medical experimentation, who were better fed and clothed. Sanitary arrangements were poor, with inadequate latrines and a lack of fresh water. In Auschwitz II-Birkenau, latrines were not installed until 1943, two years after camp construction began. The camps were infested with vermin such as disease-carrying lice, and the inmates suffered and died in epidemics of typhus and other diseases. Noma, a bacterial infection occurring among the malnourished, was a common cause of death among children in the Gypsy camp.
Block 11 of Auschwitz I was the prison within the prison, where violators of the numerous rules were punished. Some prisoners were made to spend the nights in standing cells. These cells were about , and held four men; they could do nothing but stand, and were forced during the day to work with the other prisoners. Prisoners sentenced to death for attempting to escape were confined in a dark cell and given neither food nor water until they were dead.
In the basement were the "dark cells", which had only a very tiny window and a solid door. Prisoners placed in these cells gradually suffocated as they used up all the oxygen in the cell; sometimes the SS lit a candle in the cell to use up the oxygen more quickly. Many were subjected to hanging with their hands behind their backs for hours, even days, thus dislocating their shoulder joints.
Selection and extermination process.
On July 31, 1941, Hermann Göring gave written authorization to Heydrich, Chief of the Reich Main Security Office (RSHA), to prepare and submit a plan for "Die Endlösung der Judenfrage" (the Final Solution of the Jewish question) in territories under German control and to coordinate the participation of all involved government organizations. The resulting "Generalplan Ost" (General Plan for the East) called for deporting the population of occupied Eastern Europe and the Soviet Union to Siberia, for use as slave labour or to be murdered. In addition to eliminating Jews, the Nazis also planned to reduce the population of the conquered territories by 30 million people through starvation in an action called the Hunger Plan. Food supplies would be diverted to the German army and German civilians. Cities would be razed and the land allowed to return to forest or resettled by German colonists.
Somewhere around the time of the failed offensive against Moscow in December 1941, Hitler resolved that the Jews of Europe were to be exterminated immediately. Plans for the total eradication of the Jewish population of Europe—eleven million people—were formalized at the Wannsee Conference on January 20, 1942. Some would be worked to death and the rest would be killed. Initially the victims were killed with gas vans or by "Einsatzgruppen" firing squads, but these methods proved impracticable for an operation of this scale. By 1942, killing centers at Auschwitz, Sobibór, Treblinka, and other Nazi extermination camps replaced "Einsatzgruppen" as the primary method of mass killing.
The first mass exterminations at Auschwitz took place in early September 1941, when 900 inmates were killed by gathering them in the basement of Block 11 and gassing them with Zyklon B. This building proved unsuitable for mass gassings, so the site of the killings was moved to the crematorium at Auschwitz I (Crematorium I, which operated until July 1942). There, more than 700 victims could be killed at once. In order to keep the victims calm, they were told they were to undergo disinfection and de-lousing. They were ordered to undress outside and then were locked in the building and gassed. After its decommissioning as a gas chamber, the building was converted to a storage facility and later served as an air raid shelter for the SS. The gas chamber and crematorium were reconstructed after the war using the original components, which remained on site. Some 60,000 people were killed at Crematorium I.
Mass exterminations were moved to two provisional gas chambers (Bunkers 1 and 2), where the killings continued while the larger Crematoria II, III, IV, and V were under construction. Bunker 2 was temporarily reactivated from May to November 1944, when large numbers of Hungarian Jews were exterminated. In summer 1944 the capacity of the crematoria and outdoor incineration pits was 20,000 bodies per day. A planned sixth facility—Crematorium VI—was never built.
Prisoners were transported from all over German-occupied Europe by rail, arriving in daily convoys. By July 1942, the SS were conducting "selections". Incoming Jews were segregated; those deemed able to work were sent to the right and admitted into the camp, and those deemed unfit for labor were sent to the left and immediately gassed. The group selected to die, about three-quarters of the total, included almost all children, women with small children, all the elderly, and all those who appeared on brief and superficial inspection by an SS doctor not to be completely fit. After the selection process was complete, those too ill or too young to walk to the crematoria were transported there on trucks or killed on the spot with a bullet to the head. The belongings of the arrivals were seized by the SS and sorted in an area of the camp called "Canada", so called because Canada was seen as a land of plenty. Many of the SS at the camp enriched themselves by pilfering the confiscated property.
SS officers told the victims they were to take a shower and undergo delousing. The victims undressed in an outer chamber and walked into the gas chamber, which was disguised as a shower facility. Some were even issued soap and a towel. The Zyklon B was delivered by ambulance to the crematoria by a special SS bureau known as the Hygienic Institute. The actual delivery of the gas to the victims was always handled by the SS, on the order of the supervising SS doctor. After the doors were shut, SS men dumped in the Zyklon B pellets through vents in the roof or holes in the side of the chamber. The victims were dead within 20 minutes. Despite the thick concrete walls, screaming and moaning from within could be heard outside. In one failed attempt to muffle the noise, two motorcycle engines were revved up to full throttle nearby, but the sound of yelling could still be heard over the engines.
"Sonderkommando" wearing gas masks then dragged the bodies from the chamber. The victims' glasses, artificial limbs, jewelry, and hair were removed, and any dental work was extracted so the gold could be melted down. The corpses were burned in the nearby incinerators, and the ashes were buried, thrown in the river, or used as fertilizer.
The gas chambers worked to their fullest capacity from April–July 1944, during the massacre of Hungary's Jews. Hungary was an ally of Germany during the war, but it had resisted turning over its Jews until Germany invaded that March. A rail spur leading directly into Birkenau was completed that May to deliver the victims closer to the gas chambers. From 14 May until early July 1944, 437,000 Hungarian Jews, half of the pre-war population, were deported to Auschwitz, at a rate of 12,000 a day for a considerable part of that period. The incoming volume was so great that the SS resorted to burning corpses in open-air pits as well as in the crematoria. The last selection took place on October 30, 1944.
Medical experiments.
German doctors performed a wide variety of experiments on prisoners at Auschwitz. SS doctors tested the efficacy of X-rays as a sterilization device by administering large doses to female prisoners. Prof. Dr. Carl Clauberg injected chemicals into women's uteruses in an effort to glue them shut. Bayer, then a subsidiary of IG Farben, bought prisoners to use as research subjects for testing new drugs. Prisoners were also deliberately infected with spotted fever for vaccination research and exposed to toxic substances to study the effects.
The most infamous doctor at Auschwitz was Josef Mengele, known as the "Angel of Death". Particularly interested in research on identical twins, Mengele performed cruel experiments on them, such as inducing diseases in one twin and killing the other when the first died to perform comparative autopsies. He also took a special interest in dwarfs, and he deliberately induced noma in twins, dwarfs, and other prisoners to study the effects.
Kurt Heissmeyer took twenty Jewish children from Auschwitz to use in pseudoscientific medical experiments at the Neuengamme concentration camp. In April 1945, the children were killed by hanging to conceal the project.
A skeleton collection was obtained from among a pool of 115 Jewish Auschwitz inmates, chosen for their perceived stereotypical racial characteristics. Rudolf Brandt and Wolfram Sievers, general manager of the "Ahnenerbe" (a Nazi research institute), were responsible for delivering the skeletons to the collection of the Anatomy Institute at the Reich University of Strasbourg in the Alsace region of Occupied France. The collection was sanctioned by Himmler and under the direction of August Hirt. Ultimately 87 of the inmates were shipped to Natzweiler-Struthof and killed in August 1943. Brandt and Sievers were later convicted in the Doctors' Trial in Nuremberg.
Death toll.
The exact number of victims at Auschwitz is difficult to fix with certainty, as many prisoners were never registered and much evidence was destroyed by the SS in the final days of the war. As early as 1942, Himmler visited the camp and ordered that "all mass graves were to be opened and the corpses burned. In addition the ashes were to be disposed of in such a way that it would be impossible at some future time to calculate the number of corpses burned."
Shortly following the camp's liberation, the Soviet government stated that four million people had been killed on the site, a figure now regarded as greatly exaggerated. While under interrogation, Höss said that Adolf Eichmann told him that two and a half million Jews had been killed in gas chambers and about half a million had died of other causes. Later he wrote, "I regard two and a half million far too high. Even Auschwitz had limits to its destructive possibilities". Raul Hilberg's 1961 work "The Destruction of the European Jews" estimated the number killed at a maximum of 1,000,000 Jewish victims, and Gerald Reitlinger's 1968 book "The Final Solution" estimated the number killed at 800,000 to 900,000.
In 1983, French scholar George Wellers was one of the first to use German data on deportations to estimate the number killed at Auschwitz, arriving at a figure of 1,471,595 dead, including 1.35 million Jews and 86,675 Poles. A larger study started by Franciszek Piper used timetables of train arrivals combined with deportation records to calculate at least 960,000 Jewish deaths and at least 1.1 million total deaths, a figure adopted as official by the Auschwitz-Birkenau State Museum in the 1990s. Piper also stated that a figure of as many as 1.5 million total deaths was possible.
By nation, the greatest number of Auschwitz's Jewish victims were from Hungary, accounting for 438,000 deaths, followed by Polish Jews (300,000 deaths), French (69,000), Dutch (60,000), and Greek (55,000). Fewer than one percent of Soviet Jews murdered in the Holocaust were killed in Auschwitz, as German forces had already been driven from Russia when the killing at Auschwitz reached its peak in 1944. Approximately 1 in 6 Jews killed in the Holocaust died at the camp.
The next largest group of victims were non-Jewish Poles, who accounted for 70,000 to 75,000 deaths. Twenty-one thousand Roma and Sinti were killed, along with 15,000 Soviet POWs and 10,000 to 15,000 peoples of other nations. Around 400 Jehovah's Witnesses were imprisoned at Auschwitz, at least 152 of whom died.
Escapes, resistance, and the Allies' knowledge of the camps.
Inmates were at times able to distribute information from the camp via messages and shortwave radio transmissions. The Polish government-in-exile in London first reported the gassing of prisoners on July 21, 1942. However, these reports were for a long time discarded as exaggerated or unreliable by the Allied Powers, Germany's opponents.
Information regarding Auschwitz was also available to the Allies during the years 1940–43 by the accurate and frequent reports of Polish Home Army (Armia Krajowa) Captain Witold Pilecki. Pilecki was the only known person to volunteer to be imprisoned at Auschwitz concentration camp, spending 945 days there. He gathered evidence of genocide and organized resistance structures known as Związek Organizacji Wojskowej (ZOW) at the camp. His first report was smuggled to the outside world in November 1940, through an inmate who was released from the camp. He eventually escaped on April 27, 1943, but his personal report of mass killings was dismissed as exaggeration by the Allies, as were his previous ones.
The first information about Auschwitz concentration camp was published in winter 1940–41 in the Polish underground newspapers "Polska żyje" ("Poland lives") and "Biuletyn Informacyjny" ("Newsletter"). From 1942 members of the Bureau of Information and Propaganda of the Warsaw area Home Army published in occupied Poland a few brochures based on the accounts of escapees. The first of these was a fictional memoir "Oświęcim. Pamiętnik więźnia" ("Auschwitz: Diary of a prisoner"), written by Halina Krahelska and published in April 1942 in Warsaw. Also published in 1942 were the books "Auschwitz: obóz śmierci" ("Auschwitz: camp of death") written by Natalia Zarembina, and "W piekle" ("In Hell") by Zofia Kossak-Szczucka, the Polish writer, social activist, and founder of Żegota.
In 1943, the "Kampfgruppe Auschwitz" (Combat Group Auschwitz) was organized with the aim of sending out information about what was happening. "Sonderkommandos" buried notes in the ground, hoping they would be found by the camp's liberators. The group also took and smuggled out photographs of corpses and preparations for mass killings in mid-1944.
The attitude of the Allies changed with receipt of the detailed, 32-page Vrba–Wetzler report, compiled by two Jewish prisoners, Rudolf Vrba and Alfréd Wetzler, who escaped on April 7, 1944. This report finally convinced Allied leaders that mass killings were taking place in Auschwitz.
Details from the Vrba-Wetzler report were released to the Swiss press and printed on June 6 by "The New York Times". Auschwitz Plans originating with the Polish government were provided to the U.K foreign ministry in August 1944.
Starting with a plea from the Slovakian rabbi Chaim Michael Dov Weissmandl in May 1944, there was a growing campaign by Jewish organizations to persuade the Allies to bomb Auschwitz or the railway lines leading to it. At one point British Prime Minister Winston Churchill ordered that such a plan be prepared, but he was told that precision bombing the camp to free the prisoners or disrupt the railway was not technically feasible.
In 1978, historian David S. Wyman published an essay titled "Why Auschwitz Was Never Bombed", arguing that the US Air Force had the capability to attack Auschwitz and should have done so; books by Bernard Wasserstein and Martin Gilbert raised similar questions about British inaction. Since the 1990s, other historians have argued that Allied bombing accuracy was not sufficient for Wyman's proposed attack, and that counterfactual history is an inherently problematic endeavor. The controversy over this decision has lasted to the present day in both countries.
Individual escape attempts.
At least 802 prisoners attempted to escape from the Auschwitz camps, mostly Polish or Soviet prisoners fleeing from work sites outside the camp. 144 were successful. The fates of 331 of the escapees are unknown. A common punishment for escape attempts was death by starvation; the families of successful escapees were sometimes arrested and interned in Auschwitz and prominently displayed to deter others. If someone did manage to escape, the SS picked ten people at random from the prisoner's block and starved them to death.
One daring escape from Auschwitz was staged by Ukrainian Eugeniusz Bendera and three Poles, Kazimierz Piechowski, Stanisław Gustaw Jaster, and Józef Lempart, on June 20, 1942. After breaking into a warehouse, the four dressed as members of the "SS-Totenkopfverbände" (the SS units responsible for concentration camps), armed themselves, and stole an SS staff car, which they then drove unchallenged through the main gate.
On June 24, 1944, a Belgian Jewish woman, Mala Zimetbaum, escaped with her Polish boyfriend, Edek Galinski, also in stolen SS uniforms. They were later recaptured, tortured, and executed by the SS.
Birkenau revolt.
The "Sonderkommando" units were aware that as witnesses to the killings, they themselves would eventually be killed to hide Nazi crimes. Though they knew that it would mean their deaths, the "Sonderkommando" of Birkenau "Kommando" III staged an uprising on October 7, 1944, following an announcement that some of them would be selected to be "transferred to another camp"—a common Nazi ruse for the murder of prisoners. The "Sonderkommando" attacked the SS guards with stones, axes, and makeshift hand grenades. As the SS set up machine guns to attack the prisoners in Crematorium IV, the "Sonderkommando" in Crematorium II also revolted, some of them managing to escape the compound. The rebellion was suppressed by nightfall.
Ultimately, three SS guards were killed—one of whom was burned alive by the prisoners in the oven of Crematorium II—and 250 "Sonderkommando" were killed. Hundreds of prisoners escaped, but were all soon captured and executed, along with an additional group who participated in the revolt. Crematorium IV was destroyed in the fighting, and a group of prisoners in the gas chamber of Crematorium V was spared in the chaos.
Legacy.
In the decades since its liberation, Auschwitz has become a primary symbol of the Holocaust. Historian Timothy D. Snyder attributes this to the camp's high death toll as well as its "unusual combination of an industrial camp complex and a killing facility", which left behind far more witnesses than single-purpose killing facilities such as Chełmno or Treblinka. The United Nations General Assembly has designated January 27, the date of the camp's liberation, as International Holocaust Remembrance Day. In a speech on the fiftieth anniversary of the liberation, German chancellor Helmut Kohl described Auschwitz as the "darkest and most horrific chapter of German history".
Notable memoirists of the camp include Primo Levi, Elie Wiesel, and Tadeusz Borowski. In "If This Is a Man", Levi wrote that the concentration camps represented the epitome of the totalitarian system:
Psychiatrist Viktor Frankl drew on his imprisonment at Auschwitz in composing "Man's Search for Meaning" (1946), one of the most widely read works about the camp. An existentialist work, the book argues that individuals can find purpose even among great suffering, and that this sense of purpose sustains them. Wiesel wrote about his own imprisonment at Auschwitz in "Night" (1960) and other works, and became a prominent spokesman against ethnic violence. In 1986, he was awarded the Nobel Peace Prize.
Camp survivor Simone Veil was later elected President of the European Parliament, serving from 1979–82. Two Auschwitz victims—Maximilian Kolbe, a priest who volunteered to die by starvation in place of a stranger, and Edith Stein, a Jewish convert to Catholicism—were later named saints of the Roman Catholic Church.
Auschwitz-Birkenau State Museum.
On July 2, 1947, the Polish government passed a law establishing a state memorial to the victims of Nazism on the site of the camp. In 1955, an exhibition opened displaying prisoner mug shots; hair, suitcases, and shoes taken from murdered prisoners; canisters of Zyklon B pellets; and other objects related to the killings. UNESCO added the camp to its list of World Heritage Sites in 1979. In 2011, the museum drew 1,400,000 visitors.
Pope John Paul II performed mass over the train tracks leading to the camp on June 7, 1979. In the decades following his visit, controversies erupted over a group of Carmelite nuns founding a convent on the site and erecting a large cross originally used in the pope's mass. Protesters objected to what they saw as Christianization of the site, while others argued that the cross's presence effectively recognized the camp's Catholic victims.
The , wrought-iron "Arbeit macht frei" sign over the entrance to Auschwitz I was stolen on December 18, 2009. Authorities temporarily replaced the stolen sign with a replica. Police found the sign, cut into three parts, in northern Poland two days later. "Aftonbladet" reported that the sign had been stolen by Polish thieves on behalf of a Swedish right-wing extremist group hoping to use proceeds from the proposed sale of the sign to a collector of Nazi memorabilia, to finance a series of terror attacks aimed at influencing voters in upcoming Swedish parliamentary elections. Three men pled guilty to the theft, but arrest warrants had to be issued when they failed to return from compassionate leave.
On September 4, 2003, three Israeli Air Force F-15 Eagles performed a fly-over of Auschwitz-Birkenau during a ceremony at the camp below. The flight was led by Major-General Amir Eshel, the son of Holocaust survivors.

</doc>
<doc id="2007" url="http://en.wikipedia.org/wiki?curid=2007" title="Archery">
Archery

Archery is the art, practice, or skill of propelling arrows with the use of a bow, from Latin "arcus". Historically, archery has been used for hunting and combat, while in modern times, its main use is that of a competitive sport and recreational activity. A person who participates in archery is typically known as an "archer" or a "bowman", and one who is fond of or an expert at archery can be referred to as a toxophilite.
History.
The bow seems to have been invented in the later Paleolithic or early Mesolithic periods. The oldest indication for its use in Europe comes from the in the north of Hamburg, Germany and dates from the late Paleolithic, about 10,000–9000 BCE. The arrows were made of pine and consisted of a mainshaft and a long fore shaft with a flint point. There are no definite earlier bows; previous pointed shafts are known, but may have been launched by spear-throwers rather than bows. The oldest bows known so far come from the Holmegård swamp in Denmark. Bows eventually replaced the spear-thrower as the predominant means for launching shafted projectiles, on every continent except Australia, though spear-throwers persisted alongside the bow in parts of the Americas, notably Mexico and among the Inuit.
Bows and arrows have been present in Egyptian culture since its predynastic origins. In the Levant, artifacts which may be arrow-shaft straighteners are known from the Natufian culture, (c. 12,800–10,300 BP (before present)) onwards. The Khiamian and PPN A shouldered Khiam-points may well be arrowheads.
Classical civilizations, notably the Assyrians, Armenians, Persians, Parthians, Indians, Koreans, Chinese, and Japanese fielded large numbers of archers in their armies. The English longbow proved its worth for the first time in Continental warfare at the Battle of Crécy. In the Americas archery was widespread at European contact.
Archery was highly developed in Asia. The Sanskrit term for archery, dhanurveda, came to refer to martial arts in general. In East Asia, Goguryeo, one of the Three Kingdoms of Korea was well known for its regiments of exceptionally skilled archers.
Mounted archery.
Central Asian tribesmen (after the domestication of the horse) and American Plains Indians (after gaining access to horses) became extremely adept at archery on horseback. Lightly armoured, but highly mobile archers were excellently suited to warfare in the Central Asian steppes, and they formed a large part of armies that repeatedly conquered large areas of Eurasia. Shorter bows are more suited to use on horseback, and the composite bow enabled mounted archers to use powerful weapons. Empires throughout the Eurasian landmass often strongly associated their respective "barbarian" counterparts with the usage of the bow and arrow, to the point where powerful states like the Han Dynasty referred to their neighbours, the Xiong-nu, as "Those Who Draw the Bow" For example, Xiong-nu mounted bowmen made them more than a match for the Han military, and their threat was at least partially responsible for Chinese expansion into the Ordos region, to create a stronger, more powerful buffer zone against them. It is possible that "barbarian" peoples were responsible for introducing archery or certain types of bows to their "civilized" counterparts—the Xiong-nu and the Han being one example. Similarly, short bows seem to have been introduced to Japan by northeast Asian groups.
Decline of archery.
The development of firearms rendered bows obsolete in warfare. Despite the high social status, ongoing utility, and widespread pleasure of archery in Armenia, China, Egypt, England, America, India, Japan, Korea, Turkey and elsewhere, almost every culture that gained access to even early firearms used them widely, to the neglect of archery. Early firearms were vastly inferior in rate-of-fire, and were very susceptible to wet weather. However, they had longer effective range and were tactically superior in the common situation of soldiers shooting at each other from behind obstructions. They also required significantly less training to use properly, in particular penetrating steel armour without any need to develop special musculature. Armies equipped with guns could thus provide superior firepower, and highly trained archers became obsolete on the battlefield. However, the bow and arrow is still an effective weapon, and archers have seen action in the 21st century. Traditional archery remains in use for sport, and for hunting in many areas.
Eighteenth-century revival.
Early recreational archery societies included the Finsbury Archers and the Kilwinning Papingo, established in 1688. The latter held competitions in which the archers had to dislodge a wooden parrot from the top of an abbey tower. The Company of Scottish Archers was formed in 1676 and is one of the oldest sporting bodies in the world. It remained a small and scattered pastime, however, until the late 18th century when it experienced a fashionable revival among the aristocracy. Sir Ashton Lever, an antiquarian and collector, formed the Toxophilite Society in London in 1781, with the patronage of George, the Prince of Wales.
Archery societies were set up across the country, each with its own strict entry criteria and outlandish costumes. Recreational archery soon became extravagant social and ceremonial events for the nobility, complete with flags, music and 21 gun salutes for the competitors. The clubs were "the drawing rooms of the great country houses placed outside" and thus came to play an important role in the social networks of local elites. As well as its emphasis on display and status, the sport was notable for its popularity with females. Young women could not only compete in the contests but retain and show off their sexuality while doing so. Thus, archery came to act as a forum for introductions, flirtation and romance. It was often consciously styled in the manner of a Medieval tournament with titles and laurel wreaths being presented as a reward to the victor. General meetings were held from 1789, in which local lodges convened together to standardise the rules and ceremonies. Archery was also co-opted as a distinctively British tradition, dating back to the lore of Robin Hood and it served as a patriotic form of entertainment at a time of political tension in Europe. The societies were also elitist, and the new middle class bourgeoisie were excluded from the clubs due to their lack of social status.
After the Napoleonic Wars, the sport became increasingly popular among all classes, and it was framed as a nostalgic reimagining of the preindustrial rural Britain. Particularly influential was Sir Walter Scott's 1819 novel, "Ivanhoe" that depicted the heroic character Lockseley winning an archery tournament.
A modern sport.
The 1840s saw the first attempts at turning the recreation into a modern sport. The first Grand National Archery Society meeting was held in York in 1844 and over the next decade the extravagant and festive practices of the past were gradually whittled away and the rules were standardised as the 'York Round' - a series of shoots at 60, 80, and 100 yards. Horace A. Ford helped to improve archery standards and pioneered new archery techniques. He won the Grand National 11 times in a row and published a highly influential guide to the sport in 1856.
Towards the end of the 19th century, the sport experienced declining participation as alternative sports such as croquet and tennis became more popular among the middle class. By 1889, just 50 archery clubs were left in Britain, but it was still included as a sport at the 1900 Paris Olympics.
In the United States, primitive archery was revived in the early 20th century. The last of the Yahi Indian tribe, a native known as Ishi, came out of hiding in California in 1911. His doctor, Saxton Pope, learned many of Ishi's traditional archery skills, and popularized them. The Pope and Young Club, founded in 1961 and named in honor of Pope and his friend, Arthur Young, became one of North America's leading bowhunting and conservation organizations. Founded as a nonprofit scientific organization, the Club was patterned after the prestigious Boone and Crockett Club and advocated responsible bowhunting by promoting quality, fair chase hunting, and sound conservation practices.
From the 1920s, professional engineers took an interest in archery, previously the exclusive field of traditional craft experts. They led the commercial development of new forms of bow including the modern recurve and compound bow. These modern forms are now dominant in modern Western archery; traditional bows are in a minority. In the 1980s, the skills of traditional archery were revived by American enthusiasts, and combined with the new scientific understanding. Much of this expertise is available in the "Traditional Bowyer's Bibles" (see Additional reading). Modern game archery owes much of its success to Fred Bear, an American bow hunter and bow manufacturer.
Mythology.
Deities and heroes in several mythologies are described as archers, including the Greek Artemis and Apollo, the Roman Diana and Cupid, the Germanic Agilaz, continuing in legends like those of Wilhelm Tell, Palnetoke, or Robin Hood. Armenian Hayk and Babylonian Marduk, Indian Arjuna, Abhimanyu, Eklavya, Karna, Rama, and Shiva, and Persian Arash were all archers. Earlier Greek representations of Heracles normally depict him as an archer.
The Nymphai Hyperboreioi (Νύμφαι Ὑπερβόρειοι) were worshipped on the Greek island of Delos as attendants of Artemis, presiding over aspects of archery; Hekaerge (Ἑκαέργη), represented distancing, Loxo (Λοξώ), trajectory, and Oupis (Οὖπις), aim. The
In East Asia, Yi the archer and his apprentice Feng Meng appear in several early Chinese myths, and the historical character of Zhou Tong features in many fictional forms. Jumong, the first Taewang of the Goguryeo kingdom of the Three Kingdoms of Korea, is claimed by legend to have been a near-godlike archer. Archery features in the story of Oguz Khagan.
In West African Yoruba belief, Osoosi is one of several deities of the hunt who are identified with bow and arrow iconography and other insignia associated with archery.
Equipment.
Types of bows.
While there is great variety in the construction details of bows (both historic and modern), all bows consist of a string attached to elastic limbs that store mechanical energy imparted by the user drawing the string. Bows may be broadly split into two categories: those drawn by pulling the string directly and those that use a mechanism to pull the string.
Directly drawn bows may be further divided based upon differences in the method of limb construction, notable examples being self bows, laminated bows and composite bows. Bows can also be classified by the bow shape of the limbs when unstrung; in contrast to simple straight bows, a recurve bow has tips that curve away from the archer when the bow is unstrung. The cross-section of the limb also varies; the classic longbow is a tall bow with narrow limbs that are D-shaped in cross section, and the flatbow has flat wide limbs that are approximately rectangular in cross-section. The classic D-shape comes from the use of the wood of the yew tree. The sap-wood is best suited to the tension on the back of the bow, and the heart-wood to the compression on the belly. Hence, a cross-section of a yew longbow shows the narrow, light-coloured sap-wood on the 'straight' part of the D, and the red/orange heartwood forms the curved part of the D, to balance the mechanical tension/compression stress. Cable-backed bows use cords as the back of the bow; the draw weight of the bow can be adjusted by changing the tension of the cable. They were widespread among Inuit who lacked easy access to good bow wood. One variety of cable-backed bow is the Penobscot bow or Wabenaki bow, invented by Frank Loring (Chief Big Thunder) about 1900. It consists of a small bow attached by cables on the back of a larger main bow.
Compound bows are designed to reduce the force required to hold the string at full draw, hence allowing the archer more time to aim with less muscular stress. Most compound designs use cams or elliptical wheels on the ends of the limbs to achieve this. A typical let-off is anywhere from 65%–80%. For example, a 60-pound bow with 80% let-off will only require 12 pounds of force to hold at full draw. Up to 99% let-off is possible. The compound bow was invented by Holless Wilbur Allen in the 1960s (a US patent was filed in 1966 and granted in 1969) and it has become the most widely used type of bow for all forms of archery in North America.
Mechanically drawn bows typically have a stock or other mounting, such as the crossbow. They are not limited by the strength of a single archer and larger varieties have been used as siege engines.
Types of arrows and fletchings.
The most common form of arrow consists of a shaft with an arrowhead attached to the front end and with fletchings and a nock attached to the other end. Arrows across time and history are normally carried in a container known as a quiver, which can take many different forms. Shafts of arrows are typically composed of solid wood, bamboo fiberglass, aluminium alloy, carbon fiber, or composite materials. Wooden arrows are prone to warping. Fiberglass arrows are brittle, but can be produced to uniform specifications easily. Aluminium shafts were a very popular high-performance choice in the latter half of the 20th century due to their straightness, lighter weight, and subsequently higher speed and flatter trajectories. Carbon fiber arrows became popular in the 1990s and are very light, flying even faster and flatter than aluminium arrows. Today, arrows made up of composite materials are the most popular tournament arrows at Olympic Events, especially the Easton X10 and A/C/E.
The arrowhead is the primary functional component of the arrow. Some arrows may simply use a sharpened tip of the solid shaft, but it is far more common for separate arrowheads to be made, usually from metal, stone, or other hard materials. The most commonly used forms are target points, field points, and broadheads, although there are also other types, such as bodkin, judo, and blunt heads.
Fletching is traditionally made from bird feathers. Also solid plastic vanes and thin sheetlike spin vanes are used. They are attached near the nock (rear) end of the arrow with thin double sided tape, glue, or, traditionally, sinew. Three fletches is the most common configuration in all cultures, though as many as six have been used. Two will result in unstable arrow flight. When "three-fletched" the fletches are equally spaced around the shaft with one placed such that it is perpendicular to the bow when nocked on the string (though with modern equipment, variations are seen especially when using the modern spin vanes). This fletch is called the "index fletch" or "cock feather" (also known as "the odd vane out" or "the nocking vane") and the others are sometimes called the "hen feathers". Commonly, the cock feather is of a different color. However, if archers are using fletching made of feather or similar material, they may use same color vanes, as different dyes can give varying stiffness to vanes, resulting in less precision. When "four-fletched", often two opposing fletches are cock feathers and occasionally the fletches are not evenly spaced.
The fletching may be either "parabolic" (short feathers in a smooth parabolic curve) or "shield" (generally shaped like half of a narrow shield) cut and is often attached at an angle, known as "helical" fletching, to introduce a stabilizing spin to the arrow while in flight. Whether helicial or straight fletched, when natural fletching (bird feathers) are used it is critical that all feathers come from the same side of the bird. Oversized fletchings can be used to accentuate drag and thus limit the range of the arrow significantly; these arrows are called "flu-flus". Misplacement of fletchings can often change the arrow's flight path dramatically.
Bow string.
Dacron and other modern materials offer high strength for their weight and are used on most modern bows. Linen and other traditional materials are still used on traditional bows. Almost any fiber can be made into a bow string. The author of "Arab Archery" suggests the hide of a young, emaciated camel. Njál's saga describes the refusal of a wife, Hallgerður, to cut her hair in order to make an emergency bowstring for her husband, Gunnar Hámundarson, who is then killed.
Protective equipment.
Most archers wear a bracer (also known as an arm-guard) to protect the inside of the bow arm from being hit by the string and prevent clothing from catching the bow string. The bracer does not brace the arm; the word comes from the armoury term "brassard", meaning an armoured sleeve or badge. The Navajo people have developed highly ornamented bracers as non-functional items of adornment. Some archers (mostly women) also wear protection on their chests, called chestguards or plastrons. The myth of the Amazons was that they had one breast removed to solve this problem. Roger Ascham mentions one archer, presumably with an unusual shooting style, who wore a leather guard for his face.
The drawing digits are normally protected by a leather tab, glove, or thumb ring. A simple tab of leather is commonly used, as is a skeleton glove. Medieval Europeans probably used a complete leather glove.
Eurasiatic archers who used the thumb or Mongolian draw protected their thumbs, usually with leather according to the author of "Arab Archery", but also with special rings of various hard materials. Many surviving Turkish and Chinese examples are works of considerable art. Some are so highly ornamented that the users could not have used them to loose an arrow. Possibly these were items of personal adornment, and hence value, remaining extant whilst leather had virtually no intrinsic value and would also deteriorate with time. In traditional Japanese archery a special glove is used, provided with a ridge which is used to draw the string.
Release aids.
A release aid is a mechanical device designed to give a crisp and precise loose of arrows from a compound bow. In the most commonly used, the string is released by a finger-operated trigger mechanism, held in the archer's hand or attached to their wrist. In another type, known as a back-tension release, the string is automatically released when drawn to a pre-determined tension.
Stabilisers.
Stabilisers are mounted usually on the front of the bow below the handle and on the right side, below the handle to help aiming by keeping the bow steady.
Shooting technique and form.
The standard convention on teaching archery, is to hold the bow depending upon eye dominance (though in modern Kyudo all archers are trained to hold the bow in the right hand). Therefore, if you were right eye dominant, you would hold the bow in the left hand, and draw the string with the right hand. Not everybody agrees with this line of thought, though. A smoother, and more fluid release of the string produces the finest and most consistently repeatable shots, and therefore determines the accuracy of the arrow flight. There are some who believe that the hand with the greatest dexterity, should be the hand that draws and releases the string. Either eye can be used for aiming, and even the less dominant eye can be trained over time to effectively become the more dominant. This can be achieved by retraining with the use of an eye-patch over the dominant eye as a temporary measure.
The hand that holds the bow is referred to as the bow hand and its arm the bow arm. The opposite hand is called the drawing hand or string hand. Terms such as bow shoulder or string elbow follow the same convention.
If shooting according to eye dominance, then right-eye-dominant archers, shooting in a conventional way, will hold the bow with their left hand.
If shooting according to hand dexterity, then the string will be drawn with whichever hand possesses the greatest dexterity, regardless of eye dominance.
Modern form.
To shoot an arrow, an archer first assumes the correct stance. The body should be at or nearly perpendicular to the target and the shooting line, with the feet placed shoulder-width apart. As an archer progresses from beginner to a more advanced level other stances such as the "open stance" or the "closed stance" may be used, although many choose to stick with a "neutral stance". Each archer will have a particular preference but mostly this term indicates that the leg furthest from the shooting line will be a half to a whole foot-length from the other foot, on the ground.
To load, the bow is pointed toward the ground, tipped slightly clockwise of vertical (for a right handed shooter) and the shaft of the arrow is placed on the arrow rest or shelf. The back of the arrow is attached to the bowstring with the nock (a small locking groove located at the proximal end of the arrow). This step is called "nocking the arrow". Typical arrows with three vanes should be oriented such that a single vane, the "cock feather", is pointing away from the bow, to improve the clearance of the arrow as it passes the arrow rest.
A compound bow is fitted with a special type of arrow rest, known as a launcher, and the arrow is usually loaded with the cock feather/vane pointed either up, or down, depending upon the type of launcher being used.
The bowstring and arrow are held with three fingers, or with a mechanical arrow release. Most commonly, for finger shooters, the index finger is placed above the arrow and the next two fingers below, although several other techniques have their adherents around the world, involving three fingers below the arrow, or an arrow pinching technique. "Instinctive" shooting is a technique eschewing sights and is often preferred by traditional archers (shooters of longbows and recurves). In either the split finger or three finger under case, the string is usually placed in either the first or second joint of the fingers.
Another type of string hold, used on traditional bows, is the type favoured by the Mongol warriors, known as the "thumb release", style. This involves using the thumb to draw the string, with the fingers curling around the thumb to add some support. To release the string, the fingers are opened out and the thumb relaxes to allow the string to slide off the thumb. When using this type of release, the arrow should rest on the same side of the bow as the drawing hand i.e. Left hand draw = arrow on left side of bow.
The bow is then raised and drawn, with varying alignments used for vertical versus slightly canted bow positions. This is often one fluid motion for shooters of recurves and longbows which tends to vary from archer to archer, although for a compound shooter, there is often a slightly-jerky movement occurring during the drawback of the arrow at around midpoint where the draw weight is at its maximum, before relaxing into a comfortable stable full draw position. The string hand is drawn towards the face, where it should rest lightly at the chosen fixed "anchor point". This point is consistent from shot to shot and is usually at the corner of the mouth, on the chin, to the cheek, or to the ear, depending upon one's preferred shooting style. The bow arm is held outwards toward the target. The elbow of this arm should be rotated so that the inner elbow is perpendicular to the ground, though archers with hyper extendable elbows tend to angle the inner elbow toward the ground as exemplified by the Korean archer Jang Yong-Ho. This keeps the forearm out of the way of the bowstring.
In modern form, the archer stands erect, forming a "T". The archer's lower trapezius muscles are used to pull the arrow to the anchor point. Some modern bows will be equipped with a mechanical device, called a clicker, which produces a clicking sound when the archer reaches the correct draw length. In contrast, traditional English Longbow shooters step "into the bow", exerting force with both the bow arm and the string hand arm simultaneously, especially when using bows having draw weights from 100 lbs to over 175 lbs. Heavily-stacked traditional bows (recurves, long bows, and the like) are released immediately upon reaching full draw at maximum weight, whereas compound bows reach their maximum weight in or around mid-draw, dropping holding weight significantly at full draw. Compound bows are often held at full draw for a short time to achieve maximum accuracy.
The arrow is typically released by relaxing the fingers of the drawing hand (see Bow draw), or triggering the mechanical release aid. Usually the release aims to keep the drawing arm rigid, the bow hand relaxed, and the arrow is moved back using the back muscles, as opposed to using just arm motions. An archer should also pay attention to the recoil or "follow through" of his or her body, as it may indicate problems with form (technique) that affect accuracy.
Aiming methods.
There are two main forms of aiming in archery: using a mechanical or fixed sight, or barebow.
Mechanical sights can be affixed to the bow to aid in aiming. They can be as simple as a pin, or may use optics with magnification. They usually also have a peep sight (rear sight) built into the string which aids in a consistent anchor point. Modern compound bows automatically limit the draw length which gives a consistent arrow velocity while traditional bows allow great variation in draw length. Mechanical methods to make a traditional bow's draw length consistent are sometimes used. Barebow archers often use a sight picture which includes the target, the bow, the hand, the arrow shaft and the arrow tip, as seen at the same time by the archer. With a fixed "anchor point" (where the string is brought to, or close to, the face), and a fully extended bow arm, successive shots taken with the sight picture in the same position will fall on the same point. This allows the archer to adjust aim with successive shots in order to achieve accuracy. Modern archery equipment usually includes sights. Instinctive aiming is used by many archers who use traditional bows. The two most common forms of a non-mechanical release are split-finger and three-under. Split-finger aiming requires the archer to place the index finger above the nocked arrow, while the middle and ring fingers are both placed below. Three-under aiming places the index, middle, and ring fingers under the nocked arrow. This technique allows the archer to better look down the arrow since the back of the arrow is closer to the dominant eye, and is commonly called "gun barreling" (referring to common aiming techniques used with firearms).
When using short bows, or shooting from horseback, it is difficult to use the sight picture. The archer may look at the target but without including the weapon in the field of accurate view. Aiming then involves hand/eye coordination which includes proprioception and motor/muscle memory, similar to that used when throwing a ball. With sufficient practice, such archers can normally achieve good practical accuracy for hunting or for war. Aiming without a sight picture may allow more rapid shooting.
Instinctive shooting is a style of shooting that includes the barebow aiming method that relies heavily upon the subconscious mind, proprioception, and motor/muscle memory to make aiming adjustments; the term used to refer to a general category of archers who did not use a mechanical or fixed sight.
Physics.
When a projectile is thrown by hand, the speed of the projectile is determined by the kinetic energy imparted by the thrower's muscles performing work. However, the energy must be imparted over a limited distance (determined by arm length) and therefore (because the projectile is accelerating) over a limited time, so the limiting factor is not work but rather power, which determined how much energy can be added in the limited time available. Power generated by muscles, however, is limited by force–velocity relationship, and even at the optimal contraction speed for power production, total work done by the muscle will be less than half of what could be done if the muscle were contracting over the same distance at very slow speeds, resulting in less than 1/4 the projectile launch velocity possible without the limitations of the force–velocity relationship.
When a bow is used, the muscles are able to perform work much more slowly, resulting in greater force and greater work done. This work is stored in the bow as elastic potential energy, and when the bowstring is released, this stored energy is imparted to the arrow much more quickly than can be delivered by the muscles, resulting in much higher velocity and, hence, greater distance. This same process is employed by frogs, which use elastic tendons to increase jumping distance. In archery, some energy is dissipated through elastic hysteresis, reducing the overall amount released when the bow is shot. Of the energy remaining, some is dampened both by the limbs of the bow and the bowstring. Depending on the elasticity of the arrow, some of the energy is also absorbed by compressing the arrow, primarily because the release of the bowstring is rarely in line with the arrow shaft, causing it to flex out to one side. This is because the bowstring accelerates faster than the archer's fingers can open, and consequently some sideways motion is imparted to the string, and hence arrow nock, as the power and speed of the bow pulls the string off the opening fingers. Even with a release aid mechanism some of this effect will usually be experienced, since the string always accelerates faster than the retaining part of the mechanism. This results in an in-flight oscillation of the arrow in which its center flexes out to one side and then the other repeatedly, gradually reducing as the arrow's flight proceeds; this can be clearly seen in high-speed photography of an arrow at discharge. A direct effect of these energy transfers can clearly be seen when dry firing. Dry firing refers to releasing the bow string without a nocked arrow. Because there is no arrow to receive the stored potential energy, all the energy stays in the bow. It has been suggested that dry firing may cause physical damage to the bow such as cracks and fractures, and because most bows are not specifically made to handle the high amounts of energy dry firing produces, should never be attempted.
Modern arrows are made to a specified 'spine', or stiffness rating, to maintain matched flexing and hence accuracy of aim. This flexing can be a desirable feature, since, when the spine of the shaft is matched to the acceleration of the bow(string), the arrow bends or flexes around the bow and any arrow-rest, and consequently the arrow, and fletchings, have an un-impeded flight. This feature is known as the archer's paradox. It maintains accuracy, for if part of the arrow struck a glancing blow on discharge, some inconsistency would be present, and the excellent accuracy of modern equipment would not be achieved.
The accurate flight of an arrow is dependent on its fletching. The arrow's manufacturer (a "fletcher") can arrange fletching to cause the arrow to rotate along its axis. This improves accuracy by evening pressure buildups that would otherwise cause the arrow to "plane" on the air in a random direction after shooting. Even though the arrow be made with extreme care, the slightest imperfection, or air movement, will cause some unbalanced turbulence in air flow. Consequently, rotation creates an equalization of such turbulence, which, overall, maintains the intended direction of flight i.e. accuracy. This rotation is not to be confused with the rapid gyroscopic rotation of a rifle bullet. If the fletching is not arranged to induce rotation, it will still improve accuracy by causing a restoring drag any time the arrow tilts away from its intended direction of travel from the initial.
The innovative aspect of the invention of the bow and arrow was the amount of power delivered to an extremely small area by the arrow. The huge ratio of length vs cross sectional area coupled with velocity made the arrow orders of magnitude more powerful than any other hand held weapon until firearms were invented (the same principle of concentrating a large kinetic energy on a small area continues to be used in modern anti-tank weaponry in the form of the long rod penetrator). Arrows may be designed to spread or concentrate force, depending on their applications. Practice arrows, for instance, can use a blunt tip that spreads the force over a wider area to reduce the risk of injury or limit penetration. Arrows designed to pierce armor in the Middle Ages would use a very narrow and sharp tip ("bodkinhead") to concentrate the force. Arrows used for hunting would use a narrow tip ("broadhead") that widens further, to facilitate both penetration and a large wound.
Hunting.
Using archery to take game animals is known as "bow hunting". Bow hunting differs markedly from hunting with firearms, as the distances between the hunter and the game are much shorter in order to ensure a humane kill. The skills and practices of bow hunting therefore emphasize very close approach to the prey, whether by still hunting, stalking, or waiting in a blind or tree stand. In many countries, including much of the United States, bow hunting for large and small game is legal. Bow hunters generally enjoy longer seasons than are allowed with other forms of hunting such as black powder, shotgun, or rifle. Usually, compound bows are used for large game hunting and may feature fiber optic sights and other enhancements. Using a bow and arrow to take fish is known as "bow fishing".
Modern competitive archery.
Competitive archery involves shooting arrows at a target for accuracy from a set distance or distances. This is the most popular form of competitive archery worldwide and is called target archery. A form particularly popular in Europe and America is field archery, shot at targets generally set at various distances in a wooded setting. Para-Archery is an adaptation of archery for athletes with a disability. It is governed by the World Archery Federation (WA), and is one of the sports in the Summer Paralympic Games. There are also several other lesser-known and historical forms of archery, as well as archery novelty games and flight archery, where the aim is to shoot the greatest distance.

</doc>
<doc id="2009" url="http://en.wikipedia.org/wiki?curid=2009" title="Alvar Aalto">
Alvar Aalto

Hugo Alvar Henrik Aalto (3 February 1898 – 11 May 1976) was a Finnish architect and designer, as well as a sculptor and painter. His work includes architecture, furniture, textiles and glassware. Aalto's early career runs in parallel with the rapid economic growth and industrialization of Finland during the first half of the twentieth century and many of his clients were industrialists; among these were the Ahlström-Gullichsen family. The span of his career, from the 1920s to the 1970s, is reflected in the styles of his work, ranging from Nordic Classicism of the early work, to a rational International Style Modernism during the 1930s to a more organic modernist style from the 1940s onwards. His furniture designs were considered Scandinavian Modern. What is typical for his entire career, however, is a concern for design as a Gesamtkunstwerk, a "total work of art"; whereby he – together with his first wife Aino Aalto – would design not just the building, but give special treatments to the interior surfaces and design furniture, lamps, and furnishings and glassware. The Alvar Aalto Museum, designed by Aalto himself, is located in what is regarded as his home city Jyväskylä.
Biography.
Life.
Hugo Alvar Henrik Aalto was born in Kuortane, Finland. His father, Johan Henrik Aalto, was a Finnish-speaking land-surveyor and his mother, Selly (Selma) Matilda (née Hackstedt) was a Swedish-speaking postmistress. When Aalto was 5 years old, the family moved to Alajärvi, and from there to Jyväskylä in Central Finland. Aalto studied at the Jyväskylä Lyceum school, completing his basic education in 1916. In 1916 he then enrolled to study architecture at the Helsinki University of Technology. His studies were interrupted by the Finnish Civil War, which he fought in. He fought on the side of the "White Army" and fought at the Battle of Länkipohja and the Battle of Tampere. He built his first piece of architecture while still a student, a house for his parents, at Alajärvi. Afterwards, he continued his education, graduating in 1921. In the summer of 1922 he began his official military service, finishing at the Hamina reserve officer training school, and was promoted to reserve second lieutenant in June 1923.
In 1920, while still a student, Aalto made his first trip abroad, travelling via Stockholm to Gothenburg, where he even briefly found work with the architect Arvid Bjerke. In 1922, he accomplished his first independent piece at the Industrial Exposition in Tampere. In 1923 he returned to Jyväskylä, where he opened his first architectural office, under the name 'Alvar Aalto, Architect and Monumental Artist'. At that same time he also wrote articles for the Jyväskylä newspaper "Sisä-Suomi" under the pseudonym Remus. During this time, he designed a number of small single-family houses in Jyväskylä, and the office's workload steadily increased. In 1925, he married architect Aino Marsio. Their honeymoon journey to Italy was Aalto's first trip there, though Aino had previously made a study trip there. The latter trip together sealed an intellectual bond with the culture of the Mediterranean region that was to remain important to Aalto for the rest of his life. On their return, they continued with a number of local projects, notably the Jyväskylä Worker's Club. However, the Aaltos moved their office to Turku in 1927, and started collaborating with architect Erik Bryggman. The office moved again in 1933 to Helsinki.
The Aaltos designed and built a joint house-office (1935–36) for themselves in Munkkiniemi, Helsinki, but later (1954–56) had a purpose-built office erected in the same neighbourhood – nowadays the former is a "house museum" and the latter the premises of the Alvar Aalto Academy. In 1926 the young Aaltos designed and had built a summer cottage in Alajärvi, Villa Flora. In 1938, the Aaltos visited the United States for the first time, ostensibly to visit the Finnish Pavilion, which they had designed, for the New York World Fair of the following year. Aino Aalto died of cancer in 1949. Aino and Alvar Aalto had 2 children, a daughter Johanna "Hanni" Alanen, born Aalto, 1925, and a son Hamilkar Aalto, 1928. In 1952 Aalto married architect Elissa Mäkiniemi (died 1994), who had been working as an assistant in his office. In 1952 Aalto designed and had built a summer cottage, the so-called Experimental House, for himself and his new wife in Muuratsalo in Central Finland. Alvar Aalto died on 11 May 1976, in Helsinki, and is buried in the Hietaniemi cemetery in Helsinki.
Architecture career.
Early career: classicism.
Although he is sometimes regarded as among the first and most influential architects of Nordic modernism, a closer examination of the historical facts reveals that Aalto (while a pioneer in Finland) closely followed and had personal contacts with other pioneers in Sweden, in particular Gunnar Asplund and Sven Markelius. What they and many others of that generation in the Nordic countries had in common was that they started off from a classical education and were first designing classical architecture, though what historians now call Nordic Classicism – a style that had been a reaction to the previous dominant style of National Romanticism – before moving, in the late 1920s, towards Modernism. On returning to Jyväskylä in 1923 to establish his own architect's office, Aalto busied himself with a number of single-family homes, all designed in the Nordic Classicism style, such as the manor-like house for his mother's cousin Terho Manner in Töysa in 1923, a summer villa for the Jyväskylä chief constable in 1923 and the Alatalo farmhouse in Tarvaala in 1924. During this period he also completed his first public buildings, the Jyväskylä Workers' Club in 1925, the Jyväskylä Defence Corps building in 1926 and the Seinajoki Defence Corp building in 1924–29. Aalto also entered several architectural competitions for prestigious state public buildings, both in Finland and abroad, including the two competitions for the Finnish Parliament building in 1923 and 1924, the extension to the University of Helsinki in 1931, and the building to house the League of Nations in Geneva, Switzerland, in 1926–27. Furthermore, this was the period when Aalto was most prolific in his writings, with articles for professional journals and newspapers. Among his most well-known essays from this period are "Urban culture" (1924), "Temple baths on Jyväskylä ridge" (1925), "Abbé Coignard's sermon" (1925), and "From doorstep to living room" (1926).
Early career: functionalism.
The shift in Aalto's design approach from classicism to modernism is epitomised by the Viipuri Library (1927–35), which went through a transformation from an originally classical competition entry proposal to the completed high-modernist building. Yet his humanistic approach is in full evidence in the library: the interior displays natural materials, warm colours, and undulating lines. Due to problems over financing and a change of site, the Viipuri Library project lasted eight years, and during that same time he also designed the Turun Sanomat Building (1929–30) and Paimio Sanatorium (1929–32). Thus, the Turun Sanomat Building first heralded Aalto's move towards modernism, and this was then carried forward both in the Paimio Sanatorium and in the on-going design for the library. Although the Turun Sanomat Building and Paimio Sanatorium are comparatively pure modernist works, they too carried the seeds of his questioning of such an orthodox modernist approach and a move to a more daring, synthetic attitude. It has been said that his work on two of these three buildings (not the Viipuri Library) showed similarities to Walter Gropius' style, in particular his work on the Bauhaus school of design in Dessau. His work on the Viipuri building started to show his individuality in a departure from the European norms.
Through Sven Markelius, Aalto became a member of the Congres Internationaux d'Architecture Moderne (CIAM), attending the second congress in Frankfurt in 1929 and the fourth congress in Athens in 1933, where he established a close friendship with László Moholy-Nagy, Sigfried Giedion and Philip Morton Shand. It was during this time that he followed closely the work of the main driving force behind the new modernism, Le Corbusier, and visited him in his Paris office several times in the following years.
It was not until the completion of the Paimio Sanatorium (1932) and Viipuri Library (1935) that Aalto first achieved world attention in architecture. His reputation grew in the USA following the critical reception of his design for the Finnish Pavilion at the 1939 New York World's Fair, described by Frank Lloyd Wright as a "work of genius". It could be said that Aalto's international reputation was sealed with his inclusion in the second edition of Sigfried Giedion's influential book on Modernist architecture, "Space, Time and Architecture: The growth of a new tradition" (1949), in which Aalto received more attention than any other Modernist architect, including Le Corbusier. In his analysis of Aalto, Giedion gave primacy to qualities that depart from direct functionality, such as mood, atmosphere, intensity of life and even national characteristics, declaring that "Finland is with Aalto wherever he goes".
In 1938, the Museum of Modern Art, in New York organized an exhibit that eventually went on a 12-city tour. Afterwards he visited America for the first time and gave a series of lectures at Yale.
Mid career: experimentation.
During the 1930s Alvar spent some time experimenting with laminated wood, making sculptures, and abstract reliefs, characterized by irregular curved forms. Utilizing this knowledge he was able to solve technical problems concerning the flexibility of wood and also of working out spatial issues in his designs. Aalto's early experiments with wood and his move away from a purist modernism would be tested in built form with the commission to design Villa Mairea (1939) in Noormarkku, the luxury home of the young industrialist couple Harry and Maire Gullichsen. It was Maire Gullichsen who acted as the main client, and she worked closely not only with Alvar but also Aino Aalto on the design, inspiring them to be more daring in their work. The original design was to include a private art gallery, but this was never built. The building forms a U-shape around a central inner "garden" the central feature of which is a kidney-shaped swimming pool. Adjacent to the pool is a sauna executed in a rustic style, alluding to both Finnish and Japanese precedents. The design of the house is a synthesis of numerous stylistic influences, from traditional Finnish vernacular to purist modernism, as well as influences from English and Japanese architecture. While the house is clearly intended for a wealthy family, Aalto nevertheless argued that it was also an experiment that would prove useful in the design of mass housing. It created zones for different activities within the structure.
His increased fame led to offers and commissions outside Finland. In 1941 he accepted an invitation as a visiting professor to Massachusetts Institute of Technology in the USA. This was during the Second World War, and he involved his students in designing low-cost, small-scale housing for the reconstruction of war-torn Finland. While teaching at MIT, Aalto also designed the student dormitory, Baker House, completed in 1948. The dormitory lay along the Charles River and its undulating form provided maximum view and ventilation for each resident. This building was the first building of Aalto's redbrick period. Originally used in Baker House to signify the Ivy League university tradition, on his return to Finland Aalto used it in a number of key buildings, in particular, in several of the buildings in the new Helsinki University of Technology campus (starting in 1950), Säynätsalo Town Hall (1952), Helsinki Pensions Institute (1954), Helsinki House of Culture (1958), as well as in his own summer house, the so-called Experimental House in Muuratsalo (1957).
In the 50's he immersed himself in his sculpting, be it with bronze, marble, or mixed media. This paid off as he produced an outstanding piece for the memorial of the Battle of Suomussalmi (1960), located on the battlefield. It consists of a leaning bronze pillar on a pedestal.
Mature career: monumentalism.
The early 1960s and 1970s (up until his death in 1976) were marked by key works in Helsinki, in particular the huge town plan for the void in centre of Helsinki adjacent to Töölö Bay and the vast railway yards, and marked on the edges by significant buildings such as the National Museum and the main railway station, both by Eliel Saarinen. In his town plan Aalto proposed a line of separate marble-clad buildings fronting the bay which would house various cultural institutions, including a concert hall, opera, museum of architecture and headquarters for the Finnish Academy. The scheme also extended into the Kamppi district with a series of tall office blocks. Aalto first presented his scheme in 1961, but it went through various modifications during the early 1960s. Only two fragments of the overall plan were ever realized: the Finlandia Hall concert hall (1976) fronting Töölö Bay, and an office building in the Kamppi district for the Helsinki Electricity Company (1975). The Miesian formal language of geometric grids employed in the buildings was also used by Aalto for other sites in Helsinki, including the Enso-Gutzeit building (1962), the Academic Bookstore (1962) and the SYP Bank building (1969).
Following Aalto's death in 1976 his office continued to operate under the direction of his widow, Elissa, completing works already to some extent designed. These works include the Jyväskylä City Theatre and Essen opera house. Since the death of Elissa Aalto the office has continued to operate as the Alvar Aalto Academy, giving advice on the restoration of Aalto buildings and organising the vast archive material.
Furniture career.
Whereas Aalto was famous for his architecture, his furniture designs were well thought of and are still popular today. He studied Josef Hoffmann and the Wiener Werkstätte, and for a period of time, worked under Eliel Saarinen. He also gained inspiration from Gebrüder Thonet. During the late 1920s and 1930s he, working closely with Aino Aalto, also focused a lot of his energy on furniture design, partly due to the decision to design much of the individual furniture pieces and lamps for the Paimio Sanatorium. Of particular significance was the experimentation in bent plywood chairs, most notably the so-called Paimio chair, which had been designed for the sitting tuberculosis patient. The Aaltos, together with visual arts promoter Maire Gullichsen and art historian Nils-Gustav Hahl founded the Artek company in 1935, ostensibly to sell Aalto products, but also other imported products. He became the first furniture designer to use the cantilever principle in chair design using wood.
Awards.
Aalto's awards included the Royal Gold Medal for Architecture from the Royal Institute of British Architects (1957) and the Gold Medal from the American Institute of Architects (1963). He was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1957. He also was a member of the Academy of Finland, and was its president from 1963 to 1968. From 1925 to 1956 he was a member of the Congrès International d'Architecture Moderne. In 1960 he received an honorary doctorate at the Norwegian University of Science and Technology (NTNU).
Works.
Aalto's career spans the changes in style from (Nordic Classicism) to purist International Style Modernism to a more personal, synthetic and idiosyncratic Modernism. Aalto's wide field of design activity ranges from the large scale of city planning and architecture to interior design, furniture and glassware design and painting. It has been estimated that during his entire career Aalto designed over 500 individual buildings, approximately 300 of which were built, the vast majority of which are in Finland. He also has a few buildings in France, Germany, Italy and the USA.
Aalto's work with wood, was influenced by early Scandinavian architects; however, his experiments and departure from the norm brought attention to his ability to make wood do things not previously done. His techniques in the way he cut the beech tree, for example, and also his ability to use plywood as structural and aesthetic. Other examples include the rough-hewn vertical placement of logs at his pavilion at the Lapua expo, looking similar to a medieval barricade, at the orchestra platform at turku and the Paris expo at the World Fair, he used varying sizes and shapes of planks. Also at Paris and at Villa Mairea he utilized birch boarding in a vertical arrangement. Also his famous undulating walls and ceilings made of red pine. In his roofing, he created massive spans (155-foot at the covered statium at Otaniemi) all without tie rods. His stairway at Villa Mairea, he evokes feelings of a natural forest by binding beech wood with withes into columns.
Aalto claimed that his paintings were not made as individual artworks but as part of his process of architectural design, and many of his small-scale "sculptural" experiments with wood led to later larger architectural details and forms. These experiments also led to a number of patents: for example, he invented a new form of laminated bent-plywood furniture in 1932. His experimental method had been influenced by his meetings with various members of the Bauhaus design school, especially László Moholy-Nagy, whom he first met in 1930. Aalto's furniture was exhibited in London in 1935, to great critical acclaim, and to cope with the consumer demand Aalto, together with his wife Aino, Maire Gullichsen and Nils-Gustav Hahl founded the company Artek that same year. Aalto glassware (Aino as well as Alvar) is manufactured by Iittala. Aalto was one of the first architects outside of Germany, France, and the Netherlands to master modern architecture.
Aalto's 'High Stool' and 'Stool E60' (manufactured by Artek) are currently used in Apple Stores across the world to serve as seating for customers. Finished in black lacquer, the stools are used to seat customers at the 'Genius Bar' and also in other areas of the store at times when seating is required for a product workshop or special event. Aalto was also influential in bringing modern art to the Finnish people, in particular the work of his friends, Alexander Milne Calder and Fernand Léger.
Critique of Aalto's architecture.
As already mentioned, Aalto's international reputation was sealed with his inclusion in the second edition of Sigfried Giedion's influential book on Modernist architecture, "Space, Time and Architecture: The growth of a new tradition" (1949), in which Aalto received more attention than any other Modernist architect, including Le Corbusier. In his analysis of Aalto, Giedion gave primacy to qualities that depart from direct functionality, such as mood, atmosphere, intensity of life and even national characteristics, declaring that "Finland is with Aalto wherever he goes". However, a few more recent architecture critics and historians have questioned Aalto's position of influence in the canonic history. Italian Marxist architecture historians Manfredo Tafuri and Francesco Dal Co put forward the viewpoint that Aalto's "historical significance has perhaps been rather exaggerated; with Aalto we are outside of the great themes that have made the course of contemporary architecture so dramatic. The qualities of his works have a meaning only as masterful distractions, not subject to reproduction outside the remote reality in which they have their roots." Their viewpoint was propounded by their own priority given to urbanism, seeing Aalto as an anti-urban, and thus consequently disparaging what they regarded as peripheral non-urban areas of the world: "Essentially his architecture is not appropriate to urban typologies." Similarly concerned with the appropriateness of Aalto's form language, at the other end of the political spectrum, American postmodernist critic Charles Jencks made a claim for the need for buildings to signify meaning; however, he then lifted out Aalto's Pensions Institute building as an example of what he termed Aalto's 'soft paternalism': "Conceived as a fragmented mass to break up the feeling of bureaucracy, it succeeds all too well in being humane and killing the pensioner with kindness. The forms are familiar red brick and ribbon-strip windows broken by copper and bronze elements – all carried through with a literal-mindedness that borders on the soporific." But also during Aalto's lifetime he faced critique from his fellow architects in Finland, most notably Kirmo Mikkola and Juhani Pallasmaa; by the last decade of his life Aalto's work was seen as idiosyncratic and individualistic, when the opposing tendencies of rationalism and constructivism – often championed under left-wing politics – argued for anonymous virtually non-aesthetic architecture. Mikkola wrote of Aalto's late works: "Aalto has moved to his present baroque line..."
Memorials.
Aalto has been commemorated in a number of ways:
Further reading.
Göran Schildt has written and edited many books on Aalto, the most well-known being the three-volume biography, usually referred to as the definitive biography on Aalto.

</doc>
<doc id="2011" url="http://en.wikipedia.org/wiki?curid=2011" title="Comparison of American and British English">
Comparison of American and British English

This is one of a series of articles about the differences between British English and American English, which, "for the purposes of these articles", are defined as follows:
Written forms of British and American English as found in newspapers and textbooks vary little in their essential features, with only occasional noticeable differences in comparable media (comparing American newspapers with British newspapers, for example). This kind of formal English, particularly written English, is often called "standard English".
The spoken forms of British English vary considerably, reflecting a long history of dialect development amid isolated populations. In the United Kingdom, dialects, word use and accents vary not only between England, Northern Ireland, Scotland and Wales, but also within them. "Received Pronunciation" (RP) refers to a way of pronouncing standard English that is actually used by about two percent of the UK population. It remains the accent upon which dictionary pronunciation guides are based, and for teaching English as a foreign language. It is referred to colloquially as "the Queen's English", "Oxford English" and "BBC English", although by no means do all graduates of the university speak with such an accent and the BBC no longer requires it or uses it exclusively.
An unofficial standard for "spoken" American English has also developed, as a result of mass media and geographic and social mobility, and broadly describes the English typically heard from network newscasters, commonly referred to as non-regional diction, although local newscasters tend toward more parochial forms of speech. Despite this unofficial standard, regional variations of American English have not only persisted but have actually intensified, according to linguist William Labov.
Regional dialects in the United States typically reflect some elements of the language of the main immigrant groups in any particular region of the country, especially in terms of pronunciation and vernacular vocabulary. Scholars have mapped at least four major regional variations of spoken American English: Northern, Southern, Midland, and Western. After the American Civil War, the settlement of the western territories by migrants from the east led to dialect mixing and levelling, so that regional dialects are most strongly differentiated in the eastern parts of the country that were settled earlier. Localized dialects also exist with quite distinct variations, such as in Southern Appalachia and New York.
British and American English are the reference norms for English as spoken, written, and taught in the rest of the world, excluding countries where English is spoken natively such as Australia, Canada, Ireland and New Zealand. In many former British Empire countries where English is not spoken natively, British English forms are closely followed, alongside numerous AmE usages which have become widespread throughout the Anglosphere. Conversely, in many countries historically influenced by the United States where English is not spoken natively, American English forms are closely followed. Many of these countries, while retaining strong BrE or AmE influences, have developed their own unique dialects, which include Indian English and Philippine English.
Chief among other native English dialects are Canadian English and Australian English, which rank third and fourth in the number of native speakers. For the most part, Canadian English, while featuring numerous British forms alongside indigenous Canadianisms, shares vocabulary, phonology and syntax with American English, leading many to recognize "North American English" as an organic grouping of dialects. Australian English likewise shares many American and British English usages alongside plentiful features unique to Australia, and retains a significantly higher degree of distinctiveness from both the larger varieties than does Canadian English. South African English, New Zealand English and the Hiberno-English of Ireland are also distinctive and rank fifth, sixth and seventh in the number of native speakers.
Historical background.
The English language was first introduced to the Americas by British colonization, beginning in 1607 in Jamestown, Virginia. Similarly, the language spread to numerous other parts of the world as a result of British trade and colonization elsewhere and the spread of the former British Empire, which, by 1921, held sway over a population of 470–570 million people, approximately a quarter of the world's population at that time.
Over the past 400 years the form of the language used in the Americas—especially in the United States—and that used in the United Kingdom have diverged in a few minor ways, leading to the versions now occasionally referred to as American English and British English. Differences between the two include pronunciation, grammar, vocabulary (lexis), spelling, punctuation, idioms, and formatting of dates and numbers, although the differences in written and most spoken grammar structure tend to be much less than those of other aspects of the language in terms of mutual intelligibility. A small number of words have completely different meanings in the two versions or are even unknown or not used in one of the versions. One particular contribution towards formalizing these differences came from Noah Webster, who wrote the first American dictionary (published 1828) with the intention of showing that people in the United States spoke a different dialect from Britain, much like a regional accent.
This divergence between American English and British English has provided opportunities for humorous comment, e.g. George Bernard Shaw has a character say that the United States and United Kingdom are "two countries divided by a common language"; and Oscar Wilde that "We have really everything in common with America nowadays, except, of course, the language" ("The Canterville Ghost", 1888). Henry Sweet incorrectly predicted in 1877 that within a century American English, Australian English and British English would be mutually unintelligible. It may be the case that increased worldwide communication through radio, television, the Internet and globalization has reduced the tendency towards regional variation. This can result either in some variations becoming extinct (for instance, "the wireless", being progressively superseded by "the radio") or in the acceptance of wide variations as "perfectly good English" everywhere.
Although spoken American and British English are generally mutually intelligible, there are occasional differences which might cause embarrassment—for example, in American English a "rubber" is usually interpreted as a "condom" rather than an "eraser"; and a British "fanny" refers to the female pubic area, while the American "fanny" refers to an "ass" (US) or an "arse" (UK). Likewise the Australian "root" means to have sexual intercourse whilst in both British and American English it means to support someone for success.
Grammar.
Nouns.
Formal and notional agreement.
In British English (BrE), collective nouns can take either singular ("formal agreement") or plural ("notional agreement") verb forms, according to whether the emphasis is on the body as a whole or on the individual members respectively; compare "a committee was appointed" with "the committee were unable to agree". The term "the Government" always takes a plural verb in British civil service convention, perhaps to emphasise the principle of cabinet collective responsibility. Compare also the following lines of Elvis Costello's song "Oliver's Army": "Oliver's Army is here to stay / Oliver's Army are on their way ". Some of these nouns, for example "staff", actually combine with plural verbs most of the time.
In American English (AmE), collective nouns are almost always singular in construction: "the committee was unable to agree". However, when a speaker wishes to emphasize that the individuals are acting separately, a plural pronoun may be employed with a singular or plural verb: "the team takes their seats", rather than "the team takes its seats". However, such a sentence would most likely be recast as "the team members take their seats". Despite exceptions such as usage in "The New York Times", the names of sports teams are usually treated as plurals even if the form of the name is singular.
The difference occurs for all nouns of multitude, both general terms such as "team" and "company" and proper nouns (for example where a place name is used to refer to a sports team). For instance,
BrE: "SuperHeavy is a band that shouldn't work" or "First Aid Kit are a band full of contradictions"; AmE: "The Clash is a well-known band".
BrE: "Spain are the champions"; AmE: "Spain is the champion".
Proper nouns that are plural in form take a plural verb in both AmE and BrE; for example, "The Beatles are a well-known band"; "The Seahawks are the champions", with one major exception: largely for historical reasons, in American English, the "United States is" is almost universal. This is due to the growth in federal control over state governments following the American Civil War ("cf." the inclusion of the term "indivisible" in the Pledge of Allegiance to the United States flag); before this, the construction "the United States are" was more common.
Verbs.
Verbal auxiliaries.
where the AmE response would be "Why, he must have." omitting the form of "do". The BrE usage is commonly found with all forms of "do", for example:
Transitivity.
The following verbs show differences in transitivity between BrE and AmE:
Vocabulary.
Most of the differences in lexis or vocabulary between British and American English are in connection with concepts originating from the 19th century to the mid 20th century, when new words were coined independently. Almost the entire vocabularies of the car/automobile and railway/railroad industries (see Rail terminology) are different between the UK and US, for example. Other sources of difference are slang or vulgar terms (where frequent new coinage occurs) and idiomatic phrases, including phrasal verbs. The differences most likely to create confusion are those where the same word or phrase is used for two different concepts. Regional variations, even within the US or the UK, can create the same problems. From the mid-20th century, movies and television have spread new words in both countries, usually from the US to the UK.
It is not a straightforward matter to classify differences of vocabulary. David Crystal identifies some of the problems of classification on the facing page to his list of American English/British English lexical variation and states "this should be enough to suggest caution when working through an apparently simple list of equivalents".
Overview of lexical differences.
"Note: A lexicon is not made up of different words but different "units of meaning" (lexical units or lexical items e.g. "fly ball" in baseball), including idioms and figures of speech. This makes it easier to compare the dialects."
Though the influence of cross-culture media has done much to familiarize BrE and AmE speakers with each other's regional words and terms, many words are still recognized as part of a single form of English. Though the use of a British word would be acceptable in AmE (and vice versa), most listeners would recognize the word as coming from the other form of English and treat it much the same as a word borrowed from any other language. For instance a British speaker using the word "chap" or "mate" to refer to a friend would be heard in much the same way as an American using the Spanish word "amigo".
Words and phrases that have their origins in BrE.
Most speakers of AmE are aware of some BrE terms, although they may not generally use them or may be confused as to whether someone intends the American or British meaning (such as for "biscuit"). It is generally very easy to guess what some words, such as "driving licence", mean. However, use of many other British words such as "naff" (slang but commonly used to mean "not very good") are unheard of in American English.
Words and phrases that have their origins in AmE.
Speakers of BrE are likely to understand most common AmE terms, examples such as "sidewalk" (pavement), "gas (gasoline/petrol)", "counterclockwise" (anticlockwise) or "elevator (lift)", without any problem, thanks in part to considerable exposure to American popular culture and literature. Certain terms that are heard less frequently, especially those likely to be absent or rare in American popular culture, e.g. "copacetic (satisfactory)", are unlikely to be understood by most BrE speakers.
Divergence.
Words and phrases with different meanings.
Words such as "bill" and "biscuit" are used regularly in both AmE and BrE but mean different things in each form. In AmE a bill is usually paper money (as in "dollar bill") though it can mean the same as in BrE, an invoice (as in "the repair bill was £250"). In AmE a biscuit is what in BrE is called a scone. In BrE a biscuit is what AmE calls a cookie. As chronicled by Winston Churchill, the opposite meanings of the verb "to table" created a misunderstanding during a meeting of the Allied forces; in BrE to table an item on an agenda means to "open it up" for discussion whereas in AmE, it means to "remove" it from discussion, or at times, to suspend or delay discussion.
The word "football" in BrE refers to Association football, also once known as soccer. In AmE, "football" means American football. However, the standard AmE term "soccer", a contraction of "association (football)", is also of British origin, derived from the formalization of different codes of football in the 19th century, and was a fairly unremarkable usage (possibly marked for class) in BrE until relatively recently; it has lately become perceived incorrectly as an Americanism. 
Similarly, the word "hockey" in BrE refers to field hockey and in AmE, "hockey" means ice hockey.
Other ambiguity (complex cases).
Words with completely different meanings are relatively few; most of the time there are either (1) words with one or more shared meanings and one or more meanings unique to one variety (for example, bathroom and toilet) or (2) words the meanings of which are actually common to both BrE and AmE but that show differences in frequency, connotation or denotation (for example, "smart", "clever", "mad").
Some differences in usage and/or meaning can cause confusion or embarrassment. For example the word "fanny" is a slang word for vulva in BrE but means buttocks in AmE—the AmE phrase "fanny pack" is "bum bag" in BrE. In AmE the word "fag" (short for "faggot") is a highly offensive term for a homosexual male but in BrE it is a normal and well-used term for a cigarette, for hard work, or for a chore, while a faggot itself is a sort of meatball. In AmE the word "pissed" means being annoyed whereas in BrE it is a coarse word for being drunk (in both varieties, "pissed off" means irritated).
Similarly, in AmE the word "pants" is the common word for the BrE "trousers", while the majority of BrE speakers would understand "pants" to mean "underwear". Many dialects in the North of England agree with the AmE usage and use "pants" to refer to "trousers"; this is often incorrectly considered an Americanism by people from elsewhere in Britain. The word "pants" is a shortening of the archaic "pantaloons", which shares the same source as the French for trousers, "pantalon".
Sometimes the confusion is more subtle. In AmE the word "quite" used as a qualifier is generally a reinforcement: for example, "I'm quite hungry" means "I'm very hungry". In BrE "quite" (which is much more common in conversation) may have this meaning, as in "quite right" or "quite mad", but it more commonly means "somewhat", so that in BrE "I'm quite hungry" can mean "I'm somewhat hungry". This divergence of use can lead to misunderstanding.
Social and cultural differences.
Lexical items that reflect separate social and cultural development.
Education.
School.
In the US, 5th grade is typically a part of elementary school while 8th grade is often the third and final year of junior high. The US does not have a uniform nationwide system of schooling and even within individual states there can be different systems depending on the school district or town/city.
In the UK the US equivalent of a "high school" is often referred to as a "secondary school" regardless of whether it is state funded or private. Secondary education in the United States also includes "middle school" or "junior high school", a two- or three-year transitional school between elementary school and high school. "Middle school" is sometimes used in the UK as a synonym for the younger "junior school", covering the second half of the primary curriculum—current years 4 to 6 in some areas. But in Dorset (South England) it is used to describe the second school in the three-tier system, which is normally from year 5 to year 8, In other regions such as a town called Evesham and the surrounding area in Worcestershire the second tier goes from year 6 to year 8, and both starting secondary school in year 9. In Kirklees, West Yorkshire in the villages of the Dearne Valley there is a 3 tier system: First Schools year Reception to year 5, Middle School (Scissett/Kirkburton Middle School) year 6 to year 8 and High School ()years 9 to year 13.
A "public school" has opposite meanings in the two countries. In the US this is a government-owned institution supported by taxpayers. In England and Wales the term strictly refers to an ill-defined group of prestigious private independent schools funded by students' fees, although it is often more loosely used to refer to any independent school. Independent schools are also known as "private schools", and the latter is the correct term in Scotland and Northern Ireland for all such fee-funded schools. Strictly, the term "public school" is not used in Scotland and Northern Ireland in the same sense as in England, but nevertheless Gordonstoun, the Scottish private school which Charles, Prince of Wales attended, is sometimes referred to as a "public school", as are some other Scottish private schools. Government-funded schools in Scotland and Northern Ireland are properly referred to as "state schools"—but are sometimes confusingly referred to as "public schools" (with the same meaning as in the US); whereas in the US, where most public schools are administered by local governments, a "state school" is typically a college or university run by one of the states. The UK use of the term "public" school is in contrast with "private" education, i.e. to be educated privately with a tutor.
Speakers in both the United States and the United Kingdom use several additional terms for specific types of secondary school. A US "prep school" or "preparatory school" is an independent school funded by tuition fees; the same term is used in the UK for a private school for pupils under thirteen, designed to prepare them for fee-paying public schools. An American "parochial school" covers costs through tuition and has affiliation with a religious institution, most often a Catholic church or diocese. (The term "parochial" is almost never used to describe schools run by fundamentalist Protestant groups.) In England, where the state-funded education system grew from parish schools organized by the local established church, the Church of England (C. of E., or C.E.), and many schools, especially primary schools (up to age 11) retain a church connection and are known as "church schools", "C.E. Schools" or "C.E. (Aided) Schools". There are also "faith schools" associated with the Roman Catholic Church and other major faiths, with a mixture of funding arrangements.
In the US, a "magnet school" receives government funding and has special admission requirements: pupils gain admission through superior performance on admission tests. The UK has city academies, which are independent privately sponsored schools run with public funding and which can select up to 10% of pupils by aptitude. Moreover in the UK 36 Local Education Authorities retain selection by ability at 11. They maintain grammar schools (State funded secondary schools), which admit pupils according to performance in an examination (known as the 11+) and Comprehensive schools that take pupils of all abilities. Grammar schools select the most academically able 10% to 23% of those who sit the exam. Students who fail the exam go to a Secondary modern school sometimes called a high school and increasingly an academy. In areas where there are no grammar schools the comprehensives likewise may term themselves high schools or academies. Nationally only 6% of pupils attend grammar schools, mainly in 4 distinct counties. Some private schools are called grammar schools, chiefly those that were grammar schools long before the advent of state education.
University.
In the UK a university student is said to "study", to "read" or informally simply to "do" a subject. In the recent past the expression 'to read a subject' was more common at the older universities such as Oxford and Cambridge. In the US a student "studies" or "majors in" a subject (although "concentration" or "emphasis" is also used in some US colleges or universities to refer to the major subject of study). "To major in" something refers to the student's principal course of study; "to study" may refer to any class being taken.
BrE:
AmE:
At university level in BrE, each "module" is taught or facilitated by a "lecturer" or "tutor"; "professor" is the job-title of a senior academic. (In AmE, at some universities, the equivalent of the BrE lecturer is instructor, especially when the teacher has a lesser degree or no University degree, though the usage may become confusing according to whether the subject being taught is considered technical or not. Also, it is not to be confused with Adjunct Instructor/Professor.) In AmE each "class" is generally taught by a "professor" (although some US tertiary educational institutions follow the BrE usage), while the position of "lecturer" is occasionally given to individuals hired on a temporary basis to teach one or more classes and who may or not have a doctoral degree.
The word "course" in American use typically refers to the study of a restricted topic or individual subject (for example, "a course in Early Medieval England", "a course in Integral Calculus") over a limited period of time (such as a semester or term) and is equivalent to a "module" or sometimes "unit" at a British university. In the UK a "course of study" or simply "course" is likely to refer to the entire program of study, which may extend over several years and be made up of any number of "modules," hence is also practically synonymous to a degree programme. A few university-specific exceptions exist: for example, at Cambridge the word "paper" is used to refer to a "module", while the whole course of study is called "Tripos".
A "dissertation" in AmE refers to the final written product of a doctoral student to fulfil the requirement of that programme. In BrE, the same word refers to the final written product of a student in an undergraduate or taught master's programme.
Another source of confusion is the different usage of the word "college". (See a full international discussion of the various meanings at college.) In the US this refers to a post-high school institution that grants either associate's or bachelor's degrees, while in the UK it refers to any post-secondary institution that is not a university (including "Sixth Form College" after the name in secondary education for Years 12 and 13, the "6th form") where intermediary courses such as A Levels or NVQs can be taken and GCSE courses can be retaken. College may sometimes be used in the UK or in Commonwealth countries as part of the name of a secondary or high school (for example, Dubai College). In the case of Oxford, Cambridge, Aberdeen, London, Lancaster, Durham, Kent and York universities, all members are also members of a college which is part of the university, for example, one is a member of King's College, Cambridge and hence the University.
In both the US and UK "college" can refer to some division within a university that comprises related academic departments such as the "college of business and economics" though in the UK "faculty" is more often used. Institutions in the US that offer two to four years of post-high school education often have the word "college" as part of their name, while those offering more advanced degrees are called a "university". (There are exceptions: Boston College, Dartmouth College and The College of William & Mary are examples of colleges that offer advanced degrees, while Vincennes University is an unusual example of a "university" that offers only associate degrees in the vast majority of its academic programs.) American students who pursue a "bachelor's degree" (four years of higher education) or an "associate degree" (two years of higher education) are "college students" regardless of whether they attend a college or a university and refer to their educational institutions informally as "colleges." A student who pursues a master's degree or a doctorate degree in the arts and sciences is in AmE a "graduate student"; in BrE a "postgraduate student" although "graduate student" is also sometimes used. Students of advanced professional programs are known by their field ("business student", "law student", "medical student"). Some universities also have a residential college system, the details of which may vary but generally involve common living and dining spaces as well as college-organized activities. Nonetheless, when it comes to the level of education, AmE generally uses the word "college" (e.g. going to college) whereas BrE generally uses the word "university" (e.g. going to university) regardless of the institution's official designation/status in both countries.
In the context of higher education, the word "school" is used slightly differently in BrE and AmE. In BrE, except for the University of London, the word school is used to refer to an academic department in a university. In AmE, the word school is used to refer to a collection of related academic departments and is headed by a dean. When referring to a division of a university, school is practically synonymous to a college.
"Professor" has different meanings in BrE and AmE. In BrE it is the highest academic rank, followed by Reader, Senior Lecturer and Lecturer. In AmE "Professor" refers to academic staff of all ranks, with (Full) Professor (largely equivalent to the UK meaning) followed by Associate Professor and Assistant Professor.
"Tuition" has traditionally had separate meaning in each variation. In BrE it is the educational content transferred from teacher to student at a university. In AmE it is the money (the fees) paid to receive that education (BrE: Tuition fees).
General terms.
In both the US and the UK, a student "takes" an exam, but in BrE a student can also be said to "sit" an exam. The expression "he sits for" an exam also arises in BrE but only rarely in AmE; American lawyers-to-be "sit for" their bar exams and American master's and doctoral students may "sit for" their comprehensive exams, but in nearly all other instances, Americans "take" their exams.
When preparing for an exam students "revise" (BrE)/"review" (AmE) what they have studied; the BrE idiom "to revise for" has the equivalent "to review for" in AmE.
Examinations are supervised by "invigilators" in the UK and "proctors" (or "(exam) supervisors") in the US (a "proctor" in the UK is an official responsible for student discipline at the University of Oxford or Cambridge). In the UK a teacher "sets" an exam, while in the US, a teacher "writes" (prepares) and then "gives" (administers) an exam.
BrE:
AmE:
In BrE, students are awarded "marks" as credit for requirements (e.g. tests, projects) while in AmE, students are awarded "points" or "grades" for the same. Similarly, in BrE, a candidate's work is being "marked", while in AmE it is said to be "graded" to determine what mark or grade is given.
There is additionally a difference between American and British usage in the word "school". In British usage "school" by itself refers only to primary (elementary) and secondary (high) schools and to "sixth forms" attached to secondary schools—if one "goes to school", this type of institution is implied. By contrast an American student at a university may talk of "going to school" or "being in school". US law students and medical students almost universally speak in terms of going to "law school" and "med school", respectively. However, the word is used in BrE in the context of higher education to describe a division grouping together several related subjects within a university, for example a "School of European Languages" containing "departments" for each language and also in the term "art school". It is also the name of some of the constituent colleges of the University of London, for example, School of Oriental and African Studies, London School of Economics.
Among high-school and college students in the United States, the words "freshman" (or the gender-neutral term "frosh" or "first year"), "sophomore", "junior" and "senior" refer to the first, second, third, and fourth years respectively. For first-year students, "frosh" is another gender-neutral term that can be used as a qualifier, for example "Frosh class elections". It is important that the context of either high school or college first be established or else it must be stated direct (that is, "She is a high school freshman". "He is a college junior."). Many institutes in both countries also use the term "first-year" as a gender-neutral replacement for "freshman", although in the US this is recent usage, formerly referring only to those in the first year as a graduate student. One exception is the University of Virginia; since its founding in 1819 the terms "first-year", "second-year", "third-year", and "fourth-year" have been used to describe undergraduate university students. At the United States service academies, at least those operated by the federal government directly, a different terminology is used, namely "fourth class", "third class", "second class" and "first class" (the order of numbering being the reverse of the number of years in attendance). In the UK first-year university students are sometimes called "freshers" early in the academic year; however, there are no specific names for those in other years nor for school pupils. Graduate and professional students in the United States are known by their year of study, such as a "second-year medical student" or a "fifth-year doctoral candidate." Law students are often referred to as "1L", "2L", or "3L" rather than "nth-year law students"; similarly, medical students are frequently referred to as "M1", "M2", "M3", or "M4".
While anyone in the US who finishes studying at any educational institution by passing relevant examinations is said to "graduate" and to be a "graduate", in the UK only degree and above level students can "graduate". "Student" itself has a wider meaning in AmE, meaning any person of any age studying at any educational institution or level, whereas in BrE it tends to be used for people studying at a post-secondary educational institution and the term "pupil" is more widely used for a young person at primary or secondary school, though the use of "student" for secondary school pupils in the UK is increasingly used, particularly for "sixth form" (years 12 and 13).
The names of individual institutions can be confusing. There are several "University High Schools" in the United States that are not affiliated with any post-secondary institutions and cannot grant degrees, and there is one public high school, Central High School of Philadelphia, which does grant bachelor's degrees to the top ten per cent of graduating seniors. British secondary schools occasionally have the word "college" in their names.
When it comes to the admissions process, applicants are usually asked to solicit "letters of reference" or reference forms from referees in BrE. In AmE, these are called "letters of recommendation" or recommendation forms. Consequently, the writers of these letters are known as "referees" and "recommenders", respectively.
In the context of education, for AmE, the word "staff" mainly refers to school personnel who are neither administrators nor have teaching loads or academic responsibilities; personnel who have academic responsibilities are referred to as members of their institution's "faculty." In BrE, the word "staff" refers to both academic and non-academic school personnel. As mentioned previously, the term "faculty" in BrE refers more to a collection of related academic departments.
Politics.
In Britain, political candidates "stand for election", while in the US, they "run for office". There is virtually no crossover between BrE and AmE in the use of these terms.
Business/Finance.
In financial statements, what is referred to in AmE as "revenue" or "sales" is known in BrE as "turnover."
Employment/Recruitment.
In BrE, the term "curriculum vitae" (commonly abbreviated to "CV") is used to describe the document prepared by applicants containing their credentials required for a job. In AmE, the term "résumé" is more commonly used, with "CV" primarily used in academic or research contexts, and is usually more comprehensive than the "résumé".
Transport/Transportation.
Americans refer to "transportation" and British people to "transport". ("Transportation" in Britain has traditionally meant the punishment of criminals by deporting them to an overseas penal colony.) In AmE, the word "transport" is mainly used only as a verb, seldom as a noun or adjective except in reference to certain specialized objects, such as a "tape transport" or a "military transport" (e.g., a troop transport, a kind of vehicle, not an act of transporting).
Road transport.
Differences in terminology are especially obvious in the context of roads. The British term "dual carriageway", in American parlance, would be "divided highway". The "central reservation" on a "motorway" or "dual carriageway" in the UK would be the "median" or "center divide" on a "freeway", "expressway", "highway" or "parkway" in the US. The one-way lanes that make it possible to enter and leave such roads at an intermediate point without disrupting the flow of traffic are known as "slip roads" in the UK but US civil engineers call them "ramps" and both further distinguish between "on-ramps" or "entry-slips" (for entering) and "off-ramps" or "exit-slips" (for leaving). When American engineers speak of "slip roads", they are referring to a street that runs alongside the main road (separated by a berm) to allow off-the-highway access to the premises that are there, sometimes also known as a frontage road—in both the US and UK this is also known as a "service road".
In the UK, the term "outside lane" refers to the higher-speed "overtaking lane" ("passing lane" in the US) closest to the centre of the road, while "inside lane" refers to the lane closer to the edge of the road. In the US "outside lane" is used only in the context of a turn, in which case it depends in which direction the road is turning (i.e. if the road bends right the left lane is the "outside lane" but if the road bends left it is the right lane). Both also refer to "slow" and "fast" lanes (even though all actual traffic speeds may be at or around the legal speed limit).
In the UK "drink driving" is against the law, while in the US, where the action is also outlawed, the term is "drunk driving". The legal term in the US is "driving while intoxicated" (DWI) or "driving under the influence of alcohol" (DUI). The equivalent legal phrase in the UK is "drunk in charge of a motor vehicle" (DIC) or more commonly "driving with excess alcohol".
Specific auto parts and transport terms have different names in the two dialects, for example:<br>
Rail transport.
There are also differences in terminology in the context of rail transport. The best known is "railway" in Britain and "railroad" in America, but there are several others. A "railway station" in the UK is a "railroad station" or "train station" in the US; trains have "drivers" (often called "engine drivers") in Britain, while in America trains are driven by "engineers"; trains have "guards" in the UK and "conductors" in the US; a place where two tracks meet is called a set of "points" in the UK and a "switch" in the US; and a place where a road crosses a railway line at ground level is called a "level crossing" in Britain and a "grade crossing" in America. In Britain, the term "sleeper" is used for the devices that bear the weight of the rails and are known as "ties" or "crossties" in the United States. The British term "platform" in the sense "The train is at Platform 1" would be known in the US by the term "track", and used in the phrase "The train is on Track 1". Also, the British term "Brake Van" or "Guard's Van", is a "Caboose" in the US. Finally the American English phrase "All aboard!" when getting on a train is rarely used in Britain; the nearest British equivalent is "Take your seats!", and when the train reaches its final stop, in Britain the phrase used by announcers is "All change!" while in America it is "All out!"
Television.
Traditionally, a "show" on British television would have referred to a light-entertainment program (BrE "programme") with one or more performers and a participative audience, whereas in American television, the term is used for any type of program. British English traditionally referred to other types of program by their type, such as drama, serial etc., but the term "show" has now taken on the American meaning. In American television the episodes of a program first broadcast in a particular year constitute a "season", while the entire run of the program—which may span several seasons—is called a "series". In British television, on the other hand, the word "series" may apply to the episodes of a program in one particular year, for example, "The 1998 series of "Grange Hill"", as well as to the entire run. However, the entire run may occasionally be referred to as a "show".
The term "telecast", meaning television broadcast, is not used in British English. A television program would be "broadcast", "aired" or "shown" in Britain.
Levels of buildings.
There are also variations in floor numbering between the US and UK. In most countries, including the UK, the "first floor" is one above the entrance level, while the entrance level is the "ground floor". In the US the ground floor is considered the first floor. In a British lift one would press the "G" or "0" button to return to the ground floor, whereas in an American elevator, one would push the "1", "G", or "L" (for Lobby) button to return to the ground floor. The "L" button (or sometimes "-1") in a British lift would take you to the lower ground floor, which implies that the building is built on a slope and thus there are two ground floors - there would similarly be a "U" button (or "0") for upper ground floor.
American (AmE) "apartment buildings" / (BrE) "blocks of flats" are frequently exceptions to this rule. The ground floor often contains the lobby and parking area for the tenants, while the numbered floors begin one level above and contain only the flats (AmE "apartments") themselves.
Immigration.
In AmE, when immigrants apply for immigration benefits but are unsuccessful, they are said to be "denied" the benefit (e.g. visa application is denied, application for extension of stay is denied, entry to the US is denied). In BrE, those whose applications are unsuccessful are said to be "refused" that benefit (e.g. visa application is refused, entry to the UK is refused).
Units and measurement.
Numbers.
When saying or writing out numbers, the British insert an "and" before the tens and units, as in "one hundred and sixty-two" or "two thousand and three". In the United States it is considered correct to drop the "and", as in "one hundred sixty-two" or "two thousand three".
Some American schools teach students to pronounce decimally written fractions (for example, ".5") as though they were longhand fractions ("five tenths"), such as "thirteen and seven tenths" for 13.7. This formality is often dropped in common speech and is steadily disappearing in instruction in mathematics and science as well as in international American schools. In the UK, 13.7 would be read "thirteen point seven".
In counting, it is common in both varieties of English to count in hundreds up to 1,900—so "1,200" may be "twelve hundred". However, Americans use this pattern for much higher numbers than is the norm in British English, referring to twenty-four hundred where British English would most often use two thousand four hundred. Even below 2,000, Americans are more likely than the British are to read numbers like 1,234 as "twelve hundred thirty-four", instead of "one thousand two hundred and thirty-four".
In the case of years, however, "twelve thirty-four" would be the norm on both sides of the Atlantic for the year 1234. The year 2000 and years beyond it are read as "two thousand", "two thousand (and) one" and the like by both British and American speakers. For years after 2009, "twenty ten", "twenty twelve" etc. are becoming common.
For the house number (or bus number, etc.) 272, British people tend to say "two seven two" or "two hundred and seventy two", while Americans tend to say "two seventy-two".
There is also a historical difference between billions, trillions and so forth. Americans use "billion" to mean one thousand million (1,000,000,000), whereas in the UK, until the latter part of the 20th century, it was used to mean one million million (1,000,000,000,000). In 1974 the British prime minister, Harold Wilson, told the House of Commons that UK government statistics would now use the short scale; followed by the Chancellor, Denis Healey, in 1975, that the treasury would now adopt the US billion version. One thousand million was sometimes described as a "milliard", the definition adopted by most other European languages. However, the "American" version has since been adopted for all published writing, and the word "milliard" is obsolete in English, as are "billiard" (but not "billiards", the game), "trilliard", and so on. All major British publications and broadcasters, including the BBC, which long used "thousand million" to avoid ambiguity, now use "billion" to mean thousand million.
Many people have no direct experience of manipulating numbers this large, and many non-American readers may interpret "billion" as 1012 (even if they are young enough to have been taught otherwise at school); moreover usage of the "long" billion is standard in some non-English speaking countries. For these reasons, defining the word may be advisable when writing for the public. See long and short scales for a more detailed discussion of the evolution of these terms in English and other languages.
When referring to the numeral 0, British people would normally use "nought", "oh", or "zero", although "nil" is common in sports scores. Americans use the term "zero" most frequently; "oh" is also often used (though never when the quantity in question is nothing), and occasionally slang terms such as "zilch" or "zip". Phrases such as "the team won two–zip" or "the team leads the series two–nothing" are heard when reporting sports scores. In the case of association football—known as "football" in Britain and "soccer" in America—Americans will sometimes use "nil" as in Britain, although this usage is mostly confined to soccer journalists and hardcore fans and is not universal among either group. The digit 0, for example, when a phone or account number is being read aloud, is nearly always pronounced "oh" in both language varieties for the sake of convenience. In the internet age the use of the term "oh" can cause certain inconveniences when one is referencing an email address, causing confusion as to whether the character in question is a zero or the letter O.
When reading numbers in a sequence, such as a telephone or serial number, British people will usually use the terms "double" followed by the repeated number. Hence 007 is "double oh seven". Exceptions are the emergency telephone number 999, which is always "nine nine nine" and the apocalyptic "Number of the Beast", which is always "six six six". In the US 911 (the US emergency telephone number) is usually read "nine one one", while 9/11 (in reference to the September 11, 2001 attacks) is usually read "nine eleven".
Dates.
Dates are usually written differently in the short (numerical) form. Christmas Day 2000, for example, is 25/12/00 or 25.12.00 in the UK and 12/25/00 in the US, although the formats 25/12/2000, 25.12.2000, and 12/25/2000 now have more currency than they had before the Year 2000 problem. Occasionally other formats are encountered, such as the ISO 8601 2000-12-25, popular among programmers, scientists and others seeking to avoid ambiguity, and to make alphanumerical order coincide with chronological order. The difference in short-form date order can lead to misunderstanding. For example 06/04/05 could mean either June 4, 2005 (if read as US format), 6 April 2005 (if seen as in UK format) or even 5 April 2006 if taken to be an older ISO 8601-style format where 2-digit years were allowed.
A consequence of the different short-form of dates is that in the UK, many people are reluctant to refer to "9/11", although its meaning is instantly understood. On the BBC "September the 11th" is generally used in preference to 9/11. However, 9/11 is commonplace in the British press to refer to the events of September 11, 2001.
When using the name of the month rather than the number to write a date in the UK, the predominant modern, style is for the day to precede the month, e. g., 21 April. Month preceding date is almost invariably the style in the US. British usage often changes the day from an integer to an ordinal, i.e. 21st instead of 21. In speech, "of" and "the" are used in the UK, as in "the 21st of April". In written language, the words "the" and "of" may be and are usually dropped, i.e. 21 April. Meanwhile, the US would say this as "April 21st". One of the few exceptions in American English is saying "the Fourth of July", which is an abbreviation for the national holiday Independence Day.
Phrases such as the following are common in Britain but are generally unknown in the US: "A week today", "a week tomorrow", "a week Tuesday" and "Tuesday week" (although this is also used in central Texas); these all refer to a day more than a week in the future. "A fortnight Friday" and "Friday fortnight" refer to a day two weeks after the coming Friday). "A week on Tuesday" and "a fortnight on Friday" could refer either to a day in the past ("it's a week on Tuesday, you need to get another one") or in the future ("see you a week on Tuesday"), depending on context. In the US the standard construction is "a week from today", "a week from tomorrow", etc. BrE speakers may also say "Thursday last" or "Thursday gone" where AmE would prefer "last Thursday". "I'll see you (on) Thursday coming" or "let's meet this coming Thursday" in BrE refer to a meeting later this week, while "not until Thursday next" would refer to next week.
Time.
The 24-hour clock ("18:00", "18.00" or "1800") is considered normal in the UK and Europe in many applications including air, rail and bus timetables; it is largely unused in the US outside of military, police, aviation and medical applications. British English tends to use the full stop or period (.) when telling time, compared to American English which uses Colons (:) (i.e. 11:15 PM or 23:15 for AmE and 11.15 pm or 23.15 for BrE).
Fifteen minutes after the hour is called "quarter past" in British usage and "a quarter after" or, less commonly, "a quarter past" in American usage. Fifteen minutes before the hour is usually called "quarter to" in British usage and "a quarter of", "a quarter to" or "a quarter 'til" in American usage; the form "a quarter to" is associated with parts of the Northern United States, while "a quarter 'til" is found chiefly in the Appalachian region. Thirty minutes after the hour is commonly called "half past" in both BrE and AmE; "half after" used to be more common in the US. In informal British speech, the preposition is sometimes omitted, so that 5:30 may be referred to as "half five". The AmE formations "top of the hour" and "bottom of the hour" are not used in BrE. Forms such as "eleven forty" are common in both dialects.
Mass.
In British usage, human body mass is colloquially expressed in stones (equal to 14 pounds). People normally describe themselves as weighing, for example, "11 stone 4" (11 stones and 4 pounds) and not "158 pounds" (the conventional way of expressing the same weight in the United States). Stones are never used in the United States, and most Americans are unfamiliar with the term. Kilogrammes (note the difference from the U.S. spelling, "kilograms") are the official measurement in the United Kingdom, although very few people know their weight in kilogrammes. This is rarely noticed by the British (one such occasion might be a weight measurement at a hospital).
When used as the unit of measurement the plural form of "stone" is correctly "stone" (as in "11 stone"). When describing the units, the correct plural is "stones" (as in "Please enter your weight in stones and pounds").
Mathematics.
Besides the differences between the shorthand word for the subject itself (i.e. "Maths" for BrE and "Math" for AmE), there are also differences in terms within the subject.
In geometry, what is referred to as a "trapezoid" (a quadrilateral with exactly 1 pair of parallel sides) in US textbooks is a "trapezium" in its UK counterparts. The "slope" of the line in AmE is said to be the "gradient" of a line in BrE. The skill of "factoring" polynomials in AmE is called "factorisation" in BrE; likewise, the words "factor" and "factorise," respectively refer to their present tense forms.
In BrE the term mathematics is not commonly used for simple arithmetic. "2 + 2 = 4" is referred as arithmetic, not mathematics.
Holiday greetings.
When people greet one another with Christmas in North America, they say, "Merry Christmas!" In the U.K, "Happy Christmas!" is heard. It is increasingly common for Americans to say "Happy holidays", referring to all winter holidays (Christmas, Thanksgiving, New Year's Day, Hanukkah, Winter solstice, Kwanzaa, etc.); though it remains chiefly a commercial practice, used mostly at stores or in advertising. The phrase is rarely heard in the U.K. "Season's greetings" is a common phrase printed in greeting cards in both America and Britain. In Britain, the term "holiday season" or "holiday period" refers to the period in the summer when most people take their major annual holiday, and many people are absent from work.
Idiosyncratic differences.
Figures of speech.
Both BrE and AmE use the expression "I couldn't care less" to mean the speaker does not care at all. Many Americans use "I could care less" to mean the same thing. This variant is frequently derided as sloppy, as the literal meaning of the words is that the speaker "does" care to some extent.
In both areas, saying, "I don't mind" often means, "I'm not annoyed" (for example, by someone's smoking), while "I don't care" often means, "The matter is trivial or boring". However, in answering a question such as "Tea or coffee?", if either alternative is equally acceptable an American may answer, "I don't care", while a British person may answer, "I don't mind". Either sounds odd to the other.
In BrE the phrase "I can't be arsed (to do something)" is a recent vulgar equivalent to the British or American "I can't be bothered (to do it)". To non-BrE speakers this may be confused with the Southern English pronunciation of "I can't be asked (to do that thing)", which sounds either defiantly rude or nonsensical.
BrE uses the exclamation "No fear!" where current AmE has "No way!" An example from Dorothy L. Sayers:
This usage may confuse users of AmE, who are likely to interpret and even use "No fear!" as enthusiastic willingness to move forward (because the speaker has "no fear" of doing so).
Equivalent idioms.
A number of English idioms that have essentially the same meaning show lexical differences between the British and the American version; for instance:
 In the US, a "carpet" typically refers to a fitted carpet.
Writing.
Spelling.
Before the early 18th century English spelling was not standardized. Different standards became noticeable after the publishing of influential dictionaries. For the most part current BrE spellings follow those of Samuel Johnson's "Dictionary of the English Language" (1755), while AmE spellings follow those of Noah Webster's "An American Dictionary of the English Language" (1828). In Britain, the influences of those who preferred the French spellings of certain words proved decisive. In many cases AmE spelling deviated from mainstream British spelling; on the other hand it has also often retained older forms. Many of the now characteristic AmE spellings were popularized, although often not created, by Noah Webster. Webster chose already-existing alternative spellings "on such grounds as simplicity, analogy or etymology". Webster did attempt to introduce some reformed spellings, as did the Simplified Spelling Board in the early 20th century, but most were not adopted. Later spelling changes in the UK had little effect on present-day US spelling, and vice versa.
Punctuation.
Full stops and periods in abbreviations.
Americans tend to write "Mr.", "Mrs.", "St.", "Dr." whereas British "open punctuation" style will write "Mr", "Mrs", "St", "Dr", following the rule that a full stop/period is used only when the last letter of the abbreviation is not the last letter of the complete word. This kind of abbreviation is known as a "contraction" in the UK. The use of full stops/periods after most abbreviations was once standard in the UK, but current publications generally tend to follow the modern open style. Unit symbols such as "kg" and "Hz" are never punctuated.
Restrictive and non-restrictive modifiers.
In American English, restrictive and non-restrictive modifying phrases require different words and sentence structures. In particular, a non-restrictive modifying phrase must be set off by commas, and it generally uses "which" as its pronoun. A restrictive modifying phrase, by contrast, is not set off by commas, and uses the pronoun "that." An example of the first in American English is: "The dog, which bit the man, was brown." In that sentence the phrase "which bit the man" is non-restrictive: it is merely providing background information about a dog whose identity is otherwise not in question. The contrasting sentence in American English would be: "The dog that bit the man was brown." In this sentence, the phrase "that bit the man" is restrictive: it tells the reader that, of several dogs that might have bitten the man, the actual biter was brown. Interchanging the two structures is grammatically incorrect in American English because they have different meanings.
British English, by contrast, generally does not require its writers to construct sentences in a manner that distinguishes between the restrictive and non-restrictive forms of modifiers. Thus, a writer of British English might write: "The dog which bit the man was brown." In this sentence, it is ambiguous whether the phrase "which bit the man" is serving to identify a particular dog among several candidates or just to provide background information about a dog whose identity is otherwise not in doubt. The reader must try to infer the distinction from context or from his own knowledge.
H. W. Fowler, in "A Dictionary of Modern English Usage" of 1926, recommends “that”, without a preceding comma, for restrictive (“defining”) use and “which”, with a comma, for descriptive (“non-defining”) use. However, he notes that it was not (then) commonly British English usage, and that British and American usages differed, without explicitly identifying this usage as American. He also notes several problems with this usage “The most important of these is its ["that"'s] insistence on being the first word of its clause ; it cannot, like "whom" & "which", endure that a preposition governing it should, by coming before it, part it from the antecedent or the main sentence ; such a preposition has to go, instead, at the end of the clause ; that is quite in harmony with the closer connexion between a defining, (or "that"-) clause & the antecedent than between a non-defining (or "which"-) clause & the antecedent ; but it forces the writer to choose between ending his ["sic" their?] sentence or clause with a preposition & and giving up "that" for "which".” However, Fowler also goes on to reprise his assertion that prepositional endings are acceptable: “to shrink with horror from ending with a preposition is no more than a foolish superstition”.
Quoting.
Americans begin their quotations with double quotation marks (") and use single quotation marks (') for quotations within quotations. BrE usage varies, with some authoritative sources such as "The Economist" and "The Times" recommending the same usage as in the US, whereas other authoritative sources, such as "The King's English", recommend single quotation marks. In journals and newspapers, quotation mark double/single use depends on the individual publication's house style.
Americans almost always place commas and periods inside adjacent quotation marks. Specific exceptions are made for cases in which the addition of a period or comma could create confusion, such as the quotation of web addresses or certain types of data strings. In both styles, question marks and exclamation marks are placed inside the quotation marks if they belong to the quotation and outside otherwise. With narration of direct speech, both styles retain punctuation inside the quotation marks, with a full stop changing into a comma if followed by explanatory text, also known as a dialogue tag. Americans tend to apply quotations when signifying doubt of veracity (sarcastically or seriously), to imply another meaning to a word or to imply a cynical take on a paraphrased quotation, without punctuation at all.
The American style is used by most American newspapers, publishing houses and style guides in the United States and Canada (including the Modern Language Association's "MLA Style Manual", the American Psychological Association's "APA Publication Manual", the University of Chicago's "The Chicago Manual of Style", the American Institute of Physics's "AIP Style Manual", the American Medical Association's "AMA Manual of Style", the American Political Science Association's "APSA Style Manual", the Associated Press' "The AP Guide to Punctuation" and the Canadian Public Works' "The Canadian Style").
"Hart's Rules" and the "Oxford Dictionary for Writers and Editors" call the British style "new" quoting. It is also similar to the use of quotation marks in many other languages (including Portuguese, Spanish, French, Italian, Catalan, Dutch and German). A few US professional societies whose professions frequently employ various non-word characters, such as chemistry and computer programming, use the British form in their style guides (see "ACS Style Guide"). According to the "Jargon File", American hackers switched to what they later discovered to be the British quotation system because placing a period inside a quotation mark can change the meaning of data strings that are meant to be typed character-for-character. (It may be noted that the current American system places periods and commas outside the quotation marks in these cases anyway.)
Parentheses/brackets.
In British English, "( )" marks are often referred to as brackets, whereas "[ ]" are called square brackets and "{ }" are called curly brackets. In formal British English and in American English "( )" marks are parentheses (singular: parenthesis), "[ ]" are called brackets, and "{ }" can often be called curly braces. In both countries, standard usage is to place punctuation outside the parenthesis, unless the entire sentence is contained within them:
In the case of a parenthetical expression which is itself a complete sentence, the final punctuation may be placed inside the parenthesis, particularly if not a period:
Titles and headlines.
Use of capitalisation varies.
Sometimes the words in titles of publications and newspaper headlines as well as chapter and section headings are capitalised in the same manner as in normal sentences (sentence case). That is, only the first letter of the first word is capitalised, along with proper nouns, etc.
However, publishers sometimes require additional words in titles and headlines to have the initial capital, for added emphasis, as it is often perceived as appearing more professional. In AmE this is common in titles but less so in newspaper headlines. The exact rules differ between publishers and are often ambiguous; a typical approach is to capitalise all words other than short articles, prepositions, and conjunctions. This should probably be regarded as a common stylistic difference rather than a linguistic difference, as neither form would be considered incorrect or unusual in either the UK or the US. Many British tabloid newspapers (such as "The Sun", "The Daily Sport") use fully capitalised headlines for impact as opposed to readability (for example, BERLIN WALL FALLS or BIRD FLU PANIC). On the other hand the broadsheets (such as "The Guardian", "The Times", and "The Independent") usually follow the sentence style of having only the first letter of the first word capitalised.
American newspapers commonly use a comma as a shorthand for "and" in headlines. For example, "The Washington Post" had the headline "A TRUE CONSERVATIVE: For McCain, Bush Has Both Praise, Advice."

</doc>
<doc id="2014" url="http://en.wikipedia.org/wiki?curid=2014" title="Atomic semantics">
Atomic semantics

Atomic semantics is a term which describes the guarantees provided by a data register shared by several processors in a parallel machine or in a network of computers working together.
Atomic semantics are defined for a variable with a single writer but multiple readers. These
semantics are very strong: they guarantee that the read and write operations to the variable behave exactly as if they happened instantaneously in some point in time which is within the actual time where the operation took place.

</doc>
<doc id="2015" url="http://en.wikipedia.org/wiki?curid=2015" title="Antarctic Circumpolar Current">
Antarctic Circumpolar Current

The Antarctic Circumpolar Current (ACC) is an ocean current that flows clockwise from west to east around Antarctica. An alternative name for the ACC is the West Wind Drift. The ACC is the dominant circulation feature of the Southern Ocean and, at approximately 125 Sverdrups, the largest ocean current. The current is circumpolar due to the lack of any landmass connecting with Antarctica and this keeps warm ocean waters away from Antarctica, enabling that continent to maintain its huge ice sheet.
Associated with the Circumpolar Current is the Antarctic Convergence, where the cold Antarctic waters meet the warmer waters of the subantarctic, creating a zone of upwelling nutrients. These nurture high levels of phytoplankton with associated copepods and krill, and resultant foodchains supporting fish, whales, seals, penguins, albatrosses and a wealth of other species.
The ACC has been known to sailors for centuries; it greatly speeds up any voyages from west to east, but makes sailing extremely difficult from east to west; though this is mostly due to the prevailing westerly winds. The circumstances preceding the mutiny on the "Bounty" and Jack London's story "Make Westing" poignantly illustrated the difficulty it caused for mariners seeking to round Cape Horn on the clipper ship route between New York and California. The clipper route, which is the fastest sailing route around the world, follows the ACC around three continental capes – Cape Agulhas (Africa), South East Cape (Australia) and Cape Horn (South America).
The current creates the Ross and Weddell gyres.
Structure.
The ACC connects the Atlantic, Pacific and Indian Ocean basins, and serves as a principal pathway of exchange between these basins. The current is strongly constrained by landform and bathymetric features. To trace it starting arbitrarily at South America, it flows through the Drake Passage between South America and the Antarctic Peninsula and then is split by the Scotia Arc to the east, with a shallow warm branch flowing to the north in the Falkland Current and a deeper branch passing through the Arc more to the east before also turning to the north. Passing through the Indian Ocean, the current is split by the Kerguelen Plateau in the Indian Ocean, and then moving northward again. Deflection is also seen as it passes over the mid-ocean ridge in the Southeast Pacific.
The current is accompanied by a number of fronts. The northern boundary of the ACC is defined by the northern edge of the Subantarctic Front, this being the most northerly water to pass through Drake Passage and therefore be circumpolar. Much of the ACC transport is carried in this front, which is defined as the latitude at which a subsurface salinity minimum or a thick layer of unstratified Subantarctic Mode Water first appears, allowed by temperature dominating density stratification. Still further south lies the Polar front, which is marked by a transition to very cold, relatively fresh, Antarctic Surface Water at the surface. Here a temperature minimum is allowed by salinity dominating density stratification, due to the lower temperatures. Further south still is the Southern Antarctic Circumpolar Current Front (SACCF), which is determined as the southernmost extent of Circumpolar Deep Water (temperature of about 2 °C at 400 m). This water mass flows along the shelfbreak of the western Antarctic Peninsula and thus marks the most southerly water flowing through Drake Passage and therefore circumpolar. The bulk of the transport is carried in the middle two fronts. The total transport of the ACC at Drake Passage is estimated to be around 135 Sverdrups (135,000,000 m³/s), or about 135 times the transport of all the world's rivers combined. There is a relatively small addition of flow in the Indian Ocean, with the transport south of Tasmania reaching around 147 Sv, at which point the current is probably the largest on the planet.
Dynamics.
The circumpolar current is driven by the strong westerly winds in the latitudes of the Southern Ocean.
In latitudes where there are continents, winds blowing on light surface water can simply pile up light water against these continents. But in the Southern Ocean, the momentum imparted to the surface waters cannot be offset in this way. There are different theories on how the Circumpolar Current balance the momentum imparted by the winds. The increasing eastward momentum imparted by the winds causes water parcels to drift outwards from the axis of the Earth's rotation (in other words, northward) as a result of the Coriolis force. This northward Ekman transport is balanced by a southward, pressure-driven flow below the depths of the major ridge systems. Some theories connect these flows directly, implying that there is significant upwelling of dense deep waters within the Southern Ocean, transformation of these waters into light surface waters, and a transformation of waters in the opposite direction to the north. Such theories link the magnitude of the Circumpolar Current with the global thermohaline circulation, particularly the properties of the North Atlantic.
Alternatively, ocean eddies, the oceanic equivalent of atmospheric storms, or the large-scale meanders of the Circumpolar Current may directly transport momentum downwards in the water column. This is because such flows can produce a net southward flow in the troughs and a net northward flow over the ridges without requiring any transformation of density. In practice both the thermohaline and the eddy/meander mechanisms are likely to be important.
The current flows at a rate of about four km per hour. Recent studies have indicated that the Antarctic Circumpolar Current varies with time. Evidence of this is the Antarctic Circumpolar Wave, a periodic oscillation that affects the climate of much of the southern hemisphere. There is also the Antarctic oscillation, which involves changes in the location and strength of Antarctic winds. Trends in the Antarctic Oscillation have been hypothesized to account for an increase in the transport of the Circumpolar Current over the past two decades.
Formation.
Published estimates of the onset of the Antarctic Circumpolar Current vary, but it is commonly considered to have started at the Eocene/Oligocene boundary. The isolation of Antarctica and formation of the ACC occurred with the openings of the Tasmanian Seaway and the Drake Passage. The Tasmanian Seaway separates East Antarctica and Australia, and is reported to have opened to water circulation 33.5 Ma. The timing of the opening of the Drake Passage, between South America and the Antarctic Peninsula, is more disputed; tectonic and sediment evidence show that it could have been open as early as pre 34 Ma, estimates of the opening of the Drake passage are between 20 and 40 Ma. The isolation of Antarctica by the current is credited by many researchers with causing the glaciation of Antarctica and global cooling in the Eocene epoch. Oceanic models have shown that the opening of these two passages limited polar heat convergence and caused a cooling of sea surface temperatures by several degrees; other models have shown that CO2 levels also played a significant role in the glaciation of Antarctica [5].
Phytoplankton.
Antarctic sea ice cycles seasonally, in February–March the amount of sea ice is lowest, and in August–September the sea ice is at its greatest extent. Ice levels have been monitored by satellite since 1973. Upwelling of deep water under the sea ice brings substantial amounts of nutrients. As the ice melts, the melt water provides stability and the critical depth is well below the mixing depth, which allows for a positive net primary production. As the sea ice recedes epontic algae dominate the first phase of the bloom, and a strong bloom dominate by diatoms follows the ice melt south [9].
Another phytoplankton bloom occurs more to the north near the antarctic convergence, here nutrients are present from thermohaline circulation. Phytoplankton blooms are dominated by diatoms and grazed by copepods in the open ocean, and by krill closer to the continent. Diatom production continues through the summer, and populations of krill are sustained, bringing large numbers of cetaceans, cephalopods, seals, birds and fish to the area [10].
Phytoplankton blooms are believed to be limited by irradiance in the austral (southern hemisphere) spring, and by biologically available iron in the summer. Much of the biology in the area occurs along the major fronts of the current, the Subtropical, SubAntarctic, and the Antarctic Polar fronts, these are areas associated with well defined temperature changes. Size and distribution of phytoplankton are also related to fronts. Microphytoplankton (>20μm) are found at fronts and at sea ice boundaries, while nanophytoplankton (<20μm) are found between fronts.
Studies of phytoplankton stocks in the southern sea have shown that the Antarctic Circumpolar Current is dominated by diatoms, while the Weddell Sea has abundant coccolithophorids and silicoflagellates. Surveys of the SW Indian Ocean have shown phytoplankton group variation based on their location relative to the Polar Front, with diatoms dominating South of the front, and dinoflagellates and flagellates in higher populations North of the front [10].
Some research has been done on Antarctic phytoplankton as a carbon sink. Areas of open water left from ice melt are good areas for phytoplankton blooms. The phytoplankton takes carbon from the atmosphere during photosynthesis. As the blooms die and sink, the carbon can be stored in sediments for thousands of years. This natural carbon sink is estimated to remove 3.5 million tonnes from the ocean each year. 3.5 million tonnes of carbon taken from the ocean and atmosphere is equivalent to 12.8 million tonnes of carbon dioxide.
Studies.
An expedition in May 2008 by 19 scientists studied the geology and biology of eight Macquarie Ridge sea mounts, as well as the Antarctic Circumpolar Current to investigate the effects of climate change of the southern Ocean. The circumpolar current merges the waters of the Atlantic, Indian, and Pacific Oceans and carries up to 150 times the volume of water flowing in all of the world's rivers. After studying the circumpolar current it is clear that it strongly influences regional and global climate as well as underwater biodiversity.
Dr Adrian Glover of the Natural History Museum, London says that the current helps preserve wooden shipwrecks by preventing wood-boring "ship worms" from reaching targets such as Ernest Shackleton's ship the "Endurance".

</doc>
<doc id="2017" url="http://en.wikipedia.org/wiki?curid=2017" title="Arbor Day">
Arbor Day

Arbor Day (from the Latin "arbor", meaning tree) is a holiday in which individuals and groups are encouraged to plant and care for trees. Today, many countries observe such a holiday. Though usually observed in the spring, the date varies, depending on climate and suitable planting season.
Origins.
First Arbor Day in the world.
The small Spanish village of Villanueva de la Sierra is the town where was held the first Arbor Day around the world, an initiative launched in 1805 by the local priest with the enthusiastic support of the entire population.
First American Arbor Day.
The first American Arbor Day was originated in Nebraska City, Nebraska, United States by J. Sterling Morton. On April 10, 1872, an estimated one million trees were planted in Nebraska.
Birdsey Northrop of Connecticut was responsible for globalizing it when he visited Japan in 1883 and delivered his Arbor Day and Village Improvement message. In that same year, the American Forestry Association made Northrop the Chairman of the committee to campaign for Arbor Day nationwide. He also brought his enthusiasm for Arbor Day to Australia, Canada, and Europe.
McCreight and Roosevelt.
Beginning in 1906, Pennsylvania conservationist Major Israel McCreight of DuBois, Pennsylvania, argued that President Theodore Roosevelt’s conservation speeches were limited to businessmen in the lumber industry and recommended a campaign of youth education and a national policy on conservation education. McCreight urged President Roosevelt to make a public statement to school children about trees and the destruction of American forests. Conservationist Gifford Pinchot, Chief of the United States Forest Service, embraced McCreight’s recommendations and asked the President to speak to the public school children of the United States about conservation. On April 15, 1907, Roosevelt issued an "Arbor Day Proclamation to the School Children of the United States" about the importance of trees and that forestry deserves to be taught in U.S. schools. Pinchot wrote McCreight, “we shall all be indebted to you for having made the suggestion.”
Around the world.
Australia.
National Schools Tree Day is held on the last Friday of July for schools and National Tree Day the last Sunday in July throughout Australia. Many states have Arbor Day although only Victoria has Arbor Week, which was suggested by Premier Dick Hamer in the 1980s. Arbor Day has been observed in Australia since 20 June 1889.
Belgium.
International Day of Treeplanting is celebrated in Flanders on or around 21 March as a theme-day/educational-day/observance, not as public holidays. Tree planting is sometimes combined with awareness campaigns of the fight against cancer: "Kom Op Tegen Kanker".
Brazil.
The Arbor Day (Dia da Árvore) is celebrated on September 21. It's not a national holiday. However, schools nationwide celebrate this day with environment-related activities, namely tree planting.
British Virgin Islands.
Arbour Day is celebrated on November 22. It is sponsored by the National Parks Trust of the Virgin Islands. Activities include an annual national Arbour Day Poetry Competition and tree planting ceremonies throughout the territory.
Cambodia.
National Tree Planting Day is on June 1.
Cambodia celebrates an arbor day on 9 July.
Canada.
Founded by Don Clark of Schomberg, Ontario for his wife Margret Clark in 1906. In Canada, Maple Leaf Day falls on the last Wednesday in September during National Forest Week. Ontario celebrates Arbor Week from the last Friday in April to the first Sunday in May. Nova Scotia celebrates Arbor Day on the Thursday during National Forest Week, which is the first full week in May. Prince Edward Island celebrates Arbor Day on the 3rd Friday in May during Arbor Week.
Central African Republic.
National Tree Planting Day is on July 20.
Czech Republic.
National Tree Planting Day is on October 20. The tree of year is voted.
China.
In 1981, the fourth session of the Fifth National People's Congress of the People's Republic of China adopted the Resolution on the Unfolding of a Nationwide Voluntary Tree-planting Campaign. This resolution established the Arbor Day () and stipulated that every able-bodied citizen between the ages of 11 and 60 should plant three to five trees per year or do the equivalent amount of work in seedling, cultivation, tree tending or other services. Supporting documentation instructs all units to report population statistics to the local afforestation committees as the basis for workload allocation. Moreover, those failing to do their duty are expected to make up planting requirements, provide funds equivalent to the value of labor required or pay heavy fines. Therefore, the tree-planting campaign is actually compulsory, or at least obligatory (that is, an obligation to the community). The "voluntary" in the title referred to the fact that the tree-planters would "volunteer" their labour. The People's Republic of China celebrates Arbor Day on March 12, a day founded by Lin Daoyang, continue to use following the date of Arbor Day of Republic of China.
Costa Rica.
"Día del Árbol" is on June 15.
Egypt.
Arbor Day is on January 15.
Germany.
Arbor Day ("Tag des Baumes") is on April 25. First celebration was in 1952.
India.
Van Mahotsav is an annual pan-Indian tree planting festival, occupying a week in the month of July. During this event millions of trees are planted. It was initiated in 1950 by K. M. Munshi, the then Union Minister for Agriculture and Food to create an enthusiasm in the mind of the populace for the conservation of forests and planting of trees.
The name Van Mahotsava (the festival of trees) originated in July 1947 after a successful tree-planting drive was undertaken in Delhi, in which national leaders like Jawaharlal Nehru, Dr Rajendra Prasad and Abdul Kalam Azad participated. Paryawaran Sachetak Samiti, a leading environmental organization conducts mass events & concrete activities on this special day celebration each year. The week was simultaneously celebrated in a number of states in the country.
Iran.
In Iran it is known as National Tree Planting Day. By Solar Hijri calendar, it is on the 15th day of month Esfand which usually corresponds with March 5.
This day is the first day of the Natural Recyclable Resources week (March 5 to 12).
This is the time in which the saplings of the all kinds in terms of different climates of different parts of Iran would be shared among the people. They also are going to be taught the ways of planting trees.
Israel.
The Jewish holiday Tu Bishvat, the new year for trees, is on the 15th day of the month of Shvat, which usually falls in January or February. Originally based on the date used to calculate the age of fruit trees for tithing as mandated in Leviticus 19:23–25, the holiday now is most often observed by planting trees, or raising money to plant trees. Tu Bishvat is a semi official holiday in Israel, schools are open but Hebrew speaking schools will often go on tree planting excursions.
Japan.
Japan celebrates a similarly themed Greenery Day, held on May 4. Although it has a similar theme to Arbor Day, its roots lay in celebration of the birthday of Emperor Hirohito.
Kenya.
National Tree Planting Day is on April 21. Often people plant palm trees and coconut trees along the Indian Ocean that borders the East coast of Kenya.
Lesotho.
National Tree Planting Day is on March 21.
Luxembourg.
National Tree Planting Day is in November since 1991. It is organized by natur&ëmwelt.
Republic of Macedonia.
Having in mind the bad condition of the forest fund, and in particular the catastrophic wildfires which occurred in the summer of 2007, a citizen's initiative for afforestation was started in the Republic of Macedonia. The campaign by the name 'Tree Day-Plant Your Future' was first organized on 12 March 2008, when an official non-working day was declared and more than 150,000 Macedonians planted 2 million trees in one day (symbolically, one for each citizen). Six million more were planted in November the same year, and another 12,5 million trees in 2009.
Malawi.
National Tree Planting Day is on the 2nd Monday of December.
Mexico.
National Tree Day is on the 2nd Thursday of July.
Namibia.
Its first Arbor Day was celebrated on 2004-10-08.
Netherlands.
Since conference and of the Food and Agriculture Organization's publication "World Festival of Trees", and a resolution of the United Nations in 1954: "The Conference, recognising the need of arousing mass consciousness of the aesthetic, physical and economic value of trees, recommends a World Festival of Trees to be celebrated annually in each member country on a date suited to local conditions"; it has been adopted by the Netherlands. In 1957, the National Committee Day of Planting Trees/Foundation of National Festival of Trees ("Nationale Boomplantdag"/"Nationale Boomfeestdag") was created.
On the third Wednesday in March each year (near the spring equinox), three quarters of Dutch schoolchildren aged 10/11 and Dutch celebrities plant trees. Stichting Nationale Boomfeestdag organizes all the activities in the Netherlands for this day. Some municipalities however plant the trees around 21 September because of the planting season.
In 2007, the 50th anniversary was celebrated with special golden jubilee-activities.
New Zealand.
New Zealand's first Arbor Day planting was in Greytown in the Wairarapa on 3 July 1890. The first official celebration will take place in Wellington in August 2012, with the planting of pohutukawa and Norfolk pines along Thorndon Esplanade.
Born in 1855, Dr Leonard Cockayne (generally recognised as the greatest botanist who has lived, worked, and died in New Zealand) worked extensively on native plants throughout New Zealand and wrote many notable botanical texts. Even as early as the 1920s he held a vision for school students of New Zealand to be involved in planting native trees and plants in their school grounds. This vision bore fruit and schools in New Zealand have long planted native trees on Arbor Day.
Since 1977, New Zealand has celebrated Arbor Day on June 5, which is also World Environment Day, prior to then Arbor Day, in New Zealand, was celebrated on August 4 – which is rather late in the year for tree planting in New Zealand hence the date change.
What the Department of Conservation (DOC) does for Arbor Day:
Many of DOC's Arbor Day activities focus on ecological restoration projects using native plants to restore habitats that have been damaged or destroyed by humans or invasive pests and weeds. There are great restoration projects underway around New Zealand and many organisations including community groups, landowners, conservation organisations, iwi, volunteers, schools, local businesses, nurseries and councils are involved in them. These projects are part of a vision to protect and restore the indigenous biodiversity.
Niger.
Since 1975, Niger has celebrated Arbor Day as part of its Independence Day: 3 August. On this day, aiding the fight against desertification, each Nigerien plants a tree.
Pakistan.
National tree plantation day of Pakistan ( قومی شجر کاری دن ) is celebrated on 18 August.
Philippines.
Arbor Day in the Philippines has been institutionalized to be observed every June 25 throughout the nation by planting trees and ornamental plants and other forms of relevant activities. The necessity to promote a healthier ecosystem for the people through the rehabilitation and regreening of the environment was stressed in Proclamation No. 643 that amended Proclamation No. 396 of June 2, 2003. Proclamation No. 396 enjoined the "active participation of all government agencies, including government-owned and controlled corporations, private sector, schools, civil society groups and the citizenry in tree planting activity and declaring June 25, 2003 as ."
Poland.
In Poland, Arbor Day is celebrated on October 10.
Portugal.
Arbor Day is celebrated on March 21. It's not a national holiday but instead schools nationwide celebrate this day with environment-related activities, namely tree planting.
South Africa.
Arbor Day was celebrated from 1945 until 2000 in South Africa, when the national government extended it to National Arbor Week, which lasts from 1–7 September. , one common and one rare, are highlighted to increase public awareness of indigenous trees, while various "greening" activities are undertaken by schools, businesses and other organizations.
South Korea.
Arbor Day (Sikmogil, 식목일) was a public holiday in South Korea on April 5 until 2005. The day is still celebrated, though. On non-leap years, the day coincides with Hansik.
Spain.
In Spain is usually held on the International Forest Day on 21 March, but following the 1915 decree spirit that forced to celebrate the Arbor Day throughout Spain, each municipality or collective decides the date for its Arbor Day, usually between February and May. In Villanueva de la Sierra (Extremadura), where the first Arbor Day in the world was held in 1805, it is celebrated, as on that occasion, on Tuesday Carnaval. It is a great day in the local festive calendar.
As an example of commitment to nature, the small town of Pescueza, with only 180 inhabitants, organizes every spring a large plantation of holm oaks, which is called the “Festivalino” promoted by city council, several foundations and citizen participation where several thousand people together repopulates naked lands and regaining life. All wrapped up in a fun party atmosphere, joy, music and renew.
Sri Lanka.
National Tree Planting Day is on November 15.
Taiwan.
Arbor Day (植樹節) has been a traditional holiday in the Republic of China since 1927. In 1914, the founder of the agricultural college at Nanking University suggested to the now-defunct Ministry of Agriculture and Forestry that China should imitate the practice in the United States of Arbor Day. The holiday would be held the same day as the Qingming Festival. However, for unknown reasons, the suggestion was not made through the formal process, so nothing came from this original request. After the successful conclusion of the Northern Expedition, the now-defunct Ministry of Agriculture and Minerals formally petitioned the Executive Yuan to establish Arbor Day to commemorate the passing of Dr. Sun Yat-sen, the Father of Modern China. He had been a major advocate of afforestation in his life, because it would increase people's livelihoods. The Executive Yuan approved Arbor Day in the spirit of Dr. Sun that year and has since been celebrated on March 12 for this purpose.
Tanzania.
National Tree Planting Day is on January 1
Uganda.
National Tree Planting Day is on March 24.
United Kingdom.
First mounted in 1975, National Tree Week is a celebration of the start of the winter tree planting season. Around a million trees are planted each year by schools, community organizations and local authorities.
United States.
Arbor Day was founded in 1872 by Julius Sterling Morton in Nebraska City, Nebraska. By the 1920s, each state in the United States had passed public laws that stipulated a certain day to be Arbor Day or Arbor and Bird Day observance.
National Arbor Day is celebrated every year on the last Friday in April; in Nebraska, it is a civic holiday. Each state celebrates its own state holiday. The customary observance is to plant a tree. On the first Arbor Day, April 10, 1872, an estimated one million trees were planted.
Venezuela.
Venezuela recognizes "Día del Arbol" on the last Sunday of May.

</doc>
<doc id="2018" url="http://en.wikipedia.org/wiki?curid=2018" title="A. J. Ayer">
A. J. Ayer

Sir Alfred Jules "Freddie" Ayer (; 29 October 1910 – 27 June 1989) was a British philosopher known for his promotion of logical positivism, particularly in his books "Language, Truth, and Logic" (1936) and "The Problem of Knowledge" (1956).
Ayer was a Special Operations Executive and MI6 agent during the Second World War. He was the Grote Professor of the Philosophy of Mind and Logic at University College London from 1946 until 1959, when he became Wykeham Professor of Logic at the University of Oxford. He was president of the Aristotelian Society from 1951 to 1952. He was knighted in 1970.
Life.
Ayer was born in St John's Wood, London, to a wealthy family, and was educated at Ascham St Vincent's Preparatory School and Eton. It was at Eton that Ayer first became known for his characteristic bravado and precocity. In the final examinations at Eton, Ayer came second in his year, and first in classics. In his final year, as a member of Eton's senior council, he unsuccessfully campaigned for the abolition of corporal punishment at the school. He won a classics scholarship to Christ Church, Oxford. He served as an officer in the Welsh Guards during World War II, working for the Special Operations Executive (SOE) and spying for MI6. He was an extrovert, and social mixer, and was married four times, including to Dee Wells and Vanessa Salmon (thus becoming stepfather to Nigella Lawson). Reputedly he liked dancing and attending the clubs in London and New York. He was also obsessed with sport: he had played rugby for Eton, and was a noted cricketer and a keen supporter of the Tottenham Hotspur football team. For an academic, Ayer was an unusually well-connected figure in his time, with close links to 'high-society' and the establishment. Presiding over Oxford high-tables, he is often described as charming, but at times he could also be intimidating.
In "Language, Truth and Logic" (1936), Ayer rejected atheism, as he understood it, on the grounds that any religious discourse was meaningless. He believed that religious language was unverifiable and as such literally nonsense. Consequently "There is no God" was for Ayer as meaningless and metaphysical an utterance as "God exists." Though Ayer could not give assent to the declaration "There is no God," he was an atheist in the sense that he withheld assent from affirmations of God's existence. However, in "Language, Truth and Logic" he distinguishes himself from both agnostics and atheists by saying that both these stances take the statement "God exists" as a meaningful hypothesis, which Ayer himself does not. He also criticises C. A. Mace's opinion that metaphysics is a form of intellectual poetry. The stance of a person who believes "God" denotes no verifiable hypothesis is sometimes referred to as igtheism (for example, by Paul Kurtz). In later years Ayer did refer to himself as an atheist and stated that he did not believe in God. He followed in the footsteps of Bertrand Russell by debating with the Jesuit scholar Frederick Copleston on the topic of religion.
Ayer's version of emotivism divides "the ordinary system of ethics" into four classes:
He focuses on propositions of the first class—moral judgments—saying that those of the second class belong to science, those of the third are mere commands, and those of the fourth (which are considered in normative ethics as opposed to meta-ethics) are too concrete for ethical philosophy. While class three statements were irrelevant to Ayer's brand of emotivism, they would later play a significant role in Stevenson's.
Ayer argues that moral judgments cannot be translated into non-ethical, empirical terms and thus cannot be verified; in this he agrees with ethical intuitionists. But he differs from intuitionists by discarding appeals to intuition as "worthless" for determining moral truths, since the intuition of one person often contradicts that of another. Instead, Ayer concludes that ethical concepts are "mere pseudo-concepts":
Between 1945 and 1947, together with Russell and George Orwell, he contributed a series of articles to "Polemic", a short-lived British "Magazine of Philosophy, Psychology, and Aesthetics" edited by the ex-Communist Humphrey Slater.
Ayer was closely associated with the British humanist movement. He was an Honorary Associate of the Rationalist Press Association from 1947 until his death. He was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1963. In 1965, he became the first president of the Agnostics' Adoption Society and in the same year succeeded Julian Huxley as president of the British Humanist Association, a post he held until 1970. In 1968 he edited "The Humanist Outlook", a collection of essays on the meaning of humanism. In addition he was one of the signers of the Humanist Manifesto.
He taught or lectured several times in the United States, including serving as a visiting professor at Bard College in the fall of 1987. At a party that same year held by fashion designer Fernando Sanchez, Ayer, then 77, confronted Mike Tyson who was forcing himself upon the (then) little-known model Naomi Campbell. When Ayer demanded that Tyson stop, the boxer said: "Do you know who the fuck I am? I'm the heavyweight champion of the world," to which Ayer replied: "And I am the former Wykeham Professor of Logic. We are both pre-eminent in our field. I suggest that we talk about this like rational men". Ayer and Tyson then began to talk, while Naomi Campbell slipped out.
From 1959 to his retirement in 1978, Sir Alfred held the Wykham Chair, Professor of Logic at Oxford. He was knighted in 1970.
Ayer died on 27 June 1989. From 1980 – 1989, Ayer lived at 51 York Street, Marylebone, where a memorial plaque was unveiled on 19 November 1995.
Personal life.
Ayer was married four times to three women. His first marriage was from 1932–1941 to (Grace Isabel) Renée (d. 1980), who subsequently married philosopher Stuart Hampshire; Ayer's friend and colleague. In 1960 he married Alberta Constance (Dee) Wells (1925–2003), with whom he had one son. Ayer's marriage to Wells was dissolved in 1983 and that same year he married Vanessa Mary Addison, former wife of politician Nigel Lawson. She died in 1985 and in 1989 he remarried Dee Wells, who survived him. Ayer also had a daughter with Hollywood columnist Sheilah Graham Westbrook.
Near-death experience.
In 1988, shortly before his death, Ayer wrote an article entitled, "What I saw when I was dead", describing an unusual near-death experience. Of the experience, Ayer first said that it "slightly weakened my conviction that my genuine death ... will be the end of me, though I continue to hope that it will be." However, a few days later he revised this, saying "what I should have said is that my experiences have weakened, not my belief that there is no life after death, but my inflexible attitude towards that belief".
In 2001 Dr. Jeremy George, the attending physician, claimed that Ayer had confided to him: "I saw a Divine Being. I'm afraid I'm going to have to revise all my books and opinions." Ayer's son Nick, however, said that he had never mentioned this to him though he did find his father's words to be extraordinary, and said he had long felt there was something possibly suspect about his father's version of his near death experience.
Works.
Ayer is best known for popularising the verification principle, in particular through his presentation of it in "Language, Truth, and Logic" (1936). The principle was at the time at the heart of the debates of the so-called Vienna Circle which Ayer visited as a young guest. Others, including the leading light of the circle, Moritz Schlick, were already offering their own papers on the issue. Ayer's own formulation was that a sentence can only be meaningful if it has verifiable empirical import, otherwise it is either "analytical" if tautologous, or "metaphysical" (i.e. meaningless, or "literally senseless"). He started to work on the book at the age of 23 and it was published when he was 26. Ayer's philosophical ideas were deeply influenced by those of the Vienna Circle and David Hume. His clear, vibrant and polemical exposition of them makes "Language, Truth and Logic" essential reading on the tenets of logical empiricism– the book is regarded as a classic of 20th century analytic philosophy, and is widely read in philosophy courses around the world. In it, Ayer also proposed that the distinction between a conscious man and an unconscious machine resolves itself into a distinction between 'different types of perceptible behaviour', an argument which anticipates the Turing test published in 1950 to test a machine's capability to demonstrate intelligence.
Ayer wrote two books on the philosopher Bertrand Russell, "Russell and Moore: The Analytic Heritage" (1971) and "Russell" (1972). He also wrote an introductory book on the philosophy of David Hume and a short biography of Voltaire.
Ayer was strong critic of the German philosopher Martin Heidegger. As a logical positivist Ayer was in conflict with Heidegger's proposed vast, overarching theories regarding existence. These he felt were completely unverifiable through empirical demonstration and logical analysis. This sort of philosophy was an unfortunate strain in modern thought. He considered Heidegger to be the worst example of such philosophy, which Ayer believed to be entirely useless.
In 1972–1973 Ayer gave the Gifford Lectures at University of St Andrews, later published as "The Central Questions of Philosophy". In the preface to the book, he defends his selection to hold the lectureship on the basis that Lord Gifford wished to promote '"Natural Theology", in the widest sense of that term', and that non-believers are allowed to give the lectures if they are "able reverent men, true thinkers, sincere lovers of and earnest inquirers after truth". He still believed in the viewpoint he shared with the logical positivists: that large parts of what was traditionally called "philosophy"– including the whole of metaphysics, theology and aesthetics– were not matters that could be judged as being true or false and that it was thus meaningless to discuss them.
In "The Concept of a Person and Other Essays" (1963), Ayer heavily criticized Wittgenstein's private language argument.
Ayer's sense-data theory in "Foundations of Empirical Knowledge" was famously criticised by fellow Oxonian J. L. Austin in "Sense and Sensibilia", a landmark 1950s work of common language philosophy. Ayer responded to this in the essay "Has Austin Refuted the Sense-data Theory?", which can be found in his "Metaphysics and Common Sense" (1969).

</doc>
<doc id="2019" url="http://en.wikipedia.org/wiki?curid=2019" title="André Weil">
André Weil

André Weil (; 6 May 1906 – 6 August 1998) was an influential French mathematician of the 20th century, known for his foundational work in number theory and algebraic geometry. He was a founding member and the "de facto" early leader of the influential Bourbaki group. The philosopher Simone Weil was his sister.
Life.
Andrew Weil was born in Paris to Alsatian agnostic Jewish parents who fled the annexation of Alsace-Lorraine by Germany. The famous philosopher Simone Weil was Weil's only sibling. He studied in Paris, Rome and Göttingen and received his doctorate in 1928. While in Germany, Weil befriended Carl Ludwig Siegel. Starting in 1930, he spent two academic years at Aligarh Muslim University. Aside from mathematics, Weil held lifelong interests in Hinduism and Sanskrit literature. After teaching for one year in Marseille, he taught for six years in Strasbourg. He married Éveline in 1937.
Weil was in Finland when World War II broke out; he had been traveling in Scandinavia since April 1939. His wife Éveline returned to France without him. Weil was mistakenly arrested in Finland at the outbreak of the Winter War on suspicion of spying; however, accounts of his life having been in danger were shown to be exaggerated. Weil returned to France via Sweden and the United Kingdom, and was detained at Le Havre in January 1940. He was charged with failure to report for duty, and was imprisoned in Le Havre and then Rouen. It was in the military prison in Bonne-Nouvelle, a district of Rouen, from February to May, that Weil completed the work that made his reputation. He was tried on 3 May 1940. Sentenced to five years, he requested to be attached to a military unit instead, and was given the chance to join a regiment in Cherbourg. After the fall of France, he met up with his family in Marseille, where he arrived by sea. He then went to Clermont-Ferrand, where he managed to join his wife Éveline, who had been living in German-occupied France.
In January 1941, Weil and his family sailed from Marseille to New York. He spent the remainder of the war in the United States, where he was supported by the Rockefeller Foundation and the Guggenheim Foundation. For two years, he taught undergraduate mathematics at Lehigh University. After the war, he moved to Brazil and taught at the Universidade de São Paulo from 1945 to 1947, where he worked with Oscar Zariski. He then returned to the United States and taught at the University of Chicago from 1947 to 1958, before moving to the Institute for Advanced Study, where he would spend the remainder of his career. In 1979, Weil shared the second Wolf Prize in Mathematics with Jean Leray.
Work.
Weil made substantial contributions in a number of areas, the most important being his discovery of profound connections between algebraic geometry and number theory. This began in his doctoral work leading to the Mordell–Weil theorem (1928, and shortly applied in Siegel's theorem on integral points). Mordell's theorem had an "ad hoc" proof; Weil began the separation of the infinite descent argument into two types of structural approach, by means of height functions for sizing rational points, and by means of Galois cohomology, which would not be categorized as such for another two decades. Both aspects of Weil's work have steadily developed into substantial theories.
Among his major accomplishments were the 1940 proof, of the Riemann hypothesis for zeta-functions of curves over finite fields, and his subsequent laying of proper foundations for algebraic geometry to support that result (from 1942 to 1946, most intensively). The so-called Weil conjectures were hugely influential from around 1950; these statements were later proved by Bernard Dwork, Alexander Grothendieck, Michael Artin, and finally by Pierre Deligne, who completed the most difficult step in 1973.
Weil introduced the adele ring in the late 1930s, following Claude Chevalley's lead with the ideles, and gave a proof of the Riemann–Roch theorem with them (a version appeared in his "Basic Number Theory" in 1967). His 'matrix divisor' (vector bundle "avant la lettre") Riemann–Roch theorem from 1938 was a very early anticipation of later ideas such as moduli spaces of bundles. The Weil conjecture on Tamagawa numbers proved resistant for many years. Eventually the adelic approach became basic in automorphic representation theory. He picked up another credited "Weil conjecture", around 1967, which later under pressure from Serge Lang (resp. of Serre) became known as the Taniyama–Shimura conjecture (resp. Taniyama–Weil conjecture) based on a roughly formulated question of Taniyama at the 1955 Nikkō conference. His attitude towards conjectures was that one should not dignify a guess as a conjecture lightly, and in the Taniyama case, the evidence was only there after extensive computational work carried out from the late 1960s.
Other significant results were on Pontryagin duality and differential geometry. He introduced the concept of a uniform space in general topology, as a by-product of his collaboration with Nicolas Bourbaki (of which he was a Founding Father). His work on sheaf theory hardly appears in his published papers, but correspondence with Henri Cartan in the late 1940s, and reprinted in his collected papers, proved most influential.
He discovered that the so-called Weil representation, previously introduced in quantum mechanics by Irving Segal and Shale, gave a contemporary framework for understanding the classical theory of quadratic forms. This was also a beginning of a substantial development by others, connecting representation theory and theta functions.
He also wrote several books on the history of Number Theory.
As expositor.
Weil's ideas made an important contribution to the writings and seminars of Bourbaki, before and after World War II.
He says on page 114 of his autobiography that he was responsible for the null set symbol (Ø) and that it came from the Norwegian alphabet, which he alone among the Bourbaki group was familiar with.
Beliefs.
Indian (Hindu) thought had great influence on Weil. In his autobiography, he says that the only religious ideas that appealed to him were those to be found in Hindu philosophical thought. Although he was an agnostic, he respected religions.
Books.
His Collected Papers:
His autobiography:
Memoir by his daughter:
"At Home with Andre and Simone Weil by Sylvie Weil, translated by Benjamin Ivry; ISBN 978-0-8101-2704-3, Northwestern University Press, 2010.

</doc>
<doc id="2020" url="http://en.wikipedia.org/wiki?curid=2020" title="Achaeans (Homer)">
Achaeans (Homer)

The Achaeans (; "Akhaioí") constitute one of the collective names for the Greeks in Homer's "Iliad" (used 598 times) and "Odyssey". The other common names are Danaans (; "Danaoi"; used 138 times in the "Iliad") and Argives (; ; used 182 times in the "Iliad") while Panhellenes ( "Panhellenes") and Hellenes (; "Hellenes") both appear only once; all of the aforementioned terms were used synonymously to denote a common Greek civilizational identity. In the historical period, the Achaeans were the inhabitants of the region of Achaea, a region in the north-central part of the Peloponnese. The city-states of this region later formed a confederation known as the Achaean League, which was influential during the 3rd and 2nd centuries BC.
Homeric versus later use.
The Homeric "long-haired Achaeans" would have been a part of the Mycenaean civilization that dominated Greece from circa 1600 BC until 1100 BC. However, by the Archaic and Classical periods, the term "Achaeans" referred to inhabitants of the much smaller region of Achaea. Herodotus identified the Achaeans of the northern Peloponnese as descendants of the earlier, Homeric Achaeans. According to Pausanias, writing in the 2nd century CE, the term "Achaean" was originally given to those Greeks inhabiting the Argolis and Laconia. However, this clearly is not the manner in which Homer uses the term.
Pausanias and Herodotus both recount the legend that the Achaeans were forced from their homelands by the Dorians, during the legendary Dorian invasion of the Peloponnese. They then moved into the region that later bore the name of Achaea.
A scholarly consensus has not yet been reached on the origin of the historic Achaeans relative to the Homeric Achaeans and is still hotly debated. Former emphasis on presumed race, such as John A. Scott's article about the blond locks of the Achaeans as compared to the dark locks of "Mediterranean" Poseidon, on the basis of hints in Homer, has been rejected. The contrasting belief that "Achaeans", as understood through Homer, is "a name without a country", an "ethnos" created in the Epic tradition, has modern supporters among those who conclude that "Achaeans" were redefined in the 5th century BC, as contemporary speakers of Aeolic Greek.
Karl Beloch has suggested that there was no Dorian invasion, but rather that the Peloponnesian Dorians were the Achaeans. Eduard Meyer, disagreeing with Beloch, has instead put forth the suggestion that the real-life Achaeans were mainland pre-Dorian Greeks. His conclusion is based on his research on the similarity between the languages of the Achaeans and pre-historic Arcadians. William Prentice disagrees with both, noting that archeological evidence suggests that the Achaeans instead migrated from "southern Asia Minor to Greece, probably settling first in lower Thessaly" probably prior to 2000 BC.
Emil Forrer, a Swiss Hittitologist who worked on the Boghazköy tablets in Berlin, stated that the Achaeans of pre-Homeric Greece were directly associated with the term "Land of Ahhiyawa" mentioned in the Hittite texts. However, his conclusions at the time were challenged by other Hittitologists (i.e. Johannes Friedrich in 1927 and Albrecht Götze in 1930), as well as by Ferdinand Sommer who published his monumental "Die Ahhijava-Urkunden" ("The Ahhiyawa Documents") in 1932.
Hittite documents.
Some Hittite texts mention a nation lying to the west called Ahhiyawa. In the earliest reference to this land, a letter outlining the treaty violations of the Hittite vassal Madduwatta, it is called "Ahhiya". Another important example is the "Tawagalawa Letter" written by an unnamed Hittite king (most probably Hattusili III) of the empire period (14th–13th century BC) to the king of "Ahhiyawa", treating him as an equal and suggesting that Miletus ("Millawanda") was under his control. It also refers to an earlier ""Wilusa" episode" involving hostility on the part of "Ahhiyawa". Ahhiya(wa) has been identified with the Achaeans of the Trojan War and the city of Wilusa with the legendary city of Troy (note the similarity with early Greek "Wilion", later "Ilion", the name of the acropolis of Troy). The exact relationship of the term "Ahhiyawa" to the Achaeans beyond a similarity in pronunciation was hotly debated by scholars, even following the discovery that Mycenaean Linear B is an early form of Greek; the earlier debate was summed up in 1984 by Hans G. Güterbock of the Oriental Institute. More recent research based on new readings and interpretations of the Hittite texts, as well as of the material evidence for Mycenaean contacts with the Anatolian mainland, came to the conclusion that "Ahhiyawa" referred to the Mycenaean world, or at least to a part of it.
Egyptian sources.
It has been proposed that "Ekwesh" of the Egyptian records may relate to "Achaea" (compared to Hittite "Ahhiyawa"), whereas "Denyen" and "Tanaju" may relate to Classical Greek "Danaoi". The earliest textual reference to the Mycenaean world is in the Annals of Thutmosis III (ca. 1479–1425 BC), which refers that messengers from the king of the Tanaju, in circa 1437 BC, offered greeting gifts to the Egyptian king, in order to initiate diplomatic relations, when the latter campaigned in Syria. Tanaju is also listed in an inscription at the Mortuary Temple of Amenhotep III. The latter ruled Egypt in circa 1382–1344 BC. Moreover, a list of the cities and regions of the Tanaju is also mentioned in this inscription; among the cities listed are Mycenae, Nauplion, Kythera, Messenia and the Thebaid (region of Thebes).
During the 5th year of Pharaoh Merneptah, a confederation of Libyan and northern peoples is supposed to have attacked the western delta. Included amongst the ethnic names of the repulsed invaders is the Ekwesh or Eqwesh, whom some have seen as Achaeans, although Egyptian texts specifically mention these Ekwesh to be circumcised (which does not seem to have been a general practice in the Aegean at the time). Homer mentions an Achaean attack upon the delta, and Menelaus speaks of the same in Book IV of the "Odyssey" to Telemachus when he recounts his own return home from the Trojan War. Later Greek myths also say that Helen had spent the time of the Trojan War in Egypt, and not at Troy, and that after Troy the Greeks went there to recover her.
Greek mythology.
In Greek mythology, the perceived cultural divisions among the Hellenes were represented as legendary lines of descent that identified kinship groups, with each line being derived from an eponymous ancestor. Each of the Greek "ethne" were said to be named in honor of their respective ancestors: Achaeus of the Achaeans, Danaus of the Danaans, Cadmus of the Cadmeans (the Thebans), Hellen of the Hellenes (not to be confused with Helen of Troy), Aeolus of the Aeolians, Ion of the Ionians, and Dorus of the Dorians.
Kadmos from Phoenicia, Danaus from Egypt, and Pelops from Anatolia each gained a foothold in mainland Greece and were assimilated and Hellenized. Hellen, Graikos, Magnes, and Macedon were sons of Deucalion and Pyrrha, the only people who survived the Great Flood; the "ethne" were said to have originally been named "Graikoi" after the elder son but later renamed "Hellenes" after Hellen who was proved to be the strongest. Sons of Hellen and the nymph Orseis were Dorus, Xuthos, and Aeolus. Sons of Xuthos and Kreousa, daughter of Erechthea, were Ion and Achaeus.
According to Hyginus, 22 Achaeans killed 362 Trojans during their ten years at Troy.
Etymology.
For the etymology of the name "Akhaioi", see Achaeans (tribe). The etymology of "Danaoi" is uncertain. According to R. S. P. Beekes "the name is certainly Pre-Greek".

</doc>
<doc id="2021" url="http://en.wikipedia.org/wiki?curid=2021" title="Atle Selberg">
Atle Selberg

Atle Selberg (14 June 1917 – 6 August 2007) was a Norwegian mathematician known for his work in analytic number theory, and in the theory of automorphic forms, in particular bringing them into relation with spectral theory. He was awarded the Fields Medal in 1950.
Early years.
Selberg was born in Langesund, Norway, the son of teacher Anna Kristina Selberg and mathematician Ole Michael Ludvigsen Selberg. Two of his brothers also went on to become mathematicians as well, and the remaining one became a professor of engineering. 
While he was still at school he was influenced by the work of Srinivasa Ramanujan and he found the exact analytical formula for the partition function as suggested by the works of Ramanujan; however, this result was first published by Hans Rademacher. During the war he fought against the German invasion of Norway, and was imprisoned several times. 
He studied at the University of Oslo and completed his Ph.D. in 1943.
World War II.
During World War II, Selberg worked in isolation due to the German occupation of Norway. After the war his accomplishments became known, including a proof that a positive proportion of the zeros of the Riemann zeta function lie on the line formula_1. 
After the war, he turned to sieve theory, a previously neglected topic which Selberg's work brought into prominence. In a 1947 paper he introduced the Selberg sieve, a method well adapted in particular to providing auxiliary upper bounds, and which contributed to Chen's theorem, among other important results. 
In March 1948, Selberg established, by elementary means, the asymptotic formula
where
for primes formula_4. By July of that year, Selberg and Paul Erdős had each obtained elementary proofs of the prime number theorem, both using Selberg's then unpublished asymptotic formula as a starting point. Circumstances leading up to the proofs, as well as publication disagreements, led to a bitter dispute between the two mathematicians. 
For his fundamental accomplishments during the 1940s, Selberg received the 1950 Fields Medal.
Institute for Advanced Study.
Selberg moved to the United States and settled at the Institute for Advanced Study in Princeton, New Jersey in the 1950s where he remained until his death. During the 1950s he worked on introducing spectral theory into number theory, culminating in his development of the Selberg trace formula, the most famous and influential of his results. In its simplest form, this establishes a duality between the lengths of closed geodesics on a compact Riemann surface and the eigenvalues of the Laplacian, which is analogous to the duality between the prime numbers and the zeros of the zeta function.
He was awarded the 1986 Wolf Prize in Mathematics. He was also awarded an honorary Abel Prize in 2002, its founding year, before the awarding of the regular prizes began.
Selberg received many distinctions for his work in addition to the Fields Medal, the Wolf Prize and the Gunnerus Medal. He was elected to the Norwegian Academy of Science and Letters, the Royal Danish Academy of Sciences and Letters and the American Academy of Arts and Sciences.
Selberg had two children, Ingrid Selberg and Lars Selberg. Ingrid Selberg is married to playwright Mustapha Matura.
He died at home in Princeton on 6 August 2007 of heart failure.

</doc>
<doc id="2023" url="http://en.wikipedia.org/wiki?curid=2023" title="Aeschylus">
Aeschylus

Aeschylus ( or ; , "Aiskhulos"; c. 525/524 BC – c. 456/455 BC) was the first of the three ancient Greek tragedians whose plays can still be read or performed, the others being Sophocles and Euripides. He is often described as the father of tragedy: Our knowledge of the genre begins with his work and our understanding of earlier tragedies is largely based on inferences from his surviving plays. According to Aristotle, he expanded the number of characters in plays to allow for conflict amongst them, whereas previously characters had interacted only with the chorus.
Only seven of his estimated seventy to ninety plays have survived into modern times, and there is a longstanding debate about his authorship of one of these plays, "Prometheus Bound". Fragments of some other plays have survived in quotes and more continue to be discovered on Egyptian papyrus, often giving us surprising insights into his work. He was probably the first dramatist to present plays as a trilogy; his Oresteia is the only ancient example of the form to have survived.
At least one of his works was influenced by the Persian invasion of Greece, which took place during his lifetime. This play, "The Persians", is the only extant classical Greek tragedy concerned with recent history (very few of that kind were ever written) and it is a useful source of information about that period. So important was the war to Aeschylus and the Greeks that, upon his death, around 456 BC, his epitaph commemorated his participation in the Greek victory at Marathon rather than his success as a playwright.
He was a deep, religious thinker. Few poets have ever presented evil in such stark and tragic terms, yet he had an exalted view of Zeus, whom he celebrated with a grand simplicity reminiscent of the Psalms, and a faith in progress or the healing power of time.
Life.
There are no reliable sources for the life of Aeschylus.
He was said to have been born in c. 525 BC in Eleusis, a small town about 27 kilometers northwest of Athens, which is nestled in the fertile valleys of western Attica, though the date is most likely based on counting back forty years from his first victory in the Great Dionysia. His family was wealthy and well established; his father Euphorion was a member of the Eupatridae, the ancient nobility of Attica, though this might be a fiction that the ancients invented to account for the grandeur of his plays.
As a youth he worked at a vineyard until, according to the 2nd-century AD geographer Pausanias, the god Dionysus visited him in his sleep and commanded him to turn his attention to the nascent art of tragedy. As soon as he woke from the dream, the young Aeschylus began writing a tragedy, and his first performance took place in 499 BC, when he was only 26 years old; He would win his first victory at the City Dionysia in 484 BC.
In 510 BC, Cleomenes I (Aeschylus was 15 at the time) expelled the sons of Peisistratus from Athens, and Cleisthenes came to power. His reforms included a system of registration that emphasized the importance of the deme over family tradition. In the last decade of the 6th century, Aeschylus and his family were living in the deme of Eleusis.
The Persian Wars would play a large role in the playwright's life and career. In 490 BC, Aeschylus and his brother Cynegeirus fought to defend Athens against Darius I's invading Persian army at the Battle of Marathon. The Athenians emerged triumphant, a victory celebrated across the city-states of Greece. Cynegeirus, however, died in the battle, receiving a mortal wound while trying to prevent a Persian ship retreating from the shore, for which his countrymen extolled him as a hero.
In 480, Aeschylus was called into military service again, this time against Xerxes I's invading forces at the Battle of Salamis, and perhaps, too, at the Battle of Plataea in 479. Ion of Chios was a witness for Aeschylus's war record and his contribution in Salamis. Salamis holds a prominent place in "The Persians", his oldest surviving play, which was performed in 472 BC and won first prize at the Dionysia.
Aeschylus was one of many Greeks who had been initiated into the Eleusinian Mysteries, a cult to Demeter based in his hometown of Eleusis. As the name implies, members of the cult were supposed to have gained some secret knowledge. Firm details of specific rites are sparse, as members were sworn under the penalty of death not to reveal anything about the Mysteries to non-initiates. Nevertheless, according to Aristotle some thought that Aeschylus had revealed some of the cult's secrets on stage.
Other sources claim that an angry mob tried to kill Aeschylus on the spot, but he fled the scene. Heracleides of Pontus asserts that the crowd watching the play tried to stone Aeschylus. He then took refuge at the altar in the orchestra of the Theater of Dionysus. When he stood trial for his offense he pleaded ignorance. He was acquitted, with the jury sympathetic to the wounds that Aeschylus and his brother Cynegeirus suffered at Marathon. According to the 2nd-century AD author Aelian, Aeschylus's younger brother Ameinias helped acquit his brother by showing the jury the stump of the hand that he lost at Salamis, where he was voted bravest warrior. The truth is that the award for bravery at Salamis went to Ameinias of Pallene, not Aeschylus's brother.
Aeschylus travelled to Sicily once or twice in the 470s BC, having been invited by Hiero I of Syracuse, a major Greek city on the eastern side of the island; and during one of these trips he produced "The Women of Aetna" (in honor of the city founded by Hieron) and restaged his "Persians". By 473 BC, after the death of Phrynichus, one of his chief rivals, Aeschylus was the yearly favorite in the Dionysia, winning first prize in nearly every competition. In 472 BC, Aeschylus staged the production that included the "Persians", with Pericles serving as "choregos".
In 458 BC, he returned to Sicily for the last time, visiting the city of Gela where he died in 456 or 455 BC. Valerius Maximus wrote that he was killed outside the city by a tortoise dropped by an eagle which had mistook his head for a rock suitable for shattering the shell of the reptile. Pliny, in his "Naturalis Historiæ", adds that Aeschylus had been staying outdoors to avoid a prophecy that he would be killed by a falling object. Aeschylus's work was so respected by the Athenians that after his death, his were the only tragedies allowed to be restaged in subsequent competitions. His sons Euphorion and Euæon and his nephew Philocles also became playwrights.
The inscription on Aeschylus's gravestone makes no mention of his theatrical renown, commemorating only his military achievements:
The inscription on his graveyard signifies according to Castoriadis the primary importance of "belonging to the City", of the solidarity that existed within the collective body of soldiers - citizens.
Personal life.
Aeschylus married and had two sons, Euphorion and Euaeon, both of whom became tragic poets. Euphorion won first prize in 431 in competition against both Sophocles and Euripides. His nephew, Philocles (his sister's son), was also a tragic poet, and won first prize in the competition against Sophocles' "Oedipus Rex".
A scholiast has noted that Philocles' "Tereus" was part of his "Pandionis" tetralogy. Aeschylus had at least two brothers, Cynegeirus and Ameinias.
Works.
The roots of Greek drama are in religious festivals for the gods, chiefly Dionysus, the god of wine. During Aeschylus's lifetime, dramatic competitions became part of the City Dionysia in the spring. The festival opened with a procession, followed with a competition of boys singing dithyrambs and culminated in a pair of dramatic competitions. The first competition Aeschylus would have participated in, consisted of three playwrights each presenting three tragic plays followed by a shorter comedic satyr play. A second competition of five comedic playwrights followed, and the winners of both competitions were chosen by a panel of judges.
Aeschylus entered many of these competitions in his lifetime, and various ancient sources attribute between seventy and ninety plays to him. Only seven tragedies have survived intact: "The Persians", "Seven against Thebes", "The Suppliants", the trilogy known as "The Oresteia", consisting of the three tragedies "Agamemnon", "The Libation Bearers" and "The Eumenides", together with "Prometheus Bound" (whose authorship is disputed). With the exception of this last play – the success of which is uncertain – all of Aeschylus's extant tragedies are known to have won first prize at the City Dionysia.
The Alexandrian "Life of Aeschylus" claims that he won the first prize at the City Dionysia thirteen times. This compares favorably with Sophocles' reported eighteen victories (with a substantially larger catalogue, at an estimated 120 plays), and dwarfs the five victories of Euripides, who is thought to have written roughly 90 plays.
Trilogies.
One hallmark of Aeschylean dramaturgy appears to have been his tendency to write connected trilogies, in which each play serves as a chapter in a continuous dramatic narrative. "The Oresteia" is the only extant example of this type of connected trilogy, but there is evidence that Aeschylus often wrote such trilogies. The comic satyr plays that follow his trilogies also drew upon stories derived from myths.
For example, the "Oresteia"'s satyr play "Proteus" treated the story of Menelaus' detour in Egypt on his way home from the Trojan War. Based on the evidence provided by a catalogue of Aeschylean play titles, scholia, and play fragments recorded by later authors, it is assumed that three other of his extant plays were components of connected trilogies: "Seven against Thebes" being the final play in an Oedipus trilogy, and "The Suppliants" and "Prometheus Bound" each being the first play in a Danaid trilogy and Prometheus trilogy, respectively (see below). Scholars have moreover suggested several completely lost trilogies derived from known play titles. A number of these trilogies treated myths surrounding the Trojan War. One, collectively called the "Achilleis", comprised the titles "Myrmidons", "Nereids" and "Phrygians" (alternately, "The Ransoming of Hector").
Another trilogy apparently recounts the entry of the Trojan ally Memnon into the war, and his death at the hands of Achilles ("Memnon" and "The Weighing of Souls" being two components of the trilogy); "The Award of the Arms", "The Phrygian Women", and "The Salaminian Women" suggest a trilogy about the madness and subsequent suicide of the Greek hero Ajax; Aeschylus also seems to have written about Odysseus' return to Ithaca after the war (including his killing of his wife Penelope's suitors and its consequences) in a trilogy consisting of "The Soul-raisers", "Penelope" and "The Bone-gatherers". Other suggested trilogies touched on the myth of Jason and the Argonauts ("Argô", "Lemnian Women", "Hypsipylê"); the life of Perseus ("The Net-draggers", "Polydektês", "Phorkides"); the birth and exploits of Dionysus ("Semele", "Bacchae", "Pentheus"); and the aftermath of the war portrayed in "Seven against Thebes" ("Eleusinians", "Argives" (or "Argive Women"), "Sons of the Seven").
Surviving plays.
"The Persians".
The earliest of his plays to survive is "The Persians" ("Persai"), performed in 472 BC and based on experiences in Aeschylus's own life, specifically the Battle of Salamis. It is unique among surviving Greek tragedies in that it describes a recent historical event. "The Persians" focuses on the popular Greek theme of "hubris" by blaming Persia's loss on the pride of its king.
It opens with the arrival of a messenger in Susa, the Persian capital, bearing news of the catastrophic Persian defeat at Salamis to Atossa, the mother of the Persian King Xerxes. Atossa then travels to the tomb of Darius, her husband, where his ghost appears to explain the cause of the defeat. It is, he says, the result of Xerxes' hubris in building a bridge across the Hellespont, an action which angered the gods. Xerxes appears at the end of the play, not realizing the cause of his defeat, and the play closes to lamentations by Xerxes and the chorus.
"Seven against Thebes".
"Seven against Thebes" ("Hepta epi Thebas"), which was performed in 467 BC, has the contrasting theme of the interference of the gods in human affairs. It also marks the first known appearance in Aeschylus's work of a theme which would continue through his plays, that of the polis (the city) being a key development of human civilization.
The play tells the story of Eteocles and Polynices, the sons of the shamed King of Thebes, Oedipus. The sons agree to alternate in the throne of the city, but after the first year Eteocles refuses to step down, and Polynices wages war to claim his crown. The brothers kill each other in single combat, and the original ending of the play consisted of lamentations for the dead brothers.
A new ending was added to the play some fifty years later: Antigone and Ismene mourn their dead brothers, a messenger enters announcing an edict prohibiting the burial of Polynices; and finally, Antigone declares her intention to defy this edict. The play was the third in a connected Oedipus trilogy; the first two plays were "Laius" and "Oedipus". The concluding satyr play was "The Sphinx".
"The Suppliants".
Aeschylus continued his emphasis on the polis with "The Suppliants" in 463 BC ("Hiketides"), which pays tribute to the democratic undercurrents running through Athens in advance of the establishment of a democratic government in 461. In the play, the Danaids, the fifty daughters of Danaus, founder of Argos, flee a forced marriage to their cousins in Egypt. They turn to King Pelasgus of Argos for protection, but Pelasgus refuses until the people of Argos weigh in on the decision, a distinctly democratic move on the part of the king. The people decide that the Danaids deserve protection, and they are allowed within the walls of Argos despite Egyptian protests.
The 1952 publication of Oxyrhynchus Papyrus 2256 fr. 3 confirmed a long-assumed (because of "The Suppliants"' cliffhanger ending) Danaid trilogy, whose constituent plays are generally agreed to be "The Suppliants", "The Egyptians" and "The Danaids". A plausible reconstruction of the trilogy's last two-thirds runs thus: In "The Egyptians", the Argive-Egyptian war threatened in the first play has transpired. During the course of the war, King Pelasgus has been killed, and Danaus rules Argos. He negotiates a peace settlement with Aegyptus, as a condition of which, his fifty daughters will marry the fifty sons of Aegyptus. Danaus secretly informs his daughters of an oracle predicting that one of his sons-in-law would kill him; he therefore orders the Danaids to murder their husbands on their wedding night. His daughters agree. "The Danaids" would open the day after the wedding.
In short order, it is revealed that forty-nine of the Danaids killed their husbands as ordered; Hypermnestra, however, loved her husband Lynceus, and thus spared his life and helped him to escape. Angered by his daughter's disobedience, Danaus orders her imprisonment and, possibly, her execution. In the trilogy's climax and dénouement, Lynceus reveals himself to Danaus, and kills him (thus fulfilling the oracle). He and Hypermnestra will establish a ruling dynasty in Argos. The other forty-nine Danaids are absolved of their murderous crime, and married off to unspecified Argive men. The satyr play following this trilogy was titled "Amymone", after one of the Danaids.
"The Oresteia".
The only complete (save a few missing lines in several spots) trilogy of Greek plays by any playwright still extant is the "Oresteia" (458 BC); although the satyr play that originally followed it, "Proteus", is lost except for some fragments. The trilogy consists of "Agamemnon", "The Libation Bearers" ("Choephoroi"), and "The Eumenides". Together, these plays tell the bloody story of the family of Agamemnon, King of Argos.
"Agamemnon".
Aeschylus begins in Greece describing the return of king Agamemnon from his victory in the Trojan War, from the perspective of the towns people (the Chorus) and his wife, Clytemnestra. However dark foreshadowings build to the death of the king at the hands of his wife, who was angry at his sacrifice of their daughter Iphigenia, killed so the Gods would stop a storm hindering the Greek fleet in the war. She was also unhappy at his keeping of the Trojan prophetess Cassandra as a concubine. Cassandra foretells of the murder of Agamenon, and of herself, to the assembled townsfolk, who are horrified. She then enters the palace knowing that she cannot avoid her fate. The ending of the play includes a prediction of the return of Orestes, son of Agamemnon, who will seek to avenge his father."
"The Libation Bearers".
"The Libation Bearers" continues the tale, opening with Orestes arrival at Agamemnon's tomb. At the tomb, Electra meets Orestes, who has returned from exile in Phocis, and they plan revenge upon Clytemnestra and her lover Aegisthus. Clytemnestra's account of a nightmare in which she gives birth to a snake is recounted by the chorus; and this leads her to order Electra, her daughter, to pour libations on Agamemnon's tomb (with the assistance of libation bearers) in hope of making amends. Orestes enters the palace pretending to bear news of his own death, and when Clytemnestra calls in Aegisthus to share in the news, Orestes kills them both. Orestes is then beset by the Furies, who avenge the murders of kin in Greek mythology.
"The Eumenides".
The final play of "The Oresteia" addresses the question of Orestes' guilt. The Furies drive Orestes from Argos and into the wilderness. He makes his way to the temple of Apollo and begs him to drive the Furies away. Apollo had encouraged Orestes to kill Clytemnestra, and so bears some of the guilt for the murder. The Furies are a more ancient race of the gods, and Apollo sends Orestes to the temple of Athena, with Hermes as a guide.
The Furies track him down, and the goddess Athena, patron of Athens, steps in and declares that a trial is necessary. Apollo argues Orestes' case and, after the judges, including Athena deliver a tie vote, Athena announces that Orestes is acquitted. She renames the Furies "The Eumenides" (The Good-spirited, or Kindly Ones), and extols the importance of reason in the development of laws, and, as in "The Suppliants", the ideals of a democratic Athens are praised.
"Prometheus Bound".
In addition to these six works, a seventh tragedy, "Prometheus Bound", is attributed to Aeschylus by ancient authorities. Since the late 19th century, however, scholars have increasingly doubted this ascription, largely on stylistic grounds. Its production date is also in dispute, with theories ranging from the 480s BC to as late as the 410s.
The play consists mostly of static dialogue, as throughout the play the Titan Prometheus is bound to a rock as punishment from the Olympian Zeus for providing fire to humans. The god Hephaestus, the Titan Oceanus, and the chorus of Oceanids all express sympathy for Prometheus' plight. Prometheus meets Io, a fellow victim of Zeus' cruelty; and prophesies her future travels, revealing that one of her descendants will free Prometheus. The play closes with Zeus sending Prometheus into the abyss because Prometheus refuses to divulge the secret of a potential marriage that could prove Zeus' downfall.
The "Prometheus Bound" appears to have been the first play in a trilogy called the "Prometheia". In the second play, "Prometheus Unbound", Heracles frees Prometheus from his chains and kills the eagle that had been sent daily to eat Prometheus' perpetually regenerating liver. Perhaps foreshadowing his eventual reconciliation with Prometheus, we learn that Zeus has released the other Titans whom he imprisoned at the conclusion of the Titanomachy.
In the trilogy's conclusion, "Prometheus the Fire-Bringer", it appears that the Titan finally warns Zeus not to sleep with the sea nymph Thetis, for she is fated to give birth to a son greater than the father. Not wishing to be overthrown, Zeus marries Thetis off to the mortal Peleus; the product of that union is Achilles, Greek hero of the Trojan War. After reconciling with Prometheus, Zeus probably inaugurates a festival in his honor at Athens.
Lost plays.
Only the titles and assorted fragments of Aeschylus's other plays have come down to us. We have enough fragments of some plays (along with comments made by later authors and scholiasts) to produce rough synopses of their plots.
"Myrmidons".
This play was based on books 9 and 16 in Homer's "Iliad". Achilles sits in silent indignation over his humiliation at Agamemnon's hands for most of the play. Envoys from the Greek army attempt to reconcile him to Agamemnon, but he yields only to his friend and lover Patroclus, who then battles the Trojans in Achilles' armour. The bravery and death of Patroclus are reported in a messenger's speech, which is followed by mourning.
"Nereids".
This play was based on books 18, 19, and 22 of the "Iliad", follows the Daughters of Nereus, the sea god, lament Patroclus' death. In this play a messenger tells how Achilles, perhaps reconciled to Agamemnon and the Greeks, slew Hector.
"Phrygians", or "Hector's Ransom".
In this play, Achilles sits in silent mourning over Patroclus, after a brief discussion with Hermes. Hermes then brings in King Priam of Troy, who wins over Achilles and ransoms his son's body in a spectacular coup de théâtre. A scale is brought on stage and Hector's body is placed in one scale and gold in the other. The dynamic dancing of the chorus of Trojans when they enter with Priam is reported by Aristophanes.
"Niobe".
The children of Niobe, the heroine, have been slain by Apollo and Artemis because Niobe had gloated that she had more children than their mother, Leto. Niobe sits in silent mourning on stage during most of the play. In the "Republic", Plato quotes the line "God plants a fault in mortals when he wills to destroy a house utterly." 
These are the remaining plays ascribed to Aeschylus which are known to us:
Influence.
Influence on Greek drama and culture.
When Aeschylus first began writing, the theatre had only just begun to evolve, although earlier playwrights like Thespis had already expanded the cast to include an actor who was able to interact with the chorus. Aeschylus added a second actor, allowing for greater dramatic variety, while the chorus played a less important role. He is sometimes credited with introducing "skenographia", or scene-decoration, though Aristotle gives this distinction to Sophocles. Aeschylus is also said to have made the costumes more elaborate and dramatic, and having his actors wear platform boots ("cothurni") to make them more visible to the audience. According to a later account of Aeschylus's life, as they walked on stage in the first performance of the "Eumenides", the chorus of Furies were so frightening in appearance that they caused young children to faint, patriarchs to urinate, and pregnant women to go into labour.
His plays were written in verse, no violence is performed on stage, and the plays have a remoteness from daily life in Athens, either by relating stories about the gods or by being set, like "The Persians", in far-away locales. Aeschylus's work has a strong moral and religious emphasis. The "Oresteia" trilogy concentrated on man's position in the cosmos in relation to the gods, divine law, and divine punishment.
Aeschylus's popularity is evident in the praise the comic playwright Aristophanes gives him in "The Frogs", produced some half-century after Aeschylus's death. Appearing as a character in the play, Aeschylus claims at line 1022 that his "Seven against Thebes" "made everyone watching it to love being warlike"; with his "Persians", Aeschylus claims at lines 1026–7 that he "taught the Athenians to desire always to defeat their enemies." Aeschylus goes on to say at lines 1039ff. that his plays inspired the Athenians to be brave and virtuous.
Influence outside of Greek culture.
Aeschylus's works were influential beyond his own time. Hugh Lloyd-Jones (Regius Professor of Greek Emeritus at Oxford University) draws attention to Wagner's reverence of Aeschylus. Michael Ewans argues in his "Wagner and Aeschylus. The Ring and the Oresteia" (London: Faber. 1982) that the influence was so great as to merit a direct character by character comparison between Wagner's "Ring" and Aeschylus's "Oresteia". A critic of his book however, while not denying that Wagner read and respected Aeschylus, has described his arguments as unreasonable and forced.
Sir J. T. Sheppard argues in the second half of his "Aeschylus and Sophocles: Their Work and Influence" that Aeschylus, along with Sophocles, have played a major part in the formation of dramatic literature from the Renaissance to the present, specifically in French and Elizabethan drama. He also claims that their influence went beyond just drama and applies to literature in general, citing Milton and the Romantics.
During his presidential campaign in 1968, Senator Robert F. Kennedy quoted the Edith Hamilton translation of Aeschylus on the night of the assassination of Martin Luther King, Jr. Kennedy was notified of King's murder before a campaign stop in Indianapolis, Indiana and was warned not to attend the event due to fears of rioting from the mostly African-American crowd. Kennedy insisted on attending and delivered an impromptu speech that delivered news of King's death to the crowd.
Acknowledging the audience's emotions, Kennedy referred to his own grief at the murder of his brother, President John F. Kennedy and, quoting a passage from the play Agamemnon, said: "My favorite poet was Aeschylus. And he once wrote: 'Even in our sleep, pain which cannot forget falls drop by drop upon the heart, until in our own despair, against our will, comes wisdom through the awful grace of God.' What we need in the United States is not division; what we need in the United States is not hatred; what we need in the United States is not violence and lawlessness; but is love and wisdom, and compassion toward one another, and a feeling of justice toward those who still suffer within our country, whether they be white or whether they be black... Let us dedicate ourselves to what the Greeks wrote so many years ago: to tame the savageness of man and make gentle the life of this world." The quotation from Aeschylus was later inscribed on a memorial at the gravesite of Robert Kennedy following his own assassination.

</doc>
<doc id="2024" url="http://en.wikipedia.org/wiki?curid=2024" title="Amber Road">
Amber Road

Prehistoric trade routes between Northern and Southern Europe were defined by the amber trade. The Amber Road was an ancient trade route for the transfer of amber from coastal areas of the North Sea and the Baltic Sea to the Mediterranean Sea. As an important raw material, sometimes dubbed "the gold of the north", amber was transported from the North Sea and Baltic Sea coasts overland by way of the Vistula and Dnieper rivers to Italy, Greece, the Black Sea, Syria and Egypt thousands of years ago, and long after.
Antiquity.
From at least the sixteenth century BC amber was moved from Northern Europe to the Mediterranean area. The breast ornament of the Egyptian pharaoh Tutankhamen (ca. 1333-1324 BC) contains large Baltic amber beads Heinrich Schliemann found Baltic amber beads at Mycenae, as shown by spectroscopic investigation. The quantity of amber in the Royal Tomb of Qatna, Syria, is unparalleled for known second millennium BC sites in the Levant and the Ancient Near East. Amber was sent from the North Sea to the temple of Apollo at Delphi as an offering. From the Black Sea, trade could continue to Asia along the Silk Road, another ancient trade route. In Roman times, a main route ran south from the Baltic coast through the land of the Boii (modern Czech Republic and Slovakia) to the head of the Adriatic Sea (modern Gulf of Venice).
The Old Prussian towns of Kaup and Truso on the Baltic were the starting points of the route to the south. In Scandinavia the amber road probably gave rise to the thriving Nordic Bronze Age culture, bringing influences from the Mediterranean Sea to the northernmost countries of Europe.
Sometimes the Kaliningrad Oblast is called the Янтарный край, which means "the amber area".
Overview of known amber finding places in Europe.
Amber roads connect amber finding locations to customer sites in Europe, in the Middle East regions and in the Far East.
Overview of known amber roads by country.
Central Europe.
The shortest (and possibly oldest) road avoids alpine areas and led from the Baltic coastline (nowadays Lithuania and Poland), through Biskupin and what is now Wrocław, passed the Moravian Gate, followed the river Morava, crossed the Danube near Carnuntum in the Noricum Province, headed southwest past Poetovio, Celeia, Emona, Nauportus, and reached Aquileia at the Adriatic coast. One of the oldest directions of the last stage of the Amber Road to the south of the Danube, noted in the myth about the Argonauts, used the Sava and Kupa rivers, ending with a short continental road from Nauportus to "Tarsatica" (Trsat, Rijeka) on the coast of the Adriatic.
Germany.
Several roads connected the North Sea and Baltic Sea, especially the city of Hamburg to the Brenner Pass, proceeding southwards to Brindisi (nowadays Italy) and Ambracia (nowadays Greece).
Switzerland.
The Swiss region indicates a number of alpine roads, concentrating around the capital city Bern and probably originating from the borders of the Rhône River and the Rhine.
The Netherlands.
A small section, including Baarn, Barneveld, Amersfoort and Amerongen, connected the North Sea with the Lower Rhine.
Belgium.
A small section led southwards from Antwerp and Bruges to the towns Braine-l’Alleud and Braine-le-Comte, both originally named "Brennia-Brenna". The route continued by following the Meuse River towards Bern in Switzerland.
France.
Three routes may be identified leading from an amber finding region or delta at the mouth of the River Openia towards Bresse and Bern, crossing the Alps to Switzerland and Italy.
Southern France and Spain.
Routes connecting amber finding locations at Ambares (near Bordeaux), leading to Béarn and the Pyrenees. Routes connecting the amber finding locations in northern Spain and in the Pyrenees were a trading route to the Mediterranean Sea.

</doc>
<doc id="2025" url="http://en.wikipedia.org/wiki?curid=2025" title="Crandall University">
Crandall University

Crandall University is a small Liberal Arts university located in Moncton, New Brunswick, Canada. Crandall is operated by the Convention of Atlantic Baptist Churches.
The Charity.
Crandall University 106736150RR0001 was registered as a charitable organization in Canada on 1967-01-01. The primary areas in which the charity is now carrying on programs to achieve its charitable purposes, ranked according to the percentage of time and resources devoted to each program area follow:
The charity carried on charitable programs to further its charitable purpose(s) (as defined in its governing documents) this fiscal period:
Library and Archives.
Crandall University houses the Baptist Heritage Center whose 300 artifacts preserve the material history of Atlantic Baptists, the Convention of Atlantic Baptist Churches, and its predecessor organizations. The collection and archives includes objects used in worship services, furniture, musical instruments, church building architecture pictures and printed material. 
History.
The school was founded in 1949 under the name United Baptist Bible Training School (UBBTS), and served as both a secondary school and a Bible school. Over two decades, the focus of the school gradually shifted toward post-secondary programs. In 1968, UBBTS became a Bible and junior Christian liberal arts college, and in 1970 the name was changed to Atlantic Baptist College (ABC). A sustained campaign to expand the school's faculty and improve the level of education resulted in ABC being able to grant full Bachelor of Arts degrees in 1983. Its campus at this time was located along the Salisbury Road, west of Moncton's central business district.
The institution moved to a new campus constructed on the Gorge Road, north of the central business district, in 1996. The name was also changed to Atlantic Baptist University, a reflection of expanded student enrollment and academic accreditation. ABU sports teams play under the name "Blue Tide". The institution was the first, and thus far only, English university in Moncton. The "Atlantic Baptist University Act" was passed by the Legislative Assembly of New Brunswick in 2008.
In 2009, plans for a $24 million expansion to the campus, including a new academic building, a second residence and a sports complex were unveiled. Construction is currently underway. The expansion will allow the student enrollment to increase to 1200.
On August 21, 2009 it was announced that the institution had changed its name to Crandall University in honour of Rev. Joseph Crandall, a pioneering Baptist minister in New Brunswick.
In 2011 Crandall University got a new mascot for the changes to the school in 2011.
In 2012, Crandall University came under public scrutiny for receiving municipal funds despite being perceived as having an anti-gay hiring policy.
Controversy.
The University has been criticized for accepting public money (municipal, provincial and federal) to fund programs and expansions to the campus but maintaining a hiring policy which would prohibit gay faculty. A year after the controversy erupted, the University opted to not apply for $150,000 in public funding that it had received annually in order to avoid changing its hiring policy. 

</doc>
<doc id="2027" url="http://en.wikipedia.org/wiki?curid=2027" title="Andrew Wiles">
Andrew Wiles

Sir Andrew John Wiles, KBE, FRS (born 11 April 1953) is a British mathematician and a Royal Society Research Professor at the University of Oxford, specialising in number theory. He is most notable for proving Fermat's Last Theorem.
Early life and education.
Wiles is the son of Maurice Frank Wiles (1923–2005), the Regius Professor of Divinity at the University of Oxford and Patricia Wiles (née Mowll). His father worked as the Chaplain at Ridley Hall, Cambridge, for the years 1952–55. Wiles was born in Cambridge, England, in 1953, and he attended King's College School, Cambridge, and The Leys School, Cambridge.
Wiles states that he came across Fermat's Last Theorem on his way home from school when he was 10 years old. He stopped by his local library where he found a book about the theorem. Fascinated by the existence of a theorem that was so easy to state that he, a ten-year old, could understand it, but nobody had proven it, he decided to be the first person to prove it. However, he soon realised that his knowledge was too limited, so he abandoned his childhood dream, until it was brought back to his attention at the age of 33 by Ken Ribet's 1986 proof of the epsilon conjecture, which Gerhard Frey had previously linked to Fermat's famous equation.
Mathematical career.
Wiles earned his bachelor's degree in mathematics in 1974 after his study at Merton College, Oxford, and a PhD in 1980, after his research at Clare College, Cambridge. After a stay at the Institute for Advanced Study in New Jersey in 1981, Wiles became a professor at Princeton University. In 1985–86, Wiles was a Guggenheim Fellow at the Institut des Hautes Études Scientifiques near Paris and at the École Normale Supérieure. From 1988 to 1990, Wiles was a Royal Society Research Professor at the University of Oxford, and then he returned to Princeton. He rejoined Oxford in 2011 as Royal Society Research Professor.
Wiles's graduate research was guided by John Coates beginning in the summer of 1975. Together these colleagues worked on the arithmetic of elliptic curves with complex multiplication by the methods of Iwasawa theory. He further worked with Barry Mazur on the main conjecture of Iwasawa theory over the rational numbers, and soon afterward, he generalised this result to totally real fields.
The proof of Fermat's Last Theorem.
Starting in the summer of 1986, based on successive progress of the previous few years of Gerhard Frey, Jean-Pierre Serre and Ken Ribet, it became clear that Fermat's Last Theorem could be proven as a corollary of a limited form of the modularity theorem (unproven at the time and then known as the "Taniyama–Shimura-Weil conjecture"). The modularity theorem involved elliptic curves, which was also Wiles' own specialist area.
The conjecture was seen by contemporary mathematicians as important, but extraordinarily difficult or perhaps inaccessible to proof. For example, Wiles' ex-supervisor John Coates states that it seemed "impossible to actually prove", and Ken Ribet considered himself "one of the vast majority of people who believed [it] was completely inaccessible", adding that "Andrew Wiles was probably one of the few people on earth who had the audacity to dream that you can actually go and prove [it]." 
Despite this, Wiles, who had had a childhood fascination with Fermat's Last Theorem, decided to undertake the challenge of proving the conjecture at least to the extent needed for Frey's curve. He dedicated all of his research time to this problem for over 6 years in near-total secrecy, covering up his efforts by releasing prior work in small segments as separate papers and confiding only in his wife. In 1993, he presented his proof to the public for the first time at a conference in Cambridge. In August 1993 it was discovered that the proof contained a flaw in one area. Wiles tried and failed for over a year to repair his proof. According to Wiles, the crucial idea for circumventing, rather than closing this area, came to him on 19 September 1994 when he was on the verge of giving up. Together with his former student Richard Taylor, he published a second paper which circumvented the problem and thus completed the proof. Both papers were published in 1995 in a special volume of the "Annals of Mathematics".
Recognition by the media.
His proof of Fermat's Last Theorem has stood up to the scrutiny of the world's mathematical experts. Wiles was interviewed for an episode of the BBC documentary series "Horizon" that focused on Fermat's Last Theorem. This was renamed "The Proof", and it was made an episode of the Public Broadcasting Service's science television series "Nova". He has been a foreign member of the US National Academy of Sciences since 1996.
Awards and honours.
Wiles has been awarded several major prizes in mathematics and science:
Wiles nomination for election to the Royal Society reads: 

</doc>
<doc id="2028" url="http://en.wikipedia.org/wiki?curid=2028" title="Ambient">
Ambient

Ambient or Ambiance may refer to:

</doc>
<doc id="2029" url="http://en.wikipedia.org/wiki?curid=2029" title="Anne Brontë">
Anne Brontë

Anne Brontë ( or ; 17 January 1820 – 28 May 1849) was a British novelist and poet, the youngest member of the Brontë literary family.
The daughter of a poor Irish clergyman in the Church of England, Anne Brontë lived most of her life with her family at the parish of Haworth on the Yorkshire moors. For a couple of years she went to a boarding school. At the age of 19 she left Haworth and worked as a governess between 1839 and 1845. After leaving her teaching position, she fulfilled her literary ambitions. She wrote a volume of poetry with her sisters ("Poems by Currer, Ellis, and Acton Bell", 1846) and two novels. "Agnes Grey", based upon her experiences as a governess, was published in 1847. Her second and last novel, "The Tenant of Wildfell Hall", which is considered to be one of the first sustained feminist novels, appeared in 1848. Anne's life was cut short when she died of pulmonary tuberculosis at the age of 29.
Mainly because the re-publication of "The Tenant of Wildfell Hall" was prevented by Charlotte Brontë after Anne's death, she is less known than her sisters Charlotte, author of four novels including "Jane Eyre", and Emily, author of "Wuthering Heights".
However, her novels, like those of her sisters, have become classics of English literature.
Family background.
Anne's father, Patrick Brontë (1777–1861), was born in a two-room cottage in Emdale, Loughbrickland, County Down, Ireland. He was the oldest of ten children born to Hugh Brunty and Eleanor McCrory, poor Irish peasant farmers. The family surname "mac Aedh Ó Proinntigh" was Anglicised as Prunty or Brunty. Struggling against poverty, Patrick learned to read and write and from 1798 taught others. In 1802, at the age of 25, he won a place to study theology at St. John's College, Cambridge where he changed his name, Brunty, to the more distinguished sounding Brontë. In 1807 he was ordained in the priesthood in the Church of England. He served as a curate first in Essex and latterly in Wellington, Shropshire. In 1810, he published his first poem "Winter Evening Thoughts" in a local newspaper, followed in 1811 by a collection of moral verse, "Cottage Poems". In 1811, he became vicar of St. Peter's Church in Hartshead in Yorkshire. The following year he was appointed an examiner in Classics at Woodhouse Grove School, near Bradford a Wesleyan academy where, aged 35, he met his future wife, Maria Branwell, the headmaster's niece.
Anne's mother, Maria Branwell (1783–1821), was the daughter of Thomas Branwell, a successful, property-owning grocer and tea merchant in Penzance and Anne Carne, the daughter of a silversmith. The eleventh of twelve children, Maria enjoyed the benefits of belonging to a prosperous family in a small town. After the death of her parents within a year of each other, Maria went to help her aunt administer the housekeeping functions of the school. A tiny, neat woman aged 30, she was well read and intelligent. Her strong Methodist faith attracted Patrick Brontë because his own leanings were similar.
Though from considerably different backgrounds, within three months Patrick Brontë and Maria Branwell were married on 29 December 1812. Their first child, Maria (1814–1825), was born after they moved to Hartshead. In 1815, Patrick was appointed curate of the chapel in Thornton, near Bradford; a second daughter, Elizabeth (1815–1825), was born shortly after. Four more children followed: Charlotte, (1816–1855), Patrick Branwell (1817–1848), Emily, (1818–1848) and Anne (1820–1849).
Early life.
Anne, the youngest member of the Brontë children, was born on 17 January 1820, at 74 Market Street in Thornton where her father was curate and she was baptised there on 25 March 1820. Anne's father was appointed to the perpetual curacy in Haworth, a small town seven miles (11 km) away. In April 1820, the Brontës moved into the five-roomed Haworth Parsonage which became their home for the rest of their lives.
Anne was barely a year old when her mother became ill of what is believed to have been uterine cancer. Maria Branwell died on 15 September 1821. In order to provide a mother for his children, Patrick tried to remarry, but without success. Maria's sister, Elizabeth Branwell (1776–1842), moved to the parsonage, initially to nurse her dying sister, but she spent the rest of her life there raising the children. She did it from a sense of duty, but she was a stern woman who expected respect, rather than love. There was little affection between her and the older children, but Anne, according to tradition, was her favourite.
In Elizabeth Gaskell's biography, Anne's father remembered her as precocious, reporting that once, when she was four years old, in reply to his question about what a child most wanted, she answered: "age and experience".
In summer 1824, Patrick sent Maria, Elizabeth, Charlotte and Emily to Crofton Hall in Crofton, West Yorkshire, and subsequently to the Clergy Daughter's School at Cowan Bridge in Lancashire. When his eldest daughters died of consumption in 1825, Maria on 6 May and Elizabeth on 15 June, Charlotte and Emily were immediately brought home. The unexpected deaths distressed the family so much that Patrick could not face sending them away again. For the next five years, they were educated at home, largely by their father and aunt. The children made little attempt to mix with others outside the parsonage, but relied on each other for friendship and companionship. The bleak moors surrounding Haworth became their playground. Anne shared a room with her aunt, they were close which may have influenced Anne's personality and religious beliefs. Like her sister Charlotte, Anne grew up devoted to the Christian faith.
Education.
Anne's studies at home included music and drawing. Anne, Emily and Branwell had piano lessons from the Keighley church organist. They had art lessons from John Bradley of Keighley and all drew with some skill. Their aunt tried to teach the girls how to run a household, but their minds were more inclined to literature. Their father's well-stocked library was a source of knowledge. They read the Bible, Homer, Virgil, Shakespeare, Milton, Byron, Scott, and many others, they examined articles from Blackwood's Edinburgh Magazine, Fraser's Magazine, and The Edinburgh Review and read history, geography and biographies.
Reading fed the children's imagination. Their creativity soared after their father presented Branwell with a set of toy soldiers in June 1826. They gave the soldiers names and developed their characters, which they called the "Twelves". This led to the creation of an imaginary world: the African kingdom of "Angria" which was illustrated with maps and watercolour renderings. The children devised plots about the inhabitants of Angria and its capital city, "Glass Town", later called Verreopolis or Verdopolis.
The fantasy worlds and kingdoms gradually acquired the characteristics of real world—sovereigns, armies, heroes, outlaws, fugitives, inns, schools and publishers. The characters and lands created by the children had newspapers, magazines and chronicles which were written in extremely tiny books, with writing so small it was difficult to read without a magnifying glass. These creations and writings were an apprenticeship for their later, literary talents.
Juvenilia.
Around 1831, when Anne was eleven, she and Emily broke away from Charlotte and Branwell to create and develop their own fantasy world, "Gondal". Anne was particularly close to Emily especially after Charlotte's departure for Roe Head School, in January 1831. When Charlotte's friend Ellen Nussey visited Haworth in 1833, she reported that Emily and Anne were "like twins", "inseparable companions". She described Anne:
"Anne, dear gentle Anne was quite different in appearance from the others, and she was her aunt's favourite. Her hair was a very pretty light brown, and fell on her neck in graceful curls. She had lovely violet-blue eyes; fine pencilled eyebrows and a clear almost transparent complexion. She still pursued her studies and especially her sewing, under the surveillance of her aunt."
Anne took lessons from Charlotte, after she returned from Roe Head. Charlotte returned to Roe Head as a teacher on 29 July 1835 accompanied by Emily as a pupil; her tuition largely financed by Charlotte's teaching. Within a few months, Emily unable to adapt to life at school, was physically ill from homesickness. She was withdrawn from school by October, and replaced by Anne.
Aged 15, it was Anne's first time away from home, and she made few friends at Roe Head. She was quiet and hard working, and determined to stay and get the education she needed to support herself. She stayed for two years, winning a good-conduct medal in December 1836, and returning home only during Christmas and summer holidays. Anne and Charlotte do not appear to have been close while at Roe Head (Charlotte's letters almost never mention her) but Charlotte was concerned about her sister's health. Sometime before December 1837, Anne became seriously ill with gastritis and underwent a religious crisis. A Moravian minister was called to see her several times during her illness, suggesting her distress was caused, in part, by conflict with the local Anglican clergy. Charlotte wrote to her father who took Anne home where she remained while she recovered.
Employment at Blake Hall.
In 1839, a year after leaving the school and aged 19, she was seeking a teaching position. As the daughter of a poor clergyman, she needed to earn a living. Her father had no private income and the parsonage would revert to the church on his death. Teaching or working as governess for a family were among the few options available to poor but educated women. In April 1839, Anne started work as a governess for the Ingham family at Blake Hall, near Mirfield.
The children in her charge were spoilt and wild, persistently disobedient and tormented her. She had great difficulty controlling them, and little success in instilling any education. She was not empowered to inflict punishment, and when she complained about their behaviour received no support, but was criticised for not being capable. The Inghams, dissatisfied with their children's progress, dismissed Anne. She returned home at Christmas, 1839, joining Charlotte and Emily, who had left their positions, and Branwell. The episode at Blake Hall was so traumatic that she reproduced it in almost perfect detail in her novel, "Agnes Grey".
William Weightman.
On her return to Haworth, she met William Weightman (1814–1842), her father's new curate, who started work in the parish in August 1839. Aged 25, he had obtained a two-year licentiate in theology from the University of Durham. He was welcome at the parsonage. Her acquaintance with him parallels her writing a number of poems, which may suggest she fell in love with him although there is disagreement over this possibility. Little evidence exists beyond a teasing anecdote of Charlotte's to Ellen Nussey in January 1842.
The source of "Agnes Grey"'s renewed interest in poetry is, however, the curate to whom she is attracted. William Weightman aroused much curiosity. It seems clear he was a good-looking, engaging young man, whose easy humour and kindness towards the sisters made a considerable impression. It is such a character that she portrays in Edward Weston, and that her heroine Agnes Grey finds deeply appealing.
If Anne formed an attachment to Weightman it does not imply that he was attracted to her. It is possible that Weightman was no more aware of her, her sisters or their friend Ellen Nussey. Nor does it imply that Anne believed him to be interested in her. If anything, her poems suggest the opposite–they speak of quietly experienced but intensely felt emotions, hidden from others, without any indication of being requited. It is possible that an initially mild attraction to Weightman assumed increasing importance to Anne over time, in the absence of other opportunities for love, marriage and children.
Anne would have seen Weightman on her holidays at home, particularly during the summer of 1842 when her sisters were away. Weightman died of cholera in the same year. Anne expressed her grief for his death in her poem "I will not mourn thee, lovely one", in which she called him "our darling".
Governess.
Anne obtained a second post as governess to the children of the Reverend Edmund Robinson and his wife Lydia, at Thorp Green Hall, a comfortable country house near York. Anne was employed at Thorp Green Hall from 1840 to 1845. The house appeared as Horton Lodge in her novel "Agnes Grey". Anne had four pupils: Lydia, age 15, Elizabeth, age 13, Mary, age 12, and Edmund, age 8. Initially, she encountered similar problems as she had experienced at Blake Hall. Anne missed her home and family, commenting in a diary paper in 1841 that she did not like her situation and wished to leave it. Her quiet, gentle disposition did not help. However, despite her outwardly placid appearance, Anne was determined and with experience, made a success of her position, becoming well liked by her employers. Her charges, the Robinson girls, became lifelong friends.
For the next five years, Anne spent no more than five or six weeks a year with her family, during holidays at Christmas and in June. The rest of her time was spent with the Robinsons at Thorp Green. She was obliged to accompany them on annual holidays to Scarborough. Between 1840 and 1844, Anne spent around five weeks each summer at the coastal town and loved the place. A number of locations in Scarborough were the setting for "Agnes Grey"'s final scenes and for Linden-Car village in "The Tenant of Wildfell Hall".
Whilst working for the Robinsons, Anne and her sisters considered the possibility of setting up a school. Various locations including the parsonage were considered. The project never materialised and Anne chose to return to Thorp Green. She came home on the death of her aunt in early November 1842 while her sisters were in Brussels. Elizabeth Branwell left a £350 legacy (£ as of 2015) for each of her nieces.
It was at the Long Plantation at Thorp Green in 1842 that Anne wrote her three-verse poem "Lines Composed in a Wood on a Windy Day", which was published in 1846 under her pen-name of Acton Bell.
Anne returned to Thorp Green in January 1843 where she secured a position for Branwell. He was to take over as tutor to the Robinsons' son, Edmund, who was growing too old to be in Anne's care. Branwell did not live in the house as Anne did. Anne's vaunted calm appears to have been the result of hard-fought battles, balancing deeply felt emotions with careful thought, a sense of responsibility and resolute determination. All three Brontë sisters worked as governesses or teachers, and all experienced problems controlling their charges, gaining support from their employers, and coping with homesickness—but Anne was the only one who persevered and made a success of her work.
Back at the parsonage.
Anne and Branwell taught at Thorp Green for the next three years. Branwell entered into a secret relationship with his employer's wife, Lydia Robinson. When Anne and her brother returned home for the holidays in June 1846, she resigned her position. While Anne gave no reason for leaving Thorp Green, it is thought she wanted to leave on becoming aware of the relationship between her brother and Mrs Robinson. Branwell was dismissed when his employer found out about the relationship. Anne retained close ties to Elizabeth and Mary Robinson, exchanging letters even after Branwell's disgrace. The Robinson sisters came to visit Anne in December 1848.
Anne took Emily to visit some of the places she had come to know and love in the five years spent with the Robinsons. A plan to visit Scarborough fell through and instead the sisters went to York where Anne showed her sister York Minster.
A book of poems.
In summer 1845, the Brontës were at home with their father. None had any immediate prospect of employment. Charlotte came across Emily's poems which had been shared only with Anne, her partner in the world of Gondal. Charlotte proposed that they be published. Anne revealed her own poems but Charlotte's reaction was characteristically patronising: "I thought that these verses too had a sweet sincere pathos of their own". Eventually the sisters reached an agreement. They told neither Branwell, nor their father, nor their friends about what they were doing. Anne and Emily contributed 21 poems and Charlotte 19 and with Aunt Branwell's money, they paid to have the collection published.
Afraid their work would be judged differently if they revealed they were women, the book appeared using three pseudonyms—or pen-names, the initials of which were the same as their own. Charlotte became Currer Bell, Emily, Ellis Bell and Anne, Acton Bell. "Poems by Currer, Ellis, and Acton Bell" was available for sale in May 1846. The cost of publication was about three-quarters of Anne's salary at Thorp Green. On 7 May 1846, the first three copies were delivered to Haworth Parsonage. It achieved three somewhat favourable reviews, but was a dismal failure, with only two copies being sold in the first year. Anne, however, found a market for her more recent poetry. The "Leeds Intelligencer" and "Fraser's Magazine" published her poem "The Narrow Way" under her pseudonym, Acton Bell in December 1848. Four months earlier, in August, Fraser's Magazine had published her poem "The Three Guides".
Novels.
"Agnes Grey".
Even before the fate of the book of poems became apparent, the sisters began work on their first novels. Charlotte wrote "The Professor", Emily "Wuthering Heights", and Anne "Agnes Grey". By July 1846, a package with the three manuscripts was making the rounds of London publishers.
After a number of rejections, Emily's "Wuthering Heights" and Anne's "Agnes Grey" were accepted by a publisher, but Charlotte's novel was rejected by every publisher to whom it was sent. Charlotte was not long in completing her second novel, "Jane Eyre", and it was immediately accepted by Smith, Elder & Co. and was the first to appear in print. While Anne and Emily's novels 'lingered in the press', Charlotte's second novel was an immediate and resounding success. Anne and Emily were obliged to pay fifty pounds to help meet their publishing costs. Their publisher, urged on by the success of "Jane Eyre", published Anne and Emily's novels in December 1847. They sold well, but "Agnes Grey" was outshone by Emily's more dramatic "Wuthering Heights".
"The Tenant of Wildfell Hall".
Anne's second novel, "The Tenant of Wildfell Hall", was published in the last week of June 1848. It was an instant, phenomenal success; within six weeks it was sold out.
"The Tenant of Wildfell Hall" is perhaps the most shocking of the Brontës' novels. In seeking to present the truth in literature, Anne's depiction of alcoholism and debauchery was profoundly disturbing to 19th-century sensibilities. Helen Graham, the tenant of the title, intrigues Gilbert Markham and gradually she reveals her past as an artist and wife of the dissipated Arthur Huntingdon. The book's brilliance lies in its revelation of the position of women at the time, and its multi-layered plot.
It is easy today to underestimate the extent to which the novel challenged existing social and legal structures. May Sinclair, in 1913, said that the slamming of Helen Huntingdon's bedroom door against her husband reverberated throughout Victorian England. Anne's heroine eventually left her husband to protect their young son from his influence. She supported herself and her son by painting while living in hiding, fearful of discovery. In doing so, she violated not only social conventions, but English law. At the time, a married woman had no independent legal existence apart from her husband; could not own property, sue for divorce, or control custody of her children. If she attempted to live apart, her husband had the right to reclaim her. If she took their child, she was liable for kidnapping. By living on her own income she was held to be stealing her husband's property, since any property she held or income she made was legally his.
London visit.
In July 1848, to dispel the rumour that the "Bell brothers" were all the same person, Charlotte and Anne went to London to reveal their identities to the publisher George Smith. The women spent several days in his company. Many years after Anne's death, he wrote in the Cornhill Magazine his impressions of her, describing her as:
"...a gentle, quiet, rather subdued person, by no means pretty, yet of a pleasing appearance. Her manner was curiously expressive of a wish for protection and encouragement, a kind of constant appeal which invited sympathy."
In the second edition of "The Tenant of Wildfell Hall", which appeared in August 1848, Anne clearly stated her intentions in writing it. She presented a forceful rebuttal to critics (Charlotte was among them) who considered her portrayal of Huntingdon overly graphic and disturbing. 
Anne sharply castigated reviewers who speculated on the sex of the authors, and the appropriateness of their writing, in words that do little to reinforce the stereotype of Anne as meek and gentle.
The increasing popularity of the Bells' work led to renewed interest in the "Poems by Currer, Ellis, and Acton Bell", originally published by Aylott and Jones. The remaining print run was bought by Smith and Elder, and reissued under new covers in November 1848. It still sold poorly.
Family tragedies.
Although Anne and her sisters were only in their late twenties, a highly successful literary career appeared a certainty for them. However, an impending tragedy was to engulf the family. Within the next ten months, three of the siblings, including Anne, would be dead.
Branwell's health had deteriorated over two years, but its seriousness was disguised by his persistent drunkenness. He died on the morning of 24 September 1848. His sudden death came as a shock to the family. He was aged 31. The cause was recorded as chronic bronchitis – marasmus; though it is now believed he was suffering from tuberculosis.
The family had suffered from coughs and colds during the winter of 1848, and Emily next became severely ill. She deteriorated rapidly over two months, persistently refusing all medical aid until the morning of 19 December, when, being very weak, she declared: "if you will send for a doctor, I will see him now". It was, however, far too late. At about two o'clock that afternoon, after a hard, short conflict in which she struggled desperately to hang on to life, she died, aged 30.
Emily's death deeply affected Anne, and her grief undermined her physical health. Over Christmas, Anne caught influenza. Her symptoms intensified, and her father sent for a Leeds physician in early January. The doctor diagnosed her condition as consumption (tuberculosis) and intimated that it was quite advanced, leaving little hope of recovery. Anne met the news with characteristic determination and self-control.
Unlike Emily, Anne took all the recommended medicines and followed the advice she was given. That same month she wrote her last poem, "A dreadful darkness closes in", in which she deals with being terminally ill. Her health fluctuated as the months passed, but she progressively grew thinner and weaker.
Death.
In February 1849, Anne seemed somewhat better. She decided to make a return visit to Scarborough in the hope that the change of location and fresh sea air might initiate a recovery. On 24 May 1849, Anne said her goodbyes to her father and the servants at Haworth, and set off for Scarborough with Charlotte and Ellen Nussey. En route, they spent a day and a night in York, where, escorting Anne around in a wheelchair, they did some shopping, and at Anne's request, visited York Minster. However, it was clear that Anne had little strength left.
On Sunday, 27 May, Anne asked Charlotte whether it would be easier if she returned home to die instead of remaining in Scarborough. A doctor, consulted the next day, indicated that death was close. Anne received the news quietly. She expressed her love and concern for Ellen and Charlotte, and seeing Charlotte's distress, whispered to her to "take courage". Conscious and calm, Anne died at about two o'clock in the afternoon, Monday, 28 May 1849.
Over the following days, Charlotte made the decision to "lay the flower where it had fallen". Anne was buried, not in Haworth with the rest of her family, but in Scarborough. The funeral was held on Wednesday 30 May which did not allow time for Patrick Brontë to make the journey, had he wished to do so. The former schoolmistress at Roe Head, Miss Wooler, was in Scarborough and she was the only other mourner at Anne's funeral. She was buried in St Mary's churchyard, beneath the castle walls, overlooking the bay. Charlotte commissioned a stone to be placed over her grave, with the simple inscription "Here lie the remains of Anne Brontë, daughter of the Revd P. Brontë, Incumbent of Haworth, Yorkshire. She died Aged 28 May 28th 1849". When Charlotte visited the grave three years later, she discovered multiple errors on the headstone, and thus it was refaced. However, Anne's age at death was still written as 28 when, in fact, she was 29 when she died. In April 2013, the correction was finally made when a new inscribed plinth was laid by the Brontë Society in front of the eroded headstone.
Reputation.
A year after Anne's death, further editions of her novels were reprinted but Charlotte prevented re-publication of "The Tenant of Wildfell Hall". In 1850, Charlotte wrote ""Wildfell Hall" it hardly appears to me desirable to preserve. The choice of subject in that work is a mistake, it was too little consonant with the character, tastes and ideas of the gentle, retiring inexperienced writer." Subsequent critics paid less attention to Anne's work, although in recent years, with increasing critical interest in female authors, her life is being re-examined and her work re-evaluated leading to her acceptance, not as a minor Brontë, but as a major literary figure in her own right. Sally McDonald of the Brontë Society said in 2013, "In some ways though she is now viewed as the most radical of the sisters, writing about tough subjects such as women's need to maintain independence and how alcoholism can tear a family apart."

</doc>
<doc id="2030" url="http://en.wikipedia.org/wiki?curid=2030" title="Augustine of Hippo">
Augustine of Hippo

Augustine of Hippo ( or ; ;
13 November 354 – 28 August 430), also known as Saint Augustine or Saint Austin, was an early Christian theologian and philosopher whose writings were very influential in the development of Western Christianity and Western philosophy. He was bishop of Hippo Regius (present-day Annaba, Algeria) located in the Roman province of Africa. Writing during the Patristic Era, he is viewed as one of the most important Church Fathers in the Western Christianity. Among his most important works are "City of God" and "Confessions", which continue to be read widely today.
According to his contemporary, Jerome, Augustine "established anew the ancient Faith." In his early years, he was heavily influenced by Manichaeism and afterward by the Neo-Platonism of Plotinus. After his conversion to Christianity and his baptism in 387, Augustine developed his own approach to philosophy and theology, accommodating a variety of methods and perspectives. Believing that the grace of Christ was indispensable to human freedom, he helped to formulate the doctrine of original sin and made seminal contributions to the development of just war theory.
When the Western Roman Empire began to disintegrate, Augustine developed the concept of the Catholic Church as a spiritual City of God (in a book of the same name), distinct from the material Earthly City. His thoughts profoundly influenced the medieval worldview. Augustine's "City of God" was closely identified with the segment of the Church that adhered to the concept of the Trinity as defined by the Council of Nicaea and the Council of Constantinople.
In the Catholic Church and the Anglican Communion, he is a saint, a pre-eminent Doctor of the Church, and the patron of the Augustinians. His memorial is celebrated on 28 August, the day of his death. He is the patron saint of brewers, printers, theologians, the alleviation of sore eyes, and a number of cities and dioceses. Many Protestants, especially Calvinists, consider him to be one of the theological fathers of the Protestant Reformation due to his teachings on salvation and divine grace.
In the East, many of his teachings are not accepted. The most important doctrinal controversy surrounding his name is the filioque. Other doctrines that are sometimes unacceptable are his view of original sin, the doctrine of grace, and predestination. Nonetheless, though considered to be mistaken on some points, he is still considered a saint, and his feast day is celebrated on 15 June. He carries the additional title of "Blessed "as opposed to Saint among the Orthodox Church, due to teachings seen as controversial with the doctrine.
Life.
Childhood and education.
Augustine was born in 354 in the municipium of Thagaste (now Souk Ahras, Algeria) in Roman Africa. His mother, Monica, was a devout Christian; his father Patricius was a Pagan who converted to Christianity on his deathbed. Scholars believe that Augustine's ancestors included Berbers, Latins, and Phoenicians. He considered himself to be Punic. Augustine's family name, Aurelius, suggests that his father's ancestors were freedmen of the "gens Aurelia" given full Roman citizenship by the Edict of Caracalla in 212. Augustine's family had been Roman, from a legal standpoint, for at least a century when he was born. It is assumed that his mother, Monica, was of Berber origin, on the basis of her name, but as his family were "honestiores", an upper class of citizens known as honorable men, Augustine's first language is likely to have been Latin. At the age of 11, he was sent to school at Madaurus (now M'Daourouch), a small Numidian city about 19 miles south of Thagaste. There he became familiar with Latin literature, as well as pagan beliefs and practices. His first insight into the nature of sin occurred when he and a number of friends stole fruit they did not even want from a neighborhood garden. While at home in 369 and 370, he read Cicero's dialogue "Hortensius" (now lost), which he described as leaving a lasting impression on him and sparking his interest in philosophy.
At the age of 17, through the generosity of his fellow citizen Romanianus, Augustine went to Carthage to continue his education in rhetoric. Although raised as a Christian, Augustine left the church to follow the Manichaean religion, much to the despair of his mother. As a youth Augustine lived a hedonistic lifestyle for a time, associating with young men who boasted of their sexual exploits with women and men. They urged the inexperienced boys, like Augustine, to seek experience or to make up stories about their experiences in order to gain acceptance. It was during this period that he uttered his famous prayer, "Grant me chastity and continence, but not yet."
At about the age of 19, Augustine began an affair with a young woman in Carthage. Possibly because his mother wanted him to marry a person of his class, the woman remained his lover for over thirteen years and gave birth to his son Adeodatus, who was viewed as extremely intelligent by his contemporaries. In 385, Augustine abandoned his lover in order to prepare himself to marry an heiress.
Teaching rhetoric.
During the years 373 and 374, Augustine taught grammar at Thagaste. The following year he moved to Carthage to conduct a school of rhetoric, and would remain there for the next nine years. Disturbed by the unruly behavior of the students in Carthage, in 383 he moved to establish a school in Rome, where he believed the best and brightest rhetoricians practiced. However, Augustine was disappointed with the Roman schools, where he was met with apathy. Once the time came for his students to pay their fees, they simply fled. Manichaean friends introduced him to the prefect of the City of Rome, Symmachus, who had been asked to provide a professor of rhetoric for the imperial court at Milan.
Augustine won the job and headed north to take up his position in late 384. At the age of thirty, he had won the most visible academic position in the Latin world, at a time when such posts gave ready access to political careers. During this period, although Augustine showed some fervor for Manichaeism, he was never an initiate or "elect", but remained an "auditor", the lowest level in the sect's hierarchy.
While still at Carthage, he had begun to move away from Manichaeism, in part because of a disappointing meeting with the Manichaean Bishop, Faustus of Mileve, a key exponent of Manichaean theology. In Rome, he is reported to have completely turned away from Manichaeanism, and instead embraced the scepticism of the New Academy movement. At Milan, his mother pressured him to become a Christian. Augustine's own studies in Neoplatonism were also leading him in this direction, and his friend Simplicianus urged him that way as well. But it was the bishop of Milan, Ambrose, who had most influence over Augustine. Like Augustine, Ambrose was a master of rhetoric, but older and more experienced.
Augustine's mother had followed him to Milan and he allowed her to arrange a marriage, for which he abandoned his concubine. It is believed that Augustine truly loved the woman he had lived with for so long and was deeply hurt by ending this relationship. In fact, there is evidence that Augustine may have considered his relationship with the concubine to be equivalent to marriage, though not legally recognized as such. In his "Confessions," he admitted that the experience eventually produced a decreased sensitivity to pain over time. He had to wait two years until his fiancée came of age, and he soon took another concubine. Augustine eventually broke off his engagement to his eleven-year-old fiancée, but never renewed his relationship with either of his concubines.
Alypius of Thagaste steered Augustine away from marriage, saying that they could not live a life together in the love of wisdom if he married. Augustine looked back years later on the life at Cassiciacum, a villa outside of Milan where he gathered with his followers, and described it as "Christianae vitae otium" – the Christian life of leisure. Augustine had been awarded a job of professor of rhetoric in Milan at the time he was living at Cassiciacum around 383.
Christian conversion and priesthood.
In the summer of 386, after having heard and been inspired and moved by the story of Placianus's and his friends' first reading of the life of Saint Anthony of the Desert, Augustine converted to Christianity. As Augustine later told it, his conversion was prompted by a childlike voice he heard telling him to "take up and read" (), which he took as a divine command to open the Bible and read the first thing he saw. Augustine read from Paul's Epistle to the Romans – the so-called "" section, consisting of chapters 12 through 15 – wherein Paul outlines how the Gospel transforms believers, and the believers' resulting behaviour. The specific part to which Augustine opened his Bible was Romans chapter 13, verses 13 and 14, to wit:
He later wrote an account of his conversion – his very transformation, as Paul described – in his "Confessions" (), which has since become a classic of Christian theology.
Ambrose baptized Augustine, along with his son Adeodatus, on Easter Vigil in 387 in Milan. A year later, in 388, Augustine completed his apology "On the Holiness of the Catholic Church". That year, also, Adeodatus and Augustine returned to Africa, Augustine's home continent. Augustine's mother Monica died at Ostia, Italy, as they prepared to embark for Africa. Upon their arrival, they began a life of aristocratic leisure at Augustine's family's property. Soon after, Adeodatus, too, passed away. Augustine then sold his patrimony and gave the money to the poor. The only thing he kept was the family house, which he converted into a monastic foundation for himself and a group of friends.
In 391 Augustine was ordained a priest in Hippo Regius (now Annaba), in Algeria. He became a famous preacher (more than 350 preserved sermons are believed to be authentic), and was noted for combating the Manichaean religion, to which he had formerly adhered.
In 395 he was made coadjutor Bishop of Hippo, and became full Bishop shortly thereafter, hence the name "Augustine of Hippo"; and he gave his property to the church of Thagaste. He remained in that position until his death in 430. He wrote his autobiographical "Confessions" in 397-398. His work "The City of God" was written to console his fellow Christians shortly after the Visigoths had sacked Rome in 410.
Augustine worked tirelessly in trying to convince the people of Hippo to convert to Christianity. Though he had left his monastery, he continued to lead a monastic life in the episcopal residence. He left a "regula" for his monastery that led to his designation as the "patron saint of regular clergy."
Much of Augustine's later life was recorded by his friend Possidius, bishop of Calama (present-day Guelma, Algeria), in his "Sancti Augustini Vita". Possidius admired Augustine as a man of powerful intellect and a stirring orator who took every opportunity to defend Christianity against its detractors. Possidius also described Augustine's personal traits in detail, drawing a portrait of a man who ate sparingly, worked tirelessly, despised gossip, shunned the temptations of the flesh, and exercised prudence in the financial stewardship of his see.
Death and veneration.
Shortly before Augustine's death the Vandals, a Germanic tribe that had converted to Arianism, invaded Roman Africa. The Vandals besieged Hippo in the spring of 430, when Augustine entered his final illness. According to Possidius, one of the few miracles attributed to Augustine, the healing of an ill man, took place during the siege. According to Possidius, Augustine spent his final days in prayer and repentance, requesting that the penitential Psalms of David be hung on his walls so that he could read them. He directed that the library of the church in Hippo and all the books therein should be carefully preserved. He died on 28 August 430. Shortly after his death, the Vandals lifted the siege of Hippo, but they returned not long thereafter and burned the city. They destroyed all of it but Augustine's cathedral and library, which they left untouched.
Augustine was canonized by popular acclaim, and later recognized as a Doctor of the Church in 1298 by Pope Boniface VIII. His feast day is 28 August, the day on which he died. He is considered the patron saint of brewers, printers, theologians, sore eyes, and a number of cities and dioceses.
Relics.
According to Bede's "True Martyrology", Augustine's body was later translated or moved to Cagliari, Sardinia, by the Catholic bishops expelled from North Africa by Huneric. Around 720, his remains were translated again by Peter, bishop of Pavia and uncle of the Lombard king Liutprand, to the church of San Pietro in Ciel d'Oro in Pavia, in order to save them from frequent coastal raids by Muslims. In January 1327, Pope John XXII issued the papal bull "Veneranda Santorum Patrum", in which he appointed the Augustinians guardians of the tomb of Augustine (called "Arca"), which was remade in 1362 and elaborately carved with bas-reliefs of scenes from Augustine's life.
In October 1695, some workmen in the Church of San Pietro in Ciel d'Oro in Pavia discovered a marble box containing some human bones (including part of a skull). A dispute arose between the Augustinian hermits (Order of Saint Augustine) and the regular canons (Canons Regular of Saint Augustine) as to whether these were the bones of St. Augustine. The hermits did not believe so; the canons affirmed that they were. Eventually Pope Benedict XIII (1724–1730) directed the Bishop of Pavia, Monsignor Pertusati, to make a determination. The bishop declared that, in his opinion, the bones were those of Saint Augustine.
The Augustinians were expelled from Pavia in 1700, taking refuge in Milan with the relics of Augustine, and the disassembled "Arca", which were removed to the cathedral there. San Pietro fell into disrepair, but was finally rebuilt in the 1870s, under the urging of Agostino Gaetano Riboldi, and reconsecrated in 1896 when the relics of Augustine and the shrine were once again reinstalled.
Thought.
Christian anthropology.
Augustine was one of the first Christian ancient Latin authors with a very clear vision of theological anthropology. He saw the human being as a perfect unity of two substances: soul and body. In his late treatise "" (420 AD) he exhorted to respect the body on the grounds that it belonged to the very nature of the human person. Augustine's favourite figure to describe "body-soul" unity is marriage: "caro tua, coniunx tua — your body is your wife". Initially, the two elements were in perfect harmony. After the fall of humanity they are now experiencing dramatic combat between one another. They are two categorically different things. The body is a three-dimensional object composed of the four elements, whereas the soul has no spatial dimensions. Soul is a kind of substance, participating in reason, fit for ruling the body. Augustine was not preoccupied, as Plato and Descartes were, with going too much into details in efforts to explain the metaphysics of the soul-body union. It sufficed for him to admit that they are metaphysically distinct: to be a human is to be a composite of soul and body, and the soul is superior to the body. The latter statement is grounded in his hierarchical classification of things into those that merely exist, those that exist and live, and those that exist, live, and have intelligence or reason.
Like other Church Fathers such as Athenagoras, St. Augustine "vigorously condemned the practice of induced abortion" as a crime, in any stage of pregnancy, although he accepted the distinction between "formed" and "unformed" fetuses mentioned in the Septuagint translation of , a text that, he observed, did not classify as murder the abortion of an "unformed" fetus, since it could not be said with certainty that it had already received a soul (see, e.g., "De Origine Animae" 4.4).
Astrology.
Augustine's contemporaries often believed astrology to be an exact and genuine science. Its practitioners were regarded as true men of learning and called "mathemathici". Astrology played a prominent part in Manichaean doctrine, and Augustine himself was attracted by their books in his youth, being particularly fascinated by those who claimed to foretell the future. Later, as a bishop, he used to warn that one should avoid astrologers who combine science and horoscopes. (Augustine's term "mathematici", meaning "astrologers", is sometimes mistranslated as "mathematicians".) According to Augustine, they were not genuine students of Hipparchus or Eratosthenes but "common swindlers".
Creation.
In "City of God", Augustine rejected both the immortality of the human race proposed by pagans, and contemporary ideas of ages (such as those of certain Greeks and Egyptians) that differed from the Church's sacred writings. In "The Literal Interpretation of Genesis", Augustine took the view that everything in the universe was created simultaneously by God, and not in seven calendar days like a literal account of Genesis would require. He argued that the six-day structure of creation presented in the book of Genesis represents a logical framework, rather than the passage of time in a physical way — it would bear a spiritual, rather than physical, meaning, which is no less literal. One reason for this interpretation is the passage in Sirach 18:1, "creavit omni simul" ("He created all things at once"), which Augustine took as proof that the days of Genesis 1 had to be taken non-literally. Augustine also does not envision original sin as causing structural changes in the universe, and even suggests that the bodies of Adam and Eve were already created mortal before the Fall. Apart from his specific views, Augustine recognizes that the interpretation of the creation story is difficult, and remarks that we should be willing to change our mind about it as new information comes up.
Ecclesiology.
Augustine developed his doctrine of the Church principally in reaction to the Donatist sect. He taught that there is one Church, but that within this Church there are two realities, namely, the visible aspect (the institutional hierarchy, the Catholic sacraments, and the laity) and the invisible (the souls of those in the Church, who are either dead, sinful members or elect predestined for Heaven). The former is the institutional body established by Christ on earth which proclaims salvation and administers the sacraments while the latter is the invisible body of the elect, made up of genuine believers from all ages, and who are known only to God. The Church, which is visible and societal, will be made up of "wheat" and "tares", that is, good and wicked people (as per Mat. 13:30), until the end of time. This concept countered the Donatist claim that only those in a state of grace were the "true" or "pure" church on earth, and that priests and bishops who were not in a state of grace had no authority or ability to confect the sacraments.
Augustine's ecclesiology was more fully developed in "City of God". There he conceives of the church as a heavenly city or kingdom, ruled by love, which will ultimately triumph over all earthly empires which are self-indulgent and ruled by pride. Augustine followed Cyprian in teaching that the bishops and priests of the Church are the successors of the Apostles, and that their authority in the Church is God-given.
Eschatology.
Augustine originally believed in premillennialism, namely that Christ would establish a literal 1,000-year kingdom prior to the general resurrection, but later rejected the belief, viewing it as carnal. He was the first theologian to expound a systematic doctrine of amillennialism, although some theologians and Christian historians believe his position was closer to that of modern postmillennialists. The mediaeval Catholic church built its system of eschatology on Augustinian amillennialism, where Christ rules the earth spiritually through his triumphant church. At the Reformation, theologians such as John Calvin accepted amillennialism. Augustine taught that the eternal fate of the soul is determined at death, and that purgatorial fires of the intermediate state purify only those that died in communion with the Church. His teaching provided fuel for later theology.
Epistemological views.
Epistemological concerns shaped Augustine's intellectual development. His early dialogues ["Contra academicos" (386) and "De Magistro" (389)], both written shortly after his conversion to Christianity, reflect his engagement with skeptical arguments and show the development of his doctrine of inner illumination. The doctrine of illumination claims that God plays a part in human perception and understanding by illuminating the mind so that human beings can recognize intelligible realities that God presents. According to Augustine, illumination is obtainable to all rational minds, and is different from other forms of sense perception. It is meant to be an explanation of the conditions required for the mind to have a connection with intelligible entities. Augustine also posed the problem of other minds throughout different works, most famously perhaps in "On the Trinity" (VIII.6.9), and developed what has come to be a standard solution: the argument from analogy to other minds. In contrast to Plato and other earlier philosophers, Augustine recognized the centrality of testimony to human knowledge and argued that what others tell us can provide knowledge even if we don't have independent reasons to believe their testimonial reports.
Just war.
Augustine asserted that Christians should be pacifists as a personal, philosophical stance. Nonetheless, he asserted, peacefulness in the face of a grave wrong that could only be stopped by violence would be a sin. Defense of one's self or others could be a necessity, especially when authorized by a legitimate authority. While not breaking down the conditions necessary for war to be just, Augustine nonetheless originated the very phrase, itself, in his work "The City of God". In essence, the pursuit of peace must include the option of fighting to preserve it in the long-term. Such a war could not be pre-emptive, but defensive, to restore peace. Thomas Aquinas, centuries later, used the authority of Augustine's arguments in an attempt to define the conditions under which a war could be just.
Mariology.
Although Augustine did not develop an independent Mariology, his statements on Mary surpass in number and depth those of other early writers. Even before the Council of Ephesus, he defended the ever Virgin Mary as the Mother of God, who, because of her virginity, is full of grace. Likewise, he affirmed that the Virgin Mary "conceived as virgin, gave birth as virgin and stayed virgin forever".
Natural knowledge and biblical interpretation.
Augustine took the view that the Biblical text should not be interpreted as properly literal, but rather as metaphorical, if it contradicts what we know from science and our God-given reason. While each passage of Scripture has a literal sense, this "literal sense" does not always mean that the Scriptures are mere history; at times they are rather an extended metaphor.
Original sin.
Augustine taught that Original sin of Adam and Eve was either an act of foolishness ("insipientia") followed by pride and disobedience to God or that pride came first. The first couple disobeyed God, who had told them not to eat of the Tree of the knowledge of good and evil (Gen 2:17). The tree was a symbol of the order of creation. Self-centeredness made Adam and Eve eat of it, thus failing to acknowledge and respect the world as it was created by God, with its hierarchy of beings and values. They would not have fallen into pride and lack of wisdom, if Satan hadn't sown into their senses "the root of evil" ("radix Mali"). Their nature was wounded by concupiscence or libido, which affected human intelligence and will, as well as affections and desires, including sexual desire. In terms of metaphysics, concupiscence is not a being but bad quality, the privation of good or a wound.
Augustine's understanding of the consequences of the original sin and of necessity of the redeeming grace was developed in the struggle against Pelagius and his Pelagian disciples, Caelestius and Julian of Eclanum, who had been inspired by Rufinus of Syria, a disciple of Theodore of Mopsuestia. They refused to agree that libido wounded human will and mind, insisting that the human nature was given the power to act, to speak, and to think when God created it. Human nature cannot lose its moral capacity for doing good, but a person is free to act or not to act in a righteous way. Pelagius gave an example of eyes: they have capacity for seeing, but a person can make either good or bad use of it. Like Jovinian, Pelagians insisted that human affections and desires were not touched by the fall either. Immorality, "e.g." fornication, is exclusively a matter of will, "i.e." a person does not use natural desires in a proper way.
In opposition to that, Augustine pointed out to the apparent disobedience of the flesh to the spirit, and explained it as one of the results of original sin, punishment of Adam and Eve's disobedience to God.
Augustine had served as a "Hearer" for the Manichaeans for about nine years, who taught that the original sin was carnal knowledge. But his struggle to understand the cause of evil in the world started before that, at the age of nineteen. By "malum" (evil) he understood most of all concupiscence, which he interpreted as a vice dominating person and causing in men and women moral disorder. A. Trapè insists that Augustine's personal experience cannot be credited for his doctrine about concupiscence. His marriage experience, though Christian marriage celebration was missing, was exemplary, very normal and by no means specifically sad. As J. Brachtendorf showed, Augustine used Ciceronian Stoic concept of passions, to interpret Paul's doctrine of universal sin and redemption.
The view that not only human soul but also senses were influenced by the fall of Adam and Eve was prevalent in Augustine's time among the Fathers of the Church. It is clear that the reason for Augustine's distancing from the affairs of the flesh was different from that of Plotinus, a neo-Platonist who taught that only through disdain for fleshly desire could one reach the ultimate state of mankind. Augustine taught the redemption, i.e. transformation and purification, of the body in the resurrection.
Some authors perceive Augustine's doctrine as directed against human sexuality and attribute his insistence on continence and devotion to God as coming from Augustine's need to reject his own highly sensual nature as described in the Confessions. But in view of his writings it is apparently a misunderstanding. Augustine taught that human sexuality has been wounded, together with the whole of human nature, and requires redemption of Christ. That healing is a process realized in conjugal acts. The virtue of continence is achieved thanks to the grace of the sacrament of Christian marriage, which becomes therefore a "remedium concupiscentiae" – remedy of concupiscence. The redemption of human sexuality will be, however, fully accomplished only in the resurrection of the body.
The sin of Adam is inherited by all human beings. Already in his pre-Pelagian writings, Augustine taught that Original Sin was transmitted by concupiscence, which he regarded as the passion of both, soul and body, making humanity a "massa damnata" (mass of perdition, condemned crowd) and much enfeebling, though not destroying, the freedom of the will.
Augustine's formulation of the doctrine of original sin was confirmed at numerous councils, "i.e." Carthage (418), Ephesus (431),
Orange (529), Trent (1546) and by popes, "i.e." Pope Innocent I (401–417) and Pope Zosimus (417–418). Anselm of Canterbury established in his "Cur Deus Homo" the definition that was followed by the great Schoolmen, namely that Original Sin is the "privation of the righteousness which every man ought to possess", thus interpreting "concupiscence" as something more than mere sexual lust, with which some of Augustine's disciples had defined it as later did Luther and Calvin, a doctrine condemned in 1567 by Pope Pius V.
Augustine taught that some people are predestined by God to salvation by an eternal, sovereign decree which is not based on man's merit or will. The saving grace which God bestows is irresistible and unfailingly results in conversion. God also grants those whom he saves with the gift of perseverance so that none of those whom God has chosen may conceivably fall away.
Free will.
Included in Augustine's theodicy is the claim that God created humans and angels as rational beings, possessing free will. Free will was not intended for sin, which means that it is not equally predisposed to good and evil. A will that has been defiled by sin is not considered to be "free" as it once was because it is bound by material things, things that can be lost and difficult to part with, thus resulting in unhappiness. Sin impairs free will, but it is restored by grace. Only a will that was once free can be subjected to the corruption of sin.
The Catholic Church considers Augustine's teaching to be consistent with free will. He often said that any can be saved if they wish. While God knows who will be saved and who will not, with no possibility that one destined to be lost will be saved, this knowledge represents God's perfect knowledge of how humans will freely choose their destinies.
Sacramental theology.
Also in reaction against the Donatists, Augustine developed a distinction between the "regularity" and "validity" of the sacraments. Regular sacraments are performed by clergy of the Catholic Church while sacraments performed by schismatics are considered irregular. Nevertheless, the validity of the sacraments do not depend upon the holiness of the priests who perform them ("ex opere operato"); therefore, irregular sacraments are still accepted as valid provided they are done in the name of Christ and in the manner prescribed by the Church. On this point Augustine departs from the earlier teaching of Cyprian, who taught that converts from schismatic movements must be re-baptised. Augustine taught that sacraments administered outside the Catholic Church, though true sacraments, avail nothing. However, he also stated that baptism, while it does not confer any grace when done outside the Church, does confer grace as soon as one is received into the Catholic Church.
Augustine upheld the early Christian understanding of the Real Presence of Christ in the Eucharist, saying that Christ's statement, "This is my body" referred to the bread he carried in his hands, and that Christians must have faith that the bread and wine are in fact the body and blood of Christ, despite what they see with their eyes.
Against the Pelagians, Augustine strongly stressed the importance of infant baptism. About the question whether baptism is an absolute necessity for salvation, however, Augustine appears to have refined his beliefs during his lifetime, causing some confusion among later theologians about his position. He said in one of his sermons that only the baptized are saved. This belief was shared by many early Christians. However, a passage from his "City of God", concerning the Apocalypse, may indicate that Augustine did believe in an exception for children born to Christian parents.
Statements on Jews.
Against certain Christian movements, some of which rejected the use of Hebrew Scripture, Augustine countered that God had chosen the Jews as a special people, and he considered the scattering of Jewish people by the Roman Empire to be a fulfillment of prophecy. He rejected homicidal attitudes, quoting part of the same prophecy, namely "Slay them not, lest they should at last forget Thy law" (Psalm 59:11). Augustine, who believed Jewish people would be converted to Christianity at "the end of time," argued that God had allowed them to survive their dispersion as a warning to Christians; as such, he argued, they should be permitted to dwell in Christian lands. The sentiment sometimes attributed to Augustine that Christians should let the Jews "survive but not thrive" (it is repeated by author James Carroll in his book "Constantine's Sword", for example) is apocryphal and is not found in any of his writings.
Views on sexuality.
For Augustine, the evil of sexual immorality was not in the sexual act itself, but rather in the emotions that typically accompany it. In "On Christian Doctrine" Augustine contrasts love, which is enjoyment on account of God, and lust, which is not on account of God. For Augustine, proper love exercises a denial of selfish pleasure and the subjugation of corporeal desire to God. He wrote that the pious virgins raped during the sack of Rome, were innocent because they did not intend to sin.
Augustine's view of sexual feelings as sinful affected his view of women. For example he considered a man’s erection to be sinful, though involuntary, because it did not take place under his conscious control. His solution was to place controls on women to limit their ability to influence men.
He believed that the serpent approached Eve because she was less rational and lacked self-control, while Adam's choice to eat was viewed as an act of kindness so that Eve would not be left alone. Augustine believed sin entered the world because man (the spirit) did not exercise control over woman (the flesh). Augustine's views on women were not all negative, however. In his "Tractates on the Gospel of John", Augustine, commenting on the Samaritan woman from John 4:1–42, uses the woman as a figure of the church.
According to Raming, the authority of the "Decretum Gratiani", a collection of Roman Catholic canon law which prohibits women from leading, teaching, or being a witness, rests largely on the views of the early church fathers—one of the most influential being St. Augustine, the Bishop of Hippo. The laws and traditions founded upon St. Augustine's views of sexuality and women continue to exercise considerable influence over church doctrinal positions regarding the role of women in the church.
Teaching philosophy.
Augustine is considered an influential figure in the history of education. A work early in Augustine's writings is "De Magistro" (the Teacher), which contains insights about education. However, his ideas changed as he found better directions or better ways of expressing his ideas. In the last years of his life Saint Augustine wrote his "Retractationes", reviewing his writings and improving specific texts. Henry Chadwick believes an accurate translation of "retractationes" may be "reconsiderations". Reconsiderations can be seen as an overarching theme of the way Saint Augustine learned. Augustine's understanding of the search for understanding/meaning/truth as a restless journey leaves room for doubt, development and change.
Gary N. McCloskey finds four "encounters of learning" in Augustine's approach to education: Through Transforming Experiences; as a Journey in Search of Understanding/Meaning/Truth; Learning with Others in Community; and Building the Habits (Love) of Learning. His emphasis on the importance of community as a means of learning distinguishes his pedagogy from some others. Augustine believed that dialogue/dialectic/discussion is the best means for learning, and this method should serve as a model for learning encounters between teachers and students. Saint Augustine’s dialogue writings model the need for lively interactive dialogue among learners.
He introduced the theory of three different categories of students, and instructed teachers to adapt their teaching styles to each student's individual learning style. The three different kinds of students are: the student who has been well-educated by knowledgeable teachers; the student who has had no education; and the student who has had a poor education, but believes himself to be well-educated. If a student has been well educated in a wide variety of subjects, the teacher must be careful not to repeat what they have already learned, but to challenge the student with material which they do not yet know thoroughly. With the student who has had no education, the teacher must be patient, willing to repeat things until the student understands, and sympathetic. Perhaps the most difficult student, however, is the one with an inferior education who believes he understands something when he does not. Augustine stressed the importance of showing this type of student the difference between "having words and having understanding," and of helping the student to remain humble with his acquisition of knowledge.
Augustine introduced the idea of teachers responding positively to the questions they may receive from their students, no matter if the student interrupted his teacher. Augustine also founded the "restrained" style of teaching. This teaching style ensures the students' full understanding of a concept because the teacher does not bombard the student with too much material; focuses on one topic at a time; helps them discover what they don't understand, rather than moving on too quickly; anticipates questions; and helps them learn to solve difficulties and find solutions to problems. Yet another of Augustine's major contributions to education is his study on the styles of teaching. He claimed there are two basic styles a teacher uses when speaking to the students. The "mixed style" includes complex and sometimes showy language to help students see the beautiful artistry of the subject they are studying. The "grand style" is not quite as elegant as the mixed style, but is exciting and heartfelt, with the purpose of igniting the same passion in the students' hearts. Augustine balanced his teaching philosophy with the traditional Bible-based practice of strict discipline.
Works.
Augustine was one of the most prolific Latin authors in terms of surviving works, and the list of his works consists of more than one hundred separate titles. They include apologetic works against the heresies of the Arians, Donatists, Manichaeans and Pelagians; texts on Christian doctrine, notably "De Doctrina Christiana" ("On Christian Doctrine"); exegetical works such as commentaries on Book of Genesis, the Psalms and Paul's Letter to the Romans; many sermons and letters; and the "Retractationes", a review of his earlier works which he wrote near the end of his life. Apart from those, Augustine is probably best known for his "Confessions", which is a personal account of his earlier life, and for "De civitate dei" ("The City of God", consisting of 22 books), which he wrote to restore the confidence of his fellow Christians, which was badly shaken by the sack of Rome by the Visigoths in 410. His "On the Trinity", in which he developed what has become known as the 'psychological analogy' of the Trinity, is also among his masterpieces, and arguably one of the greatest theological works of all time. He also wrote "On Free Choice Of The Will" ("De libero arbitrio"), addressing why God gives humans free will that can be used for evil.
Influence.
In both his philosophical and theological reasoning, Augustine was greatly influenced by Stoicism, Platonism and Neo-platonism, particularly by the work of Plotinus, author of the Enneads, probably through the mediation of Porphyry and Victorinus (as Pierre Hadot has argued). Although he later abandoned Neoplatonism, some ideas are still visible in his early writings. His early and influential writing on the human will, a central topic in ethics, would become a focus for later philosophers such as Schopenhauer, Kierkegaard, and Nietzsche. In addition, Augustine was influenced by the works of Virgil (known for his teaching on language), Cicero (known for his teaching on argument), and Aristotle (particularly his Rhetoric and Poetics).
Thomas Aquinas was influenced heavily by Augustine. On the topic of original sin, Aquinas proposed a more optimistic view of man than that of Augustine in that his conception leaves to the reason, will, and passions of fallen man their natural powers even after the Fall. Augustine's doctrine of efficacious grace found eloquent expression in the works of Bernard of Clairvaux; also Reformation theologians such as Martin Luther and John Calvin would look back to him as their inspiration.
Philosopher Bertrand Russell was impressed by Augustine's meditation on the nature of time in the "Confessions", comparing it favourably to Kant's version of the view that time is subjective. Catholic theologians generally subscribe to Augustine's belief that God exists outside of time in the "eternal present"; that time only exists within the created universe because only in space is time discernible through motion and change. His meditations on the nature of time are closely linked to his consideration of the human ability of memory. Frances Yates in her 1966 study "The Art of Memory" argues that a brief passage of the "Confessions", 10.8.12, in which Augustine writes of walking up a flight of stairs and entering the vast fields of memory clearly indicates that the ancient Romans were aware of how to use explicit spatial and architectural metaphors as a mnemonic technique for organizing large amounts of information.
Augustine's philosophical method, especially demonstrated in his "Confessions", had continuing influence on Continental philosophy throughout the 20th century. His descriptive approach to intentionality, memory, and language as these phenomena are experienced within consciousness and time anticipated and inspired the insights of modern phenomenology and hermeneutics. Edmund Husserl writes: "The analysis of time-consciousness is an age-old crux of descriptive psychology and theory of knowledge. The first thinker to be deeply sensitive to the immense difficulties to be found here was Augustine, who laboured almost to despair over this problem." Martin Heidegger refers to Augustine's descriptive philosophy at several junctures in his influential work "Being and Time". Hannah Arendt began her philosophical writing with a dissertation on Augustine's concept of love, "Der Liebesbegriff bei Augustin" (1929): "The young Arendt attempted to show that the philosophical basis for "vita socialis" in Augustine can be understood as residing in neighbourly love, grounded in his understanding of the common origin of humanity." Jean Bethke Elshtain in "Augustine and the Limits of Politics" finds likeness between Augustine and Arendt in their concepts of evil: "Augustine did not see evil as glamorously demonic but rather as absence of good, something which paradoxically is really nothing. Arendt ... envisioned even the extreme evil which produced the Holocaust as merely banal [in "Eichmann in Jerusalem"]." Augustine's philosophical legacy continues to influence contemporary critical theory through the contributions and inheritors of these 20th-century figures.
According to Leo Ruickbie, Augustine's arguments against magic, differentiating it from miracle, were crucial in the early Church's fight against paganism and became a central thesis in the later denunciation of witches and witchcraft. According to Professor Deepak Lal, Augustine's vision of the heavenly city has influenced the secular projects and traditions of the Enlightenment, Marxism, Freudianism and Eco-fundamentalism. Post-Marxist philosophers Antonio Negri and Michael Hardt rely heavily on Augustine's thought, particularly The City of God, in their book of political-philosophy "Empire."
While in his pre-Pelagian writings Augustine taught that Adam's guilt as transmitted to his descendants much enfeebles, though does not destroy, the freedom of their will, Protestant reformers Martin Luther and John Calvin affirmed that Original Sin completely destroyed liberty (see total depravity).
Augustine has influenced many modern-day theologians and authors such as John Piper. Hannah Arendt, an influential 20th century political theorist, wrote her doctoral dissertation in philosophy on St. Augustine, and continued to rely on his thought throughout her career. Ludwig Wittgenstein extensively quotes Augustine in "Philosophical Investigations" for his approach to language, both admiringly, and as a sparring partner to develop his own ideas, including an extensive opening passage from the "Confessions". In his autobiographical book "Milestones", Pope Benedict XVI, claims St. Augustine as one of the deepest influences in his thought.
In popular culture.
Augustine was played by Dary Berkani in the 1972 television movie "Augustine of Hippo". He was also played by Franco Nero in the 2010 mini-series ' and the 2012 feature film '. The modern day name links to the Agostinelli Family.
Jostein Gaarder's philosophical novel "Vita Brevis" is presented as a translation of a manuscript written by Augustine's concubine after he became the Bishop of Hippo. Augustine also appears in the novel "The Dalkey Archive" by Flann O'Brian (the pen name of Irish Author Brian O'Nolan). He is summoned to an underwater cavern by an absurd scientist called De Selby; together they discuss life in Heaven and the characters of other Saints. Walter M. Miller, Jr.'s novel "A Canticle for Leibowitz" cites St. Augustine as possibly positing the first version of a theory of evolution.
Bob Dylan recorded a song entitled "I Dreamed I Saw St. Augustine" on his album "John Wesley Harding". Pop artist Sting pays an homage of sorts to Augustine's struggles with lust with the song "Saint Augustine in Hell" which appears on the singer's 1993 album "Ten Summoner's Tales". Christian Rock artist Disciple named their fourth track on their 2010 release "Horseshoes and Handgrenades" after Augustine, called: "The Ballad of St. Augustine". The song "St. Augustine" appears on Girlyman's album, "Supernova". American rock band Moe named and referenced Augustine of Hippo in their song entitled, "St. Augustine."

</doc>
<doc id="2032" url="http://en.wikipedia.org/wiki?curid=2032" title="Acting">
Acting

Acting is the work of an actor or actress, which is a person in theatre, television, film, or any other storytelling medium who tells the story by portraying a character and, usually, speaking or singing the written text or play.
Most early sources in the West that examine the art of acting (, "hypokrisis") discuss it as part of rhetoric.
Definition and history.
One of the first actors is believed to be an ancient Greek called Thespis of Icaria. An apocryphal story says that Thespis stepped out of the dithyrambic chorus and spoke to them as a separate character. Before Thespis, the chorus narrated (for example, "Dionysus did this, Dionysus said that"). When Thespis stepped out from the chorus (year 12 BC), he spoke as if he was the character (for example, "I am Dionysus. I did this"). From Thespis' name derives the word "thespian".
Acting requires a wide range of skills, including vocal projection, clarity of speech, physical expressivity, emotional facility, a well-developed imagination, and the ability to interpret drama. Acting also often demands an ability to employ dialects, accents and body language, improvisation, observation and emulation, mime, and stage combat. Many actors train at length in special programs or colleges to develop these skills, and today the vast majority of professional actors have undergone extensive training. Even though one actor may have years of training, they always strive for more lessons; the cinematic and theatrical world is always changing and because of this, the actor must stay as up to date as possible. Actors and actresses will often have many instructors and teachers for a full range of training involving, but not limited to, singing, scene-work, monologue techniques, audition techniques, and partner work.
Professional actors.
Not all people working as actors in film, television or theatre are professionally trained. Conservatories typically offer two- to four-year training on all aspects of acting. Universities will offer three- to four-year programs, where a student is often able to choose to focus on drama, while still learning about other aspects of theatre. Schools will vary in their approach, but in North America the most popular method taught derives from the "system" of Constantin Stanislavski, which was developed and popularised in America by Lee Strasberg, Stella Adler, and others. The ambiguously termed method acting came about through iterations of Stanislavski's system by Strasberg. Part of this style of training includes actors memorizing lines to be able to work off-book, a term that means being able to work without a script. Other approaches may include a more physical approach, following the teachings of Jerzy Grotowski and others, or may be based on the training developed by other theatre practitioners including Sanford Meisner. Other classes may include mask work, improvisation, and acting for the camera. Regardless of a school's approach, students should expect intensive training in textual interpretation, voice and movement. Although there are some teachers who will encourage the improvisation as technique in order to free the actor of limitations in rehearsal. Harold Guskin's approach or "taking it off the page" as he calls it is steeped in this philosophy. Applications to drama programs and conservatories are through auditions in the United States. Anybody over the age of 18 can usually apply to drama school.
Training may also start at a very young age. Acting classes and professional schools targeted at the under-18 crowd are offered in many locations. These classes introduce young actors to different aspects of acting and theatre, including scene study.
Amateur actors.
Amateur actors are actors who do not require payment for performances. Although there are some paid professional actors who do amateur work for multiple reasons. Some may be for educational purposes or even charity events.
Improvisation.
Improvisation was created by Viola Spolin after working with Neva Boyd at a Hull House in Chicago, Illinois. She was Boyds student from 1924 to 1927. Improv was created on the realization that adults do not play games. Spolin felt that playing games were good exercises and can benefit in future acting. With improv, people can find true expressive freedom since they don't ever know how the situation is going to turn out. When one continues to operate with an open mind they will have a real sense of spontaneity rather than pre-planning a response. You perform a character of your own making, and with that character and the others working with you, you create a new and spontaneous piece. Improv is also used to cover up if an actor or actress makes a mistake.
Semiotics of Acting.
Semiotics of Acting is the actor’s ability to transform into a convincing character in front of the audience. The audience no longer sees the actor as a performer, but sees a character as a completely different being. Once this shift occurs, the actor becomes a semiotic device communicating a set of signs to the audience. A character’s signification can represent a multitude of different meanings to the audience. This may or may not be intended by the actor, who has limited control over how the audience will “read” the character. For example, if the actor is playing a character diagnosed with cancer, the audience may not just see a cancer patient, but may instead see a character similar to other cancer victims or survivors they have known. The actor’s performance, like any text, must be read by the audience. 
However, the actor is judged by giving a convincing and believable performance. The actor’s performance is mediated by particular semiotic signs including facial expression, emotion, and vocabulary. All these examples are known as performance signs. Performance signs are simple codes that the audience must decode during the actor's performance. It is the actor’s job to deliver those codes effectively to the audience. If the audience does not find the character believable, then the actor has failed in their performance. Like other forms of communication, non-verbal or visual clues are tremendously important. Acting teacher Sanford Meisner once said, “An ounce of emotion is worth a pound of words.” Great actors master performance signs in order to win over an audience. 
Acting involves two forms of communication: intrascenic (communication between characters) and extrascenic (communication between the characters and the audience). Both intrascenic and extrascenic communication must work in order for the audience to read the semiotic signs of the actor’s performance. The characters must have intrascenic skills – “good chemistry” – in a scene in order for the audience to understand the performance. 
The actor represents the text of the script as performance signs. Actors bring the text to life through performance and through the personal qualities they may contribute to the narrative of script. Actors represent the ideas of the text, but also create a new visually dimensioned reality through their performance.
Becoming an actor representing semiotic signs can be a very difficult process. One must understand the performance signs, the audience, and human emotion.

</doc>
<doc id="2037" url="http://en.wikipedia.org/wiki?curid=2037" title="Delian League">
Delian League

The Delian League, founded in 478 BC, was an association of Greek city-states, members numbering between 150 to 173, under the leadership of Athens, whose purpose was to continue fighting the Persian Empire after the Greek victory in the Battle of Plataea at the end of the Second Persian invasion of Greece. The League's modern name derives from its official meeting place, the island of Delos, where congresses were held in the temple and where the treasury stood until, in a symbolic gesture, Pericles moved it to Athens in 454 BC. 
Shortly after its inception, Athens began to use the League's navy for its own purposes. This behavior frequently led to conflict between Athens and the less powerful members of the League. By 431 BC, Athens' heavy-handed control of the Delian League prompted the outbreak of the Peloponnesian War; the League was dissolved upon the war's conclusion in 404 BC.
Background.
The Greco-Persian Wars had their roots in the conquest of the Greek cities of Asia Minor, and particularly Ionia, by the Achaemenid Persian Empire of Cyrus the Great shortly after 550 BC. The Persians found the Ionians difficult to rule, eventually settling for sponsoring a tyrant in each Ionian city. While Greek states had in the past often been ruled by tyrants, this was a form of arbitrary government that was on the decline. By 500 BC, Ionia appears to have been ripe for rebellion against these Persian clients. The simmering tension finally broke into open revolt due to the actions of the tyrant of Miletus, Aristagoras. Attempting to save himself after a disastrous Persian-sponsored expedition in 499 BC, Aristagoras chose to declare Miletus a democracy. This triggered similar revolutions across Ionia, extending to Doris and Aeolis, beginning the Ionian Revolt.
The Greek states of Athens and Eretria allowed themselves to be drawn into this conflict by Aristagoras, and during their only campaigning season (498 BC) they contributed to the capture and burning of the Persian regional capital of Sardis. After this, the Ionian revolt carried on (without further outside aid) for a further five years, until it was finally completely crushed by the Persians. However, in a decision of great historic significance, the Persian king Darius the Great decided that, despite successfully subduing the revolt, there remained the unfinished business of exacting punishment on Athens and Eretria for supporting the revolt. The Ionian revolt had severely threatened the stability of Darius's empire, and the states of mainland Greece would continue to threaten that stability unless dealt with. Darius thus began to contemplate the complete conquest of Greece, beginning with the destruction of Athens and Eretria.
In the next two decades there would be two Persian invasions of Greece, occasioning, thanks to Greek historians, some of the most famous battles in history. During the first invasion, Thrace, Macedon and the Aegean Islands were added to the Persian Empire, and Eretria was duly destroyed. However, the invasion ended in 490 BC with the decisive Athenian victory at the Battle of Marathon. Between the two invasions, Darius died, and responsibility for the war passed to his son Xerxes I. 
Xerxes then personally led a second Persian invasion of Greece in 480 BC, taking an enormous (although oft-exaggerated) army and navy to Greece. Those Greeks who chose to resist (the 'Allies') were defeated in the twin simultaneous battles of Thermopylae on land and Artemisium at sea. All of Greece except the Peloponnesus thus having fallen into Persian hands, the Persians then seeking to destroy the Allied navy once and for all, suffered a decisive defeat at the Battle of Salamis. The following year, 479 BC, the Allies assembled the largest Greek army yet seen and defeated the Persian invasion force at the Battle of Plataea, ending the invasion and the threat to Greece.
The Allied fleet defeated the demoralized remnants of the Persian fleet in the Battle of Mycale— on the same day as Plataea, according to tradition. This action marks the end of the Persian invasion, and the beginning of the next phase in the Greco-Persian wars, the Greek counterattack. After Mycale, the Greek cities of Asia Minor again revolted, with the Persians now powerless to stop them. The Allied fleet then sailed to the Thracian Chersonese, still held by the Persians, and besieged and captured the town of Sestos. The following year, 478 BC, the Allies sent a force to capture the city of Byzantion (modern day Istanbul). The siege was successful, but the behaviour of the Spartan general Pausanias alienated many of the Allies, and resulted in Pausanias's recall.
Formation of the League.
After Byzantion, Sparta was eager to end its involvement in the war. The Spartans were of the view that, with the liberation of mainland Greece, and the Greek cities of Asia Minor, the war's purpose had already been reached. There was also perhaps a feeling that establishing long-term security for the Asian Greeks would prove impossible. In the aftermath of Mycale, the Spartan king Leotychides had proposed transplanting all the Greeks from Asia Minor to Europe as the only method of permanently freeing them from Persian dominion.
Xanthippus, the Athenian commander at Mycale, had furiously rejected this; the Ionian cities were originally Athenian colonies, and the Athenians, if no-one else, would protect the Ionians. This marked the point at which the leadership of the Greek alliance effectively passed to the Athenians. With the Spartan withdrawal after Byzantion, the leadership of the Athenians became explicit.
The loose alliance of city states which had fought against Xerxes's invasion had been dominated by Sparta and the Peloponnesian league. With the withdrawal of these states, a congress was called on the holy island of Delos to institute a new alliance to continue the fight against the Persians; hence the modern designation "Delian League". According to Thucydides, the official aim of the League was to "avenge the wrongs they suffered by ravaging the territory of the king." 
In reality, this goal was divided into three main efforts— to prepare for future invasion, to seek revenge against Persia, and to organize a means of dividing spoils of war. The members were given a choice of either offering armed forces or paying a tax to the joint treasury; most states chose the tax. League members swore to have the same friends and enemies, and dropped ingots of iron into the sea to symbolize the permanence of their alliance. The Athenian politician Aristides would spend the rest of his life occupied in the affairs of the alliance, dying (according to Plutarch) a few years later in Pontus, whilst determining what the tax of new members was to be.
Composition and expansion.
In the first ten years of the league's existence, Cimon/Kimon forced Karystos in Euboea to join the league, conquered the island of Skyros and sent Athenian colonists there.
Over time, especially with the suppression of rebellions, Athens exercised hegemony over the rest of the league. Thucydides describes how Athens's control over the League grew: 
 Of all the causes of defection, that connected with arrears of tribute and vessels, and with failure of service, was the chief; for the Athenians were very severe and exacting, and made themselves offensive by applying the screw of necessity to men who were not used to and in fact not disposed for any continuous labor. In some other respects the Athenians were not the old popular rulers they had been at first; and if they had more than their fair share of service, it was correspondingly easy for them to reduce any that tried to leave the confederacy. The Athenians also arranged for the other members of the league to pay its share of the expense in money instead of in ships and men, and for this the subject city-states had themselves to blame, their wish to get out of giving service making most leave their homes. Thus while Athens was increasing her navy with the funds they contributed, a revolt always found itself without enough resources or experienced leaders for war.
Rebellions.
Naxos.
The first member of the league to attempt to secede was the island of Naxos in c. 471 BC. After being defeated, Naxos is believed (based on similar, later revolts) to have been forced to tear down its walls, and lost its fleet and its vote in the League.
Thasos.
In 465 BC, Athens founded the colony of Amphipolis on the Strymon river. Thasos, a member of the League, saw her interests in the mines of Mt. Pangaion threatened and defected from the League to Persia. She called to Sparta for assistance but was denied, as Sparta was facing the largest helot revolution in its history. 
An aftermath of the war was that Cimon was ostracised, and the relations between Athens and Sparta turned hostile. After a three-year siege, Thasos was recaptured and forced back into the League. The siege of Thasos marks the transformation of the Delian league from an alliance into, in the words of Thucydides, a hegemony. 
After two years Thasos surrendered to the Athenian leader Cimon. In result, the fortification walls of Thasos were torn down, their land and naval ships were confiscated by Athens. The mines of Thasos were also turned over to Athens, and they had to pay yearly tribute and fines.
Policies of the League.
In 461 BC, Cimon was ostracized and was succeeded in his influence by democrats such as Ephialtes and Pericles. This signaled a complete change in Athenian foreign policy, neglecting the alliance with the Spartans and instead allying with her enemies, Argos and Thessaly. Megara deserted the Spartan-led Peloponnesian League and allied herself with Athens, allowing construction of a double line of walls across the Isthmus of Corinth and protecting Athens from attack from that quarter. Around the same time, due to encouragement from influential speaker Themistocles, the Athenians also constructed the Long Walls connecting their city to the Piraeus, its port, making it effectively invulnerable to attack by land.
In 454 BC, the Athenian general Pericles moved the Delian League's treasury from Delos to Athens, allegedly to keep it safe from Persia. However, Plutarch indicates that many of Pericles' rivals viewed the transfer to Athens as usurping monetary resources to fund elaborate building projects. Athens also switched from accepting ships, men and weapons as dues from league members, to only accepting money. 
The new treasury established in Athens was used for many purposes, not all relating to the defence of members of the league. It was from tribute paid to the league that Pericles set to building the Parthenon on the Acropolis, replacing an older temple, as well as many other non-defense related expenditures. The Delian League was turning from an alliance into an empire.
Wars against Persia.
War with the Persians continued. In 460 BC, Egypt revolted under local leaders the Hellenes called Inaros and Amyrtaeus, who requested aid from Athens. Pericles led 250 ships, originally intended to attack Cyprus, to their aid because it would further damage Persia. After four years, however, the Egyptian rebellion was defeated by the Achaemenid general Megabyzus, who captured the greater part of the Athenian forces. In fact, according to Isocrates, the Athenians and their allies lost some 20,000 men in the expedition. The remainder escaped to Cyrene and thence returned home.
This was the Athenians' main (public) reason for moving the treasury of the League from Delos to Athens, further consolidating their control over the League. The Persians followed up their victory by sending a fleet to re-establish their control over Cyprus, and 200 ships were sent out to counter them under Cimon, who returned from ostracism in 451 BC. He died during the blockade of Citium, though the fleet won a double victory by land and sea over the Persians off Salamis, Cyprus.
This battle was the last major one fought against the Persians. Many writers report that a peace treaty, known as the Peace of Callias, was formalized in 450 BC, but some writers believe that the treaty was a myth created later to inflate the stature of Athens. However, an understanding was definitely reached, enabling the Athenians to focus their attention on events in Greece proper.
Wars in Greece.
Soon, war with the Peloponnesians broke out. In 458 BC, the Athenians blockaded the island of Aegina, and simultaneously defended Megara from the Corinthians by sending out an army composed of those too young or old for regular military service. The following year, Sparta sent an army into Boeotia, reviving the power of Thebes in order to help hold the Athenians in check. Their return was blocked, and they resolved to march on Athens, where the Long Walls were not yet completed, winning a victory at the Battle of Tanagra. All this accomplished, however, was to allow them to return home via the Megarid. Two months later, the Athenians under Myronides invaded Boeotia, and winning the Battle of Oenophyta gained control of the whole country except Thebes.
Reverses followed peace with Persia in 449 BC. The Battle of Coronea, in 447 BC, led to the abandonment of Boeotia. Euboea and Megara both revolted, and while the former was restored to its status as a tributary ally, the latter was a permanent loss. The Delian and Peloponnesian Leagues signed a peace treaty, which was set to endure for thirty years. It only lasted until 431 BC, when the Peloponnesian War broke out.
Those who revolted unsuccessfully during the war saw the example made of the Mytilenians, the principal people on Lesbos. After an unsuccessful revolt, the Athenians ordered the death of the entire male population. After some thought, they rescinded this order, and only put to death the leading 1000 ringleaders of the revolt, and redistributed the land of the entire island to Athenian shareholders, who were sent out to reside on Lesbos.
This type of treatment was not reserved solely for those who revolted. Thucydides documents the example of Melos, a small island, neutral in the war, though originally founded by Spartans. The Melians were offered a choice to join the Athenians, or be conquered. Choosing to resist, their town was besieged and conquered; the males were put to death and the women sold into slavery (see Melian dialogue).
The Athenian Empire (454–404 BC).
By 454, the Delian League could be fairly characterized as an Athenian Empire; at the start of the Peloponnesian War, only Chios and Lesbos were left to contribute ships, and these states were by now far too weak to secede without support. Lesbos tried to revolt first, and failed completely. Chios, the greatest and most powerful of the original members of the Delian League save Athens, was the last to revolt, and in the aftermath of the Syracusan Expedition enjoyed a success of several years, inspiring all of Ionia to revolt. Athens was eventually still able to suppress these revolts.
To further strengthen Athens' grip on its empire, Pericles in 450 began a policy of establishing "cleruchiai"— quasi-colonies that remained tied to Athens and which served as garrisons to maintain control of the League's vast territory. Furthermore, Pericles employed a number of offices to maintain Athens' empire: "proxenoi", who fostered good relations between Athens and League members; "episkopoi" and "archontes", who oversaw the collection of tribute; and "hellenotamiai", who received the tribute on Athens' behalf.
Athens's empire was not very stable and after only 27 years of war, the Spartans, aided by the Persians and internal strife, were able to defeat it. However, it did not remain defeated long. The Second Athenian Empire, a maritime self-defense league, was founded in 377 BC and was led by Athens. Athens would never recover the full extent of her power, and her enemies were now far stronger and more varied.

</doc>
<doc id="2038" url="http://en.wikipedia.org/wiki?curid=2038" title="August Horch">
August Horch

August Horch (12 October 1868 – 3 February 1951) was a German engineer and automobile pioneer, the founder of the manufacturing giant which would eventually become Audi.
Beginnings.
Horch was born in Winningen, Rhenish Prussia. His initial trade was as a blacksmith, and then was educated at Hochschule Mittweida (Mittweida Technical College). After receiving a degree in engineering, he worked in shipbuilding. Horch worked for Karl Benz from 1896, before founding "A. Horch & Co." in November 1899, in Ehrenfeld, Cologne, Germany.
Manufacturing.
The first Horch automobile was built in 1901. The company moved to Reichenbach in 1902 and Zwickau in 1904. Horch left the company in 1909 after a dispute, and set up in competition in Zwickau. His new firm was initially called "Horch Automobil-Werke GmbH", but following a legal dispute over the "Horch" name, he decided to make another automobile company. (The court decided that "Horch" was a registered trademark on behalf of August Horch's former partners and August Horch was not entitled to use it any more). Consequently, Horch named his new company "Audi Automobilwerke GmbH" in 1910, "Audi" being the Latinization of Horch.
Post Audi.
Horch left Audi in 1920 and went to Berlin and took various jobs. He published his autobiography, "I Built Cars (Ich Baute Autos)" in 1937. He also served on the board of Auto Union, the successor to Audi Automobilwerke GmbH. He was an honorary citizen of Zwickau and had a street named for his Audi cars in both Zwickau and his birthplace Winningen. He was made an honorary professor at Braunschweig University of Technology.

</doc>
<doc id="2039" url="http://en.wikipedia.org/wiki?curid=2039" title="Avionics">
Avionics

Avionics are the electronic systems used on aircraft, artificial satellites, and spacecraft.
Avionic systems include communications, navigation, the display and management of multiple systems, and the hundreds of systems that are fitted to aircraft to perform individual functions. These can be as simple as a searchlight for a police helicopter or as complicated as the tactical system for an airborne early warning platform.
The term "avionics" is a portmanteau of the words "aviation" and "electronics".
History.
The term avionics was coined by journalist Philip J. Klass as a portmanteau of aviation electronics. Many modern avionics have their origins in World War II wartime developments. For example, autopilot systems that are prolific today were started to help bomber planes fly steadily enough to hit precision targets from high altitudes. Famously, radar was developed in the UK, Germany, and the United States during the same period. Modern avionics is a substantial portion of military aircraft spending. Aircraft like the F‑15E and the now retired F‑14 have roughly 20 percent of their budget spent on avionics. Most modern helicopters now have budget splits of 60/40 in favour of avionics. 
The civilian market has also seen a growth in cost of avionics. Flight control systems (fly-by-wire) and new navigation needs brought on by tighter airspaces, have pushed up development costs. The major change has been the recent boom in consumer flying. As more people begin to use planes as their primary method of transportation, more elaborate methods of controlling aircraft safely in these high restrictive airspaces have been invented.
Modern avionics.
Avionics plays a heavy role in modernization initiatives like the Federal Aviation Administration's (FAA) Next Generation Air Transportation System project in the United States and the Single European Sky ATM Research (SESAR) initiative in Europe. The Joint Planning and Development Office put forth a roadmap for avionics in six areas:
Founded in 1957, the Aircraft Electronics Association (AEA) represents more than 1,300 member companies, including government-certified international repair stations specializing in maintenance, repair and installation of avionics and electronic systems in general aviation aircraft. The AEA membership also includes manufacturers of avionics equipment, instrument repair facilities, instrument manufacturers, airframe manufacturers, test equipment manufacturers, major distributors, engineers and educational institutions.
Aircraft avionics.
The cockpit of an aircraft is a typical location for avionic equipment, including control, monitoring, communication, navigation, weather, and anti-collision systems. The majority of aircraft power their avionics using 14- or 28‑volt DC electrical systems; however, larger, more sophisticated aircraft (such as airliners or military combat aircraft) have AC systems operating at 400 Hz, 115 volts AC. There are several major vendors of flight avionics, including Panasonic Avionics Corporation, Honeywell (which now owns Bendix/King), Rockwell Collins, Thales Group, GE Aviation Systems, Garmin, Parker Hannifin, UTC Aerospace Systems and Avidyne Corporation.
One source of international standards for avionics equipment are prepared by the Airlines Electronic Engineering Committee (AEEC) and published by ARINC.
Communications.
Communications connect the flight deck to the ground and the flight deck to the passengers. On‑board communications are provided by public-address systems and aircraft intercoms.
The VHF aviation communication system works on the airband of 118.000 MHz to 136.975 MHz. Each channel is spaced from the adjacent ones by 8.33 kHz in Europe, 25 kHz elsewhere. VHF is also used for line of sight communication such as aircraft-to-aircraft and aircraft-to-ATC. Amplitude modulation (AM) is used, and the conversation is performed in simplex mode. Aircraft communication can also take place using HF (especially for trans-oceanic flights) or satellite communication.
Navigation.
Navigation is the determination of position and direction on or above the surface of the Earth. Avionics can use satellite-based systems (such as GPS and WAAS), ground-based systems (such as VOR or LORAN), or any combination thereof. Navigation systems calculate the position automatically and display it to the flight crew on moving map displays. Older avionics required a pilot or navigator to plot the intersection of signals on a paper map to determine an aircraft's location; modern systems calculate the position automatically and display it to the flight crew on moving map displays.
Monitoring.
 The first hints of glass cockpits emerged in the 1970s when flight-worthy cathode ray tubes (CRT) screens began to replace electromechanical displays, gauges and instruments. A "glass" cockpit refers to the use of computer monitors instead of gauges and other analog displays. Aircraft were getting progressively more displays, dials and information dashboards that eventually competed for space and pilot attention. In the 1970s, the average aircraft had more than 100 cockpit instruments and controls.
Glass cockpits started to come into being with the Gulfstream G‑IV private jet in 1985. One of the key challenges in glass cockpits is to balance how much control is automated and how much the pilot should do manually. Generally they try to automate flight operations while keeping the pilot constantly informed.
Aircraft flight-control systems.
Aircraft have means of automatically controlling flight. Today automated flight control is common to reduce pilot error and workload at key times like landing or takeoff. Autopilot was first invented by Lawrence Sperry during World War II to fly bomber planes steady enough to hit precision targets from 25,000 feet. When it was first adopted by the U.S. military, a Honeywell engineer sat in the back seat with bolt cutters to disconnect the autopilot in case of emergency. Nowadays most commercial planes are equipped with aircraft flight control systems in order to reduce pilot error and workload at landing or takeoff.
The first simple commercial auto-pilots were used to control heading and altitude and had limited authority on things like thrust and flight control surfaces. In helicopters, auto-stabilization was used in a similar way. The first systems were electromechanical. The advent of fly by wire and electro-actuated flight surfaces (rather than the traditional hydraulic) has increased safety. As with displays and instruments, critical devices that were electro-mechanical had a finite life. With safety critical systems, the software is very strictly tested.
Collision-avoidance systems.
To supplement air traffic control, most large transport aircraft and many smaller ones use a traffic alert and collision avoidance system (TCAS), which can detect the location of nearby aircraft, and provide instructions for avoiding a midair collision. Smaller aircraft may use simpler traffic alerting systems such as TPAS, which are passive (they do not actively interrogate the transponders of other aircraft) and do not provide advisories for conflict resolution.
To help avoid controlled flight into terrain (CFIT), aircraft use systems such as ground-proximity warning systems (GPWS), which use radar altimeters as a key element. One of the major weaknesses of GPWS is the lack of "look-ahead" information, because it only provides altitude above terrain "look-down". In order to overcome this weakness, modern aircraft use a terrain awareness warning system (TAWS).
Black Boxes.
Commercial aircraft cockpit data recorders, commonly known as a "black box", store flight information and audio from the cockpit. They are often recovered from a plane after a crash to determine control settings and other parameters during the incident.
Weather systems.
Weather systems such as weather radar (typically Arinc 708 on commercial aircraft) and lightning detectors are important for aircraft flying at night or in instrument meteorological conditions, where it is not possible for pilots to see the weather ahead. Heavy precipitation (as sensed by radar) or severe turbulence (as sensed by lightning activity) are both indications of strong convective activity and severe turbulence, and weather systems allow pilots to deviate around these areas.
Lightning detectors like the Stormscope or Strikefinder have become inexpensive enough that they are practical for light aircraft. In addition to radar and lightning detection, observations and extended radar pictures (such as NEXRAD) are now available through satellite data connections, allowing pilots to see weather conditions far beyond the range of their own in-flight systems. Modern displays allow weather information to be integrated with moving maps, terrain, and traffic onto a single screen, greatly simplifying navigation.
Modern weather systems also include wind shear and turbulence detection and terrain and traffic warning systems. In‑plane weather avionics are especially popular in Africa, India, and other countries where air-travel is a growing market, but ground support is not as well developed.
Aircraft management systems.
There has been a progression towards centralized control of the multiple complex systems fitted to aircraft, including engine monitoring and management. Health and usaproposes an integrated architecture with application software portable across an assembly of common hardware modules. It has been used in fourth generation jet fighters and the latest generation of airliners.
Mission or tactical avionics.
Military aircraft have been designed either to deliver a weapon or to be the eyes and ears of other weapon systems. The vast array of sensors available to the military is used for whatever tactical means required. As with aircraft management, the bigger sensor platforms (like the E‑3D, JSTARS, ASTOR, Nimrod MRA4, Merlin HM Mk 1) have mission-management computers.
Police and EMS aircraft also carry sophisticated tactical sensors.
Military communications.
While aircraft communications provide the backbone for safe flight, the tactical systems are designed to withstand the rigors of the battle field. UHF, VHF Tactical (30–88 MHz) and SatCom systems combined with ECCM methods, and cryptography secure the communications. Data links such as Link 11, 16, 22 and BOWMAN, JTRS and even TETRA provide the means of transmitting data (such as images, targeting information etc.).
Radar.
Airborne radar was one of the first tactical sensors. The benefit of altitude providing range has meant a significant focus on airborne radar technologies. Radars include airborne early warning (AEW), anti-submarine warfare (ASW), and even weather radar (Arinc 708) and ground tracking/proximity radar.
The military uses radar in fast jets to help pilots fly at low levels. While the civil market has had weather radar for a while, there are strict rules about using it to navigate the aircraft.
Sonar.
Dipping sonar fitted to a range of military helicopters allows the helicopter to protect shipping assets from submarines or surface threats. Maritime support aircraft can drop active and passive sonar devices (sonobuoys) and these are also used to determine the location of hostile submarines.
Electro-Optics.
Electro-optic systems include devices such as the head-up display (HUD), forward looking infrared (FLIR), and passive infrared devices (Passive infrared sensor). These are all used to provide imagery and information to the flight crew. This imagery is used for everything from search and rescue to navigational aids and target acquisition.
ESM/DAS.
Electronic support measures and defensive aids are used extensively to gather information about threats or possible threats. They can be used to launch devices (in some cases automatically) to counter direct threats against the aircraft. They are also used to determine the state of a threat and identify it.
Aircraft networks.
The avionics systems in military, commercial and advanced models of civilian aircraft are interconnected using an avionics databus. Common avionics databus protocols, with their primary application, include:
Disaster relief and air ambulance.
Disaster relief and EMS aircraft (mostly helicopters) are now a significant market. Military aircraft are often now built with a role available to assist in civil obedience. Disaster relief helicopters are almost always fitted with video/FLIR systems to allow them to monitor and coordinate real-time relief efforts. They can also be fitted with searchlights and loudspeakers.
EMS and disaster relief helicopters will be required to fly in unpleasant conditions, this may require more aircraft sensors, some of which were until recently considered purely for military aircraft.

</doc>
<doc id="2041" url="http://en.wikipedia.org/wiki?curid=2041" title="Ares">
Ares

Ares ( ) is the Greek god of war. He is one of the Twelve Olympians, and the son of Zeus and Hera. In Greek literature, he often represents the physical or violent and untamed aspect of war, in contrast to the armored Athena, whose functions as a goddess of intelligence include military strategy and generalship.
The Greeks were toward Ares: although he embodied the physical valor necessary for success in war, he was a dangerous force, "overwhelming, insatiable in battle, destructive, and man-slaughtering." His sons Fear "(Phobos)" and Terror "(Deimos)" and his lover, or sister, Discord "(Enyo)" accompanied him on his war chariot. In the "Iliad," his father Zeus tells him that he is the god most hateful to him. An association with Ares endows places and objects with a savage, dangerous, or militarized quality. His value as a war god is placed in doubt: during the Trojan War, Ares was on the losing side, while Athena, often depicted in Greek art as holding Nike (Victory) in her hand, favored the triumphant Greeks.
Ares plays a relatively limited role in Greek mythology as represented in literary narratives, though his numerous love affairs and abundant offspring are often alluded to. When Ares does appear in myths, he typically faces humiliation. He is well known as the lover of Aphrodite, the goddess of love, who was married to Hephaestus, god of craftsmanship. The most famous story related to Ares and Aphrodite shows them exposed to ridicule through the wronged husband's clever device.
The counterpart of Ares among the Roman gods is Mars, who as a father of the Roman people was given a more important and dignified place in ancient Roman religion as a guardian deity. During the Hellenization of Latin literature, the myths of Ares were reinterpreted by Roman writers under the name of Mars. Greek writers under Roman rule also recorded cult practices and beliefs pertaining to Mars under the name of Ares. Thus in the classical tradition of later Western art and literature, the mythology of the two figures becomes virtually indistinguishable.
Names and epithets.
The etymology of the name "Ares" is traditionally connected with the Greek word ("arē"), the Ionic form of the Doric ("ara"), "bane, ruin, curse, imprecation". There may also be a connection with the Roman god of war Mars, via hypothetical Proto-Indo-European *"M̥rēs"; compare Ancient Greek μάρναμαι ("marnamai"), "I fight, I battle". Walter Burkert notes that "Ares is apparently an ancient abstract noun meaning throng of battle, war." R. S. P. Beekes has suggested a Pre-Greek origin of the name.
The earliest attested form of the name is the Mycenaean Greek , "a-re", written in the Linear B syllabic script.
The adjectival epithet, "Areios," was frequently appended to the names of other gods when they took on a warrior aspect or became involved in warfare: "Zeus Areios", "Athena Areia", even "Aphrodite Areia". In the "Iliad", the word "ares" is used as a common noun synonymous with "battle."
Inscriptions as early as Mycenaean times, and continuing into the Classical period, attest to Enyalios as another name for the god of war.
Character, origins, and worship.
Ares was one of the Twelve Olympians in the archaic tradition represented by the "Iliad" and "Odyssey." Zeus expresses a recurring Greek revulsion toward the god when Ares returns wounded and complaining from the battlefield at Troy:
Then looking at him darkly Zeus who gathers the clouds spoke to him:<br>'Do not sit beside me and whine, you double-faced liar.<br>To me you are the most hateful of all gods who hold Olympos.<br>Forever quarrelling is dear to your heart, wars and battles.<br>…<br>And yet I will not long endure to see you in pain, since<br>you are my child, and it was to me that your mother bore you.<br>But were you born of some other god and proved so ruinous<br>long since you would have been dropped beneath the gods of the bright sky."
This ambivalence is expressed also in the Greeks' association of the god with the Thracians, whom they regarded as a barbarous and warlike people. Thrace was Ares' birthplace, his true home, and his refuge after the affair with Aphrodite was exposed to the general mockery of the other gods.
A late-6th-century BC funerary inscription from Attica emphasizes the consequences of coming under Ares' sway:
Stay and mourn at the tomb of dead Kroisos<br>Whom raging Ares destroyed one day, fighting in the foremost ranks.
Ares in Sparta.
In Sparta, Ares was viewed as a masculine soldier: his resilience, physical strength, and military intelligence were unrivaled. Human sacrifices were offered to him. Also, an ancient statue, representing the god in chains, suggested that the martial spirit and victory were to be kept in the city of Sparta.
Ares in the Arabian Peninsula.
Ares was also worshipped by the inhabitants of Tylos. It is not known if he was worshipped in the form of an Arabian god (and which one) or if he was worshipped in his Greek form.
Attributes.
The birds of Ares ("Ornithes Areioi") were a flock of feather-dart-dropping birds that guarded the Amazons' shrine of the god on a coastal island in the Black Sea.
Cult and ritual.
Although Ares received occasional sacrifice from armies going to war, the god had a formal temple and cult at only a few sites. At Sparta, however, each company of youths sacrificed a puppy to Enyalios before engaging in ritual fighting at the Phoebaeum. The chthonic night-time sacrifice of a dog to Enyalios became assimilated to the cult of Ares.
Just east of Sparta stood an archaic statue of the god in chains, to show that the spirit of war and victory was to be kept in the city.
The temple to Ares in the agora of Athens, which Pausanias saw in the second century AD, had been moved and rededicated there during the time of Augustus. Essentially it was a Roman temple to the Augustan Mars Ultor. From archaic times, the Areopagus, the "mount of Ares" at some distance from the Acropolis, was a site of trials. Paul of Tarsus later preached about Christianity there. Its connection with Ares, perhaps based on a false etymology, is etiological myth. A second temple to Ares has been located at the archaeological site of Metropolis in what is now Western Turkey.
Attendants.
Deimos, "Terror" or "Dread", and Phobos, "Fear" or "Horror", are his companions in war. According to Hesiod, they were also his children, borne by Aphrodite. Eris, the goddess of discord, or Enyo, the goddess of war, bloodshed, and violence, was considered the sister and companion of the violent Ares. In at least one tradition, Enyalius, rather than another name for Ares, was his son by Enyo.
Ares may also be accompanied by Kydoimos, the demon of the din of battle; the Makhai ("Battles"); the "Hysminai" ("Acts of manslaughter"); Polemos, a minor spirit of war, or only an epithet of Ares, since it has no specific dominion; and Polemos's daughter, Alala, the goddess or personification of the Greek war-cry, whose name Ares uses as his own war-cry. Ares's sister Hebe ("Youth") also draws baths for him.
According to Pausanias, local inhabitants of Therapne, Sparta, recognized Thero, "feral, savage," as a nurse of Ares.
Founding of Thebes.
One of the roles of Ares was expressed in mainland Greece as the founding myth of Thebes: Ares was the progenitor of the water-dragon slain by Cadmus, for the dragon's teeth were sown into the ground as if a crop and sprang up as the fully armored autochthonic Spartoi. To propitiate Ares, Cadmus took as a bride Harmonia, a daughter of Ares' union with Aphrodite. In this way, Cadmus harmonized all strife and founded the city of Thebes.
Consorts and children.
The union of Ares and Aphrodite created the gods Eros, Anteros, Phobos, Deimos, Harmonia, and Adrestia. While Eros and Anteros' godly stations favored their mother, Adrestia preferred to emulate her father, often accompanying him to war. Other versions include Alcippe as one of his daughters.
Upon one occasion, Ares incurred the anger of Poseidon by slaying his son Halirrhothius, who had raped Alcippe, a daughter of the war-god. For this deed, Poseidon summoned Ares to appear before the tribunal of the Olympic gods, which was held upon a hill in Athens. Ares was acquitted. This event is supposed to have given rise to the name Areopagus (or Hill of Ares), which afterward became famous as the site of a court of justice.
Accounts tell of Cycnus (Κύκνος) of Macedonia, a son of Ares who was so murderous that he tried to build a temple with the skulls and the bones of travellers. Heracles slaughtered this abominable monstrosity, engendering the wrath of Ares, whom the hero wounded in conflict.
Other accounts.
In the tale sung by the bard in the hall of Alcinous, the Sun-god Helios once spied Ares and Aphrodite enjoying each other secretly in the hall of Hephaestus, her husband. He reported the incident to Hephaestus. Contriving to catch the illicit couple in the act, Hephaestus fashioned a finely-knitted and nearly invisible net with which to snare them. At the appropriate time, this net was sprung, and trapped Ares and Aphrodite locked in very private embrace.
But Hephaestus was not satisfied with his revenge, so he invited the Olympian gods and goddesses to view the unfortunate pair. For the sake of modesty, the goddesses demurred, but the male gods went to witness the sight. Some commented on the beauty of Aphrodite, others remarked that they would eagerly trade places with Ares, but all who were present mocked the two. Once the couple were loosed, Ares, embarrassed, returned to his homeland, Thrace, and Aphrodite went to Paphos.
In a much later interpolated detail, Ares put the youth Alectryon by his door to warn them of Helios' arrival, as Helios would tell Hephaestus of Aphrodite's infidelity if the two were discovered, but Alectryon fell asleep. Helios discovered the two and alerted Hephaestus. Furious Ares turned the sleepy Alectryon into a rooster, which now always announces the arrival of the sun in the morning.
Ares and the giants.
In one archaic myth, related only in the "Iliad" by the goddess Dione to her daughter Aphrodite, two chthonic giants, the Aloadae, named Otus and Ephialtes, threw Ares into chains and put him in a bronze urn, where he remained for thirteen months, a lunar year. "And that would have been the end of Ares and his appetite for war, if the beautiful Eriboea, the young giants' stepmother, had not told Hermes what they had done," she related. "In this one suspects a festival of licence which is unleashed in the thirteenth month."
Ares was held screaming and howling in the urn until Hermes rescued him, and Artemis tricked the Aloadae into slaying each other. In Nonnus' "Dionysiaca" Ares also killed Ekhidnades, the giant son of Echidna, and a great enemy of the gods. Scholars have not concluded whether the nameless Ekhidnades ("of Echidna's lineage") was entirely Nonnus' invention or not. 
Iliad.
In the "Iliad", Homer represented Ares as having no fixed allegiances, rewarding courage on both sides: he promised Athena and Hera that he would fight on the side of the Achaeans ("Iliad" V.830–834, XXI.410–414), but Aphrodite persuaded Ares to side with the Trojans. During the war, Diomedes fought with Hector and saw Ares fighting on the Trojans' side. Diomedes called for his soldiers to fall back slowly (V.590–605).
Athene, or Athena, Ares's sister, saw his interference and asked Zeus, his father, for permission to drive Ares away from the battlefield, which Zeus granted (V.711–769). Hera and Athena encouraged Diomedes to attack Ares (V.780–834). Diomedes thrust with his spear at Ares, with Athena driving it home, and Ares' cries made Achaeans and Trojans alike tremble (V.855–864). Ares fled to Mt. Olympus, forcing the Trojans to fall back.
When Hera mentioned to Zeus that Ares' son, Ascalaphus, was killed, Ares overheard and wanted to join the fight on the side of the Achaeans, disregarding Zeus' order that no Olympic god should enter the battle, but Athena stopped him (XV.110–128). Later, when Zeus allowed the gods to fight in the war again (XX.20–29), Ares was the first to act, attacking Athena to avenge himself for his previous injury. Athena overpowered him by striking Ares with a boulder (XXI.391–408).
Renaissance.
In Renaissance and Neoclassical works of art, Ares' symbols are a spear and helmet, his animal is a dog, and his bird is the vulture. In literary works of these eras, Ares is replaced by the Roman Mars, a romantic emblem of manly valor rather than the cruel and blood-thirsty god of Greek mythology.
In popular culture.
Ares figures in war-themed video games and in popular fictions.
NASA named their transport ship as "Ares", which replaced the Space Shuttle. This was an extension of NASA's practice of using Roman and Greek names for their rockets and programs: "Saturn" for manned rockets, "Mercury" for a satellite program, and the Apollo program, rather than any association with the nature of the war god.

</doc>
<doc id="2042" url="http://en.wikipedia.org/wiki?curid=2042" title="Alexander Grothendieck">
Alexander Grothendieck

Alexander Grothendieck (; ; born 28 March 1928) is a French mathematician, born in Germany, raised and living primarily in France, and who spent much of his working life stateless, who is the central figure behind the creation of the modern theory of algebraic geometry. His research program vastly extended the scope of the field, incorporating major elements of commutative algebra, homological algebra, sheaf theory, and category theory into its foundations. This new perspective led to revolutionary advances across many areas of pure mathematics. He consistently spelt his first name "Alexand"er"" rather than the French "Alexand"re""; his family name, "Grothendieck" (from his mother) is Low German, which is similar to Dutch, hence he is sometimes mistakenly believed to be of Dutch origin.
After a very productive public mathematical career lasting 1949–1970, particularly 1958–1970 (when he was at IHES), Grothendieck largely ceased mathematical activity after 1970 (age 42), though with some private work 1970–1988. Driven by deep personal and political convictions, Grothendieck left the Institut des Hautes Études Scientifiques, where he had been appointed professor and accomplished his greatest work, after a dispute over military funding in 1970. His mathematical activity essentially ceased after this, and he devoted his energies to political causes, though he did produce some mathematical work privately. He formally retired in 1988 and within a few years moved to the Pyrenees, where he currently lives in isolation from human society.
Influence.
Within algebraic geometry itself, his theory of schemes is used in technical work. His generalization of the classical Riemann-Roch theorem started the study of algebraic and topological K-theory. His construction of new cohomology theories has left consequences for algebraic number theory, algebraic topology, and representation theory. His creation of topos theory has appeared in set theory and logic.
One of his results is the discovery of the first arithmetic Weil cohomology theory: the ℓ-adic étale cohomology. This result opened the way for a proof of the Weil conjectures, ultimately completed by his student Pierre Deligne. To this day, ℓ-adic cohomology remains a fundamental tool for number theorists, with applications to the Langlands program.
Grothendieck’s way of thinking has influenced generations of mathematicians long after his departure from mathematics. His emphasis on the role of universal properties brought category theory into the mainstream as an important organizing principle. His notion of abelian category is now the basic object of study in homological algebra. His conjectural theory of motives has been a driving force behind modern developments in algebraic K-theory, motivic homotopy theory, and motivic integration.
Life.
Family and childhood.
Alexander Grothendieck was born in Berlin to anarchist parents: a father from an originally Hassidic family, Alexander "Sascha" Schapiro aka Tanaroff, who had been imprisoned in Russia and moved to Germany in 1922, and a mother from a Protestant family in Hamburg, Johanna "Hanka" Grothendieck, who worked as a journalist; both of his parents had broken away from their early backgrounds in their teens. At the time of his birth Grothendieck's mother was married to the journalist Johannes Raddatz, and his birthname was initially recorded as "Alexander Raddatz". The marriage was dissolved in 1929 and Schapiro/Tanaroff acknowledged his paternity, but never married Hanka Grothendieck.
Grothendieck lived with his parents until 1933 in Berlin. At the end of that year, Schapiro moved to Paris to evade the Nazis, and Hanka followed him the next year. They left Grothendieck in the care of Wilhelm Heydorn, a Lutheran Pastor and teacher in Hamburg where he went to school. During this time, his parents took part in the Spanish Civil War in supporting rather than fighting roles. Grothendieck could speak French, English and German.
World War II.
In 1939 Grothendieck went to France and lived in various camps for displaced persons with his mother. They lived first at the Camp de Rieucros, and later, for the remainder of World War II, in the village of Le Chambon-sur-Lignon. There he was sheltered and hidden in local boarding-houses or pensions. His father was arrested and sent via Drancy to the Auschwitz concentration camp, where he died in 1942. In Chambon, Grothendieck attended the Collège Cévenol (now known as the Le Collège-Lycée Cévenol International), a unique secondary school founded in 1938 by local Protestant pacifists and anti-war activists. Many of the refugee children hidden in Chambon attended Cévenol, and it was at this school that Grothendieck apparently first became fascinated with mathematics.
Studies and contact with research mathematics.
After the war, the young Grothendieck studied mathematics in France, initially at the University of Montpellier where he did not initially perform well, flunking such classes as astronomy. Working on his own, he rediscovered the Lebesgue measure. After three years of increasingly independent studies there he went to continue his studies in Paris in 1948.
Initially, Grothendieck attended Henri Cartan's Seminar at École Normale Supérieure, but lacked the necessary background to follow the high-powered seminar. On the advice of Cartan and Weil, he moved to the University of Nancy where he wrote his dissertation under Laurent Schwartz in functional analysis, from 1950 to 1953. At this time he was a leading expert in the theory of topological vector spaces. By 1957, he set this subject aside in order to work in algebraic geometry and homological algebra.
The IHÉS years.
Installed at the Institut des Hautes Études Scientifiques (IHÉS) in 1958, Grothendieck attracted attention by an intense and highly productive activity of seminars ("de facto" working groups drafting into foundational work some of the ablest French and other mathematicians of the younger generation). Grothendieck himself practically ceased publication of papers through the conventional, learned journal route. He was, however, able to play a dominant role in mathematics for around a decade, gathering a strong school.
During this time he had officially as students Michel Demazure (who worked on SGA3, on group schemes), Luc Illusie (cotangent complex), Michel Raynaud, Jean-Louis Verdier (cofounder of the derived category theory) and Pierre Deligne. Collaborators on the SGA projects also included Mike Artin (étale cohomology) and Nick Katz (monodromy theory and Lefschetz pencils). Jean Giraud worked out torsor theory extensions of non-abelian cohomology. Many others were involved.
The "Golden Age".
Alexander Grothendieck's work during the "Golden Age" period at IHÉS established several unifying themes in algebraic geometry, number theory, topology, category theory and complex analysis. His first (pre-IHÉS) breakthrough in algebraic geometry was the Grothendieck–Hirzebruch–Riemann–Roch theorem, a far-reaching generalisation of the Hirzebruch–Riemann–Roch theorem proved algebraically; in this context he also introduced K-theory. Then, following the programme he outlined in his talk at the 1958 International Congress of Mathematicians, he introduced the theory of schemes, developing it in detail in his Éléments de géométrie algébrique (EGA) and providing the new more flexible and general foundations for algebraic geometry that has been adopted in the field since that time. He went on to introduce the étale cohomology theory of schemes, providing the key tools for proving the Weil conjectures, as well as crystalline cohomology and algebraic de Rham cohomology to complement it. Closely linked to these cohomology theories, he originated topos theory as a generalisation of topology (relevant also in categorical logic). He also provided an algebraic definition of fundamental groups of schemes and more generally the main structures of a categorical Galois theory. As a framework for his coherent duality theory he also introduced derived categories, which were further developed by Verdier.
The results of work on these and other topics were published in the EGA and in less polished form in the notes of the Séminaire de géométrie algébrique (SGA) that he directed at IHES.
Politics and retreat from scientific community.
Grothendieck's political views were radical and pacifist. Thus, he strongly opposed both United States intervention in Vietnam and Soviet military expansionism. He gave lectures on category theory in the forests surrounding Hanoi while the city was being bombed, to protest against the Vietnam War. He retired from scientific life around 1970, after having discovered the partly military funding of IHÉS. He returned to academia a few years later as a professor at the University of Montpellier, where he stayed until his retirement in 1988. His criticisms of the scientific community, and especially of several mathematics circles, are also contained in a letter, written in 1988, in which he states the reasons for his refusal of the Crafoord Prize. He declined the prize on ethical grounds in an open letter to the media.
While the issue of military funding was perhaps the most obvious explanation for Grothendieck's departure from IHÉS, those who knew him say that the causes of the rupture ran deeper. Pierre Cartier, a "visiteur de longue durée" ("long-term guest") at the IHÉS, wrote a piece about Grothendieck for a special volume published on the occasion of the IHÉS's fortieth anniversary. The "Grothendieck Festschrift" was a three-volume collection of research papers to mark his sixtieth birthday (falling in 1988), and published in 1990.
In it Cartier notes that, as the son of an antimilitary anarchist and one who grew up among the disenfranchised, Grothendieck always had a deep compassion for the poor and the downtrodden. As Cartier puts it, Grothendieck came to find Bures-sur-Yvette "une cage dorée" ("a golden cage"). While Grothendieck was at the IHÉS, opposition to the Vietnam War was heating up, and Cartier suggests that this also reinforced Grothendieck's distaste at having become a mandarin of the scientific world. In addition, after several years at the IHÉS Grothendieck seemed to cast about for new intellectual interests. By the late 1960s he had started to become interested in scientific areas outside mathematics. David Ruelle, a physicist who joined the IHÉS faculty in 1964, said that Grothendieck came to talk to him a few times about physics. (In the 1970s Ruelle and the Dutch mathematician Floris Takens produced a new model for turbulence, and it was Ruelle who invented the concept of a strange attractor in a dynamical system.) Biology interested Grothendieck much more than physics, and he organized some seminars on biological topics.
In 1970, Grothendieck, with two other mathematicians, Claude Chevalley and Pierre Samuel, created a political group called Survivre—the name later changed to Survivre et vivre. Survivre et vivre was dedicated to antimilitary and ecological issues, and also developed strong criticism of the indiscriminate use of science and technology.
After leaving the IHÉS, Grothendieck became a temporary professor at Collège de France for two years. A permanent position became open at the end of his tenure, but the application Grothendieck submitted made it clear that he had no plans to continue his mathematical research. The position was given to Jacques Tits.
He then went to Université de Montpellier, where he became increasingly estranged from the mathematical community. His mathematical career, for the most part, ended when he left the IHÉS.
Manuscripts written in the 1980s.
While not publishing mathematical research in conventional ways during the 1980s, he produced several influential manuscripts with limited distribution, with both mathematical and biographical content.
"La Longue Marche à travers la théorie de Galois" "The Long March Through Galois Theory" is an approximately 1600-page handwritten manuscript produced by Grothendieck during the years 1980–1981, containing many of the ideas leading to the "Esquisse d'un programme" (see below, and also a more detailed entry), and in particular studying the Teichmüller theory.
In 1983 he wrote an extended manuscript (about 600 pages) entitled "Pursuing Stacks", stimulated by correspondence with Ronald Brown, (see also and Tim Porter at University of Bangor in Wales), and starting with a letter addressed to Daniel Quillen. This letter and successive parts were distributed from Bangor (see External Links below): in an informal manner, as a kind of diary, Grothendieck explained and developed his ideas on the relationship between algebraic homotopy theory and algebraic geometry and prospects for a noncommutative theory of stacks. The manuscript, which is being edited for publication by G. Maltsiniotis, later led to another of his monumental works, "Les Dérivateurs". Written in 1991, this latter opus of about 2000 pages further developed the homotopical ideas begun in "Pursuing Stacks". Much of this work anticipated the subsequent development of the motivic homotopy theory of Fabien Morel and V. Voevodsky in the mid-1990s.
In 1984 he wrote a proposal to get a position through the Centre National de la Recherche Scientifique, which he held from 1984 to his retirement in 1988. The proposal, entitled "Esquisse d'un Programme" ("Program Sketch") describes new ideas for studying the moduli space of complex curves. Although Grothendieck himself never published his work in this area, the proposal became the inspiration for work by other mathematicians and the source of the theory of dessins d'enfants and of a new field emerging as anabelian geometry. "Esquisse d’un Programme" was published in the two-volume proceedings Geometric Galois Actions (Cambridge University Press, 1997).
During this period he also released his work on Bertini type theorems contained in EGA 5, published by the in 2004.
The 1000-page autobiographical manuscript "Récoltes et semailles" (1986) is now available on the internet in the French original, and an English translation is underway (these parts of Récoltes et semailles have already been translated into Russian and published in Moscow). Some parts of "Récoltes et semailles" and the whole "La Clef des Songes" have been translated into Spanish and Russian.
In the manuscript "La Clef des Songes" he explains how considering the source of dreams led him to conclude that God exists. His growing preoccupation with spiritual matters was also evident in a letter entitled "Lettre de la Bonne Nouvelle" that he sent to 250 friends in January 1990. In it, he described his encounters with a deity and announced that a "New Age" would commence on 14 October 1996.
Over 20,000 pages of mathematical and other writings remain unpublished at the University of Montpellier.
Retirement into reclusion.
Grothendieck was co-awarded (but declined) the Crafoord Prize with Pierre Deligne in 1988.
In 1991, Grothendieck moved to an address he did not provide to his previous contacts in the mathematical community. He is now said to live in southern France or Andorra and to be reclusive.
In January 2010, Grothendieck wrote a letter to Luc Illusie. In this "Déclaration d'intention de non-publication", he states that essentially all materials that have been published in his absence have been done without his permission. He asks that none of his work should be reproduced in whole or in part, and even further that libraries containing such copies of his work remove them. A website devoted to his work was called "an abomination". This order may have been reversed later in 2010.
Citizenship.
Grothendieck was born in Germany (1928), and moved to France as a refugee at age 10 (1938). Records of his nationality were destroyed in the fall of Germany in 1945, and he did not apply for French citizenship after the war, thus being a stateless person for the majority of his working life, traveling on a Nansen passport. He later became naturalized as a French citizen in the 1980s. Part of this reluctance to hold French nationality is attributed to not wishing to serve in the French military, particularly due to the Algerian War (1954–62).
Mathematical achievements.
Grothendieck's early mathematical work was in functional analysis. Between 1949 and 1953 he worked on his doctoral thesis in this subject at Nancy, supervised by Jean Dieudonné and Laurent Schwartz. His key contributions include topological tensor products of topological vector spaces, the theory of nuclear spaces as foundational for Schwartz distributions, and the application of Lp spaces in studying linear maps between topological vector spaces. In a few years, he had turned himself into a leading authority on this area of functional analysis — to the extent that Dieudonné compares his impact in this field to that of Banach.
It is, however, in algebraic geometry and related fields where Grothendieck did his most important and influential work. From about 1955 he started to work on sheaf theory and homological algebra, producing the influential "Tôhoku paper" ("Sur quelques points d'algèbre homologique", published in the Tohoku Mathematical Journal in 1957) where he introduced Abelian categories and applied their theory to show that sheaf cohomology can be defined as certain derived functors in this context.
Homological methods and sheaf theory had already been introduced in algebraic geometry by Jean-Pierre Serre and others, after sheaves had been defined by Jean Leray. Grothendieck took them to a higher level of abstraction and turned them into a key organising principle of his theory. He shifted attention from the study of individual varieties to the "relative point of view" (pairs of varieties related by a morphism), allowing a broad generalization of many classical theorems. The first major application was the relative version of Serre's theorem showing that the cohomology of a coherent sheaf on a complete variety is finite-dimensional; Grothendieck's theorem shows that the higher direct images of coherent sheaves under a proper map are coherent; this reduces to Serre's theorem over a one-point space.
In 1956, he applied the same thinking to the Riemann–Roch theorem, which had already recently been generalized to any dimension by Hirzebruch. The Grothendieck–Riemann–Roch theorem was announced by Grothendieck at the initial Mathematische Arbeitstagung in Bonn, in 1957. It appeared in print in a paper written by Armand Borel with Serre. This result was his first major achievement in algebraic geometry. He went on to plan and execute a major foundational programme for rebuilding the foundations of algebraic geometry, which were then in a state of flux and under discussion in Claude Chevalley's seminar; he outlined his programme in his talk at the 1958 International Congress of Mathematicians.
His foundational work on algebraic geometry is at a higher level of abstraction than all prior versions. He adapted the use of non-closed generic points, which led to the theory of schemes. He also pioneered the systematic use of nilpotents. As 'functions' these can take only the value 0, but they carry infinitesimal information, in purely algebraic settings. His "theory of schemes" has become established as the best universal foundation for this major field, because of its great expressive power as well as technical depth. In that setting one can use birational geometry, techniques from number theory, Galois theory and commutative algebra, and close analogues of the methods of algebraic topology, all in an integrated way.
He is also noted for his mastery of abstract approaches to mathematics and his perfectionism in matters of formulation and presentation. Relatively little of his work after 1960 was published by the conventional route of the learned journal, circulating initially in duplicated volumes of seminar notes; his influence was to a considerable extent personal. His influence spilled over into many other branches of mathematics, for example the contemporary theory of D-modules. (It also provoked adverse reactions, with many mathematicians seeking out more concrete areas and problems.)
EGA and SGA.
The bulk of Grothendieck's published work is collected in the monumental, and yet incomplete, "Éléments de géométrie algébrique" (EGA) and "Séminaire de géométrie algébrique" (SGA). The collection "Fondements de la Géometrie Algébrique" (FGA), which gathers together talks given in the Séminaire Bourbaki, also contains important material.
Perhaps Grothendieck's deepest single accomplishment is the invention of the étale and l-adic cohomology theories, which explain an observation of André Weil's that there is a deep connection between the topological characteristics of a variety and its diophantine (number theoretic) properties. For example, the number of solutions of an equation over a finite field reflects the topological nature of its solutions over the complex numbers. Weil realized that to prove such a connection one needed a new cohomology theory, but neither he nor any other expert saw how to do this until such a theory was found by Grothendieck.
This program culminated in the proofs of the Weil conjectures, the last of which was settled by Grothendieck's student Pierre Deligne in the early 1970s after Grothendieck had largely withdrawn from mathematics.
Major mathematical topics (from "Récoltes et Semailles").
He wrote a retrospective assessment of his mathematical work (see the external link "La Vision" below). As his main mathematical achievements ("maître-thèmes"), he chose this collection of 12 topics (his chronological order):
He wrote that the central theme of the topics above is that of topos theory, while the first and last were of the least importance to him.
Here the term "yoga" denotes a kind of "meta-theory" that can be used heuristically; Michel Raynaud writes the other terms "Ariadne's thread" and "philosophy" as effective equivalents.

</doc>
<doc id="2047" url="http://en.wikipedia.org/wiki?curid=2047" title="Alcoholics Anonymous">
Alcoholics Anonymous

Alcoholics Anonymous (AA) is an international mutual aid fellowship founded in 1935 by Bill Wilson and Dr. Bob Smith in Akron, Ohio. AA states that its primary purpose is "to stay sober and help other alcoholics achieve sobriety". With other early members Wilson and Smith developed AA's Twelve Step program of spiritual and character development. AA's Twelve Traditions were introduced in 1946 to help the fellowship be stable and unified while disengaged from "outside issues" and influences. The Traditions recommend that members and groups remain anonymous in public media, altruistically helping other alcoholics and avoiding affiliations with any other organization. The Traditions also recommend that those representing AA avoid dogma and coercive hierarchies. Subsequent fellowships such as Narcotics Anonymous have adopted and adapted the Twelve Steps and the Twelve Traditions to their respective primary purposes.
AA has no opinion on the medical nature of alcoholism; nonetheless, AA is regarded as a proponent and popularizer of the disease theory of alcoholism. AA is credited with helping many alcoholics achieve and maintain sobriety.
The American Psychiatric Association has recommended sustained treatment in conjunction with AA's program, or similar community resources, for chronic alcoholics unresponsive to brief treatment. AA's data show that 36% are still attending AA a year after their first meetings.
The first female member, Florence Rankin, joined AA in March 1937, and the first non-Protestant member, a Roman Catholic, joined in 1939. AA membership has since spread "across diverse cultures holding different beliefs and values", including geopolitical areas resistant to grassroots movements. In the Fourth Edition of Alcoholics Anonymous (November 2001), it states "Since the third edition was published in 1976, worldwide membership of AA has just about doubled, to an estimated two million or more..." 
AA's name is derived from its first book, informally called "The Big Book", originally titled "Alcoholics Anonymous: The Story of How More Than One Hundred Men Have Recovered From Alcoholism".
Oxford Group origins.
AA sprang from The Oxford Group, a non-denominational movement modeled after first-century Christianity. Some members found the Group to help in maintaining sobriety. One such "Grouper", as they were called, was Ebby Thacher, Wilson's former drinking buddy and his acknowledged sponsor. Following the evangelical bent of the Group, Thacher told Wilson that he had "got religion" and was sober, and that Wilson could do the same if he set aside objections to religion and instead formed a personal idea of God, "another power" or "higher power".
Wilson felt with Thacher a "kinship of common suffering" and—while drunk—attended his first Group gathering. Within days, Wilson admitted himself to the Charles B. Towns Hospital, but not before drinking four beers on the way—the last time Wilson drank alcohol. Under the care of Dr. William Duncan Silkworth (an early benefactor of AA), Wilson's detox included the deliriant belladonna. At the hospital in a state of despair, Wilson experienced a bright flash of light, which he felt to be God revealing himself.
Following his hospital discharge Wilson joined the Oxford Group and recruited other alcoholics to the Group. Wilson's early efforts to help others become sober were ineffective, prompting Dr. Silkworth to suggest that Wilson place less stress on religion and more on "the science" of treating alcoholism. Wilson's first success came during a business trip to Akron, Ohio, where he was introduced to Dr. Robert Smith, a surgeon and Oxford Group member who was unable to stay sober. After thirty days of working with Wilson, Smith drank his last drink on June 10, 1935, the date marked by AA for its anniversaries.
While Wilson and Smith credited their sobriety to working with alcoholics under the auspices of the Oxford Group, a Group associate pastor sermonized against Wilson and his alcoholic Groupers for forming a "secret, ashamed sub-group" engaged in "divergent works". By 1937, Wilson separated from the Oxford Group. AA Historian Ernest Kurtz described the split:
"...more and more, Bill discovered that new adherents could get sober by believing in each other and in the strength of this group. Men [no women were members yet] who had proven over and over again, by extremely painful experience, that they could not get sober on their own had somehow become more powerful when two or three of them worked on their common problem. This, then—whatever it was that occurred among them—was what they could accept as a power greater than themselves. They did not need the Oxford Group."
In 1955, Wilson acknowledged AA's debt, saying "The Oxford Groupers had clearly shown us what to do. And just as importantly, we learned from them "what not to do."" Among the Oxford Group practices that AA retained were informal gatherings, a "changed-life" developed through "stages", and working with others for no material gain. AA's analogs for these are meetings, "the steps", and sponsorship. AA's tradition of anonymity was a reaction to the publicity-seeking practices of the Oxford Group, as well as AA's wish to not promote, Wilson said, "erratic public characters who through broken anonymity might get drunk and destroy confidence in us."
The Big Book, the Twelve Steps and the Twelve Traditions.
To promote the fellowship, Wilson and other members wrote the initially-titled book, "Alcoholics Anonymous: The Story of How More Than One Hundred Men Have Recovered from Alcoholism", from which AA drew its name. Informally known as "The Big Book" (with its first 164 pages virtually unchanged since the 1939 edition), it suggests a twelve-step program in which members admit that they are powerless over alcohol and need help from a "higher power". They seek guidance and strength through prayer and meditation from God or a Higher Power of their own understanding; take a moral inventory with care to include resentments; list and become ready to remove character defects; list and make amends to those harmed; continue to take a moral inventory, pray, meditate, and try to help other alcoholics recover. The second half of the book, "Personal Stories" (subject to additions, removal and retitling in subsequent editions), is made of AA members' redemptive autobiographical sketches.
In 1941, interviews on American radio and favorable articles in US magazines, including a piece by Jack Alexander in "The Saturday Evening Post", led to increased book sales and membership. By 1946, as the growing fellowship quarreled over structure, purpose, and authority, as well as finances and publicity, Wilson began to form and promote what became known as AA's "Twelve Traditions," which are guidelines for an altruistic, unaffiliated, non-coercive, and non-hierarchical structure that limited AA's purpose to only helping alcoholics on a non-professional level while shunning publicity. Eventually he gained formal adoption and inclusion of the Twelve Traditions in all future editions of the Big Book. At the 1955 conference in St. Louis, Missouri, Wilson relinquished stewardship of AA to the General Service Conference, as AA grew to millions of members internationally.
Organization and finances.
AA says it is "not organized in the formal or political sense", and Bill Wilson called it a "benign anarchy". In Ireland, Shane Butler said that AA “looks like it couldn’t survive as there’s no leadership or top-level telling local cumanns what to do, but it has worked and proved itself extremely robust.” Butler explained that "AA’s 'inverted pyramid' style of governance has helped it to avoid many of the pitfalls that political and religious institutions have encountered since it was established here in 1946."
In 2006, AA counted 1,867,212 members and 106,202 AA groups worldwide. The Twelve Traditions informally guide how individual AA groups function, and the Twelve Concepts for World Service guide how the organization is structured globally.
A member who accepts a service position or an organizing role is a "trusted servant" with terms rotating and limited, typically lasting three months to two years and determined by group vote and the nature of the position. Each group is a self-governing entity with AA World Services acting only in an advisory capacity. AA is served entirely by alcoholics, except for seven "nonalcoholic friends of the fellowship" of the 21-member AA Board of Trustees.
AA groups are self-supporting, relying on voluntary donations from members to cover expenses. The AA General Service Office (GSO) limits contributions to US$3,000 a year. Above the group level, AA may hire outside professionals for services that require specialized expertise or full-time responsibilities.
AA receives proceeds from books and literature that constitute more than 50% of the income for its General Service Office. Unlike individual groups, the GSO is not self-supporting and maintains a small salaried staff. It also maintains service centers, which coordinate activities such as printing literature, responding to public inquiries, and organizing conferences. They are funded by local members and are responsible to the AA groups they represent. Other International General Service Offices (Australia, Costa Rica, Russia, etc.) are independent of AA World Services in New York.
Program.
The scope of AA's program is much broader than just abstinence from drinking alcohol. Its goal is to effect enough change in the alcoholic's thinking "to bring about recovery from alcoholism" through a spiritual awakening. A spiritual awakening is achieved by taking the Twelve Steps, and sobriety is furthered by volunteering for AA and regular AA meeting attendance or contact with AA members. Members are encouraged to find an experienced fellow alcoholic, called a sponsor, to help them understand and follow the AA program. The sponsor should preferably have experience of all twelve of the steps, be the same gender as the sponsored person, and refrain from imposing personal views on the sponsored person. Following the helper therapy principle, sponsors in AA benefit as much, if not more, from their relationship than do those they sponsor. Helping behaviors correlate with increased abstinence and lower probabilities of binge drinking.
AA's program is an inheritor of Counter-Enlightenment philosophy. AA shares the view that acceptance of one's inherent limitations is critical to finding one's proper place among other humans and God. Such ideas are described as "Counter-Enlightenment" because they are contrary to the Enlightenment's ideal that humans have the capacity to make their lives and societies a heaven on earth using their own power and reason. 
After evaluating AA's literature and observing AA meetings for sixteen months, sociologists David R. Rudy and Arthur L. Greil found that for an AA member to remain sober a high level of commitment is necessary. This commitment is facilitated by a change in the member's worldview. To help members stay sober AA must, they argue, provide an all-encompassing worldview while creating and sustaining an atmosphere of transcendence in the organization. To be all-encompassing AA's ideology places an emphasis on tolerance rather than on a narrow religious worldview that could make the organization unpalatable to potential members and thereby limit its effectiveness. AA's emphasis on the spiritual nature of its program, however, is necessary to institutionalize a feeling of transcendence. A tension results from the risk that the necessity of transcendence, if taken too literally, would compromise AA's efforts to maintain a broad appeal. As this tension is an integral part of AA, Rudy and Greil argue that AA is best described as a "quasi-religious organization".
Meetings.
AA meetings are "quasi-ritualized therapeutic sessions run by and for, alcoholics". They are usually informal and often feature discussions. Local AA directories list a variety of weekly meetings. Those listed as "closed" are only for those with "a desire to stop drinking", while "open" meetings are available to anyone, but nonalcoholics can attend as observers. At speaker meetings, one or two members tell their stories, while discussion meetings allocate the most time for general discussion. Some meetings are devoted to studying and discussing the AA literature. Except for men's and women's meetings, most meetings targeting specific demographics (including newcomers, gay people, and young people) do not exclude other alcoholics. While AA has pamphlets that suggest meeting formats, groups have the autonomy to hold and conduct meetings as they wish "except in matters affecting other groups or AA as a whole". Different cultures affect ritual aspects of meetings, but around the world "many particularities of the AA meeting format can be observed at almost any AA gathering".
Confidentiality.
US courts have not extended the status of privileged communication, such as that enjoyed by clergy and lawyers, to AA related communications between members.
Spirituality.
A study found a robust association between an increase in attendance to AA meetings with increased spirituality and a decrease in the frequency and intensity of alcohol use over time. The research also found that AA was effective for agnostics and atheists. The authors concluded that though spirituality is an important mechanism of behavioral change for alcoholics, it is not the only means used. Since the mid-1970s, a number of 'agnostic' or 'no-prayer' AA groups have begun across the U.S., Canada, and other parts of the world, which hold meetings that adhere to a tradition allowing alcoholics to freely express any doubts or disbelief they may harbor in relation to their recovery, and forgo use of closing prayers.
Disease concept of alcoholism.
More informally than not, AA's membership has helped popularize the disease concept of alcoholism, though AA officially has had no part in the development of such postulates which had appeared as early as the late eighteenth century. Though AA initially avoided the term "disease", in 1973 conference-approved literature categorically stated that "we had the disease of alcoholism." Regardless of official positions, from AA's inception most members have believed alcoholism to be a disease.
Though cautious regarding the medical nature of alcoholism, AA has let others voice opinions. The Big Book states that alcoholism "is an illness which only a spiritual experience will conquer." Ernest Kurtz says this is "The closest the book Alcoholics Anonymous comes to a definition of alcoholism." In his introduction to The Big Book, non-member Dr. William Silkworth said those unable to moderate their drinking have an allergy. Addressing the allergy concept, AA said "The doctor’s theory that we have an allergy to alcohol interests us. As laymen, our opinion as to its soundness may, of course, mean little." AA later acknowledged that "alcoholism is not a true allergy, the experts now inform us." Wilson explained in 1960 why AA had refrained from using the term "disease":
We AAs have never called alcoholism a disease because, technically speaking, it is not a disease entity. For example, there is no such thing as heart disease. Instead there are many separate heart ailments or combinations of them. It is something like that with alcoholism. Therefore, we did not wish to get in wrong with the medical profession by pronouncing alcoholism a disease entity. Hence, we have always called it an illness or a malady—a far safer term for us to use.
Canadian and United States demographics.
AA's New York General Service Office regularly surveys AA members in North America. Its 2011 survey of over 8,000 members in Canada and the United States concluded that, in North America, AA members who responded to the survey were 65% male and 35% female. Average member sobriety is slightly under 10 years with 36% sober more than ten years, 12% sober from five to ten years, 24% sober from one to five years, and 27% sober less than one year. Before coming to AA, 63% of members received some type of treatment or counseling, such as medical, psychological, or spiritual. After coming to AA, 62% received outside treatment or counseling. Of those members, 82% said that outside help played an important part in their recovery. The same survey showed that AA received 12% of its membership from court ordered attendance.
Effectiveness.
Research limitations.
AA tends to polarize observers into believers and non-believers, and discussion of AA often creates controversy rather than objective reflection. Moreover, a randomized study of AA is difficult: AA members are not randomly selected from the population of chronic alcoholics, with the possible exception of those who are mandated by courts to attend AA meetings; they are instead self-selected. There are two opposing types of self-selection bias: (1) drinkers may be motivated to stop drinking before they participate in AA; (2) AA may attract the more severe and difficult cases. Controlled experiments with AA versus non-AA subjects are also difficult because AA is so easily accessible. Twelve-step groups like AA are not conducive to probability sampling of members. Research on AA is therefore susceptible to sampling bias.
Studies.
Studies of AA's efficacy have produced inconsistent results. While some studies have suggested an association between AA attendance and increased abstinence or other positive outcomes, other studies have not. A Cochrane Review of eight studies, published between 1967 and 2005, measuring the effectiveness of AA, found "no experimental studies unequivocally demonstrated the effectiveness of AA" in treating alcoholism, based on a meta-analysis of the results of eight trials involving 3,417 individuals. To determine further the effectiveness of AA, the authors suggested that more studies comparing treatment outcomes with control groups were necessary.
Lance Dodes, former director of substance abuse treatment at Harvard’s McLean Hospital and assistant clinical professor of psychiatry at Harvard Medical School, says Alcoholics Anonymous helps between 5 percent and 10 percent of its participants. Dodes also believes A.A. harms 90 percent of participants because of the perception that "If you fail in A.A., it's you that's failed" and not A.A.
Retention.
Every third year since 1968, AA has issued a pamphlet summarizing its latest triennial survey of meeting attendants. Additional published comments and analysis for academics and professionals have supplemented the survey results from 1970 through 1990. The 1990 commentary evaluated data of triennial surveys from 1977 through 1989 and found that the distribution of those with one year or less indicated that one quarter (26%) of those who first attend an AA meeting are still attending after one year. Furthermore, nearly one third (31.5%) leave the program after one month, and by the end of the third month, almost half (47.4%) leave. Of those who stay for three months, half (50.0%) will attain one year. After the first year, the rate of attrition slows. Only those in the first year were recorded by month.
Two landmark surveys that sampled the general population produced independent results on AA continuance rates. The 1990 National Longitudinal Alcohol Epidemiologic Survey (NLAES) found that Alcoholics Anonymous has a 31% continuance rate. The 2001-2002 National Epidemiological Survey on Alcoholism and Related Conditions (NESARC) indicates a slightly higher rate, at 35.2%.
Sobriety of members.
Internal AA surveys suggest that about 40% of the members sober for less than a year will remain another year. About 80% of those sober more than one year, but less than five years will remain sober and active in the fellowship another year. About 90% of the members sober five years or more will remain sober and active in the fellowship another year. Those who remained sober outside the fellowship could not be calculated using the survey results.
Health-care costs.
As a volunteer-supported program, AA is free of charge. This contrasts with treatments for alcoholism such as inpatient treatment, drug therapy, psychotherapy, and cognitive-based therapy. One study found that the institutional use of twelve-step-facilitation therapy to encourage participation in AA reduced healthcare expenditures by 45% when compared to another group that was not encouraged to participate in AA.
Relationship with institutions.
Hospitals.
Many AA meetings take place in treatment facilities. Carrying the message of AA into hospitals was how the co-founders of AA first remained sober. They discovered great value of working with alcoholics who are still suffering, and that even if the alcoholic they were working with did not stay sober, they did. Bill Wilson wrote, "Practical experience shows that nothing will so much insure immunity from drinking as intensive work with other alcoholics". Bill Wilson visited Towns Hospital in New York City in an attempt to help the alcoholics who were patients there in 1934. At St. Thomas Hospital in Akron, Ohio, Smith worked with still more alcoholics. In 1939, a New York mental institution, Rockland State Hospital, was one of the first institutions to allow AA hospital groups. Service to corrections and treatment facilities used to be combined until the General Service Conference, in 1977, voted to dissolve its Institutions Committee and form two separate committees, one for treatment facilities, and one for correctional facilities.
Prisons.
In the United States and Canada, AA meetings are held in hundreds of correctional facilities. The AA General Service Office has published a workbook with detailed recommendations for methods of approaching correctional-facility officials with the intent of developing an in-prison AA program. In addition, AA publishes a variety of pamphlets specifically for the incarcerated alcoholic. Additionally, the AA General Service Office provides a pamphlet with guidelines for members working with incarcerated alcoholics.
United States Court rulings.
United States courts have ruled that inmates, parolees, and probationers cannot be ordered to attend AA. Though AA itself was not deemed a religion, it was ruled that it contained "enough" religious components (variously described in "Griffin v. Coughlin" below as, inter alia, "religion", "religious activity", "religious exercise") to make coerced attendance at AA meetings a violation of the Establishment Clause of the First Amendment of the constitution. In 2007, the Ninth Circuit of the U.S. Court of Appeals stated that a parolee who was ordered to attend AA had standing to sue his parole office.
American treatment industry.
In 1949, the Hazelden treatment center was founded and staffed by AA members, and since then many alcoholic rehabilitation clinics have incorporated AA's precepts into their treatment programs. 31% of AA's membership results from treatment centers referrals.
United Kingdom treatment industry.
A cross-sectional survey of substance-misuse treatment providers in the West Midlands found fewer than 10% integrated twelve-step methods in their practice and only a third felt their consumers were suited for Alcoholics Anonymous or Narcotics Anonymous membership. Less than half were likely to recommend self-help groups to their clients. Providers with nursing qualifications were more likely to make such referrals than those without them. A statistically significant correlation was found between providers' self-reported level of spirituality and their likelihood of recommending AA or NA.
Criticism.
Moderation or abstinence.
Stanton Peele argued that some AA groups apply the disease model to all problem drinkers, whether or not they are "full-blown" alcoholics. Along with Nancy Shute, Peele has advocated that besides AA, other options should be available to problem drinkers who can manage their drinking with the right treatment. The Big Book, however, acknowledges "moderate drinkers" and "a certain type of hard drinker" are able to stop or moderate their drinking. The Big Book suggests no program for these drinkers, but instead seeks to help drinkers without "power of choice in drink."
Cultural identity.
One review of AA warned of detrimental iatrogenic effects of twelve-step philosophy and concluded that AA uses many methods that are also used by cults. A subsequent study concluded, however, that AA's program bore little resemblance to religious cults because the techniques used appeared beneficial. Another study found that the AA program's focus on admission of having a problem increases deviant stigma and strips members of their previous cultural identity, replacing it with the deviant identity. A survey of group members, however, found they had a bicultural identity and saw AA's program as a complement to their other national, ethnic, and religious cultures.
Literature.
Alcoholics Anonymous publishes several books, reports, pamphlets, and other media, including a periodical known as the "AA Grapevine". Two books are used primarily: "Alcoholics Anonymous" (the "Big Book") and "Twelve Steps and Twelve Traditions", the latter explaining AA's fundamental principles in depth.

</doc>
<doc id="2049" url="http://en.wikipedia.org/wiki?curid=2049" title="Alpha compositing">
Alpha compositing

In computer graphics, alpha compositing is the process of combining an image with a background to create the appearance of partial or full transparency. It is often useful to render image elements in separate passes, and then combine the resulting multiple 2D images into a single, final image called the composite. For example, compositing is used extensively when combining computer-rendered image elements with live footage.
In order to combine these image elements correctly, it is necessary to keep an associated "matte" for each element. This matte contains the coverage information—the shape of the geometry being drawn—making it possible to distinguish between parts of the image where the geometry was actually drawn and other parts of the image that are empty.
Description.
To store matte information, the concept of an alpha channel was introduced by Alvy Ray Smith in the late 1970s, and fully developed in a 1984 paper by Thomas Porter and Tom Duff. In a 2D image element, which stores a color for each pixel, additional data is stored in the alpha channel with a value between 0 and 1. A value of 0 means that the pixel does not have any coverage information and is transparent; i.e. there was no color contribution from any geometry because the geometry did not overlap this pixel. A value of 1 means that the pixel is opaque because the geometry completely overlapped the pixel.
If an alpha channel is used in an image, it is common to also multiply the color by the alpha value, to save on additional multiplications during compositing. This is usually referred to as "premultiplied alpha".
Assuming that the pixel color is expressed using "straight" (non-premultiplied) RGBA tuples, a pixel value of (0.0, 0.5, 0.0, 0.5) implies a pixel that has 50% of the maximum green intensity and 50% opacity. If the color were fully green, its RGBA would be (0, 1, 0, 0.5).
However, if this pixel uses premultiplied alpha, all of the RGB values (0, 1, 0) are multiplied by 0.5 and then the alpha is appended to the end to yield (0, 0.5, 0, 0.5). In this case, the 0.5 value for the G channel actually indicates 100% green intensity (with 50% opacity). For this reason, knowing whether a file uses premultiplied or straight alpha is essential to correctly process or composite it.
Premultiplied alpha has some practical advantages over normal alpha blending because premultiplied alpha blending is associative and interpolation gives better results. Ordinary interpolation without premultiplied alpha leads to RGB information leaking out of fully transparent (A=0) regions, even though this RGB information is ideally invisible. When interpolating images with abrupt borders between transparent and opaque regions, this can result in borders of unusual colors that were not visible in the original image.
Premultiplication causes a loss of precision in the RGB values, so that a noticeable loss of quality can result if the color information is later brightened or if the alpha channel is removed. This loss of precision also makes premultiplied images easier to compress, as they do not record the color variations hidden inside transparent regions.
With the existence of an alpha channel, it is possible to express compositing image operations using a "compositing algebra". For example, given two image elements A and B, the most common compositing operation is to combine the images such that A appears in the foreground and B appears in the background. This can be expressed as A over B. In addition to over, Porter and Duff defined the compositing operators in, held out by (usually abbreviated out), atop, and xor (and the reverse operators rover, rin, rout, and ratop) from a consideration of choices in blending the colors of two pixels when their coverage is, conceptually, overlaid orthogonally:
The over operator is, in effect, the normal painting operation (see Painter's algorithm). The in operator is the alpha compositing equivalent of clipping.
As an example, the over operator can be accomplished by applying the following formula to each pixel value:
where formula_2 is the result of the operation, formula_3 is the color of the pixel in element A, formula_4 is the color of the pixel in element B, and formula_5 and formula_6 are the alpha of the pixels in elements A and B respectively. If it is assumed that all color values are premultiplied by their alpha values (formula_7), we can rewrite the equation for output color as:
and resulting alpha channel value is 
However, this operation may not be appropriate for all applications, since it is not associative.
The associative version of this operation is very similar; simply take the newly computed color value and divide it by its new alpha value, as follows:
Image editing applications that allow merging of layers generally prefer this second approach.
Analytical derivation of the over operator.
Porter and Duff gave a geometric interpretation of the alpha compositing formula by studying orthogonal coverages. Another derivation of the formula, based on a physical reflectance/transmittance model, can be found in a 1981 paper by Bruce A. Wallace.
A third approach is found by starting out with two very simple assumptions. For simplicity, we shall here use the shorthand notation formula_11 for representing the over operator.
The first assumption is that in the case where the background is opaque (i.e. formula_12), the over operator represents the convex combination of formula_13 and formula_14:
The second assumption is that the operator must respect the associative rule:
Now, let us assume that formula_13 and formula_14 have variable transparencies, whereas formula_19 is opaque. We're interested in finding
We know from the associative rule that the following must be true:
We know that formula_19 is opaque and thus follows that formula_23 is opaque, so in the above equation, each formula_24 operator can be written as a convex combination:
Hence we see that this represents an equation of the form formula_26. By setting formula_27 and formula_28 we get
which means that we have analytically derived a formula for the output alpha and the output color of formula_11.
An even more compact representation is given by noticing that formula_31:
It is also interesting to note that the formula_24 operator fulfills all the requirements of a non-commutative monoid, where the identity element formula_34 is chosen such that formula_35 (i.e. the identity element can be any tuple formula_36 with formula_37.)
Alpha blending.
Alpha blending is the process of combining a translucent foreground color with a background color, thereby producing a new blended color. The degree of the foreground color's translucency may range from completely transparent to completely opaque. If the foreground color is completely transparent, the blended color will be the background color. Conversely, if it is completely opaque, the blended color will be the foreground color. Of course, the translucency can range between these extremes, in which case the blended color is computed as a weighted average of the foreground and background colors.
Alpha blending is a convex combination of two colors allowing for transparency effects in computer graphics. The value of codice_1 in the color code ranges from 0.0 to 1.0, where 0.0 represents a fully transparent color, and 1.0 represents a fully opaque color. This alpha value also corresponds to the ratio of "SRC over DST" in Porter and Duff equations.
The value of the resulting color is given by:
If the destination background is opaque, then formula_39, and if you enter it to the upper equation:
The alpha component may be used to blend to red, green and blue components equally, as in 32-bit RGBA, or, alternatively, there may be three alpha values specified corresponding to each of the primary colors for spectral color filtering.
Note that the RGB color may be premultiplied, hence saving the additional multiplication before RGB in the equation above. This can be a considerable saving in processing time given that images are often made up of millions of pixels.
Other transparency methods.
Although used for similar purposes, transparent colors and image masks do not permit the smooth blending of the superimposed image pixels with those of the background (only whole image pixels or whole background pixels allowed).
A similar effect can be achieved with a 1-bit alpha channel, as found in the 16-bit RGBA Highcolor mode of the Truevision TGA image file format and related TARGA and AT-Vista/NU-Vista display adapters' Highcolor graphic mode. This mode devotes 5 bits for every primary RGB color (15-bit RGB) plus a remaining bit as the "alpha channel".
Applications.
Alpha blending is used in a variety of applications. It is natively supported by most operating systems/GUIs for drawing windows (where applicable) or widgets:
Other software may use alpha blended transparent elements in the GUI independently of OS provided APIs by precomposing elements in an off-screen memory buffer before displaying them. (Such as when displaying partially transparent composited elements in an embedded system that provides only a simple frame buffer.) Compositing software is used to combine images, and makes extensive use of alpha compositing techniques.

</doc>
<doc id="2052" url="http://en.wikipedia.org/wiki?curid=2052" title="Array data structure">
Array data structure

In computer science, an array data structure or simply an array is a data structure consisting of a collection of "elements" (values or variables), each identified by at least one "array index" or "key". An array is stored so that the position of each element can be computed from its index tuple by a mathematical formula. The simplest type of data structure is a linear array, also called one-dimensional array. 
For example, an array of 10 32-bit integer variables, with indices 0 through 9, may be stored as 10 words at memory addresses 2000, 2004, 2008, … 2036, so that the element with index "i" has the address 2000 + 4 × "i".
Because the mathematical concept of a matrix can be represented as a two-dimensional grid, two-dimensional arrays are also sometimes called matrices. In some cases the term "vector" is used in computing to refer to an array, although tuples rather than vectors are more correctly the mathematical equivalent. Arrays are often used to implement tables, especially lookup tables; the word "table" is sometimes used as a synonym of "array".
Arrays are among the oldest and most important data structures, and are used by almost every program. They are also used to implement many other data structures, such as lists and strings. They effectively exploit the addressing logic of computers. In most modern computers and many external storage devices, the memory is a one-dimensional array of words, whose indices are their addresses. Processors, especially vector processors, are often optimized for array operations.
Arrays are useful mostly because the element indices can be computed at run time. Among other things, this feature allows a single iterative statement to process arbitrarily many elements of an array. For that reason, the elements of an array data structure are required to have the same size and should use the same data representation. The set of valid index tuples and the addresses of the elements (and hence the element addressing formula) are usually, but not always, fixed while the array is in use.
The term "array" is often used to mean array data type, a kind of data type provided by most high-level programming languages that consists of a collection of values or variables that can be selected by one or more indices computed at run-time. Array types are often implemented by array structures; however, in some languages they may be implemented by hash tables, linked lists, search trees, or other data structures.
The term is also used, especially in the description of algorithms, to mean associative array or "abstract array", a theoretical computer science model (an abstract data type or ADT) intended to capture the essential properties of arrays.
History.
The first digital computers used machine-language programming to set up and access array structures for data tables, vector and matrix computations, and for many other purposes. Von Neumann wrote the first array-sorting program (merge sort) in 1945, during the building of the first stored-program computer.p. 159 Array indexing was originally done by self-modifying code, and later using index registers and indirect addressing. Some mainframes designed in the 1960s, such as the Burroughs B5000 and its successors, used memory segmentation to perform index-bounds checking in hardware.
Assembly languages generally have no special support for arrays, other than what the machine itself provides. The earliest high-level programming languages, including FORTRAN (1957), COBOL (1960), and ALGOL 60 (1960), had support for multi-dimensional arrays, and so has C (1972). In C++ (1983), class templates exist for multi-dimensional arrays whose dimension is fixed at runtime as well as for runtime-flexible arrays.
Applications.
Arrays are used to implement mathematical vectors and matrices, as well as other kinds of rectangular tables. Many databases, small and large, consist of (or include) one-dimensional arrays whose elements are records.
Arrays are used to implement other data structures, such as heaps, hash tables, deques, queues, stacks, strings, and VLists.
One or more large arrays are sometimes used to emulate in-program dynamic memory allocation, particularly memory pool allocation. Historically, this has sometimes been the only way to allocate "dynamic memory" portably.
Arrays can be used to determine partial or complete control flow in programs, as a compact alternative to (otherwise repetitive) multiple codice_1 statements. They are known in this context as control tables and are used in conjunction with a purpose built interpreter whose control flow is altered according to values contained in the array. The array may contain subroutine pointers (or relative subroutine numbers that can be acted upon by SWITCH statements) that direct the path of the execution.
Element identifier and addressing formulas.
When data objects are stored in an array, individual objects are selected by an index that is usually a non-negative scalar integer. Indices are also called subscripts. An index "maps" the array value to a stored object.
There are three ways in which the elements of an array can be indexed:
Arrays can have multiple dimensions, thus it is not uncommon to access an array using multiple indices. For example a two-dimensional array codice_2 with three rows and four columns might provide access to the element at the 2nd row and 4th column by the expression codice_3 (in a row major language) or codice_4 (in a column major language) in the case of a zero-based indexing system. Thus two indices are used for a two-dimensional array, three for a three-dimensional array, and "n" for an "n"-dimensional array.
The number of indices needed to specify an element is called the dimension, dimensionality, or rank of the array.
In standard arrays, each index is restricted to a certain range of consecutive integers (or consecutive values of some enumerated type), and the address of an element is computed by a "linear" formula on the indices.
One-dimensional arrays.
A one-dimensional array (or single dimension array) is a type of linear array. Accessing its elements involves a single subscript which can either represent a row or column index.
As an example consider the C declaration codice_5
Syntax : datatype anArrayname[sizeofArray];
In the given example the array can contain 10 elements of any value available to the codice_6 type. In C, the array element indices are 0-9 inclusive in this case. For example, the expressions codice_7 and codice_8 are the first and last elements respectively.
For a vector with linear addressing, the element with index "i" is located at the address "B" + "c" × "i", where "B" is a fixed "base address" and "c" a fixed constant, sometimes called the "address increment" or "stride".
If the valid element indices begin at 0, the constant "B" is simply the address of the first element of the array. For this reason, the C programming language specifies that array indices always begin at 0; and many programmers will call that element "zeroth" rather than "first".
However, one can choose the index of the first element by an appropriate choice of the base address "B". For example, if the array has five elements, indexed 1 through 5, and the base address "B" is replaced by "B" + 30"c", then the indices of those same elements will be 31 to 35. If the numbering does not start at 0, the constant "B" may not be the address of any element.
Multidimensional arrays.
For a two-dimensional array, the element with indices "i","j" would have address "B" + "c" · "i" + "d" · "j", where the coefficients "c" and "d" are the "row" and "column address increments", respectively.
More generally, in a "k"-dimensional array, the address of an element with indices "i"1, "i"2, …, "i""k" is
For example: int a[3][2];
This means that array a has 3 rows and 2 columns, and the array is of integer type. Here we can store 6 elements they are stored linearly but starting from first row linear then continuing with second row. The above array will be stored as a11, a12, a13, a21, a22, a23.
This formula requires only "k" multiplications and "k" additions, for any array that can fit in memory. Moreover, if any coefficient is a fixed power of 2, the multiplication can be replaced by bit shifting.
The coefficients "c""k" must be chosen so that every valid index tuple maps to the address of a distinct element.
If the minimum legal value for every index is 0, then "B" is the address of the element whose indices are all zero. As in the one-dimensional case, the element indices may be changed by changing the base address "B". Thus, if a two-dimensional array has rows and columns indexed from 1 to 10 and 1 to 20, respectively, then replacing "B" by "B" + "c"1 - − 3 "c"1 will cause them to be renumbered from 0 through 9 and 4 through 23, respectively. Taking advantage of this feature, some languages (like FORTRAN 77) specify that array indices begin at 1, as in mathematical tradition; while other languages (like Fortran 90, Pascal and Algol) let the user choose the minimum value for each index.
Dope vectors.
The addressing formula is completely defined by the dimension "d", the base address "B", and the increments "c"1, "c"2, …, "c""k". It is often useful to pack these parameters into a record called the array's "descriptor" or "stride vector" or "dope vector". The size of each element, and the minimum and maximum values allowed for each index may also be included in the dope vector. The dope vector is a complete handle for the array, and is a convenient way to pass arrays as arguments to procedures. Many useful array slicing operations (such as selecting a sub-array, swapping indices, or reversing the direction of the indices) can be performed very efficiently by manipulating the dope vector.
Compact layouts.
Often the coefficients are chosen so that the elements occupy a contiguous area of memory. However, that is not necessary. Even if arrays are always created with contiguous elements, some array slicing operations may create non-contiguous sub-arrays from them.
There are two systematic compact layouts for a two-dimensional array. For example, consider the matrix
In the row-major order layout (adopted by C for statically declared arrays), the elements in each row are stored in consecutive positions and all of the elements of a row have a lower address than any of the elements of a consecutive row:
In column-major order (traditionally used by Fortran), the elements in each column are consecutive in memory and all of the elements of a column have a lower address than any of the elements of a consecutive column:
For arrays with three or more indices, "row major order" puts in consecutive positions any two elements whose index tuples differ only by one in the "last" index. "Column major order" is analogous with respect to the "first" index.
In systems which use processor cache or virtual memory, scanning an array is much faster if successive elements are stored in consecutive positions in memory, rather than sparsely scattered. Many algorithms that use multidimensional arrays will scan them in a predictable order. A programmer (or a sophisticated compiler) may use this information to choose between row- or column-major layout for each array. For example, when computing the product "A"·"B" of two matrices, it would be best to have "A" stored in row-major order, and "B" in column-major order.
Resizing.
Static arrays have a size that is fixed when they are created and consequently do not allow elements to be inserted or removed. However, by allocating a new array and copying the contents of the old array to it, it is possible to effectively implement a "dynamic" version of an array; see dynamic array. If this operation is done infrequently, insertions at the end of the array require only amortized constant time.
Some array data structures do not reallocate storage, but do store a count of the number of elements of the array in use, called the count or size. This effectively makes the array a dynamic array with a fixed maximum size or capacity; Pascal strings are examples of this.
Non-linear formulas.
More complicated (non-linear) formulas are occasionally used. For a compact two-dimensional triangular array, for instance, the addressing formula is a polynomial of degree 2.
Efficiency.
Both "store" and "select" take (deterministic worst case) constant time. Arrays take linear (O("n")) space in the number of elements "n" that they hold.
In an array with element size "k" and on a machine with a cache line size of B bytes, iterating through an array of "n" elements requires the minimum of ceiling("nk"/B) cache misses, because its elements occupy contiguous memory locations. This is roughly a factor of B/"k" better than the number of cache misses needed to access "n" elements at random memory locations. As a consequence, sequential iteration over an array is noticeably faster in practice than iteration over many other data structures, a property called locality of reference (this does "not" mean however, that using a perfect hash or trivial hash within the same (local) array, will not be even faster - and achievable in constant time). Libraries provide low-level optimized facilities for copying ranges of memory (such as memcpy) which can be used to move contiguous blocks of array elements significantly faster than can be achieved through individual element access. The speedup of such optimized routines varies by array element size, architecture, and implementation.
Memory-wise, arrays are compact data structures with no per-element overhead. There may be a per-array overhead, e.g. to store index bounds, but this is language-dependent. It can also happen that elements stored in an array require "less" memory than the same elements stored in individual variables, because several array elements can be stored in a single word; such arrays are often called "packed" arrays. An extreme (but commonly used) case is the bit array, where every bit represents a single element. A single octet can thus hold up to 256 different combinations of up to 8 different conditions, in the most compact form.
Array accesses with statically predictable access patterns are a major source of data parallelism.
Comparison with other data structures.
Growable arrays are similar to arrays but add the ability to insert and delete elements; adding and deleting at the end is particularly efficient. However, they reserve linear (Θ("n")) additional storage, whereas arrays do not reserve additional storage.
Associative arrays provide a mechanism for array-like functionality without huge storage overheads when the index values are sparse. For example, an array that contains values only at indexes 1 and 2 billion may benefit from using such a structure. Specialized associative arrays with integer keys include Patricia tries, Judy arrays, and van Emde Boas trees.
Balanced trees require O(log "n") time for indexed access, but also permit inserting or deleting elements in O(log "n") time, whereas growable arrays require linear (Θ("n")) time to insert or delete elements at an arbitrary position.
Linked lists allow constant time removal and insertion in the middle but take linear time for indexed access. Their memory use is typically worse than arrays, but is still linear.
An Iliffe vector is an alternative to a multidimensional array structure. It uses a one-dimensional array of references to arrays of one dimension less. For two dimensions, in particular, this alternative structure would be a vector of pointers to vectors, one for each row. Thus an element in row "i" and column "j" of an array "A" would be accessed by double indexing ("A"["i"]["j"] in typical notation). This alternative structure allows "ragged" or "jagged" arrays, where each row may have a different size — or, in general, where the valid range of each index depends on the values of all preceding indices. It also saves one multiplication (by the column address increment) replacing it by a bit shift (to index the vector of row pointers) and one extra memory access (fetching the row address), which may be worthwhile in some architectures.
Dimension.
The dimension of an array is the number of indices needed to select an element. Thus, if the array is seen as a function on a set of possible index combinations, it is the dimension of the space of which its domain is a discrete subset. Thus a one-dimensional array is a list of data, a two-dimensional array a rectangle of data, a three-dimensional array a block of data, etc.
This should not be confused with the dimension of the set of all matrices with a given domain, that is, the number of elements in the array. For example, an array with 5 rows and 4 columns is two-dimensional, but such matrices form a 20-dimensional space. Similarly, a three-dimensional vector can be represented by a one-dimensional array of size three.

</doc>
<doc id="2053" url="http://en.wikipedia.org/wiki?curid=2053" title="Advance Australia Fair">
Advance Australia Fair

"Advance Australia Fair" is the official national anthem of Australia. Created by the Scottish-born composer Peter Dodds McCormick, the song was first performed in 1878, and was sung in Australia as a patriotic song. It did not gain its status as the official anthem until 1984, following a plebiscite to choose the national song in 1977. Other songs and marches have been influenced by "Advance Australia Fair", such as the Australian vice-regal salute.
History.
Origin.
"Advance Australia Fair" was composed in the late 19th century by Peter Dodds McCormick under the pen-name "Amicus" (which means "friend" in Latin). It was first performed by Andrew Fairfax at a Highland Society function in Sydney on 30 November 1878. The song quickly gained popularity and an amended version was sung by a choir of around 10,000 at the inauguration of the Commonwealth of Australia on 1 January 1901. In 1907 the Australian Government awarded McCormick £100 for his composition.
In a letter to R.B. Fuller, dated 1 August 1913, McCormick described the circumstances that inspired him to write "Advance Australia Fair":
The earliest known sound recording of "Advance Australia Fair" appears in "The Landing of the Australian Troops in Egypt" (circa 1916), a short commercial recording dramatising the arrival of Australian troops in Egypt "en route" to Gallipoli.
Before its adoption as Australia's national anthem, "Advance Australia Fair" had considerable use elsewhere. For example, Australia's national broadcaster, the Australian Broadcasting Commission, used it to announce its news bulletins until 1952. It was also frequently played at the start or end of official functions. Towards the end of World War II it was played in picture theatres after "God Save the King" and the American national anthem.
Competitions, plebiscite and adoption.
In 1951 there was a competition for a new national anthem to celebrate the golden jubilee of the Federation of Australia. The entry by the Austrian-born conductor Henry Krips, "This Land of Mine", won the competition but it was decided to make no change to the status quo.
Until 1974 "God Save the Queen" was Australia's national anthem. In 1973 the Whitlam government decided that the country needed an anthem that could represent Australia with "distinction" and started a competition to find one. The Australia Council for the Arts organised the contest, which was dubbed the "Australian National Anthem Quest". The contest was held in two stages, the first seeking lyrics and the second music, each having an A$5,000 prize for the winning entry. On the recommendation of the Council for the Arts, none of the new entries were felt worthy enough, so the contest ended with the suggestions for "Advance Australia Fair", "Waltzing Matilda" and "Song of Australia".
In 1974 the Whitlam government then performed a nationwide opinion survey to determine the song to be sung on occasions of national significance. Conducted through the Australian Bureau of Statistics, it polled 60,000 people nationally. "Advance Australia Fair" was chosen and was enshrined as the national song, to be used on all occasions excepting those of a specifically regal nature. A spokesman for the Prime Minister Gough Whitlam stated that the Government regarded the tune primarily as the national anthem.
In January 1976 the Fraser government reinstated "God Save the Queen" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. This was conducted as a plebiscite to choose the National Song, held as an optional additional question in the 1977 referendum on various issues. "Advance Australia Fair" received 43.29% of the vote, defeating the three alternatives, "Waltzing Matilda" (28.28%), "Song of Australia" (9.65%) and the existing national anthem, "God Save the Queen" (18.78%).
"Advance Australia Fair", with modified lyrics from the original (see development of lyrics), was adopted as the Australian national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke. "God Save the Queen", now known as the royal anthem, continues to be played alongside the Australian national anthem at public engagements in Australia that are attended by the Queen or members of the Royal Family.
Lyrics.
The lyrics of the anthem officially adopted in 1984 are as follows:
Copyright.
Even though any copyright of Peter Dodds McCormick's original lyrics has expired, as he died in 1916, the Commonwealth of Australia does claim copyright on the official lyrics and particular arrangements of music. Non-commercial use of the anthem is permitted without case-by-case permission, but commercial use does require permission.
Orchestral version.
The wordless orchestral version of "Advance Australia Fair" that is now regularly played for Australian victories at international sporting medal ceremonies, and at the openings of major domestic sporting, cultural and community events, is by Tommy Tycho, an immigrant from Hungary. It was first commissioned by ABC Records in 1984 and then televised by Channel 10 in 1986 in their Australia Day Broadcast, featuring Julie Anthony as the soloist.
Development of lyrics.
Since the original lyrics were written in 1879, there have been several changes, in some cases with the intent of increasing the anthem's inclusiveness and gender neutrality. Some of these were minor while others have significantly changed the song. The original song was four verses long. For its adoption as the national anthem, the song was cut from four verses to two. The first verse was kept largely as the 1879 original, except for the change in the first line from "Australia's sons let us rejoice" to "Australians all let us rejoice". The second, third and fourth verses of the original were dropped, in favour of a modified version of the new third verse which was sung at Federation in 1901.
The original lyrics published in 1879 were as follows:
The 1901 Federation version of the third verse was originally sung as:
Criticism.
Both the lyrics and melody of the official anthem have been criticised in some quarters as being dull and unendearing to the Australian people. A National Party senator, Sandy Macdonald, said in 2001 that "Advance Australia Fair" is so boring that the nation risks singing itself to sleep, with boring music and words impossible to understand. A parliamentary colleague, Peter Slipper, said that Australia should consider another anthem.
Specific criticism is also directed at the fourth line of lyrics, "our home is girt by sea", both for its use of the archaic word "girt" and for being an excessively poetic way of acknowledging the unremarkable fact that Australia is an island. The current version of the anthem has a mix of old and new language, rather than having one style of language consistently throughout. Criticism has come from various people, including Australian Labor Party politician Craig Emerson, but others, including former Labor leader Kim Beazley, have defended it.
Alternative Christian verse.
A Christian movement, Awakening, in the 1990s substituted an alternative second verse naming Christ and promoting Christian values. An archived claim that the verse was sung in the 1930s at Smithton, Tasmania, is unsubstantiated and has been withdrawn from the original website. It was sung during the Global March for Jesus in 1998 and again at World Youth Day 2008 with the qualification "This is not the official verse, but a Catholic adaptation of the Australian National Anthem." 
The version was later controversially adopted by some Christian private schools for singing as a hymn at internal assemblies. The substituted verse did not appear in the 1879 publication of Peter Dodds McCormick’s original work. The office of the Prime Minister at the time, Julia Gillard, said that, under national protocols, the anthem should not be modified and alternative words should not be used.

</doc>
<doc id="2061" url="http://en.wikipedia.org/wiki?curid=2061" title="Automatic number announcement circuit">
Automatic number announcement circuit

An automatic number announcement circuit (ANAC) is a component of a central office of a telephone company that provides a service to installation and service technicians to determine the telephone number of a line. The facility has a telephone number that may be called to listen to an automatic announcement that includes the caller's telephone number.
The ANAC number is useful primarily during the installation of landline telephones to quickly identify one of multiple lines.
Operation.
A technician calls the local telephone number of the automatic number announcement service. This call is connected to equipment at a local central office that uses a voice synthesizer or digital samples to announce the telephone number of the line calling in. The main purpose of this system is to allow telephone company technicians to identify the telephone line they are connected to.
Automatic number announcement systems are based on automatic number identification, and meant for phone company technicians, the ANAC system works with unlisted numbers, numbers with caller ID blocking, and numbers with no outgoing calls allowed. Installers of multi-line business services where outgoing calls from all lines display the company's main number on call display can use ANAC to identify a specific line in the system, even if CID displays every line as "line one".
Some ANACs are very regional or local in scope, while others are state-/province- or area-code-wide: there appears to be no consistent national system for them. Every telephone company, whether large or small, determines its own ANAC for each individual central office, which tends to perpetuate the current situation of a mess of overlapping and/or spotty areas of coverage. No official lists of ANAC numbers are published as telephone companies believe overuse of these numbers could make them more likely to be busy when needed by installers.
958 local test exchanges.
Under the North American Numbering Plan, almost all North American area codes reserve telephone numbers beginning with "958" and "959" for internal local and long distance testing (respectively), sometimes called plant testing. (One exception is Winnipeg, which reserves "959" only). Numbers within this block are used for various test utilities such as a ringback number (to test the ringer when installing telephone sets), milliwatt tone (a number simply answers with a continuous test tone) and a loop around (which connects a call to another inbound call to the same or another test number). ANAC numbers can also appear in the "958" range, but there is no requirement that they reside there.
In some area codes, multiple additional prefixes had been reserved for test purposes, in addition to the standard 958 and 959. Many area codes reserved 999; 320 was also formerly reserved in Bell Canada territory. As widespread inefficiencies in numbering (such as the assignment of entire blocks of 10000 numbers to every competing carrier in every small village to support local number portability schemes) have created shortages of available numbers, these prefixes are often "reclaimed" and issued as standard exchanges, moving the handful of numbers in them to one standard test exchange (usually 958).
Some carriers have been known to disable payphone calls to 958 or 959 test lines, such as Bell Canada's system-wide ANAC line at (area code) 958-2580. Conversely, a standard line on which voice service has been unsubscribed (such as an ADSL dry loop) may still accept calls to the 958 test exchange but not allow calls to standard numbers. This "soft disconnect" condition is intended to allow calls to 9-1-1 emergency services and to the telco business office to order telephone service, but to no other numbers.
Tollfree numbers.
Some large telephone companies have toll-free numbers set up. In most cases, these numbers remain undisclosed to prevent abuse, but MCI maintains this widely published, toll-free ANAC: 1-800-437-7950. This is distinct from technical support and other lines which use ANI so that a computer can automatically display the customer's account on a "screen pop" for the next available customer service representative: the MCI number is intended specifically for ANAC use.
Formerly, some companies changed their ANAC number every month for secrecy; this is still the case with a few numbers. In one example of this concern, most payphones in the United States are assigned a telephone number and can ring if the number is called. The phone can then be used to make and receive calls by anyone, making it a potential tool in anonymous criminal activity such as narcotics trafficking. Where a payphone does not have any number listed on the unit, the number can be discovered by calling an ANAC service.
Late in the 20th century, caller ID and prepaid cellphone service became commonplace. These services being more easily exploited for criminal purposes, this type of abuse of payphones faded from concern. In Canada, this behaviour has always been more difficult. As a matter of course, incoming calls to payphones are disabled; furthermore, the Bell ANAC number is also disabled (although the telephone number is marked on the payphone itself as it is needed to report a non-working coin phone to 6-1-1 repair service).
There are some private national toll-free numbers that use ANI and then have a computer read back the number that is calling, but these are not intended for use in identifying the customer's own phone number. They are used in order for the agent in the call center to confirm the phone the customer is calling from, so that a computer can automatically display the customer's account on a "screen pop" for the next available customer service representative; they are distinct from purpose-made toll-free ANAC numbers. Regardless, if one were to call one of these numbers, listen for the number confirmation and hang up, they would in effect be using this system as if it were an ANAC.
One such toll-free service is one owned by MCI - 1-800-444-4444. This number is easy to remember and, when called, will read back the number after a very short message. It is noteworthy that a suspended or out of service line or an incoming only line would not be able to reach any toll-free numbers.
ANAC numbers.
The list is presented by area code. In some regions, there are several numbers, depending on the telephone company or the area code of the caller, as there can be several central offices serving some areas.
Information is presented in the following form:
Area code: ANAC approximate geographic region
United States.
In some cases. if a prefix outside the 958 or 959 range is listed as a test exchange, these may be reclaimed and issued as standard numbers at a later date. NANPA's utilised codes report will indicate 'UA' (unassignable) for valid test prefixes; if a formerly 'UA' code newly appears on the available list or becomes an active exchange, any former test numbers from its time as a reserved prefix are presumable as invalid and deprecated. N11 prefixes such as 211, 311 and 511 are also often disappearing as test numbers as these codes are reassigned to local services such as community information, 
These numbers appear on lists circulated online, many from the 1990s. Many are outdated or no longer work:
Canada.
The current use of exchange prefixes for each area code is listed by CNAC; if an exchange changes from "plant test" to reclaimed or active, any former test numbers with the associated prefix are invalidated. Commonly-used test numbers for major carriers include:
Additional plant test codes may be in use locally in some areas:
Occasionally, a number in an existing, standard local exchange in the area is used. These will incur a toll (and might not work) outside their home area. Some may be announcing caller ID, which is not the same as ANI. As standard local calls, they are not accessible from ADSL "dry loop", inbound-only or unsubscribed lines:
In Bell Canada territory, +1-areacode-320 was formerly reserved for 320-xxxx test numbers; these were moved to the 958-xxxx range and 320-xxxx reclaimed for use as a standard exchange. The use of N11 prefixes (such as 3-1-1) for test numbers is also deprecated as 3-1-1 now often reaches city hall or municipal services while 2-1-1 is local community information.
Some lists also mention 1-555-1313 as ANAC (506 New Brunswick). The purpose of +1-areacode-555-1313, a pay-per-use "name that number" reverse lookup information service introduced in the mid-1990s, differs from ANAC. ANAC announces the caller's own number; the reverse lookup gives the directory name for a listed telephone number input by the user. 555-1313 is one of the rare uses of 555 (telephone number) for other than the standard 555-1212 directory information line.
Toll-free ANACs.
"Please note that it is always preferable to call the local ANAC; only if the local ANAC number can not be called is it advisable to call a toll-free ANAC number. It is also preferable to call an open ANAC rather than the password-protected one given below."
"The below numbers are not true ANAC numbers; however, they do read back one's phone number. These numbers provide valuable services to the customers they serve; it is, therefore, inadvisable to misuse them."
Ireland.
This service announces the line number on all Eircom lines, including lines where calls are carried by another provider using carrier preselect.
The same number also works for Smart Telecom lines provided by local-loop unbundling.
The number is called out without the leading 0. For example, 021 XXX XXXX is read back as "21 XXX XXXX".
There is also an extended ANAC service for identifying which carrier handles calls. Dialling these numbers will cause the local switch to announce which carrier the calls are being routed through for a specific category of calls.

</doc>
<doc id="2062" url="http://en.wikipedia.org/wiki?curid=2062" title="Amerigo Vespucci">
Amerigo Vespucci

Amerigo Vespucci (; March 9, 1454February 22, 1512) was an Italian explorer, financier, navigator and cartographer who first demonstrated that Brazil and the West Indies did not represent Asia's eastern outskirts as initially conjectured from Columbus' voyages, but instead constituted an entirely separate landmass hitherto unknown to Afro-Eurasians. Colloquially referred to as the New World, this second super continent came to be termed "America", deriving its name from Americus, the Latin version of Vespucci's first name.
Background.
Amerigo Vespucci was born and raised in Florence, Italy. He was the third son of Ser Nastagio (Anastasio), a Florentine notary, and Lisabetta Mini. Amerigo Vespucci was educated by his uncle, Fra Giorgio Antonio Vespucci, a Dominican friar of San Marco in Florence.
While his elder brothers were sent to the University of Pisa to pursue scholarly careers, Amerigo Vespucci embraced a mercantile life, and was hired as a clerk by the Florentine commercial house of Medici, headed by Lorenzo de' Medici. Vespucci acquired the favor and protection of Lorenzo di Pierfrancesco de' Medici who became the head of the business after the elder Lorenzo's death in 1492. In March 1492, the Medici dispatched the thirty-eight-year-old Vespucci and Donato Niccolini as confidential agents to look into the Medici branch office in Cádiz (Spain), whose managers and dealings were under suspicion. In April 1495, by the intrigues of Bishop Juan Rodríguez de Fonseca, the Crown of Castile broke their monopoly deal with Christopher Columbus and began handing out licenses to other navigators for the West Indies. Just around this time (1495–96), Vespucci was engaged as the executor of Giannotto Berardi, an Italian merchant who had recently died in Seville. Vespucci organized the fulfillment of Berardi's outstanding contract with the Castilian crown to provide twelve vessels for the Indies. After these were delivered, Vespucci continued as a provision contractor for Indies expeditions, and is known to have secured beef supplies for at least one (if not two) of Columbus' voyages.
Expeditions.
At the invitation of king Manuel I of Portugal, Vespucci participated as observer in several voyages that explored the east coast of South America between 1499 and 1502. On the first of these voyages he was aboard the ship that discovered that South America extended much further south than previously thought.
The expeditions became widely known in Europe after two accounts attributed to Vespucci were published between 1502 and 1504. In 1507, Martin Waldseemüller produced a world map on which he named the new continent America after the feminine Latin version of Vespucci's first name, which is Americus. In an accompanying book, Waldseemüller published one of the Vespucci accounts, which led to criticism that Vespucci was trying to upset Christopher Columbus' glory. However, the rediscovery in the 18th century of other letters by Vespucci has led to the view that the early published accounts, notably the Soderini Letter, could be fabrications, not by Vespucci, but by others.
Historical role.
In 1508 the position of chief of navigation of Spain ("piloto mayor de Indias") was created for Vespucci, with the responsibility of planning navigation for voyages to the Indies.
Two letters attributed to Vespucci were published during his lifetime. "Mundus Novus" (New World) was a Latin translation of a lost Italian letter sent from Lisbon to Lorenzo di Pierfrancesco de' Medici. It describes a voyage to South America in 1501–1502. "Mundus Novus" was published in late 1502 or early 1503 and soon reprinted and distributed in numerous European countries.
"Lettera di Amerigo Vespucci delle isole nuovamente trovate in quattro suoi viaggi" (Letter of Amerigo Vespucci concerning the isles newly discovered on his four voyages), known as "Lettera al Soderini" or just "Lettera", was a letter in Italian addressed to Piero Soderini. Printed in 1504 or 1505, it claimed to be an account of four voyages to the Americas made by Vespucci between 1497 and 1504. A Latin translation was published by the German Martin Waldseemüller in 1507 in "Cosmographiae Introductio", a book on cosmography and geography, as "Quattuor Americi Vespucij navigationes" (Four Voyages of Amerigo Vespucci).
On March 22, 1508, King Ferdinand made Vespucci chief navigator of Spain at a huge salary and commissioned him to found a school of navigation, in order to standardize and modernize navigation techniques used by Iberian sea captains then exploring the world. Vespucci even developed a rudimentary, but fairly accurate method of determining longitude (which only more accurate chronometers would later improve upon).
In the 18th century three unpublished familiar letters from Vespucci to Lorenzo de' Medici were rediscovered. One describes a voyage made in 1499–1500 which corresponds with the second of the "four voyages". Another was written from Cape Verde in 1501 in the early part of the third of the four voyages, before crossing the Atlantic. The third letter was sent from Lisbon after the completion of that voyage.
Some have suggested that Vespucci, in the two letters published in his lifetime, was exaggerating his role and constructed deliberate fabrications. However, many scholars now believe that the two letters were not written by him but were fabrications by others based in part on genuine letters by Vespucci.
It was the publication and widespread circulation of the letters that might have led Martin Waldseemüller to name the new continent America on his world map of 1507 in Lorraine. Vespucci used a Latinised form of his name, Americus Vespucius, in his Latin writings, which Waldseemüller used as a base for the new name, taking the feminine form "America", according to the prevalent view (for other hypotheses, see the footnote in the introduction). The book accompanying the map stated: "I do not see what right any one would have to object to calling this part, after Americus who discovered it and who is a man of intelligence, Amerige, that is, the Land of Americus, or America: since both Europa and Asia got their names from women". It is possible that Vespucci was not aware that Waldseemüller had named the continent after him.
The two disputed letters claim that Vespucci made four voyages to America, while at most two can be verified from other sources. At the moment there is a dispute between historians on when Vespucci visited mainland the first time. Some historians like Germán Arciniegas and Gabriel Camargo Pérez think that his first voyage was done in June 1497 with the Spanish Pilot Juan de la Cosa.
Vespucci's real historical importance may well rest more in his letters, whether he wrote them all or not, than in his discoveries. From these letters, the European public learned about the newly discovered continents of the Americas for the first time; its existence became generally known throughout Europe within a few years of the letters' publication.
Voyages.
The first and fourth voyages are disputed to have occurred, while the second and third are certain voyages.
First voyage.
A letter published in 1504 purports to be an account by Vespucci, written to Soderini, of a lengthy visit to the New World, leaving Spain in May 1497 and returning in October 1498. However, modern scholars have doubted that this voyage took place, and consider this letter a forgery. Whoever did write the letter makes several observations of native customs, including use of hammocks and sweat lodges. The names of Amerigo Vespucci's ships were the San Antiago, Repertaga, Wegiz, and the Girmand.
Second voyage.
About 1499–1500, Vespucci joined an expedition in the service of Spain, with Alonso de Ojeda (or Hojeda) as the fleet commander. The intention was to sail around the southern end of the African mainland into the Indian Ocean. After hitting land at the coast of what is now Guyana, the two seem to have separated. Vespucci sailed southward, discovering the mouth of the Amazon River and reaching 6°S, before turning around and seeing Trinidad and the Orinoco River and returning to Spain by way of Hispaniola. The letter, to Lorenzo di Pierfrancesco de' Medici, claims that Vespucci determined his longitude celestially
on August 23, 1499, while on this voyage. However, that claim may be fraudulent, which could cast doubt on the letter's credibility.
Third voyage.
The last certain voyage of Vespucci was led by Gonçalo Coelho in 1501–1502 in the service of Portugal. Departing from Lisbon, the fleet sailed first to Cape Verde where they met two of Pedro Álvares Cabral's ships returning from India. In a letter from Cape Verde, Vespucci says that he hopes to visit the same lands that Álvares Cabral had explored, suggesting that the intention is to sail west to Asia, as on the 1499–1500 voyage. On reaching the coast of Brazil, they sailed south along the coast of South America to Rio de Janeiro's bay. If his own account is to be believed, he reached the latitude of Patagonia before turning back, although this also seems doubtful, since his account does not mention the broad estuary of the Río de la Plata, which he must have seen if he had gotten that far south. Portuguese maps of South America, created after the voyage of Coelho and Vespucci, do not show any land south of present-day Cananéia at 25° S, so this may represent the southernmost extent of their voyages.
After the first half of the expedition, Vespucci mapped Alpha and Beta Centauri, as well as the constellation Crux, the Southern Cross. Although these stars had been known to the ancient Greeks, gradual precession had lowered them below the European horizon so that they had been forgotten. On his return to Lisbon, Vespucci wrote in a letter to Medici that the land masses they explored were much larger than anticipated and different from the Asia described by Ptolemy or Marco Polo and therefore, must be a New World, that is, a previously unknown fourth continent, after Europe, Asia, and Africa.
Fourth voyage.
Vespucci's fourth voyage was another expedition for the Portuguese crown down the eastern coast of Brazil, that set out in May 1503 and returned to Portugal in June 1504. Like his alleged first voyage, Vespucci's last voyage in 1503–1504 is also disputed to have taken place. The only source of information for the last voyage is the "Letter to Soderini", but as several modern scholars dispute Vespucci's authorship of the letter to Soderini, it is also sometimes doubted whether Vespucci undertook this trip. However, Portuguese documents do confirm a voyage to Brazil was undertaken in 1503–04 by the captain Gonçalo Coelho, very likely the same captain of the 1501 mapping expedition (Vespucci's third voyage), and so it is quite possible that Vespucci went on board this one as well. However, it is not independently confirmed Vespucci was aboard and there are some difficulties in the reported dates and details.
The letters caused controversy after Vespucci's death, especially among the supporters of Columbus who believed Columbus' priority for the discovery of America was being undermined, and seriously damaged Vespucci's reputation.
Personal.
Vespucci was a cousin of the husband of Simonetta Vespucci. He died on February 22, 1512 in Seville, Spain, of an unknown cause.

</doc>
<doc id="2063" url="http://en.wikipedia.org/wiki?curid=2063" title="Aristide Maillol">
Aristide Maillol

Aristide Joseph Bonaventure Maillol (; December 8, 1861 – September 27, 1944) was a French sculptor, painter, and printmaker.
Biography.
Maillol was born in Banyuls-sur-Mer, Roussillon. He decided at an early age to become a painter, and moved to Paris in 1881 to study art. After several applications and several years of living with poverty, his enrollment in the École des Beaux-Arts was accepted in 1885, and he studied there under Jean-Léon Gérôme and Alexandre Cabanel. His early paintings show the influence of his contemporaries Pierre Puvis de Chavannes and Paul Gauguin.
Gauguin encouraged his growing interest in decorative art, an interest that led Maillol to take up tapestry design. In 1893 Maillol opened a tapestry workshop in Banyuls, producing works whose high technical and aesthetic quality gained him recognition for renewing this art form in France. He began making small terracotta sculptures in 1895, and within a few years his concentration on sculpture led to the abandonment of his work in tapestry.
In July of 1896, Maillol married Clotilde Narcisse, one of his employees at his tapestry workshop. Their only son, Lucian, was born that October. 
Maillol’s first major sculpture, A Seated Woman, was modeled after his wife. The first version was completed in 1902. That same year, dealer Ambroise Vollard provided Maillol with his first exhibition. 
The subject of nearly all of Maillol's mature work is the female body, treated with a classical emphasis on stable forms. The figurative style of his large bronzes is perceived as an important precursor to the greater simplifications of Henry Moore, and his serene classicism set a standard for European (and American) figure sculpture until the end of World War II.
Josep Pla said of Maillol, "These archaic ideas, Greek, were the great novelty Maillol brought into the tendency of modern sculpture. What you need to love from the ancients is not the antiquity, it is the sense of permanent, renewed novelty, that is due to the nature and reason."
His important public commissions include a 1912 commission for a monument to Cézanne, as well as numerous war memorials commissioned after World War I. 
Maillol served as a juror with Florence Meyer Blumenthal in awarding the Prix Blumenthal (1919–1954) a grant awarded to painters, sculptors, decorators, engravers, writers, and musicians.
He made a series of woodcut illustrations for an edition of Vergil's "Eclogues" published by Harry Graf Kessler in 1926–27. He also illustrated "Daphnis and Chloe" by Longus (1937) and "Chansons pour elle" by Paul Verlaine (1939).
He died in Banyuls at the age of eighty-three, in an automobile accident. While driving home during a thunderstorm, the car in which he was a passenger skidded off the road and rolled over. A large collection of Maillol's work is maintained at the Musée Maillol in Paris, which was established by Dina Vierny, Maillol's model and platonic companion during the last 10 years of his life. His home a few kilometers outside Banyuls, also the site of his final resting place, has been turned into a museum where a number of his works and sketches are displayed.
Three of his bronzes grace the grand staircase of the Metropolitan Opera House in New York City: "Summer" (1910–11), "Venus Without Arms" (1920), and" Kneeling Woman: Monument to Debussy" (1950–55). The third is the artist's only reference to music, created for a monument at Saint-Germain-en-Laye, Claude Debussy's birthplace.

</doc>
<doc id="2064" url="http://en.wikipedia.org/wiki?curid=2064" title="Antonio Canova">
Antonio Canova

Antonio Canova (; 1 November 1757 – 13 October 1822) was an Italian sculptor from the Republic of Venice who became famous for his marble sculptures that delicately rendered nude flesh. The epitome of the neoclassical style, his work marked a return to classical refinement after the theatrical excesses of Baroque sculpture. Among Canova's English pupils were sculptors Sir Richard Westmacott and John Gibson.
Early life in Possagno and Venice.
Antonio Canova was born in Possagno, a village of the Republic of Venice situated amid the recesses of the hills of Asolo, where these form the last undulations of the Venetian Alps, as they subside into the plains of Treviso. At three years of age Canova was deprived of both parents, his father dying and his mother remarrying. Their loss, however, was compensated by the tender solicitude and care of his paternal grandfather and grandmother, the latter of whom lived to experience in her turn the kindest personal attention from her grandson, who, when he had the means, gave her an asylum in his house at Rome.
His father and grandfather followed the occupation of stone-cutters or minor statuaries; and it is said that their family had for several ages supplied Possagno with members of that calling. As soon as Canova's hand could hold a pencil, he was initiated into the principles of drawing by his grandfather Pasino. The latter possessed some knowledge both of drawing and of architecture, designed well, and showed considerable taste in the execution of ornamental works. He was greatly attached to his art; and upon his young charge he looked as one who was to perpetuate, not only the family name, but also the family profession.
The early years of Canova were passed in study. The bias of his mind was to sculpture, and the facilities afforded for the gratification of this predilection in the workshop of his grandfather were eagerly improved. In his ninth year he executed two small shrines of Carrara marble, which are still extant. Soon after this period he appears to have been constantly employed under his grandfather. Amongst those who patronized the old man was the patrician family Falier of Venice, and by this means young Canova was first introduced to the senator of that name, who afterwards became his most zealous patron.
Between the younger son, Giuseppe Falier, and the artist a friendship commenced which terminated only with life. The senator Falier was induced to receive him under his immediate protection. It has been related by an Italian writer and since repeated by several biographers, that Canova was indebted to a trivial circumstance – the moulding of a lion in butter – for the warm interest which Falier took in his welfare. The anecdote may or may not be true. By his patron Canova was placed under Bernardi, or, as he is generally called by filiation, Giuseppe Torretto, a sculptor of considerable eminence, who had taken up a temporary residence at Pagnano, one of Asolo's boroughs
in the vicinity of the senator's mansion.
This took place whilst Canova was in his thirteenth year; and with Torretto he continued about two years, making in many respects considerable progress. This master returned to Venice, where he soon afterwards died; but by the high terms in which he spoke of his pupil to Falier, the latter was induced to bring the young artist to Venice, whither he accordingly went, and was placed under a nephew of Torretto. With this instructor he continued about a year, studying with the utmost assiduity.
After the termination of this engagement he began to work on his own account, and received from his patron an order for a group, "Orpheus and Eurydice". The first figure, which represents Eurydice in flames and smoke, in the act of leaving Hades, was completed towards the close of his sixteenth year. It was highly esteemed by his patron and friends, and the artist was now considered qualified to appear before a public tribunal.
The kindness of some monks supplied him with his first workshop, which was the vacant cell of a monastery. Here for nearly four years he labored with the greatest perseverance and industry. He was also regular in his attendance at the academy, where he carried off several prizes. But he relied far more on the study and imitation of nature. A large portion of his time was also devoted to anatomy, which science was regarded by him as the secret of the art. He likewise frequented places of public amusement, where he carefully studied the expressions and attitudes of the performers. He formed a resolution, which was faithfully adhered to for several years, never to close his eyes at night without having produced some design. Whatever was likely to forward his advancement in sculpture he studied with ardour. On archaeological pursuits he bestowed considerable attention. With ancient and modern history he rendered himself well acquainted and he also began to acquire some of the continental languages.
Three years had now elapsed without any production coming from his chisel. He began, however, to complete the group for his patron, and the "Orpheus" which followed, evinced the great advance he had made. The work was universally applauded, and laid the foundation of his fame. Several groups succeeded this performance, among which was that of "Daedalus and Icarus", the most celebrated work of his noviciate. The terseness of style and the faithful imitation of nature which characterized them called forth the warmest admiration. His merits and reputation being now generally recognized, his thoughts began to turn from the shores of the Adriatic to the banks of the Tiber, for which he set out at the commencement of his twenty-fourth year.
Career in Rome.
Before his departure for Rome, his friends had applied to the Venetian senate for a pension, to enable him to pursue his studies without embarrassment. The application was ultimately successful. The stipend amounted to three hundred ducats (about 60 pounds per annum), and was limited to three years. Canova had obtained letters of introduction to the Venetian ambassador, the Cavaliere Zulian, an enlightened and generous protector of the arts, and was received in the most hospitable manner.
His arrival in Rome, on 28 December 1780, marks a new era in his life. It was here he was to perfect himself by a study of the most splendid relics of antiquity, and to put his talents to the severest test by a competition with the living masters of the art. The result was equal to the highest hopes cherished either by himself or by his friends. The work which first established his fame at Rome was "Theseus Vanquishing the Minotaur", now in the collections of the Victoria & Albert Museum, in London. The figures are of the heroic size. The victorious Theseus is represented as seated on the lifeless body of the monster. The exhaustion which visibly pervades his whole frame proves the terrible nature of the conflict in which he has been engaged. Simplicity and natural expression had hitherto characterized Canova's style; with these were now united more exalted conceptions of grandeur and of truth. The Theseus was regarded with fervent admiration.
Canova's next undertaking was a monument in honor of Clement XIV; but before he proceeded with it he deemed it necessary to request permission from the Venetian senate, whose servant he considered himself to be, in consideration of the pension. This he solicited, in person, and it was granted. He returned immediately to Rome, and opened his celebrated studio close to the Via del Babuino. He spent about two years of unremitting toil in arranging the design and composing the models for the tomb of the pontiff. After these were completed, other two years were employed in finishing the monument, and it was finally opened to public inspection in 1787. The work, in the opinion of enthusiastic "dilettanti", stamped the author as the first artist of modern times.
After five years of incessant labor, he completed another cenotaph, to the memory of Clement XIII, which raised his fame still higher. Works now came rapidly from his chisel. Amongst these is "Psyche", with a butterfly, which is placed on the left hand, and held by the wings with the right. This figure, which is intended as a personification of man's immaterial part, is considered as in almost every respect the most faultless and classical of Canova's works. In two different groups, and with opposite expression, the sculptor has represented "Cupid" with his bride; in the one they are standing, in the other recumbent. These and other works raised his reputation so high that the most flattering offers were sent to him from the Russian court to induce him to remove to St Petersburg, but these were declined, although many of his finest works made their way to the Hermitage Museum. "Italy", says he, in writing of the occurrence to a friend, "Italy is my country – is the country and native soil of the arts. I cannot leave her; my infancy was nurtured here. If my poor talents can be useful in any other land, they must be of some utility to Italy; and ought not her claim to be preferred to all others?"
Numerous works were produced in the years 1795–1797, of which several were repetitions of previous productions. One was the celebrated group representing the "Parting of Venus and Adonis." This famous production was sent to Naples. The French Revolution was now extending its shocks over Italy; and Canova sought obscurity and repose in his native Possagno. Thither he retired in 1798, and there he continued for about a year, principally employed in painting, of which art also he had some knowledge. Events in the political world having come to a temporary lull, he returned to Rome; but his health being impaired from arduous application, he took a journey through a part of Germany, in company with his friend Prince Rezzonico. He returned from his travels much improved, and again commenced his labors with vigour and enthusiasm.
Trips to France and England.
 The events which marked the life of the artist during the first fifteen years of the period in which he was engaged on the above-mentioned works scarcely merit notice. His mind was entirely absorbed in the labors of his studio, and, with the exception of his journeys to Paris, one to Vienna, and a few short intervals of absence in Florence and other parts of Italy, he never quit Rome. In his own words, "his statues were the sole proofs of his civil existence."
There was, however, another proof, which modesty forbade him to mention, an ever-active benevolence, especially towards artists. In 1815 he was commissioned by the Pope to superintend the transmission from Paris of those works of art which had formerly been conveyed thither under the direction of Napoleon. By his zeal and exertions – for there were many conflicting interests to reconcile – he adjusted the affair in a manner at once creditable to his judgment and fortunate for his country.
In the autumn of this year he gratified a wish he had long entertained of visiting London, where he received the highest tokens of esteem. The artist for whom he showed particular sympathy and regard in London was Benjamin Haydon, who might at the time be counted the sole representative of historical painting there, and whom he especially honored for his championship of the then recently transported to England and ignorantly depreciated by polite connoisseurs Parthenon's marbles. As a matter of fact, the Elgin marbles - after an advice by Canova - were acquired by the British Museum, while plaster copies were sent to Florence, Italy, according to Canova's request.
Canova returned to Rome in the beginning of 1816, with the ransomed spoils of his country's genius. Immediately after, he received several marks of distinction: he was made President of the Accademia di San Luca, the main artistic institution in Rome, and by the hand of the Pope himself his name was inscribed in "the Golden Volume of the Capitol", and he received the title of Marquis of Ischia, with an annual pension of 3000 crowns.
Last projects.
He now contemplated a great work, a colossal statue of "Religion". The model filled Italy with admiration; the marble was procured, and the chisel of the sculptor ready to be applied to it, when the jealousy of churchmen as to the site, or some other cause, deprived the country of the projected work. The mind of Canova was inspired with the warmest sense of devotion, and though foiled in this instance he resolved to consecrate a shrine to the cause. In his native village he began to make preparations for erecting a temple which was to contain, not only the above statue, but other works of his own; within its precincts were to repose also the ashes of the founder. Accordingly he repaired to Possagno in 1819. After the foundation-stone of this edifice had been laid, Canova returned to Rome; but every succeeding autumn he continued to visit Possagno, in order to direct the workmen, and encourage them with pecuniary rewards and medals.
In the meantime the vast expenditure exhausted his resources, and compelled him to labor with unceasing assiduity notwithstanding age and disease. During the period which intervened between commencing operations at Possagno and his death, he executed or finished some of his most striking works. Amongst these were the group "Mars and Venus", the colossal figure of Pius VI, the Pietà, the "St John", the recumbent "Magdalen". The last performance which issued from his hand was a colossal bust of his friend, the Count Cicognara.
In May 1822 he paid a visit to Naples, to superintend the construction of wax moulds for an equestrian statue of the perjured Bourbon king Ferdinand VII. This journey materially injured his health, but he rallied again on his return to Rome. Towards the latter end of the year he paid his annual visit to the place of his birth, when he experienced a relapse. He proceeded to Venice, and expired there at the age of nearly sixty-five. His disease was one which had affected him from an early age, caused by the continual use of carving-tools, producing a depression of the ribs. The most distinguished funeral honors were paid to his remains, which were deposited in the temple at Possagno on 25 October 1822. His heart was interred in a marble pyramid he designed as a mausoleum for the painter Titian in the church of Santa Maria Gloriosa dei Frari in Venice, now a monument to the sculptor.
Notable works.
Among Canova's heroic compositions, his "Perseus with the Head of Medusa" (photo, right) appeared soon after his return from Germany. The moment of representation is when the hero, flushed with conquest, displays the head of the "snaky Gorgon", whilst the right hand grasps a sword of singular device. By a public decree, this fine work was placed in one of the stanze of the Vatican hitherto reserved for the most precious works of antiquity.
In 1802, at the personal request of Napoleon, Canova returned to Paris to model a bust of the first consul. The artist was entertained with munificence, and various honors were conferred upon him. The statue (photo, left), which is colossal and entitled "Napoleon as Mars the Peacemaker", was not finished till four years after. On the fall of the great emperor, Louis XVIII presented this statue to the British government, by whom it was afterwards given to the Duke of Wellington. It is now in Apsley House, Hyde Park corner, London.
"Palamedes," "Creugas and Damoxenus," the "Combat of Theseus and the Centaur," and "Hercules and Lichas" may close the class of heroic compositions, although the catalogue might be swelled by the enumeration of various others, such as "Hector and Ajax," King Ferdinand of Naples, and others. Canova's marble statue George Washington (photo, right) was commissioned by the State of North Carolina after the war of 1812 to be displayed in its Capitol Building. The work was finished 9 years later and transported via warship, steamship, and finally mule train before being dedicated on Christmas Eve.
Under the head of compositions of grace and elegance, the statue of "Hebe" takes the first place in point of date. Four times has the artist embodied in stone the goddess of youth, and each time with some variation. The last one is in the Museum of Forlì, in Italy. The only material improvement, however, is the substitution of a support more suitable to the simplicity of the art. Each of the statues is elegant in expression, attitude, and delicacy of finish.
The "Dancing Nymphs" maintain a character similar to that of the "Hebe". "The Three Graces" and the "Venus" are more elevated. The "Awakened Nymph" is another notable work. The mother of Napoleon, his consort Maria Louise (as "Concord"), to model whom the author made a further journey to Paris in 1810, the princess Esterhazy and the muse Polymnia (Elisa Bonaparte) take their place in this class, as do the ideal heads, comprising "Corinna", "Sappho", "Laura", "Beatrice" and "Helen of Troy".
Of the cenotaphs and funeral monuments the most splendid is the monument to the archduchess Maria Christina, Duchess of Teschen, consisting of nine figures. Besides the two for the Roman Pontiffs already mentioned, there is one for Alfieri, another for Emo, a Venetian admiral, and a small model of a cenotaph for Horatio Nelson, besides a great variety of monumental relieves such as the Stele Tadini in the Chapel of the Accademia Tadini in Lovere. George Anthony Legh Keck was known to have collected some of Antonio Canovas sculptures and had them on display at his jacobean mansion house of Bank Hall in Bretherton. After the death of Legh Keck in 1860 the sculptures where auctioned off, their whereabouts is unknown.
References, notes and sources.
Canova, SD was named after Antonio Canova

</doc>
<doc id="2065" url="http://en.wikipedia.org/wiki?curid=2065" title="Auguste Rodin">
Auguste Rodin

François-Auguste-René Rodin (12 November 1840 – 17 November 1917), known as Auguste Rodin ( ; ), was a French sculptor. Although Rodin is generally considered the progenitor of modern sculpture, he did not set out to rebel against the past. He was schooled traditionally, took a craftsman-like approach to his work, and desired academic recognition, although he was never accepted into Paris's foremost school of art.
Sculpturally, Rodin possessed a unique ability to model a complex, turbulent, deeply pocketed surface in clay. Many of his most notable sculptures were roundly criticized during his lifetime. They clashed with the predominant figure sculpture tradition, in which works were decorative, formulaic, or highly thematic. Rodin's most original work departed from traditional themes of mythology and allegory, modeled the human body with realism, and celebrated individual character and physicality. Rodin was sensitive to the controversy surrounding his work, but refused to change his style. Successive works brought increasing favor from the government and the artistic community.
From the unexpected realism of his first major figure – inspired by his 1875 trip to Italy – to the unconventional memorials whose commissions he later sought, Rodin's reputation grew, such that he became the preeminent French sculptor of his time. By 1900, he was a world-renowned artist. Wealthy private clients sought Rodin's work after his World's Fair exhibit, and he kept company with a variety of high-profile intellectuals and artists. He married his lifelong companion, Rose Beuret, in the last year of both their lives. His sculptures suffered a decline in popularity after his death in 1917, but within a few decades, his legacy solidified. Rodin remains one of the few sculptors widely known outside the visual arts community.
Biography.
Formative years.
Rodin was born in 1840 into a working-class family in Paris, the second child of Marie Cheffer and Jean-Baptiste Rodin, who was a police department clerk. He was largely self-educated, and began to draw at age ten. Between ages 14 and 17, Rodin attended the "Petite École", a school specializing in art and mathematics, where he studied drawing and painting. His drawing teacher, Horace Lecoq de Boisbaudran, believed in first developing the personality of his students so that they observed with their own eyes and drew from their recollections. Rodin still expressed appreciation for his teacher much later in life. It was at Petite École that he first met Jules Dalou and Alphonse Legros.
In 1857, Rodin submitted a clay model of a companion to the "Grand École" in an attempt to win entrance; he did not succeed, and two further applications were also denied. Given that entrance requirements at the "Grand École" were not particularly high, the rejections were considerable setbacks. Rodin's inability to gain entrance may have been due to the judges' Neoclassical tastes, while Rodin had been schooled in light, 18th-century sculpture. Leaving the "Petite École" in 1857, Rodin earned a living as a craftsman and ornamenter for most of the next two decades, producing decorative objects and architectural embellishments.
Rodin's sister Maria, two years his senior, died of peritonitis in a convent in 1862. Her brother was anguished, and felt guilty because he had introduced Maria to an unfaithful suitor. Turning away from art, Rodin briefly joined a Catholic order, the Congregation of the Blessed Sacrament. Saint Peter Julian Eymard, founder and head of the congregation, recognized Rodin's talent and, sensing his lack of suitability for the order, encouraged Rodin to continue with his sculpture. He returned to work as a decorator, while taking classes with animal sculptor Antoine-Louis Barye. The teacher's attention to detail – his finely rendered musculature of animals in motion – significantly influenced Rodin.
In 1864, Rodin began to live with a young seamstress named Rose Beuret, with whom he would stay – with ranging commitment – for the rest of his life. The couple had a son, Auguste-Eugène Beuret (1866–1934). That year, Rodin offered his first sculpture for exhibition, and entered the studio of Albert-Ernest Carrier-Belleuse, a successful mass producer of "objets d'art". Rodin worked as Carrier-Belleuse' chief assistant until 1870, designing roof decorations and staircase and doorway embellishments. With the arrival of the Franco-Prussian War, Rodin was called to serve in the National Guard, but his service was brief due to his near-sightedness. Decorators' work had dwindled because of the war, yet Rodin needed to support his family; poverty was a continual difficulty for Rodin until about the age of 30. Carrier-Belleuse soon asked Rodin to join him in Belgium, where they would work on ornamentation for Brussels' bourse.
Rodin planned to stay in Belgium a few months, but he spent the next six years out of France. It was a pivotal time in his life. He had acquired skill and experience as a craftsman, but no one had yet seen his art, which sat in his workshop, since he could not afford castings. Though his relationship with Carrier-Belleuse deteriorated, Rodin found other employment in Brussels, displaying some works at salons, and his companion Rose soon joined him there. Having saved enough money to travel, Rodin visited Italy for two months in 1875, where he was drawn to the work of Donatello and Michelangelo. Their work had a profound effect on his artistic direction. Rodin said, "It is Michelangelo who has freed me from academic sculpture." Returning to Belgium, he began work on "The Age of Bronze", a life-size male figure whose realism brought Rodin attention but led to accusations of sculptural cheating.
Artistic independence.
Rose Beuret and Rodin returned to Paris in 1877, moving into a small flat on the Left Bank. Misfortune surrounded Rodin: his mother, who had wanted to see her son marry, was dead, and his father was blind and senile, cared for by Rodin's sister-in-law, Aunt Thérèse. Rodin's eleven-year-old son Auguste, possibly developmentally delayed, was also in the ever-helpful Thérèse's care. Rodin had essentially abandoned his son for six years, and would have a very limited relationship with him throughout his life. Father and son now joined the couple in their flat, with Rose as caretaker. The charges of fakery surrounding "The Age of Bronze" continued. Rodin increasingly sought more soothing female companionship in Paris, and Rose stayed in the background.
Rodin earned his living collaborating with more established sculptors on public commissions, primarily memorials and neo-baroque architectural pieces in the style of Carpeaux. In competitions for commissions he submitted models of Denis Diderot, Jean-Jacques Rousseau, and Lazare Carnot, all to no avail. On his own time, he worked on studies leading to the creation of his next important work, "St. John the Baptist Preaching".
In 1880, Carrier-Belleuse – now art director of the Sèvres national porcelain factory – offered Rodin a part-time position as a designer. The offer was in part a gesture of reconciliation, and Rodin accepted. That part of Rodin which appreciated 18th-century tastes was aroused, and he immersed himself in designs for vases and table ornaments that brought the factory renown across Europe.
The artistic community appreciated his work in this vein, and Rodin was invited to Paris Salons by such friends as writer Léon Cladel. During his early appearances at these social events, Rodin seemed shy; in his later years, as his fame grew, he displayed the loquaciousness and temperament for which he is better known. French statesman Leon Gambetta expressed a desire to meet Rodin, and the sculptor impressed him when they met at a salon. Gambetta spoke of Rodin in turn to several government ministers, likely including Edmund Turquet, the Undersecretary of the Ministry of Fine Arts, whom Rodin eventually met.
Rodin's relationship with Turquet was rewarding: through him, he won the 1880 commission to create a portal for a planned museum of decorative arts. Rodin dedicated much of the next four decades to his elaborate "Gates of Hell", an unfinished portal for a museum that was never built. Many of the portal's figures became sculptures in themselves, including Rodin's most famous, "The Thinker" and "The Kiss". With the museum commission came a free studio, granting Rodin a new level of artistic freedom. Soon, he stopped working at the porcelain factory; his income came from private commissions.
In 1883, Rodin agreed to supervise a course for sculptor Alfred Boucher in his absence, where he met the 18-year-old Camille Claudel. The two formed a passionate but stormy relationship and influenced each other artistically. Claudel inspired Rodin as a model for many of his figures, and she was a talented sculptor, assisting him on commissions.
Although busy with "The Gates of Hell", Rodin won other commissions. He pursued an opportunity to create a historical monument for the town of Calais. For a monument to French author Honoré de Balzac, Rodin was chosen in 1891. His execution of both sculptures clashed with traditional tastes, and met with varying degrees of disapproval from the organizations that sponsored the commissions. Still, Rodin was gaining support from diverse sources that propelled him toward fame.
In 1889, the Paris Salon invited Rodin to be a judge on its artistic jury. Though Rodin's career was on the rise, Claudel and Beuret were becoming increasingly impatient with Rodin's "double life". Claudel and Rodin shared an atelier at a small old castle, but Rodin refused to relinquish his ties to Beuret, his loyal companion during the lean years, and mother of his son. During one absence, Rodin wrote to Beuret, "I think of how much you must have loved me to put up with my caprices...I remain, in all tenderness, your Rodin." Claudel and Rodin parted in 1898. Claudel suffered a nervous breakdown several years later and was confined to an institution by her family until her death.
Works.
In 1864, Rodin submitted his first sculpture for exhibition, "The Man with the Broken Nose", to the Paris Salon. The subject was an elderly neighbourhood street porter. The unconventional bronze piece was not a traditional bust, but instead the head was "broken off" at the neck, the nose was flattened and crooked, and the back of the head was absent, having fallen off the clay model in an accident. The work emphasized texture and the emotional state of the subject; it illustrated the "unfinishedness" that would characterize many of Rodin's later sculptures. The Salon rejected the piece.
Early figures: the inspiration of Italy.
In Brussels, Rodin created his first full-scale work, "The Age of Bronze", having returned from Italy. Modelled by a Belgian soldier, the figure drew inspiration from Michelangelo's "Dying Slave", which Rodin had observed at the Louvre. Attempting to combine Michelangelo's mastery of the human form with his own sense of human nature, Rodin studied his model from all angles, at rest and in motion; he mounted a ladder for additional perspective, and made clay models, which he studied by candlelight. The result was a life-size, well-proportioned nude figure, posed unconventionally with his right hand atop his head, and his left arm held out at his side, forearm parallel to the body.
In 1877, the work debuted in Brussels and then was shown at the Paris Salon. The statue's apparent lack of a theme was troubling to critics – commemorating neither mythology nor a noble historical event – and it is not clear whether Rodin intended a theme. He first titled the work "The Vanquished", in which form the left hand held a spear, but he removed the spear because it obstructed the torso from certain angles. After two more intermediary titles, Rodin settled on "The Age of Bronze", suggesting the Bronze Age, and in Rodin's words, "man arising from nature". Later, however, Rodin said that he had had in mind "just a simple piece of sculpture without reference to subject".
Its mastery of form, light, and shadow made the work look so realistic that Rodin was accused of "surmoulage" – having taken a cast from a living model. Rodin vigorously denied the charges, writing to newspapers and having photographs taken of the model to prove how the sculpture differed. He demanded an inquiry and was eventually exonerated by a committee of sculptors. Leaving aside the false charges, the piece polarized critics. It had barely won acceptance for display at the Paris Salon, and criticism likened it to "a statue of a sleepwalker" and called it "an astonishingly accurate copy of a low type". Others rallied to defend the piece and Rodin's integrity. The government minister Turquet admired the piece, and "The Age of Bronze" was purchased by the state for 2,200 francs – what it had cost Rodin to have it cast in bronze.
A second male nude, "St. John the Baptist Preaching", was completed in 1878. Rodin sought to avoid another charge of "surmoulage" by making the statue larger than life: "St. John" stands almost 6' 7"" (2 m). While "The Age of Bronze" is statically posed, "St. John" gestures and seems to move toward the viewer. The effect of walking is achieved despite the figure having both feet firmly on the ground – a physical impossibility, and a technical achievement that was lost on most contemporary critics. Rodin chose this contradictory position to, in his words, "display simultaneously...views of an object which in fact can be seen only successively".
Despite the title, "St. John the Baptist Preaching" did not have an obviously religious theme. The model, an Italian peasant who presented himself at Rodin's studio, possessed an idiosyncratic sense of movement that Rodin felt compelled to capture. Rodin thought of John the Baptist, and carried that association into the title of the work. In 1880, Rodin submitted the sculpture to the Paris Salon. Critics were still mostly dismissive of his work, but the piece finished third in the Salon's sculpture category.
Regardless of the immediate receptions of "St. John" and "The Age of Bronze", Rodin had achieved a new degree of fame. Students sought him at his studio, praising his work and scorning the charges of "surmoulage". The artistic community knew his name.
"The Gates of Hell".
A commission to create a portal for Paris' planned Museum of Decorative Arts was awarded to Rodin in 1880. Although the museum was never built, Rodin worked throughout his life on "The Gates of Hell", a monumental sculptural group depicting scenes from Dante's "Inferno" in high relief. Often lacking a clear conception of his major works, Rodin compensated with hard work and a striving for perfection.
He conceived "The Gates" with the "surmoulage" controversy still in mind: "...I had made the "St. John" to refute [the charges of casting from a model], but it only partially succeeded. To prove completely that I could model from life as well as other sculptors, I determined...to make the sculpture on the door of figures smaller than life." Laws of composition gave way to the "Gates"' disordered and untamed depiction of Hell. The figures and groups in this, Rodin's meditation on the condition of man, are physically and morally isolated in their torment.
"The Gates of Hell" comprised 186 figures in its final form. Many of Rodin's best-known sculptures started as designs of figures for this composition, such as "The Thinker", "The Three Shades", and "The Kiss", and were only later presented as separate and independent works. Other well-known works derived from "The Gates" are "Ugolino", "Fugit Amor", "The Falling Man", and "The Prodigal Son".
"The Thinker" (originally titled "The Poet", after Dante) was to become one of the most well-known sculptures in the world. The original was a -high bronze piece created between 1879 and 1889, designed for the "Gates"' lintel, from which the figure would gaze down upon Hell. While "The Thinker" most obviously characterizes Dante, aspects of the Biblical Adam, the mythological Prometheus, and Rodin himself have been ascribed to him. Other observers de-emphasize the apparent intellectual theme of "The Thinker", stressing the figure's rough physicality and the emotional tension emanating from it.
"The Burghers of Calais".
The town of Calais had contemplated a historical monument for decades when Rodin learned of the project. He pursued the commission, interested in the medieval motif and patriotic theme. The mayor of Calais was tempted to hire Rodin on the spot upon visiting his studio, and soon the memorial was approved, with Rodin as its architect. It would commemorate the six townspeople of Calais who offered their lives to save their fellow citizens.
During the Hundred Years' War, the army of King Edward III besieged Calais, and Edward ordered that the town's population be killed "en masse". He agreed to spare them if six of the principal citizens would come to him prepared to die, bareheaded and barefooted and with ropes around their necks. When they came, he ordered that they be executed, but pardoned them when his queen, Philippa of Hainault, begged him to spare their lives. "The Burghers of Calais" depicts the men as they are leaving for the king's camp, carrying keys to the town's gates and citadel.
Rodin began the project in 1884, inspired by the chronicles of the siege by Jean Froissart. Though the town envisioned an allegorical, heroic piece centered on Eustache de Saint-Pierre, the eldest of the six men, Rodin conceived the sculpture as a study in the varied and complex emotions under which all six men were laboring. One year into the commission, the Calais committee was not impressed with Rodin's progress. Rodin indicated his willingness to end the project rather than change his design to meet the committee's conservative expectations, but Calais said to continue.
In 1889, "The Burghers of Calais" was first displayed to general acclaim. It is a bronze sculpture weighing two tons (1,814 kg), and its figures are 6.6 ft (2 m) tall. The six men portrayed do not display a united, heroic front; rather, each is isolated from his brothers, individually deliberating and struggling with his expected fate. Rodin soon proposed that the monument's high pedestal be eliminated, wanting to move the sculpture to ground level so that viewers could "penetrate to the heart of the subject". At ground level, the figures' positions lead the viewer around the work, and subtly suggest their common movement forward.
The committee was incensed by the untraditional proposal, but Rodin would not yield. In 1895, Calais succeeded in having "Burghers" displayed in their preferred form: the work was placed in front of a public garden on a high platform, surrounded by a cast-iron railing. Rodin had wanted it located near the town hall, where it would engage the public. Only after damage during the First World War, subsequent storage, and Rodin's death was the sculpture displayed as he had intended. It is one of Rodin's best-known and most acclaimed works.
Commissions and controversy.
Commissioned to create a monument to French writer Victor Hugo in 1889, Rodin dealt extensively with the subject of "artist and muse". Like many of Rodin's public commissions, "Monument to Victor Hugo" was met with resistance because it did not fit conventional expectations. Commenting on Rodin's monument to Victor Hugo, "The Times" in 1909 expressed that "there is some show of reason in the complaint that [Rodin's] conceptions are sometimes unsuited to his medium, and that in such cases they overstrain his vast technical powers". The 1897 plaster model was not cast in bronze until 1964.
The "Société des Gens des Lettres", a Parisian organization of writers, planned a monument to French novelist Honoré de Balzac immediately after his death in 1850. The society commissioned Rodin to create the memorial in 1891, and Rodin spent years developing the concept for his sculpture. Challenged in finding an appropriate representation of Balzac given the author's rotund physique, Rodin produced many studies: portraits, full-length figures in the nude, wearing a frock coat, or in a robe – a replica of which Rodin had requested. The realized sculpture displays Balzac cloaked in the drapery, looking forcefully into the distance with deeply gouged features. Rodin's intent had been to show Balzac at the moment of conceiving a work – to express courage, labor, and struggle.
When "Balzac" was exhibited in 1898, the negative reaction was not surprising. The "Société" rejected the work, and the press ran parodies. Criticizing the work, Morey (1918) reflected, "there may come a time, and doubtless will come a time, when it will not seem "outre" to represent a great novelist as a huge comic mask crowning a bathrobe, but even at the present day this statue impresses one as slang." A modern critic, indeed, indicates that "Balzac" is one of Rodin's masterpieces.
The monument had its supporters in Rodin's day; a manifesto defending him was signed by Monet, Debussy, and future Premier Georges Clemenceau, among many others. In the BBC series Civilization, art historian Kenneth Clark praised the monument as "the greatest piece of sculpture of the 19th Century, perhaps, indeed, the greatest since Michelangelo." Rather than try to convince skeptics of the merit of the monument, Rodin repaid the "Société" his commission and moved the figure to his garden. After this experience, Rodin did not complete another public commission. Only in 1939 was "Monument to Balzac" cast in bronze.
Other works.
The popularity of Rodin's most famous sculptures tends to obscure his total creative output. A prolific artist, he created thousands of busts, figures, and sculptural fragments over more than five decades. He painted in oils (especially in his thirties) and in watercolors. The Musée Rodin holds 7,000 of his drawings and prints, in chalk and charcoal, and thirteen vigorous drypoints. He also produced a single lithograph.
Portraiture was an important component of Rodin's oeuvre, helping him to win acceptance and financial independence. His first sculpture was a bust of his father in 1860, and he produced at least 56 portraits between 1877 and his death in 1917. Early subjects included fellow sculptor Jules Dalou (1883) and companion Camille Claudel (1884).
Later, with his reputation established, Rodin made busts of prominent contemporaries such as English politician George Wyndham (1905), Irish playwright George Bernard Shaw (1906), Austrian composer Gustav Mahler (1909), former Argentinian president Domingo Faustino Sarmiento and French statesman Georges Clemenceau (1911).
His undated drawing "Study of a Woman Nude, Standing, Arms Raised, Hands Crossed Above Head" is one of the works seized in 2012 from Cornelius Gurlitt.
Aesthetic.
Rodin was a naturalist, less concerned with monumental expression than with character and emotion. Departing with centuries of tradition, he turned away from the idealism of the Greeks, and the decorative beauty of the Baroque and neo-Baroque movements. His sculpture emphasized the individual and the concreteness of flesh, and suggested emotion through detailed, textured surfaces, and the interplay of light and shadow. To a greater degree than his contemporaries, Rodin believed that an individual's character was revealed by his physical features.
Rodin's talent for surface modeling allowed him to let every part of the body speak for the whole. The male's passion in "The Thinker" is suggested by the grip of his toes on the rock, the rigidness of his back, and the differentiation of his hands. Speaking of "The Thinker", Rodin illuminated his aesthetic: "What makes my Thinker think is that he thinks not only with his brain, with his knitted brow, his distended nostrils and compressed lips, but with every muscle of his arms, back, and legs, with his clenched fist and gripping toes."
Sculptural fragments to Rodin were autonomous works, and he considered them the essence of his artistic statement. His fragments – perhaps lacking arms, legs, or a head – took sculpture further from its traditional role of portraying likenesses, and into a realm where forms existed for their own sake. Notable examples are "The Walking Man", "Meditation without Arms", and "Iris, Messenger of the Gods".
Rodin saw suffering and conflict as hallmarks of modern art. "Nothing, really, is more moving than the maddened beast, dying from unfulfilled desire and asking in vain for grace to quell its passion." Charles Baudelaire echoed those themes, and was among Rodin's favorite poets. Rodin enjoyed music, especially the opera composer Gluck, and wrote a book about French cathedrals. He owned a work by the as-yet-unrecognized Van Gogh, and admired the forgotten El Greco.
Method.
Instead of copying traditional academic postures, Rodin preferred his models to move naturally around his studio (despite their nakedness). The sculptor often made quick sketches in clay that were later fine-tuned, cast in plaster, and forged into bronze or carved in marble. Rodin's focus was on the handling of clay.
George Bernard Shaw sat for a portrait and gave an idea of Rodin's technique: "While he worked, he achieved a number of miracles. At the end of the first fifteen minutes, after having given a simple idea of the human form to the block of clay, he produced by the action of his thumb a bust so living that I would have taken it away with me to relieve the sculptor of any further work."
He described the evolution of his bust over a month, passing through "all the stages of art's evolution": first, a "Byzantine masterpiece", then "Bernini intermingled", then an elegant Houdon. "The hand of Rodin worked not as the hand of a sculptor works, but as the work of "Elan Vital". The "Hand of God" is his own hand."
After he completed his work in clay, he employed highly skilled assistants to re-sculpt his compositions at larger sizes (including any of his large-scale monuments such as "The Thinker"), to cast the clay compositions into plaster or bronze, and to carve his marbles. Rodin's major innovation was to capitalize on such multi-staged processes of 19th century sculpture and their reliance on plaster casting.
Since clay deteriorates rapidly if not kept wet or fired into a terra-cotta, sculptors used plaster casts as a means of securing the composition they would make out of the fugitive material that is clay. This was common practice amongst Rodin's contemporaries, and sculptors would exhibit plaster casts with the hopes that they would be commissioned to have the works made in a more permanent material. Rodin, however, would have multiple plasters made and treat them as the raw material of sculpture, recombining their parts and figures into new compositions, and new names.
As Rodin's practice developed into the 1890s, he became more and more radical in his pursuit of fragmentation, the combination of figures at different scales, and the making of new compositions from his earlier work. A prime example of this is the bold "The Walking Man" (1899–1900), which was exhibited as his major one-person show in 1900. This is composed of two sculptures from the 1870s that Rodin found in his studio – a broken and damaged torso that had fallen into neglect and the lower extremities of a statuette version of his 1878 "St. John the Baptist Preaching" he was having re-sculpted at a reduced scale.
Without finessing the join between upper and lower, between torso and legs, Rodin created a work that many sculptors at the time and subsequently have seen as one of his strongest and most singular works. This is despite the fact that the object conveys two different styles, exhibits two different attitudes toward finish, and lacks any attempt to hide the arbitrary fusion of these two components. It was the freedom and creativity with which Rodin used these practices – along with his activation surfaces of sculptures through traces of his own touch and with his more open attitude toward bodily pose, sensual subject matter, and non-realistic surface – that marked Rodin's re-making of traditional 19th century sculptural techniques into the prototype for modern sculpture.
Later years (1900–1917).
By 1900, Rodin's artistic reputation was entrenched. Gaining exposure from a pavilion of his artwork set up near the 1900 World's Fair ("Exposition Universelle") in Paris, he received requests to make busts of prominent people internationally, while his assistants at the atelier produced duplicates of his works. His income from portrait commissions alone totalled probably 200,000 francs a year. As Rodin's fame grew, he attracted many followers, including the German poet Rainer Maria Rilke, and authors Octave Mirbeau, Joris-Karl Huysmans, and Oscar Wilde.
Rilke stayed with Rodin in 1905 and 1906, and did administrative work for him; he would later write a laudatory monograph on the sculptor. Rodin and Beuret's modest country estate in Meudon, purchased in 1897, was a host to such visitors as King Edward, dancer Isadora Duncan, and harpsichordist Wanda Landowska. Rodin moved to the city in 1908, renting the main floor of the Hôtel Biron, an 18th-century townhouse. He left Beuret in Meudon, and began an affair with the American-born Duchesse de Choiseul.
America.
While Rodin was beginning to be accepted in France by the time of "The Burghers of Calais", he had not yet conquered the American market and because of his technique and the frankness of some of his work, he did not have an easy time selling his work to American industrialists. Fortunately, he came to know Sarah Tyson Hallowell (1846–1924), a curator from Chicago who visited Paris to arrange exhibitions at the large Interstate Expositions of the 1870s and 1880s. Hallowell was not only a curator but an adviser and a facilitator who was trusted by a number of prominent American collectors to suggest works for their collections, the most prominent of these being the Chicago hotelier Potter Palmer and his wife, Bertha Palmer (1849–1918).
The next opportunity for Rodin in America was the 1893 Chicago World's Fair. Hallowell wanted to help promote Rodin's work and he suggested a solo exhibition, which she wrote him was "beaucoup moins beau que l'original" but impossible, outside the rules. Instead, she suggested he send a number of works for her loan exhibition of French art from American collections and she told him she would list them as being part of an American collection. Rodin sent Hallowell three works, "Cupid and Psyche", "Sphinx" and "Andromeda". All nudes, these works provoked great controversy and were ultimately hidden behind a drape with special permission given for viewers to see them.
Fortunately, "Bust of Dalou" and "Burgher of Calais" were on display in the official French pavilion at the fair and so between the works that were on display and those that were not, he was noticed. However, the works he gave Hallowell to sell found no takers, but she soon brought the controversial Quaker-born financier Charles Yerkes (1837–1905) into the fold and he purchased two large marbles for his Chicago manse; Yerkes was likely the first American to own a Rodin sculpture.
Other collectors soon followed including the tastemaking Potter Palmers of Chicago and Isabella Stewart Gardner (1840–1924) of Boston, all arranged by Sarah Hallowell. In appreciation for her efforts at unlocking the American market, Rodin eventually presented Hallowell with a bronze, a marble and a terra cotta. When Hallowell moved to Paris in 1893, she and Rodin continued their warm friendship and correspondence, which lasted to the end of the sculptor's life. After Hallowell's death, her niece, the painter Harriet Hallowell, inherited the Rodin's and after her death, the American heirs could not manage to match their value in order to export them, so they became the property of the French state.
Great Britain.
After the start of the 20th century, Rodin was a regular visitor to Great Britain, where he developed a loyal following by the beginning of the First World War. He first visited England in 1881, where his friend, the artist Alphonse Legros, had introduced him to the poet William Ernest Henley. With his personal connections and enthusiasm for Rodin's art, Henley was most responsible for Rodin's reception in Britain. (Rodin later returned the favor by sculpting a that was used as the frontispiece to Henley's collected works and, after his death, on his monument in London.
Through Henley, Rodin met Robert Louis Stevenson and Robert Browning, in whom he found further support. Encouraged by the enthusiasm of British artists, students, and high society for his art, Rodin donated a significant selection of his works to the nation in 1914.
After the revitalization of the Société Nationale des Beaux-Arts in 1890, Rodin served as the body's vice-president. In 1903, Rodin was elected president of the International Society of Painters, Sculptors, and Engravers. He replaced its former president, James Abbott McNeill Whistler, upon Whistler's death. His election to the prestigious position was largely due to the efforts of Albert Ludovici, father of English philosopher Anthony Ludovici.
During his later creative years, Rodin's work turned increasingly toward the female form, and themes of more overt masculinity and femininity. He concentrated on small dance studies, and produced numerous erotic drawings, sketched in a loose way, without taking his pencil from the paper or his eyes from the model. Rodin met American dancer Isadora Duncan in 1900, attempted to seduce her, and the next year sketched studies of her and her students. In July 1906, Rodin was also enchanted by dancers from the Royal Ballet of Cambodia, and produced some of his most famous drawings from the experience.
Fifty-three years into their relationship, Rodin married Rose Beuret. The wedding was 29 January 1917, and Beuret died two weeks later, on 16 February. Rodin was ill that year; in January, he suffered weakness from influenza, and on 16 November his physician announced that "congestion of the lungs has caused great weakness. The patient's condition is grave." Rodin died the next day, age 77, at his villa in Meudon, Île-de-France, on the outskirts of Paris.
A cast of "The Thinker" was placed next to his tomb in Meudon; it was Rodin's wish that the figure serve as his headstone and epitaph. In 1923, Marcell Tirel, Rodin's secretary, published a book alleging that Rodin's death was largely due to cold, and the fact that he had no heat at Meudon. Rodin requested permission to stay in the Hotel Biron, a museum of his works, but the director of the museum refused to let him stay there.
Legacy.
Rodin willed to the French state his studio and the right to make casts from his plasters. Because he encouraged the edition of his sculpted work, Rodin's sculptures are represented in many public and private collections. The Musée Rodin was founded in 1916 and opened in 1919 at the Hôtel Biron, where Rodin had lived, and it holds the largest Rodin collection, with more than 6,000 sculptures and 7,000 works on paper.
The relative ease of making reproductions has also encouraged many forgeries: a survey of expert opinion placed Rodin in the top ten most-faked artists. Rodin fought against forgeries of his works as early as 1901, and since his death, many cases of organized, large-scale forgeries have been revealed. A massive forgery was discovered by French authorities in the early 1990s and led to the conviction of art dealer Guy Hain.
To deal with the complexity of bronze reproduction, France has promulgated several laws since 1956 which limit reproduction to twelve casts – the maximum number that can be made from an artist's plasters and still be considered his work. As a result of this limit, "The Burghers of Calais", for example, is found in fourteen cities.
In the market for sculpture, plagued by fakes, the value of a piece increases significantly when its provenance can be established. A Rodin work with a verified history sold for US$4.8 million in 1999, and Rodin's bronze "Eve, grand modele – version sans rocher" sold for $18.9 million at a 2008 Christie's auction in New York. Art critics concerned about authenticity have argued that taking a cast does not equal reproducing a Rodin sculpture – especially given the importance of surface treatment in Rodin's work.
During his lifetime, Rodin was compared to Michelangelo, and was widely recognized as the greatest artist of the era. In the three decades following his death, his popularity waned with changing aesthetic values. Since the 1950s, Rodin's reputation has re-ascended; he is recognized as the most important sculptor of the modern era, and has been the subject of much scholarly work. The sense of incompletion offered by some of his sculpture, such as "The Walking Man", influenced the increasingly abstract sculptural forms of the 20th century.
Though highly honoured for his artistic accomplishments, Rodin did not spawn a significant, lasting school of followers. His notable students included Antoine Bourdelle, Charles Despiau, the American Malvina Hoffman, and his mistress Camille Claudel, whose sculpture received praise in France. The French order "Légion d'honneur" made him a Commander, and he received an honorary doctorate from the University of Oxford.
Rodin restored an ancient role of sculpture – to capture the physical and intellectual force of the human subject – and he freed sculpture from the repetition of traditional patterns, providing the foundation for greater experimentation in the 20th century. His popularity is ascribed to his emotion-laden representations of ordinary men and women – to his ability to find the beauty and pathos in the human animal. His most popular works, such as "The Kiss" and "The Thinker", are widely used outside the fine arts as symbols of human emotion and character. To honour Rodin's artistic legacy, the Google search engine homepage displayed a Google Doodle featuring "The Thinker" to celebrate his 172nd birthday on 12 November 2012.
In 2011 the world premiere of Boris Eifman's new ballet "Rodin" took place in Saint-Petersburg, Russia. The ballet is dedicated to the life and work of Auguste Rodin and Camille Claudel.

</doc>
<doc id="2067" url="http://en.wikipedia.org/wiki?curid=2067" title="Ann Arbor, Michigan">
Ann Arbor, Michigan

Ann Arbor is a city in the US state of Michigan and the county seat of Washtenaw County. The 2010 census recorded its population to be 113,934, making it the sixth largest city in Michigan. The Ann Arbor Metropolitan Statistical Area (MSA) includes all of Washtenaw County, which had a population of 344,791 as of 2010. The city is also part of the larger Detroit–Ann Arbor–Flint, MI Combined Statistical Area (CSA).
Ann Arbor was founded in 1824, named for wives of the village's founders and the stands of Bur Oak trees. The University of Michigan moved from Detroit to Ann Arbor in 1837, and the city showed steady growth throughout the 19th and 20th centuries, except during the Depression of 1873. During the 1960s and 1970s, the city gained a reputation as a center for left-wing politics. Ann Arbor became a focal point for political activism and served as a hub for the civil-rights movement and anti-Vietnam War movement, as well as various student movements.
Ann Arbor is home to the University of Michigan, an institution of higher education. The university shapes Ann Arbor's economy significantly as it employs about 30,000 workers, including about 12,000 in the medical center. The city's economy is also centered on high technology, with several companies drawn to the area by the university's research and development money, and by its graduates.
History.
Ann Arbor was founded in 1824 by land speculators John Allen and Elisha Walker Rumsey. On 25 May 1824, the town plat was registered with Wayne County as "Annarbour;" this represents the earliest known use of the town's name. Allen and Rumsey decided to name it for their wives, both named Ann, and for the stands of burr oak in the of land they purchased for $800 from the federal government at $1.25 per acre. The local Ojibwa named the settlement "kaw-goosh-kaw-nick", after the sound of Allen's sawmill.
Ann Arbor became the seat of Washtenaw County in 1827, and was incorporated as a village in 1833. The Ann Arbor Land Company, a group of speculators, set aside of undeveloped land and offered it to the state of Michigan as the site of the state capital, but lost the bid to Lansing. In 1837, the property was accepted instead as the site of the University of Michigan, which moved from Detroit.
Since the university's establishment in the city in 1837, the histories of the University of Michigan and Ann Arbor have been closely linked. The town became a regional transportation hub in 1839 with the arrival of the Michigan Central Railroad, and a north—south railway connecting Ann Arbor to Toledo and other markets to the south was established in 1878. Throughout the 1840s and the 1850s settlers continued to come to Ann Arbor. While the earlier settlers were primarily of British ancestry, the newer settlers also consisted of Germans, Irish, and African-Americans. In 1851, Ann Arbor was chartered as a city, though the city showed a drop in population during the Depression of 1873. It was not until the early 1880s that Ann Arbor again saw robust growth, with new immigrants coming from Greece, Italy, Russia, and Poland. Ann Arbor saw increased growth in manufacturing, particularly in milling. Ann Arbor's Jewish community also grew after the turn of the 20th century, and its first and oldest synagogue, Beth Israel Congregation, was established in 1916.
During the 1960s and 1970s, the city gained a reputation as an important center for liberal politics. Ann Arbor also became a locus for left-wing activism and served as a hub for the civil-rights movement and anti-Vietnam War movement, as well as the student movement. The first major meetings of the national left-wing campus group Students for a Democratic Society took place in Ann Arbor in 1960; in 1965, the city was home to the first U.S. teach-in against the Vietnam War. During the ensuing 15 years, many countercultural and New Left enterprises sprang up and developed large constituencies within the city. These influences washed into municipal politics during the early and mid-1970s when three members of the Human Rights Party (HRP) won city council seats on the strength of the student vote. During their time on the council, HRP representatives fought for measures including pioneering antidiscrimination ordinances, measures decriminalizing marijuana possession, and a rent-control ordinance; many of these remain in effect in modified form. Alongside these liberal and left-wing efforts, a small group of conservative institutions were born in Ann Arbor. These include Word of God (established in 1967), a charismatic inter-denominational movement; and the Thomas More Law Center (established in 1999), a religious-conservative advocacy group.
Following a 1956 vote, the city of East Ann Arbor merged with Ann Arbor to encompass the eastern sections of the city.
In the past several decades, Ann Arbor has grappled with the effects of sharply rising land values, gentrification, and urban sprawl stretching into outlying countryside. On 4 November 2003, voters approved a greenbelt plan under which the city government bought development rights on agricultural parcels of land adjacent to Ann Arbor to preserve them from sprawling development. Since then, a vociferous local debate has hinged on how and whether to accommodate and guide development within city limits. Ann Arbor consistently ranks in the "top places to live" lists published by various mainstream media outlets every year. In 2008, it was ranked by CNNMoney.com 27th out of 100 "America's best small cities." And in the year 2010, Forbes listed Ann Arbor as one of the most liveable cities in the United States of America.
Geography and cityscape.
According to the United States Census Bureau, the city has a total area of , of which, of it is land and is water, much of which is part of the Huron River. Ann Arbor is about west of Detroit. Ann Arbor Charter Township adjoins the city's north and east sides. Ann Arbor is situated on the Huron River in a productive agricultural and fruit-growing region. The landscape of Ann Arbor consists of hills and valleys, with the terrain becoming steeper near the Huron River. The elevation ranges from about along the Huron River to over on the city's west side, near Interstate 94 (I-94). Generally, the west-central and northwestern parts of the city and UM's North Campus are the highest parts of the city; the lowest parts are along the Huron River and in the southeast. Ann Arbor Municipal Airport, which is south of the city at , has an elevation of .
Ann Arbor's "Tree Town" nickname stems from the dense forestation of its parks and residential areas. The city contains more than 50,000 trees along its streets and an equal number in parks. In recent years, the emerald ash borer has destroyed many of the city's approximately 10,500 ash trees. The city contains 157 municipal parks ranging from small neighborhood green spots to large recreation areas. Several large city parks and a university park border sections of the Huron River. Fuller Recreation Area, near the University Hospital complex, contains sports fields, pedestrian and bike paths, and swimming pools. The Nichols Arboretum, owned by the University of Michigan, is a arboretum that contains hundreds of plant and tree species. It is on the city's east side, near the university's Central Campus. Located across the Huron River just beyond the university's North Campus is the university's Matthaei Botanical Gardens which contains 300 acres of gardens and a large tropical conservatory.
The Kerrytown Shops, Main Street Business District, the State Street Business District, and the South University Business District are commercial areas in downtown Ann Arbor. Three commercial areas south of downtown include the areas near I-94 and Ann Arbor-Saline Road, Briarwood Mall, and the South Industrial area. Other commercial areas include the Arborland/Washtenaw Avenue and Packard Road merchants on the east side, the Plymouth Road area in the northeast, and the Westgate/West Stadium areas on the west side. Downtown contains a mix of 19th- and early-20th-century structures and modern-style buildings, as well as a farmers' market in the Kerrytown district. The city's commercial districts are composed mostly of two- to four-story structures, although downtown and the area near Briarwood Mall contain a small number of high-rise buildings.
Ann Arbor's residential neighborhoods contain architectural styles ranging from classic 19th-century and early-20th-century designs to ranch-style houses. Among these homes are a number of kit houses built in the early 20th century. Contemporary-style houses are farther from the downtown district. Surrounding the University of Michigan campus are houses and apartment complexes occupied primarily by student renters. Tower Plaza, a 26-story condominium building located between the University of Michigan campus and downtown, is the tallest building in Ann Arbor. The 19th-century buildings and streetscape of the Old West Side neighborhood have been preserved virtually intact; in 1972, the district was listed on the National Register of Historic Places, and it is further protected by city ordinances and a nonprofit preservation group.
Climate.
Ann Arbor has a typically Midwestern humid continental climate (Köppen "Dfa"), which is influenced by the Great Lakes. There are four distinct seasons: winters are cold with moderate to heavy snowfall, while summers are very warm and humid; in between, spring and autumn are short but mild. The area experiences lake effect weather, primarily in the form of increased cloudiness during late fall and early winter. The monthly daily average temperature in July is , while the same figure for January is . Temperatures reach or exceed on 10 days, and drop to or below on 4.6 nights. Precipitation tends to be the heaviest during the summer months, but most frequent during winter. Snowfall, which normally occurs from November to April but occasionally starts in October, averages per season. The lowest recorded temperature was on 11 February 1885, and the highest recorded temperature was on 24 July 1934.
Demographics.
As of the 2010 U.S. Census, there were 113,394 people, 45,634 households, and 21,704 families residing in the city. The population density was 4,270.33 people per square mile (2653.47/km²). There were 49,982 housing units at an average density of 1,748.0 per square mile (675.0/km²), making it less densely populated than inner-ring Detroit suburbs like Oak Park and Ferndale (and than Detroit proper), but more densely populated than outer-ring suburbs like Livonia or Troy. The racial makeup of the city was 73.0% White (70.4% non-Hispanic White), 7.7% Black or African American, 0.3% Native American, 14.4% Asian, 0.0% Pacific Islander, 1.0% from other races, and 3.6% from two or more races. Hispanic or Latino of any race were 4.1% of the population.
In 2010 there was a total of 45,166 households, with an average of 2.51 persons per household.
As of 2000 the ancestry reports collected by the US census showed that in Ann Arbor 14.9% were of German, 8.5% English and 7.9% Irish ancestry according to Census 2000. 79.2% spoke only English at home, while 3.2% spoke Chinese or Mandarin, 3.1% Spanish, 1.9% Korean, 1.2% German, 1.1% Japanese and 1.0% French. Because of the pull of the university, the city has one of the highest foreign-born populations in the state, at 17.4%.
In 2000 Out of the 45,693 households, 23.0% had children under the age of 18 living with them, 37.8% were married couples living together, 7.5% had a female householder with no husband present, and 52.5% were nonfamilies. 35.5% of households were made up of individuals and 6.6% had someone living alone who was 65 years of age or older. The average household size was 2.22 and the average family size was 2.90. The age distribution was 16.8% under 18, 26.8% from 18 to 24, 31.2% from 25 to 44, 17.3% from 45 to 64, and 7.9% were 65 or older. The median age was 28 years. For every 100 females there were 97.7 males; while for every 100 females age 18 and over, there were 96.4 males.
The median income for a household in the city was $46,299, and the median income for a family was $71,293 (these figures had risen to $51,232 and $82,293 respectively as of a 2007 estimate). Males had a median income of $48,880 versus $36,561 for females. The per capita income for the city was $26,419. About 4.6% of families and 16.6% of the population were below the poverty line, including 7.3% of those under age 18 and 5.1% of those age 65 or over.
Ann Arbor's crime rate was below the national average in 2000. The violent crime rate was further below the national average than the property crime rate; the two rates were 48% and 11% lower than the U.S. average, respectively.
As of April 2013, Ann Arbor has the second largest Japanese national population in the State of Michigan, 1,541, after Novi, which had 2,666 Japanese nationals.
Economy.
The University of Michigan shapes Ann Arbor's economy significantly. It employs about 30,000 workers, including about 12,000 in the medical center. Other employers are drawn to the area by the university's research and development money, and by its graduates. High tech, health services and biotechnology are other major components of the city's economy; numerous medical offices, laboratories, and associated companies are located in the city. Automobile manufacturers, such as General Motors and Visteon, also employ residents.
High tech companies have located in the area since the 1930s, when International Radio Corporation introduced the first mass-produced AC/DC radio (the Kadette, in 1931) as well as the first pocket radio (the Kadette Jr., in 1933). The Argus camera company, originally a subsidiary of International Radio, manufactured cameras in Ann Arbor from 1936 to the 1960s. Current firms include Arbor Networks (provider of Internet traffic engineering and security systems), Arbortext (provider of XML-based publishing software), JSTOR (the digital scholarly journal archive), MediaSpan (provider of software and online services for the media industries), Truven Health Analytics, and ProQuest, which includes UMI. Ann Arbor Terminals manufactured a video-display terminal called the Ann Arbor Ambassador during the 1980s. Barracuda Networks, which provides networking, security, and storage products based on network appliances and cloud services, opened an engineering office in Ann Arbor in 2008 on Depot St. and recently announced it will move downtown to occupy the building previously used as the Borders headquarters.
Websites and online media companies in or near the city include All Media Guide, the Weather Underground, and Zattoo. Ann Arbor is the home to Internet2 and the Merit Network, a not-for-profit research and education computer network. Both are located in the South State Commons 2 building on South State Street, which once housed the Michigan Information Technology Center Foundation. The city is also home to the headquarters of Google's AdWords program—the company's primary revenue stream. The recent surge in companies operating in Ann Arbor has led to a decrease in its office and flex space vacancy rates. As of 31 December 2012, the total market vacancy rate for office and flex space is 11.80%, a 1.40% decrease in vacancy from one year ago, and the lowest overall vacancy level since 2003. The office vacancy rate decreased to 10.65% in 2012 from 12.08% in 2011, while the flex vacancy rate decreased slightly more, with a drop from 16.50% to 15.02%.
Pfizer, once the city's second largest employer, operated a large pharmaceutical research facility on the northeast side of Ann Arbor. On 22 January 2007, Pfizer announced it would close operations in Ann Arbor by the end of 2008. The facility was previously operated by Warner-Lambert and, before that, Parke-Davis. In December 2008, the University of Michigan Board of Regents approved the purchase of the facilities, and the university anticipates hiring 2,000 researchers and staff during the next 10 years. The city is the home of other research and engineering centers, including those of Lotus Engineering, General Dynamics and the National Oceanic and Atmospheric Administration (NOAA). Other research centers sited in the city are the United States Environmental Protection Agency's National Vehicle and Fuel Emissions Laboratory and the Toyota Technical Center. The city is also home to National Sanitation Foundation International, AKA: NSF International, the nonprofit non-governmental organization that develops generally accepted standards for a variety of public health related industries and subject areas.
Borders Books, started in Ann Arbor, was opened by brothers Tom and Louis Borders in 1971 with a stock of used books. The Borders chain was based in the city, as was its flagship store until it closed in September 2011. Domino's Pizza's headquarters is near Ann Arbor on Domino's Farms, a Frank Lloyd Wright-inspired complex just northeast of the city. Another Ann Arbor-based company is Zingerman's Delicatessen, which serves sandwiches, and has developed businesses under a variety of brand names. Zingerman's has grown into a family of companies which offers a variety of products (bake shop, mail order, creamery, coffee) and services (business education). Flint Ink Corp., another Ann Arbor-based company, was the world's largest privately held ink manufacturer until it was acquired by Stuttgart-based XSYS Print Solutions in October 2005. Avfuel, a global supplier of aviation fuels and services, is also headquartered in Ann Arbor. Aastrom Biosciences, a publicly traded company that develops stem cell treatments for cardiovascular diseases is headquartered in Ann Arbor.
Many cooperative enterprises were founded in the city; among those that remain are the People's Food Co-op and the Inter-Cooperative Council at the University of Michigan, a student housing cooperative founded in 1937. There are also three cohousing communities—Sunward, Great Oak, and Touchstone—located immediately to the west of the city limits.
Culture.
Several performing arts groups and facilities are on the University of Michigan's campus, as are museums dedicated to art, archaeology, and natural history and sciences. Founded in 1879, the University Musical Society is an independent performing arts organization that presents over 60 events each year, bringing international artists in music, dance, and theater. Regional and local performing arts groups not associated with the university include the Ann Arbor Civic Theatre, the Arbor Opera Theater, the Ann Arbor Symphony Orchestra, the Ann Arbor Ballet Theater, the Ann Arbor Civic Ballet (established in 1954 as Michigan's first chartered ballet company), The Ark, and Performance Network Theatre. Another unique piece of artistic expression in Ann Arbor is the fairy doors. These small portals are examples of installation art and can be found throughout the downtown area.
The Ann Arbor Hands-On Museum is located in a renovated and expanded historic downtown fire station. Multiple art galleries exist in the city, notably in the downtown area and around the University of Michigan campus. Aside from a large restaurant scene in the Main Street, South State Street, and South University Avenue areas, Ann Arbor ranks first among U.S. cities in the number of booksellers and books sold per capita. The Ann Arbor District Library maintains four branch outlets in addition to its main downtown building. The city is also home to the Gerald R. Ford Presidential Library.
Several annual events—many of them centered on performing and visual arts—draw visitors to Ann Arbor. One such event is the Ann Arbor Art Fairs, a set of four concurrent juried fairs held on downtown streets. Scheduled on Wednesday through Saturday in the third week of July, the fairs draw upward of half a million visitors. Another is the Ann Arbor Film Festival, held during the third week of March, which receives more than 2,500 submissions annually from more than 40 countries and serves as one of a handful of Academy Award–qualifying festivals in the United States.
Ann Arbor has a long history of openness to marijuana, given Ann Arbor's decriminalization of cannabis, the large number of medical marijuana dispensaries in the city (one dispensary, called People's Co-op, was directly across the street from Michigan Stadium until zoning forced it to move one mile to the west), the large number of pro-marijuana residents, and the annual Hash Bash: an event that is held on the first Saturday of April. Until (at least) the successful passage of Michigan's medical marijuana law, the event had arguably strayed from its initial intent, although for years, a number of attendees have received serious legal responses due to marijuana use on University of Michigan property, which does not fall under the City's progressive and compassionate ticketing program.
Ann Arbor has a major scene for college sports, notably at the University of Michigan, a member of the Big Ten Conference. Several well-known college sports facilities exist in the city, including Michigan Stadium, the largest American football stadium in the world with a 109,901 seating capacity. The stadium is colloquially known as "The Big House." Crisler Center and Yost Ice Arena play host to the school's basketball and ice hockey teams, respectively. Concordia University, a member of the NAIA, also fields sports teams.
A person from Ann Arbor is called an "Ann Arborite", and many long-time residents call themselves "townies". The city itself is often called "A²" ("A-squared") or "A2" ("A two") or AA, "The Deuce" (mainly by Chicagoans), "Ace Deuce", and "Tree Town". With tongue-in-cheek reference to the city's liberal political leanings, some occasionally refer to Ann Arbor as "The People's Republic of Ann Arbor" or "25 square miles surrounded by reality", the latter phrase being adapted from Wisconsin Governor Lee Dreyfus's description of Madison, Wisconsin. In "A Prairie Home Companion" broadcast from Ann Arbor, Garrison Keillor described Ann Arbor as "a city where people discuss socialism, but only in the fanciest restaurants." Ann Arbor sometimes appears on citation indexes as an author, instead of a location, often with the academic degree "MI", a misunderstanding of the abbreviation for Michigan. Ann Arbor has become increasingly gentrified in recent years.
Law and government.
Ann Arbor has a council-manager form of government. The City Council has 11 voting members: the mayor and 10 city council members. The mayor and city council members serve two-year terms: the mayor is elected every even-numbered year, while half of the city council members up for election annually (five in even-numbered and five in odd-numbered years). Two council members are elected from each of the city's five wards. The mayor is elected citywide. The mayor is the presiding officer of the City Council and has the power to appoint all Council committee members as well as board and commission members, with the approval of the City Council. The current mayor of Ann Arbor is John Hieftje, a Democrat who was first elected as mayor in 2000. Day-to-day city operations are managed by a city administrator chosen by the city council.
In 1960, Ann Arbor voters approved a $2.3 million bond issue to build the current city hall, which was designed by architect Alden B. Dow. The City Hall opened in 1963. In 1995, the building was renamed the Guy C. Larcom, Jr. Municipal Building in honor of the longtime city administrator who championed the building's construction.
Ann Arbor is part of Michigan's 15th congressional district, represented in Congress by Representative John Dingell, a Democrat. On the state level, the city is part of the 18th district in the Michigan Senate, represented by Democrat Rebekah Warren. In the Michigan House of Representatives, representation is split between the 55th district (northern Ann Arbor, part of Ann Arbor Township, and other surrounding areas, represented by Democrat Adam Zemke), the 53rd district (most of downtown and the southern half of the city, represented by Democrat Jeff Irwin) and the 52nd district (southwestern areas outside Ann Arbor proper and western Washtenaw County, represented by Democrat Gretchen Driskell).
As the county seat of Washtenaw County, the Washtenaw County Trial Court (22nd Circuit Court) is located in Ann Arbor at the Washtenaw County Courthouse on Main Street. This court has countywide general jurisdiction and has two divisions: The Civil/Criminal (criminal and civil matters) and the Family Division (which includes Juvenile Court, Friend of the Court, and Probate Court sections). Seven judges serve on the court.
Ann Arbor also has a local state district court (15th District Court), which serves only the City of Ann Arbor. In Michigan, the state district courts are limited jurisdiction courts which handle traffic violations, civil cases with claims under $25,000, landlord-tenant matters, and misdemeanor crimes.
The Ann Arbor Federal Building (attached to a post office) on Liberty Street serves as one of the courthouses for the U.S. District Court for the Eastern District of Michigan and Court of Appeals for the Sixth Circuit.
Politics.
Left-wing politics have been particularly strong in municipal government since the 1960s. Voters approved charter amendments that have lessened the penalties for possession of marijuana (1974), and that aim to protect access to abortion in the city should it ever become illegal in the State of Michigan (1990). In 1974, Kathy Kozachenko's victory in an Ann Arbor city-council race made her the country's first openly homosexual candidate to win public office. In 1975, Ann Arbor became the first U.S. city to use instant-runoff voting for a mayoral race. Adopted through a ballot initiative sponsored by the local Human Rights Party, which feared a splintering of the liberal vote, the process was repealed in 1976 after use in only one election. As of August 2009, Democrats hold the mayorship and all council seats. The left tilt of politics in the city have earned it the nickname "The People's Republic of Ann Arbor".
Education.
Higher education.
The University of Michigan dominates the city of Ann Arbor, providing the city with its distinctive college-town character.
Other local colleges and universities include Concordia University Ann Arbor, a Lutheran liberal-arts institution; a campus of the University of Phoenix; and Cleary University, a private business school. Washtenaw Community College is located in neighboring Ann Arbor Township. In 2000, the Ave Maria School of Law, a Roman Catholic law school established by Domino's Pizza founder Tom Monaghan, opened in northeastern, but the school moved to Ave Maria, Florida in 2009, and the Thomas M. Cooley Law School acquired the former Ave Maria buildings for use as a branch campus.
Primary and secondary education.
Public schools are part of the Ann Arbor Public Schools (AAPS) district. AAPS has one of America's leading music programs. In September 2008, 16,539 students had been enrolled in the Ann Arbor Public Schools. There were of 21 elementary schools, five middle schools (Forsythe, Slauson, Tappan, Scarlett, and Clague) three traditional high schools (Pioneer, Huron, and Skyline), and three alternative high schools (Community High, Stone School, and Roberto Clemente) in the district. The district also operates a K-8 open school program, Ann Arbor Open School, out of the former Mack School. This program is open to all families who live within the district. Ann Arbor Public Schools also operates a preschool and family center, with programs for at-risk infants and at-risk children before kindergarten. The district has a preschool center with both free and tuition-based programs for preschoolers in the district.
Ann Arbor is home to more than 20 private schools, including the Rudolf Steiner School of Ann Arbor, Clonlara School and Greenhills School, a prep school. The city is also home to several charter schools such as Washtenaw Technical Middle College and Honey Creek Community School. At Washtenaw Technical Middle College, students can earn an associate's degree at Washtenaw Community College and a high school diploma at the same time.
Media.
"The Ann Arbor News", owned by the Michigan-based Booth Newspapers chain, was the major daily newspaper serving Ann Arbor and the rest of Washtenaw County. The newspaper ended its 174-year print run in 2009, due to economic difficulties. It was replaced by AnnArbor.com, which ceased publication in 2013. Another Ann Arbor-based publication that has ceased production was the "Ann Arbor Paper", a free monthly. Ann Arbor has been said to be the first significant city to lose its only daily paper.
Current publications in the city include the "Ann Arbor Journal" ("A2 Journal"), a weekly community newspaper; "Ann Arbor Observer", a free monthly local magazine; and "Current", a free entertainment-focused alt-weekly. The "Ann Arbor Business Review" covers local business in the area. The "Ann Arbor Chronicle" is an online newspaper that covers local news, including meetings of the library board, county commission, and DDA. "Car and Driver" magazine and "Automobile Magazine" are also based in Ann Arbor. The University of Michigan is served by many student publications, including the independent "Michigan Daily" student newspaper, which reports on local, state, and regional issues in addition to campus news.
Four major AM radio stations based in or near Ann Arbor are WAAM 1600, a conservative news and talk station; WLBY 1290, a business news and talk station; WDEO 990, Catholic radio; and WTKA 1050, which is primarily a sports station. The city's FM stations include NPR affiliate WUOM 91.7; country station WWWW 102.9 and adult-alternative station WQKL 107.1. Freeform station WCBN-FM 88.3 is a local community radio/college radio station operated by the students of the University of Michigan featuring noncommercial, eclectic music and public-affairs programming. The city is also served by public and commercial radio broadcasters in Ypsilanti, the Lansing/Jackson area, Detroit, Windsor, and Toledo.
WPXD channel 31, an affiliate of the ION Television network, is licensed to the city. WHTV channel 18, a MyNetworkTV-affiliated station for the Lansing market, broadcasts from a transmitter in Lyndon Township, west of Ann Arbor. Community Television Network (CTN) is a city-provided cable television channel with production facilities open to city residents and nonprofit organizations. Detroit and Toledo-area radio and television stations also serve Ann Arbor, and stations from Lansing and Windsor, Ontario, can be heard in parts of the area.
Health and utilities.
The University of Michigan Medical Center, the preeminent health facility in the city, took the No.14 slot in "U.S. News & World Report" for best hospitals in the U.S., as of August 2009. The University of Michigan Health System (UMHS) includes University Hospital, C.S. Mott Children's Hospital and Women's Hospital in its core complex. UMHS also operates out-patient clinics and facilities throughout the city. The area's other major medical centers include a large facility operated by the Department of Veterans Affairs in Ann Arbor, and Saint Joseph Mercy Hospital in nearby Superior Township.
The city provides sewage disposal and water supply services, with water coming from the Huron River and groundwater sources. There are two water-treatment plants, one main and three outlying reservoirs, four pump stations, and two water towers. These facilities serve the city, which is divided into five water districts. The city's water department also operates four dams along the Huron River, two of which provide hydroelectric power. The city also offers waste management services, with Recycle Ann Arbor's handling recycling service. Other utilities are provided by private entities. Electrical power and gas are provided by DTE Energy. AT&T Inc. is the primary wired telephone service provider for the area. Cable TV service is primarily provided by Comcast.
Transportation.
Surface roads and paths.
The city is belted by three freeways: I-94, which runs along the southern portion of the city; U.S. Highway 23 (US 23, which primarily runs along the eastern edge of Ann Arbor; and M-14, which runs along the northern edge of the city. Other nearby highways include US 12, M-17, and M-153.
The streets in downtown Ann Arbor conform to a grid pattern, though this pattern is less common in the surrounding areas. Major roads branch out from the downtown district like spokes on a wheel to the highways surrounding the city. Several of the major surface arteries lead to the I-94/M-14 interchange in the west, US 23 in the east, and the city's southern areas. The city also has a system of bike routes and paths and includes the nearly complete Washtenaw County Border-to-Border Trail.
Bus service.
The Ann Arbor Transportation Authority (AATA), which brands itself as "The Ride", operates public bus services throughout the city and nearby Ypsilanti. A separate zero-fare bus service operates within and between the University of Michigan campuses. Since April 2012, route 787 (the "AirRide") connects to Detroit Airport a dozen times a day. The Michigan Flyer, a service operated by Indian Trails, cooperates with AATA for their AirRide and additionally offers bus service to East Lansing. Special bus shuttle service to Detroit Airport is available for a low fare before and after university breaks, too.
A downtown bus depot served by Greyhound Lines provides out-of-town bus service, and is the city's only remaining example of the Streamline Moderne architectural style. Megabus has twice daily direct service to Chicago, Illinois, while a bus service is provided by Amtrak for rail passengers making connections services East Lansing and Toledo, Ohio.
Airports.
Ann Arbor Municipal Airport is a small, city run general aviation airport located south of I-94. Detroit Metropolitan Airport, the area's large international airport, is about east of the city, in Romulus. Willow Run Airport east of the city near Ypsilanti serves freight, corporate, and general aviation clients.
Railroads.
The city was a major rail hub, notably for freight traffic between Toledo and ports north of Chicago, Illinois, from 1878 to 1982; however, the Ann Arbor Railroad also provided passenger service in 1913. The city was also served by the Michigan Central Railroad starting in 1837. Ann Arbor and Ypsilanti Street Railway, Michigan's first interurban, served the city from 1891 to 1929.
Amtrak, which provides service to the city at the Ann Arbor Train Station, operates the Wolverine train between Chicago and Pontiac, via Detroit. The present-day train station neighbors the city's old Michigan Central Depot, which was renovated as a restaurant in 1970.
Sister cities.
Ann Arbor has seven sister cities:

</doc>
<doc id="2070" url="http://en.wikipedia.org/wiki?curid=2070" title="Act of Settlement 1701">
Act of Settlement 1701

The Act of Settlement is an Act of the Parliament of England that was passed in 1701 to settle the succession to the English and Irish crowns and thrones on the Electress Sophia of Hanover (a granddaughter of James VI of Scotland and I of England) and her non-Roman Catholic heirs.
The act was prompted by the failure of King William III and Queen Mary II, as well as of Mary's sister Queen Anne, to produce any surviving children, and the Roman Catholic religion of all other members of the House of Stuart. The line of Sophia of Hanover was the most junior among the Stuarts, but consisted of convinced Protestants. Sophia died on 8 June 1714, before the death of Queen Anne on 1 August 1714, at which time Sophia's son duly became King George I and started the Hanoverian dynasty.
The act played a seminal role in the formation of the Kingdom of Great Britain. England and Scotland had shared a monarch since 1603, but had remained separately governed countries. The Scottish parliament was more reluctant than the English to abandon the House of Stuart, members of which had been Scottish monarchs long before they became English ones. English pressure on Scotland to accept the Act of Settlement led to the parliamentary union of the two countries in 1707.
Anyone who becomes a Roman Catholic, or who marries a Roman Catholic, becomes disqualified to inherit the throne under the Act of Settlement. The act also placed limits on both the role of foreigners in the British government and the power of the monarch with respect to the Parliament of England, though some of those provisions have been altered by subsequent legislation.
Along with the Bill of Rights 1689, the Act of Settlement remains today one of the main constitutional laws governing the succession not only to the throne of the United Kingdom, but also to those of the other Commonwealth realms, whether by assumption or by patriation. The Act of Settlement cannot be altered in any realm except by that realm's own parliament and, by convention, only with the consent of all the other realms, as it touches on the succession to the shared crown.
The original documents are currently situated in the Lower Saxon State Archives Hanover, Germany.
Original context.
Following the Glorious Revolution, the line of succession to the English throne was governed by the Bill of Rights 1689, which declared that the flight of James II from England to France during the revolution amounted to an abdication of the throne and that James' son-in-law and nephew William of Orange, and his wife, James' daughter, Mary, were James' successors, who ruled jointly as William III and Mary II. The Bill of Rights also provided that the line of succession would go through their descendants, then through Mary's sister Princess Anne, and her descendants, and then to the issue of William III by a later marriage (if he were to marry again after the death of Mary II). During the debate, the House of Lords had attempted to append Sophia and her descendants to the line of succession, but the amendment failed in the Commons.
Mary II died childless in 1694, after which William III did not remarry. In 1700, Prince William, Duke of Gloucester, who was the only child of Princess Anne to survive infancy, died of a fever at the age of 11. Thus, Anne was left as the last remaining legal heir to the throne. The Bill of Rights excluded Catholics from the throne, which ruled out James II and his descendants. However, it also provided for no further succession after Anne. Parliament thus saw the need to settle the succession on Sophia and her descendants, and thereby guarantee the continuity of the Crown in the Protestant line.
Provisions.
The Act of Settlement provided that the throne would pass to the Electress Sophia of Hanover – a granddaughter of James VI of Scotland and I of England, niece of Charles I of Scotland and England – and her Protestant descendants who had not married a Roman Catholic; those who were Roman Catholic, and those who married a Roman Catholic, were barred from ascending the throne "for ever". Eight additional provisions of the act would only come into effect upon the death of both William and Anne:
Effects.
For different reasons, various constitutionalists have praised the Act of Settlement: Henry Hallam called the Act "the seal of our constitutional laws" and David Lindsay Keir placed its importance above the Bill of Rights of 1689. Naamani Tarkow has written: "If one is to make sweeping statements, one may say that, save Magna Carta (more truly, its implications), the Act of Settlement is probably the most significant statute in English history".
Kingdom of Great Britain.
The Act of Settlement was, in many ways, the major cause of the union of Scotland with England and Wales to form the Kingdom of Great Britain. The Parliament of Scotland was not happy with the Act of Settlement and, in response, passed the Act of Security in 1704, through which Scotland reserved the right to choose its own successor to Queen Anne. Stemming from this, the Parliament of England decided that, to ensure the stability and future prosperity of Great Britain, full union of the two parliaments and nations was essential before Anne's death.
It used a combination of exclusionary legislation (the Alien Act of 1705), politics, and bribery to achieve this within three years under the Act of Union 1707. This success was in marked contrast to the four attempts at political union between 1606 and 1689, which all failed owing to a lack of political will in both kingdoms. By virtue of Article II of the Treaty of Union, which defined the succession to the throne of Great Britain, the Act of Settlement became part of Scots Law as well.
Succession to the Crown.
In addition to James II (who died a few months after the Act received the royal assent) and his Roman Catholic children Prince James and the Princess Royal, the Act also excluded the descendants of King James's sister Henrietta, the youngest daughter of Charles I. Henrietta's daughter Anne was then the Queen of Sardinia and a Roman Catholic; subsequent Jacobite pretenders are descended from her.
With the legitimate descendants of Charles I either childless (in the case of William III and Anne) or Roman Catholic, Parliament's choice was limited to the descendants of Elizabeth of Bohemia, the only other child of King James I not to have died in childhood. Elizabeth had borne nine children who reached adulthood, of whom Sophia was the "youngest". In 1701, in favour of Sophia, Parliament passed over senior living representatives of lines which included Elizabeth Charlotte, Duchess of Orléans, Louis Otto, Prince of Salm and his sisters, Anne Henriette, Princess of Condé, Benedicta Henrietta, Duchess of Brunswick-Lüneburg, and Sophia's sister Louise Hollandine of the Palatinate.
Removal from the succession due to Catholicism.
Since the Act's passing the most senior member of the Royal Family to have married a Roman Catholic, and thereby to have been removed from the line of succession, is Prince Michael of Kent, who married Baroness Marie-Christine von Reibnitz in 1978; he was fifteenth in the line of succession at the time.
The next most senior living descendant of the Electress Sophia who is ineligible to succeed on this ground is George Windsor, Earl of St Andrews, the eldest son of Prince Edward, Duke of Kent, who married the Roman Catholic Sylvana Palma Tomaselli in 1988; who would otherwise be 29th in the line of succession. His son, Lord Downpatrick, converted to Roman Catholicism in 2003 and is the most senior descendant of Sophia to be barred as a result of his religion. More recently, Peter Phillips, the son of Anne, Princess Royal, and eleventh in line to the throne, married Autumn Kelly; Kelly had been brought up as a Roman Catholic, but she converted to Anglicanism prior to the wedding. Had she not done so, Phillips would have forfeited his place in the succession upon their marriage.
Excluding those princesses who have married into Roman Catholic royal families, such as Marie of Edinburgh, Victoria Eugenie of Battenberg and Princess Beatrice of Edinburgh, one member of the Royal Family (that is, with the style of "Royal Highness") has converted to Roman Catholicism since the passage of the Act: the Duchess of Kent, wife of Prince Edward, Duke of Kent who converted on 14 January 1994, but her husband did not lose his place in the succession because she was an Anglican at the time of their marriage.
The abdication of 1936.
Under the Act of Settlement, male-preference primogeniture succession of an Anglican legitimate descendant of the Electress Sophia is automatic and immediate, neither depending on, nor waiting for, any proclamation. Thus, during the abdication crisis of 1936, caused by Edward VIII's desire to marry Wallis Simpson, the consent of all realms, along with, in some cases, new acts of parliament, was required to allow for Edward's stepping aside and the exclusion of any potential children of his marriage. In the United Kingdom, His Majesty's Declaration of Abdication Act was, with the consent of the Australian, Canadian, New Zealand, and South African governments, passed through Parliament; and the Crown thus passed to the next-in-line descendant of Sophia: Edward's brother, Prince Albert, Duke of York. The Irish Free State legislated independently. To formalise its government's consent to the abdication, the Canadian parliament passed, the following year, the Succession to the Throne Act (1 Geo. VI, c.16) and South Africa took a similar course of action.
Present status.
In the Australian Capital Territory, the Act of Settlement was, on 11 May 1989, converted, from an act of the Parliament of England into an ACT enactment, by section 34(4) of the Australian Capital Territory (Self-Government) Act 1988 (Cwlth), and then renamed "The Act of Settlement 1700" by the Legislation Act 2001.
Amendment proposals.
Challenges have been made against the Act of Settlement, especially its provisions regarding Roman Catholics and preference for males. However, legislating for alterations to the Act is a complex process, since the Act is a common denominator in the shared succession of all the Commonwealth realms. The Statute of Westminster 1931 acknowledges by established convention that any changes to the rules of succession may be made only with the agreement of all of the states involved, with concurrent amendments to be made by each state's parliament or parliaments. Further, as the current monarch's eldest child and, in turn, his eldest child, are Anglican males, any change to the succession laws would have no immediate implications. Consequently, there was little public concern with the issues and debate had been confined largely to academic circles until, in November 2010, the announcement that Prince William was to marry. This raised the question of what would happen if he were to produce first a daughter and then a son.
"The Times" reported on 6 November 1995 that Prince Charles had said on that day to Tony Blair and Paddy Ashdown that "Catholics should be able to ascend to the British throne". Ashdown claimed the Prince said: "I really can't think why we can't have Catholics on the throne". In 1998, during debate on a Succession to the Crown Bill, Junior Home Office Minister Lord Williams of Mostyn informed the House of Lords that the Queen had "no objection to the Government's view that in determining the line of succession to the throne, daughters and sons should be treated in the same way".
Australia.
In October 2011 the Australian federal government was reported to have reached an agreement with all of the states on potential changes to their laws in the wake of amendments to the Act of Settlement. The practice of the Australian states—for example, New South Wales and Victoria—has been, when legislating to repeal some imperial statutes so far as they still applied in Australia, to provide that imperial statutes concerning the royal succession remain in force.
The legal process required at the federal level remains unclear. The Australian constitution, as was noted during the crisis of 1936, contains no power for the federal parliament to legislate with respect to the monarchy. Everything thus turns upon the status and meaning of clause 2 in the Commonwealth of Australia Constitution Act 1900, which provides: "The provisions of this Act referring to the Queen shall extend to Her Majesty's heirs and successors in the sovereignty of the United Kingdom." Anne Twomey reviews three possible interpretations of the clause. First: it "mandates that whoever is the sovereign of the United Kingdom is also, by virtue of this external fact, sovereign of Australia"; accordingly, changes to British succession laws would have no effect on Australian law, but if the British amendment changed the sovereign, then the new sovereign of the United Kingdom would automatically become the new sovereign of Australia. Second, it is "merely an interpretative provision", operating to ensure that references to "the Queen" in the Constitution are references to whoever may at the time be the incumbent of the "sovereignty of the United Kingdom" as determined with regard to Australia, following the Australia Act 1986, by Australian law. Or, third, it incorporates the United Kingdom rules of succession into the Commonwealth of Australia Constitution Act, which itself can now be altered only by Australia, according to the Australia Act 1986; in that way, the British rules of succession have been patriated to Australia and, with regard to Australia, are subject to amendment or repeal solely by Australian law. However, Twomey expresses confidence that, if the High Court of Australia were to be faced with the problems of covering clause 2, it would find some way to conclude that, with regard to Australia, the clause is subject solely to Australian law. Canadian scholar Richard Toporoski theorised in 1998 that "if, let us say, an alteration were to be made in the United Kingdom to the Act of Settlement 1701, providing for the succession of the Crown... [i]t is my opinion that the domestic constitutional law of Australia or Papua New Guinea, for example, would provide for the succession in those countries of the same person who became Sovereign of the United Kingdom."
Canada.
In Canada, where the Act of Settlement is now a part of Canadian constitutional law, Tony O'Donohue, a Canadian civic politician, took issue with the provisions that exclude Roman Catholics from the throne, and which make the monarch of Canada the Supreme Governor of the Church of England, requiring him or her to be an Anglican. This, he claimed, discriminated against non-Anglicans, including Catholics, who are the largest faith group in Canada. In 2002, O'Donohue launched a court action that argued the Act of Settlement violates the Canadian Charter of Rights and Freedoms, but the case was dismissed by the court. It found that, as the Act of Settlement is part of the Canadian constitution, the Charter of Rights and Freedoms, as another part of the same constitution, does not have supremacy over it. Also, the court noted that, while Canada has the power to amend the line of succession to the Canadian throne, the Statute of Westminster stipulates that the agreement of the governments of the fifteen other Commonwealth realms that share the Crown would first have to be sought if Canada wished to continue its relationship with these countries. An appeal of the decision was dismissed on 16 March 2005. Some commentators state that, as a result of this, any single provincial legislature could hinder any attempts to change this Act, and by extension, to the line of succession for the shared crown of all 16 Commonwealth realms. Others contend that that is not the case, and changes to the succession instituted by an Act of the Parliament of Canada "[accord] with the convention of symmetry that preserves the personal unity of the British and Dominion Crowns."
With the announcement in 2007 of the engagement of Peter Phillips to Autumn Kelly, a Roman Catholic and a Canadian, discussion about the Act of Settlement was revived. Norman Spector called in "The Globe and Mail" for Prime Minister Stephen Harper to address the issue of the act's bar on Catholics, saying that Phillips' marriage to Kelly would be the first time the provisions of the act would bear directly on Canada—Phillips would be barred from acceding to the Canadian throne because he married a Roman Catholic Canadian. (In fact, the Earl of St. Andrews had already lost his place in the line of succession when he married the Roman Catholic Canadian Sylvana Palma Tomaselli in 1988, but St. Andrews' place in the line of succession was significantly lower than Phillips'.) Criticism of the Act of Settlement due to the Phillips-Kelly marriage was muted when Autumn Kelly converted to Anglicanism shortly before her marriage, thus preserving her husband's place in the line of succession.
United Kingdom.
From time to time there has been debate over repealing the clause that prevents Roman Catholics, or those who marry one, from ascending to the British throne. Proponents of repeal argue that the clause is a bigoted anachronism; Cardinal Winning, who was leader of the Roman Catholic Church in Scotland, called the act an "insult" to Catholics. Cardinal Murphy-O'Connor, the leader of the Roman Catholic Church in England, pointed out that Prince William (later the Duke of Cambridge) "can marry by law a Hindu, a Buddhist, anyone, but not a Roman Catholic". Opponents of repeal, such as Enoch Powell and Adrian Hilton, believe that it would lead to the disestablishment of the Church of England as the state religion if a Roman Catholic were to come to the throne. They also note that the monarch must swear to defend the faith and be a member of the Anglican Communion, but that a Roman Catholic monarch would, like all Roman Catholics, owe allegiance to the Pope. This would, according to opponents of repeal, amount to a loss of sovereignty for the Anglican Church.
When in December 1978 there was media speculation that Prince Charles might marry a Roman Catholic, Powell defended the provision that excludes Roman Catholics from ascending the throne, claiming his objection was not rooted in religious bigotry but in political considerations. He stated a Roman Catholic monarch would mean the acceptance of a source of authority external to the realm and "in the literal sense, foreign to the Crown-in-Parliament... Between Roman Catholicism and royal supremacy there is, as St Thomas More concluded, no reconciliation". Powell concluded that a Roman Catholic crown would be the destruction of the Church of England because "it would contradict the essential character of that church".
He continued:
When Thomas Hobbes wrote that "the Papacy is no other than the ghost of the deceased Roman Empire sitting crowned upon the grave thereof", he was promulgating an enormously important truth. Authority in the Roman Church is the exertion of that "imperium" from which England in the 16th century finally and decisively declared its national independence as the "alter imperium", the "other empire", of which Henry VIII declared "This realm of England is an empire" ... It would signal the beginning of the end of the British monarchy. It would portend the eventual surrender of everything that has made us, and keeps us still, a nation.
The Scottish Parliament unanimously passed a motion in 1999 calling for the complete removal of any discrimination linked to the monarchy and the repeal of the Act of Settlement. The following year, "The Guardian" challenged the succession law in court, claiming that it violated the European Convention on Human Rights, which provides,
"The enjoyment of the rights and freedoms set forth in this Convention shall be secured without discrimination on any ground such as sex, race, colour, language, religion, political or other opinion, national or social origin, association with a national minority, property, birth or other status."As the Convention nowhere lists the right to succeed to the Crown as a human right, the challenge was rejected.
Adrian Hilton, writing in "The Spectator" in 2003, defended the Act of Settlement as not "irrational prejudice or blind bigotry," but claimed that it was passed because "the nation had learnt that when a Roman Catholic monarch is upon the throne, religious and civil liberty is lost." He points to the Pope's claiming universal jurisdiction, and Hilton argues that "it would be intolerable to have, as the sovereign of a Protestant and free country, one who owes any allegiance to the head of any other state" and contends that, if such situation came about, "we will have undone centuries of common law." He said that because the Roman Catholic Church does not recognise the Church of England as an apostolic church, a Roman Catholic monarch who abided by their faith's doctrine would be obliged to view Anglican and Church of Scotland archbishops, bishops, and clergy as part of the laity and therefore "lacking the ordained authority to preach and celebrate the sacraments." (Hilton noted that the Church of Scotland's Presbyterian polity does not include bishops or archbishops.) Hilton said a Roman Catholic monarch would be unable to be crowned by the Archbishop of Canterbury and notes that other European states have similar religious provisions for their monarchs: Denmark, Norway, and Sweden, whose constitutions compel their monarchs to be Lutherans; the Netherlands, which has a constitution requiring its monarchs be members of the Protestant House of Orange; and Belgium, which has a constitution that provides for the succession to be through Roman Catholic houses.
In December 2004, a private member's bill—the Succession to the Crown Bill—was introduced in the House of Lords. The government, headed by Tony Blair, blocked all attempts to revise the succession laws, claiming it would raise too many constitutional issues and it was unnecessary at the time. In the British general election the following year, Michael Howard promised to work towards having the prohibition removed if the Conservative Party gained a majority of seats in the House of Commons, but the election was won by Blair's Labour Party. Four years later, plans drawn up by Chris Bryant were revealed that would end the exclusion of Catholics from the throne and end the doctrine of agnatic (male-preference) primogeniture in favour of absolute primogeniture, which governs succession solely on birth order and not on sex. The issue was raised again in January 2009, when a private members bill to amend the Act of Succession was introduced in parliament.
Across the realms.
In early 2011 Keith Vaz, a Labour Member of Parliament, introduced to the House of Commons at Westminster a private member's bill which proposed that the Act of Settlement be amended to remove the provisions relating to Roman Catholicism and change the primogeniture governing the line of succession to the British throne from agnatic to absolute cognatic. Vaz sought support for his project from the Canadian Cabinet and Prime Minister Stephen Harper, but the Office of the Prime Minister of Canada responded that the issue was "not a priority for the government or for Canadians without further elaboration on the merits or drawbacks of the proposed reforms." Stephenson King, Prime Minister of Saint Lucia, said he supported the idea and it was reported that the government of New Zealand did, as well. The Monarchist League of Canada said at the time to the media that it "supports amending the Act of Settlement in order to modernize the succession rules."
Later the same year, the Deputy Prime Minister of the United Kingdom, Nick Clegg, announced that the government was considering a change in the law. At approximately the same time, it was reported that British Prime Minister David Cameron had written to each of the prime ministers of the other fifteen Commonwealth realms, asking for their support in changing the succession to absolute primogeniture and notifying them he would raise his proposals at that year's Commonwealth Heads of Government Meeting (CHOGM) in Perth, Australia. Cameron reportedly also proposed removing the restriction on successors being or marrying Roman Catholics; however, potential Roman Catholic successors would be required to convert to Anglicanism prior to acceding to the throne. In reaction to the letter and media coverage, Harper stated that, this time, he was "supportive" of what he saw as "reasonable modernizations".
At CHOGM on 28 October 2011, the prime ministers of the other Commonwealth realms agreed to support Cameron's proposed changes to the Act. The bill put before the Parliament of the United Kingdom would act as a model for the legislation required to be passed in at least some of the other realms, and any changes would only first take effect if the Duke and Duchess of Cambridge were to have a daughter before a son.
The British group Republic asserted that succession reform would not make the monarchy any less discriminatory. As it welcomed the gender equality reforms, the British newspaper "The Guardian" criticized the lack of a proposal to remove the ban on Catholics sitting on the throne, as did Alex Salmond, First Minister of Scotland, who pointed out that "It is deeply disappointing that the reform [of the Act of Settlement of 1701] has stopped short of removing the unjustifiable barrier on a Catholic becoming monarch". On the subject, Cameron asserted: "Let me be clear, the monarch must be in communion with the Church of England because he or she is the head of that Church."

</doc>
<doc id="2075" url="http://en.wikipedia.org/wiki?curid=2075" title="Aircraft hijacking">
Aircraft hijacking

Aircraft hijacking (also known as aircraft piracy, especially within the special aircraft jurisdiction of the United States, and informally as skyjacking) is the unlawful seizure of an aircraft by an individual or a group. In most cases, the pilot is forced to fly according to the orders of the hijackers. Occasionally, however, the hijackers have flown the aircraft themselves, such as the September 11 attacks of 2001. In at least three cases, the plane was hijacked by the official pilot or co-pilot.
Unlike the typical hijackings of land vehicles or ships, skyjacking is not usually committed for robbery or theft. Most aircraft hijackers intend to use the passengers as hostages, either for monetary ransom or for some political or administrative concession by authorities. Motives vary from demanding the release of certain inmates (notably IC-814), highlighting the grievances of a particular community (notably AF 8969) to political asylum (notably ET 961). Hijackers also have used aircraft as a weapon to target particular locations (notably during the September 11, 2001 attacks).
Hijackings for hostages commonly produce an armed standoff during a period of negotiation between hijackers and authorities, followed by some form of settlement. Settlements do not always meet the hijackers' original demands. If the hijackers' demands are deemed too great and the perpetrators show no inclination to surrender, authorities sometimes employ armed special forces to attempt a rescue of the hostages (notably Operation Entebbe).
History.
The first recorded aircraft hijack took place on February 21, 1931, in Arequipa, Peru. Byron Rickards, flying a Ford Tri-Motor, was approached on the ground by armed revolutionaries. He refused to fly them anywhere and after a 10-day standoff, Rickards was informed that the revolution was successful and he could go in return for flying one group member to Lima.
In the Fort Worth Star-Telegram daily newspaper (morning edition) 19 September 1970, J. Howard "Doc" DeCelles states that he was actually the victim of the first skyjacking in December 1929. He was flying a postal route for the Mexican company Transportes Aeras Transcontinentales, ferrying mail from San Luis Potosí to Toreon and then on to Guadalajara. "Doc" was approached by Gen. Saturnino Cedillo, governor of the state of San Luis Potosí and one of the last remaining lieutenants of Pancho Villa. Cedillo was accompanied by several other men. He was told through an interpreter he had no choice in the matter. "Doc" stalled long enough to convey the information to his boss, who told him to cooperate. He had no maps, but was guided by the men as he flew above Mexican mountains. He landed on a road as directed, and was held captive for several hours under armed guard. He eventually was released with a "Buenos" from Cedillo and his staff. DeCelles kept his flight log, according to the article, but he did not file a report with authorities. "Doc" went on to work for the FAA in Fort Worth after his flying career.
The world's first fatal hijacking occurred on 28 October 1939. Earnest P. “Larry” Pletch shot Carl Bivens, 39, a flight instructor who was offering Pletch lessons in a yellow Taylor Cub monoplane with tandem controls in the air after taking off in Brookfield, Missouri. Bivens, instructing from the front seat, was shot in the back of the head twice. “Carl was telling me I had a natural ability and I should follow that line,” Pletch later confessed to prosecutors in Missouri. "I had a revolver in my pocket and without saying a word to him, I took it out of my overalls and I fired a bullet into the back of his head. He never knew what struck him." The Chicago Daily Tribune called it “One of the most spectacular crimes of the 20th century, and what is believed to be the first airplane kidnap murder on record.” Because it occurred somewhere over three Missouri counties, and involved interstate transport of a stolen airplane, it raised questions in legal circles about where, by whom, and even whether he could be prosecuted. Ernest Pletch pleaded guilty and was sentenced to life in prison, where he died in June 2001.
Between 1948 and 1957, there were 15 hijackings worldwide, an average of a little more than one per year. Between 1958 and 1967, this climbed to 48, or about five per year. The number dropped to 38 in 1968, but grew to 82 in 1969, the largest number in a single year in the history of civil aviation; in January 1969 alone, eight airliners were hijacked to Cuba. Between 1968 and 1977, the annual average jumped to 41.
In 1973, the Nixon Administration ordered the discontinuance by the CIA of the use of hijacking as a covert action weapon against the Castro regime. Cuban intelligence followed suit. That year, the two countries reached an agreement for the prosecution or return of the hijackers and the aircraft to each other's country. The Taiwanese intelligence also followed the CIA's example vis-а-vis China.
These measures plus the improvement in Israel's relations with Egypt and Jordan, the renunciation of terrorism by the Palestine Liberation Organization, the on-going peace talks between the PLO and Israel, the collapse of the communist states in East Europe, which reduced the scope for sanctuaries for terrorists, and the more cautious attitude of countries such as Libya and Syria after the U.S. declared them State-sponsors of international terrorism, the collapse of ideological terrorist groups such as the Red Army Faction and the tightening of civil aviation security measures by all countries have arrested and reversed the steep upward movement of hijackings.
However, the situation has not returned to the pre-1968 level and the number of successful hijackings continues to be high - an average of 18 a year during the 10-year period between 1988 and 1997, as against the pre-1968 average of five.
In the Dymshits–Kuznetsov hijacking affair on 15 June 1970, a group of Soviet refuseniks attempted to hijack a civilian aircraft in order to escape to the West, were caught and spent many years in Soviet prisons. This case is politically distinct in the sense that the government of Israel , which strongly denounced other cases of aircraft hijacking , endorsed this one and declared its participants to be heroes and martyrs for the Zionist cause . This was denounced as a double standard by left-wing critics such as then Knesset Member Charlie Biton.
On September 11, 2001, 19 al-Qaeda Islamic extremists hijacked American Airlines Flight 11, United Airlines Flight 175, American Airlines Flight 77, and United Airlines Flight 93 and crashed them into the Twin Towers of the World Trade Center, the southwestern side of the Pentagon building, and Stonycreek Township near Shanksville, Pennsylvania in a terrorist attack. The 2,996 death toll makes the hijackings the most fatal in history.
Military aircraft hijacking.
A Pakistan Air Force T-33 trainer was hijacked on August 20, 1971 before Indo-Pakistani war of 1971 in Karachi when a Bengali instructor pilot, Flight Lieutenant Matiur Rahman, knocked out the young Pilot Officer Rashid Minhas with the intention of defecting to India with the plane and national secrets. On regaining consciousness in mid-flight, Rashid Minhas struggled for flight control as well as relaying the news of his hijack to the PAF base. In the end of the ensuing struggle he succeeded to crash his aircraft into the ground near Thatta on seeing no way to prevent the hijack and the defection. He was posthumously awarded Pakistan's highest military award Nishan-e-Haider ("Sign of the Lion") for his act of bravery. Matiur Rahman was awarded Bangladesh's highest military award, Bir Sreshtho, for his attempt to defect to join the civil war in East Pakistan (modern-day Bangladesh).
Mystery hijacking.
D. B. Cooper is perhaps the most famous hijacker of all time and also the case is the only unsolved hijacking in America's aviation history.
Dealing with hijackings.
Before the September 11, 2001 attacks, most hijackings involved the plane landing at a certain destination, followed by the hijackers making negotiable demands. Pilots and flight attendants were trained to adopt the "Common Strategy" tactic, which was approved by the FAA. It taught crew members to comply with the hijackers' demands, get the plane to land safely and then let the security forces handle the situation. Crew members advised passengers to sit quietly in order to increase their chances of survival. They were also trained not to make any 'heroic' moves that could endanger themselves or other people. The FAA realized that the longer a hijacking persisted, the more likely it would end peacefully with the hijackers reaching their goal. The September 11 attacks presented an unprecedented threat because it involved suicide hijackers who could fly an aircraft and use it to deliberately crash the airplane into buildings for the sole purpose to cause massive casualties with no warning, no demands or negotiations, and no regard for human life. The "Common Strategy" approach was not designed to handle suicide hijackings, and the hijackers were able to exploit a weakness in the civil aviation security system. Since then, the "Common Strategy" policy in the USA and the rest of the world to deal with airplane hijackings has no longer been used.
Since the attacks, the situation for crew members, passengers and hijackers has changed. United Airlines Flight 93 crashed into a field as flight attendants and passengers—who had heard about the other three hijacked planes ramming into the World Trade Center and the Pentagon—fought hijackers who were likely flying to crash the plane either into the White House or the United States Capitol. As on Flight 93, crew members and passengers now have to calculate the risks of passive cooperation, not only for themselves but also for those on the ground. Later examples of active passenger and crew member resistance occurred when passengers and flight attendants of American Airlines Flight 63 from Paris to Miami on December 22, 2001, teamed up to help prevent Richard Reid from igniting explosives hidden in his shoes. Another example is when a few passengers and flight attendants teamed up to subdue Umar Farouk Abdulmutallab who attempted to detonate explosives sewn into his underwear aboard Northwest Flight 253 on December 25, 2009. Flight attendants and pilots now receive extensive anti-hijacking and self-defense training designed to thwart a hijacking or bombing.
Informing air traffic control.
To communicate to air traffic control that an aircraft is being hijacked, a pilot under duress should squawk 7500 or vocally, by radio communication, transmit "(Aircraft callsign); Transponder seven five zero zero." This should be done when possible and safe. An air traffic controller who suspects an aircraft may have been hijacked may ask the pilot to confirm "squawking assigned code." If the aircraft is "not" being hijacked, the pilot should "not" squawk 7500 and should inform the controller accordingly. A pilot under duress may also elect to respond that the aircraft is not being hijacked, but then neglect to change to a different squawk code. In this case, the controller would make no further requests and immediately inform the appropriate authorities. A complete lack of a response would also be taken to indicate a possible hijacking. Of course, a loss of radio communications may also be the cause for a lack of response, in which case a pilot would usually squawk 7600 anyway.
On 9/11, the suicide hijackers did not make any attempt to contact ground control to inform anyone about their hijackings, nor engage in any dialogue or negotiations. However, the hijacker-pilot of Flight 11 and the ringleader of the terrorist cell, Mohamed Atta, mistakenly transmitted announcements to ATC, meaning to go through the Boeing 767. Also, Amy Sweeney and Betty Ong called the American Airlines office, telling the workers that Flight 11 was hijacked. 9/11 hijacker-pilot Ziad Jarrah aboard Flight 93 also made a similar error when he mistakenly transmitted announcements to Cleveland ATC about the hijacking.
Prevention.
Cockpit doors on most commercial airliners have been strengthened and are now bullet resistant. In the United Kingdom, United States, Canada, Australia, Austria, the Netherlands and France, air marshals have also been added to some flights to deter and thwart hijackers. Airport security plays a major role in preventing hijackers. Screening passengers with metal detectors and luggage with x-ray machines helps prevent weapons from being taken on to an aircraft. Along with the FAA, the FBI also monitors terror suspects. Any person who is seen as a threat to civil aviation is banned from flying.
Shooting down aircraft.
According to reports, U.S. fighter pilots have been trained to shoot down hijacked commercial airliners should it become necessary. Other countries, such as India, Poland, and Russia have enacted similar laws or decrees that allow the shooting down of hijacked planes.
Polish Constitutional Court however, in September 2008, decided that the regulations were unconstitutional and dismissed them.
India.
In August 2005, India revealed its new anti-hijacking policy. The policy came into force after the Cabinet Committee on Security (CCS) approved it. The main points of the policy are:
The list of strategic targets is prepared by the Bureau of Civil Aviation in India. The decision to shoot down a plane is taken by CCS. However, due to the shortage of time, whoever – the prime minister, the defense minister or the home minister – can be reached first will take the call. In situations in which an aircraft becomes a threat while taking off – which gives very little reaction time – a decision on shooting it down may be taken by an Indian Air Force officer not below the rank of Assistant Chief of Air Staff (Operations).
Germany.
In January 2005, a federal law came into force in Germany – the "Luftsicherheitsgesetz" – that allowed "direct action by armed force" against a hijacked aircraft to prevent a 9/11-type attack. However, in February 2006 the Federal Constitutional Court of Germany struck down these provisions of the law, stating such preventive measures were unconstitutional and would essentially be state-sponsored murder, even if such an act would save many more lives on the ground. The main reasoning behind this decision was that the state would effectively be taking the lives of innocent hostages in order to avoid a terrorist attack. The Court also ruled that the Minister of Defense is constitutionally not entitled to act in terrorism matters, as this is the duty of the state and federal police forces. "See the , or "
The President of Germany, Horst Köhler, himself urged judicial review of the constitutionality of the Luftsicherheitsgesetz after he signed it into law in 2005.
International law issues.
Tokyo Convention.
The Tokyo Convention states in Article 11, defining the so-called unlawful takeover of an aircraft, that the parties signing the agreement are obliged, in case of hijacking or a threat of it, to take all the necessary measures in order to regain or keep control over an aircraft. The detailed analysis of the quoted article shows that in order of an unlawful takeover of an aircraft to take place, and at the same time to start the application of the convention, 3 conditions should be met: 
However, even without the order of the captain, any member of crew or passenger, can take reasonable measures, when he or she has reasonable grounds to believe that such action is necessary to protect the safety of the aircraft, or of people or property therein. The captain may decide to disembark a suspected person on the territory of any country, where the aircraft would land, and that country must agree to that. (Article 8 and 12 of the Convention).
Hague Convention.
The Convention for the suppression of unlawful seizure of Aircraft known as Hague convention came into force on October 14, 1971
the convention under Article 1 defined the offences which may be covered by the convention.
United States administrative law definitions.
In United States administrative law, the Code of Federal Regulations (CFR) Title 14, Aeronautics and Space, also known as the Federal Aviation Regulations, or FARs, are administered by the Federal Aviation Administration. Chapter II – Office of the Secretary, Department of Transportation (Aviation Proceedings) Subchapter A – Economics regulations, Part 243 – Passenger manifest information, Section 243.3 "Definitions" (14 CFR 243.3) says: "Air piracy" means any seizure of or exercise of control over an aircraft, by force or violence or threat of force or violence, or by any other form of intimidation, and with wrongful intent. Subparagraph (3) further defines an act of air piracy as an "Air disaster".
Hijacking in US popular culture.
The Hollywood film "Air Force One" starring Harrison Ford recounts the fictional story of the hijacking of the famous aircraft by six Kazakh ultra-nationalist terrorists.
The film "Con Air", starring Nicolas Cage and John Malkovich, features scenes in which an aircraft is hijacked by the maximum-security prisoners on board.
"" was a made-for-TV film based on the actual hijacking of TWA Flight 847, as seen through the eyes of the chief flight attendant Uli Derickson.
"Passenger 57" is a film starring Wesley Snipes as an airline security expert trapped on a passenger jet when terrorists seize control.
"Skyjacked" is a 1972 film about a crazed Vietnam war veteran hijacking a Boeing 707 and demanding to be taken to Russia by the captain, Charlton Heston.
The 1986 film "The Delta Force" starred Chuck Norris and Lee Marvin as leaders of an elite squad of special forces troops tasked with retaking a plane hijacked by Lebanese terrorists.
The 2006 film "Snakes On a Plane" starring Samuel L. Jackson is a fictional story about aircraft piracy through the in-flight release of crazed, venomous snakes.
The 2014 film "Non-Stop" starring Liam Neeson and Julianne Moore is another popular culture aircraft piracy film.

</doc>
<doc id="2076" url="http://en.wikipedia.org/wiki?curid=2076" title="Acropolis of Athens">
Acropolis of Athens

The Acropolis of Athens (; ) is an ancient citadel located on a high rocky outcrop above the city of Athens and containing the remains of several ancient buildings of great architectural and historic significance, the most famous being the Parthenon. The word acropolis comes from the Greek words ("akron", "edge, extremity") and ("polis", "city"). Although there are many other acropoleis in Greece, the significance of the Acropolis of Athens is such that it is commonly known as "The Acropolis" without qualification.
While there is evidence that the hill was inhabited as far back as the fourth millennium BC, it was Pericles (c. 495 – 429 BC) in the fifth century BC who coordinated the construction of the site's most important buildings including the Parthenon, the Propylaia, the Erechtheion and the temple of Athena Nike. The Parthenon and the other buildings were seriously damaged during the 1687 siege by the Venetians in the Morean War when the Parthenon was being used for gunpowder storage and was hit by a cannonball. 
The Acropolis was formally proclaimed as the preeminent monument on the European Cultural Heritage list of monuments on 26 March 2007.
History.
Early settlement.
The Acropolis is located on a flat-topped rock that rises above sea level in the city of Athens, with a surface area of about . It was also known as Cecropia, after the legendary serpent-man, Cecrops, the first Athenian king. 
While the earliest artifacts date to the Middle Neolithic era, there have been documented habitations in Attica from the Early Neolithic (6th millennium BC). There is little doubt that a Mycenaean megaron stood upon the hill during the late Bronze Age. Nothing of this megaron survives except, probably, a single limestone column-base and pieces of several sandstone steps. Soon after the palace was constructed, a Cyclopean massive circuit wall was built, 760 meters long, up to 10 meters high, and ranging from 3.5 to 6 meters thick. This wall would serve as the main defense for the acropolis until the 5th century. The wall consisted of two parapets built with large stone blocks and cemented with an earth mortar called "emplekton" (Greek: ἔμπλεκτον). The wall follows typical Mycenaean convention in that it followed the natural contour of the terrain and its gate was arranged obliquely, with a parapet and tower overhanging the incomers' right-hand side, thus facilitating defense. There were two lesser approaches up the hill on its north side, consisting of steep, narrow flights of steps cut in the rock. Homer is assumed to refer to this fortification when he mentions the "strong-built House of Erechtheus" ("Odyssey" 7.81). At some point before the 13th century BC, an earthquake caused a fissure near the northeastern edge of the Acropolis. This fissure extended some 35 meters to a bed of soft marl in which a well was dug. An elaborate set of stairs was built and the well served as an invaluable, protected source of drinking water during times of siege for some portion of the Mycenaean period.
The Dark Ages.
There is no conclusive evidence for the existence of a Mycenean palace on top of the Athenian Acropolis. However, if there was such a palace, it seems to have been supplanted by later building activity. Not much is known as to the architectural appearance of the Acropolis until the Archaic era. In the 7th and the 6th centuries BC, the site was taken over by Kylon during the failed Kylonian revolt, and twice by Peisistratos: all attempts directed at seizing political power by "coups d'état". Peisistratos built an entry gate or Propylaea and perhaps embarked on the construction of an earlier temple on the site of the Parthenon where fragments of sculptured limestone have been found as well as the foundations of a large unfinished temple. Nevertheless, it seems that a nine-gate wall, the "Enneapylon", had been built around the biggest water spring, the "Clepsydra", at the northwestern foot.
Archaic Acropolis.
A temple to "Athena Polias" (protectress of the city) was erected around 570–550 BC. This Doric limestone building, from which many relics survive, is referred to as the "Hekatompedon" (Greek for "hundred–footed"), "Ur-Parthenon" (German for "primitive Parthenon"), "H–Architecture" or "Bluebeard" temple, after the pedimental three-bodied man-serpent sculpture, whose beards were painted dark blue. Whether this temple replaced an older one, or just a sacred precinct or altar, is not known. Probably, the "Hekatompedon" was built where the Parthenon now stands.
Between 529–520 BC yet another temple was built by the Peisistratids, the Old Temple of Athena, usually referred to as the "Arkhaios Neōs" (ἀρχαῖος νεώς, "ancient temple"). This temple of Athena Polias was built upon the "Doerpfeld" foundations, between the Erechtheion and the still-standing Parthenon. "Arkhaios Neōs" was destroyed by the Persian invasion in 480 BC. However, the temple was probably reconstructed since in 454 BC the treasury of the Delian League was transferred in its opisthodomos. The temple may have been burnt down in 406/405 BC as Xenophon mentions that the old temple of Athena was set on fire. Pausanias does not mention it in his 2nd century AD "Description of Greece".
Around 500 BC the "Ur-Parthenon" was dismantled to make place for a newer and grander building, the "Older Parthenon" (often called "Pre-Parthenon", "early Parthenon"). Athenians decided to stop the construction of the Olympieion which was related with the tyrant Peisistratos and his sons and instead used the Piraeus limestone destined for the Olympieion to build the Older Parthenon. To accommodate it, the south part of the summit was cleared, made level by adding some 8,000 two-ton blocks of limestone, a foundation deep at some points, and the rest filled with earth kept in place by the retaining wall. However, after the victorious Battle of Marathon in 490 BC, the plan was revised and marble was used instead. The limestone phase of the building is referred to as "Pre-Parthenon I", the marble phase as "Pre-Parthenon II". In 485 BC, construction stalled to save resources as Xerxes took the throne.
The Older Parthenon was still under construction when the Persians sacked the city in 480 BC. The building was burned and looted, along with the "Ancient Temple" and practically everything else on the rock. After the Persian crisis had subsided, the Athenians incorporated many of the unfinished temple's architectural members (unfluted column drums, triglyphs, metopes, etc.) into the newly built northern curtain wall of the Acropolis, where they serve as a prominent "war memorial" and can still be seen today. The devastated site was cleared of debris. Statuary, cult objects, religious offerings and unsalvageable architectural members were buried ceremoniously in several deeply dug pits on the hill, serving conveniently as a fill for the artificial plateau created around the classic Parthenon. This "Persian debris" is the richest archaeological deposit excavated on the Acropolis and is well known throughout Greece.
The Periclean building program.
After winning at Eurymedon in 468 BC, Cimon and Themistocles ordered the reconstruction of the southern and northern walls of the Acropolis. Most of the major temples, including the Parthenon, were rebuilt under the leadership of Pericles during the Golden Age of Athens (460–430 BC). Phidias, a great Athenian sculptor, and Ictinus and Callicrates, two famous architects, were responsible for the reconstruction.
In 437 BC, Mnesicles started building the Propylaea, a monumental gate at the western end of the Acropolis with Doric columns of Pentelic marble, partly built upon the old propylaea of Peristratus. These colonnades were almost finished in 432 BC and had two wings, the northern one decorated with paintings by Polygnotus. Around the same time, south of the Propylaea, building started on the small Ionic Temple of Athena Nike in Pentelic marble with tetrastyle porches, preserving the essentials of Greek temple design. After an interruption caused by the Peloponnesian War, the temple was finished in the time of Nicias' peace, between 421 BC and 409 BC.
Construction of the elegant temple of Erechtheion in Pentelic marble (421–406 BC) was in accordance with a complex plan which took account of the extremely uneven ground and the need to circumvent several shrines in the area. The entrance, facing east, is lined with six Ionic columns. Unusually, the temple has two porches, one on the northwest corner borne by Ionic columns, the other, to the southwest, supported by huge female figures or Caryatids. The eastern part of the temple was dedicated to Athena Polias, while the western part, serving the cult of the archaic king Poseidon-Erechtheus, housed the altars of Hephaestus and Voutos, brother of Erechtheus. Little is known about the original plan of the interior which was destroyed by fire in the first century BC and has been rebuilt several times.
During the same period, a combination of sacred precincts including the temples of "Athena Polias", Poseidon, Erechtheus, Cecrops, Herse, Pandrosos and Aglauros, with its "Kore Porch" (Porch of the Maidens) or "Caryatids' balcony" was begun. Between the temple of Athena Nike and the Parthenon, there was the Sanctuary of Artemis Brauronia (or the Brauroneion), the goddess represented as a bear and worshipped in the deme of Brauron. According to Pausanias, a wooden statue or "xoanon" of the goddess and a statue of Artemis made by Praxiteles in the 4th century BC were both in the sanctuary.
Behind the Propylaea, Phidias' gigantic bronze statue of Athena Promachos ("Athena who fights in the front line"), built between 450 BC and 448 BC, dominated. The base was high, while the total height of the statue was . The goddess held a lance whose gilt tip could be seen as a reflection by crews on ships rounding Cape Sounion, and a giant shield on the left side, decorated by Mys with images of the fight between the Centaurs and the Lapiths. Other monuments that have left almost nothing visible to the present day are the Chalkotheke, the Pandroseion, Pandion's sanctuary, Athena's altar, Zeus Polieus's sanctuary and, from Roman times, the circular temple of Augustus and Rome.
Hellenistic and Roman period.
During the Hellenistic and Roman periods, many of the existing buildings in the area of the Acropolis were repaired., due to damage from age, and occasionally, war. Monuments to foreign kings were erected, notably those of the Attalid kings of Pergamon Attalos II (in front of the NW corner of the Parthenon), and Eumenes II, in front of the Propylaia. These were rededicated during the early Roman Empire to Augustus or Claudius (uncertain), and Agrippa, respectively. Eumenes was also responsible for constructing a stoa on the South slope, not unlike that of Attalos in the Agora below.
During the Julio-Claudian period, the Temple of Rome and Augustus, a small, round edifice, about 23 meters from the Parthenon, was to be the last significant ancient construction on the summit of the rock. Around the same time, on the North slope, in a cave next to the one dedicated to Pan since the classical period, a sanctuary was founded where the archons dedicated to Apollo on taking office. In 161 AD, on the South slope, the Roman Herodes Atticus built his grand amphitheatre or Odeon. It was destroyed by the invading Herulians a century later but was reconstructed in the 1950s. 
During the 3rd century, under threat from a Herulian invasion, repairs were made to the Acropolis walls, and the "Beulé Gate" was constructed to restrict entrance in front of the Propylaia, thus returning the Acropolis to use as a fortress.
Byzantine, Latin and Ottoman period.
In the Byzantine period, the Parthenon was turned into a church, dedicated to the Virgin Mary. Under the Latin Duchy of Athens, the Acropolis functioned as the city's administrative center, with the Parthenon as its cathedral, and the Propylaia as part of the Ducal Palace. A large tower was added, the "Frankopyrgos", demolished in the 19th century. 
After the Ottoman conquest of Greece, the Parthenon was used as the garrison headquarters of the Turkish army, and the Erechtheum was turned into the Governor's private Harem. The buildings of the Acropolis suffered significant damage during the 1687 siege by the Venetians in the Morean War. The Parthenon, which was being used as a gunpowder magazine, was hit by artillery fire and severely damaged. 
In subsequent years, the Acropolis was a site of bustling human activity with many Byzantine, Frankish, and Ottoman structures. The dominant feature during the Ottoman period was a mosque inside the Parthenon, complete with a minaret. Following the Greek War of Independence, most features that dated from the Byzantine, Frankish and Ottoman periods were cleared from the site in an attempt to restore the monument to its original form, "clensed" of all later additions.
Archaeological remains.
The entrance to the Acropolis was a monumental gateway called the Propylaea. To the south of the entrance is the tiny Temple of Athena Nike. At the centre of the Acropolis is the Parthenon or Temple of Athena Parthenos (Athena the Virgin). East of the entrance and north of the Parthenon is the temple known as the Erechtheum. South of the platform that forms the top of the Acropolis there are also the remains of an outdoor theatre called Theatre of Dionysus. A few hundred metres away, there is the now partially reconstructed Theatre of Herodes Atticus.
All the valuable ancient artifacts are situated in the Acropolis Museum, which resides on the southern slope of the same rock, 280 metres from the Parthenon.
Site plan.
Site plan of the Acropolis at Athens showing the major archaeological remains
The Acropolis Restoration Project.
The Project began in 1975 and is now nearing completion. The aim of the restoration was to reverse the decay of centuries of attrition, pollution, destruction by acts of war, and misguided past restorations. The project included collection and identification of all stone fragments, even small ones, from the Acropolis and its slopes and the attempt was made to restore as much as possible using reassembled original material (Anastylosis) - with new marble from Mount Penteli used sparingly. All restoration was made using titanium dowels and is designed to be completely reversible, in case future experts decide to change things. A combination of cutting-edge modern technology and extensive research and reinvention of ancient techniques were used.
The Parthenon colonnades, largely destroyed by Venetian bombardment in the 17th century, were restored, with many wrongly assembled columns now properly placed. The roof and floor of the Propylaea were partly restored, with sections of the roof made of new marble and decorated with blue and gold inserts, as in the original. Restoration of the Temple of Athena Nike was completed in 2010.
A total of 2,675 tons of architectural members were restored, with 686 stones reassembled from fragments of the originals, 905 patched with new marble, and 186 parts made entirely of new marble. A total of 530 cubic meters of new Pentelic marble were used.
Cultural significance.
Every four years, the Athenians held a festival called the Panathenaea that rivaled the Olympic Games in popularity. During the festival, a procession (believed to be depicted on the Parthenon frieze) traveled through the city via the Panathenaic Way and culminated on the Acropolis. There, a new robe of woven wool ("peplos") was placed on either the statue of Athena Polias in the Erechtheum (during a regular Panathenaea) or on the statue of Athena Parthenos in the Parthenon (during the Great Panathenaea, held every four years).
Within the later tradition of Western Civilization and classical revival the Acropolis, from at least the mid-18th century on, has often been invoked as a key symbol of the Greek legacy and of the glories of Classical Greece.

</doc>
<doc id="2077" url="http://en.wikipedia.org/wiki?curid=2077" title="Adam Weishaupt">
Adam Weishaupt

Johann Adam Weishaupt (6 February 1748 – 18 November 1830) was a German philosopher and founder of the secret society, the Order of the Illuminati.
Early life.
Adam Weishaupt was born on 6 February 1748 in Ingolstadt in the Electorate of Bavaria. Weishaupt's father Johann Georg Weishaupt (1717–1753) died when Adam was five years old. After his father's death he came under the tutelage of his godfather Johann Adam Freiherr von Ickstatt who, like his father, was a professor of law at the University of Ingolstadt. Ickstatt was a proponent of the philosophy of Christian Wolff and of the Enlightenment, and he influenced the young Weishaupt with his rationalism. Weishaupt began his formal education at age seven at a Jesuit school. He later enrolled at the University of Ingolstadt and graduated in 1768 at age 20 with a doctorate of law. In 1772 he became a professor of law. The following year he married Afra Sausenhofer of Eichstätt.
After Pope Clement XIV’s suppression of the Society of Jesus in 1773, Weishaupt became a professor of canon law, a position that was held exclusively by the Jesuits until that time. In 1775 Weishaupt was introduced to the empirical philosophy of Johann Georg Heinrich Feder of the University of Göttingen. Both Feder and Weishaupt would later become opponents of Kantian idealism.
Founder of the Illuminati.
On May day 1776 Johann Adam Weishaupt founded the "Illuminati" in the Electorate of Bavaria. He adopted the name of "Brother Spartacus" within the order. Although the Order was not egalitarian or democratic internally, it sought to promote the doctrines of equality and freedom throughout society.
The actual character of the society was an elaborate network of spies and counter-spies. Each isolated cell of initiates reported to a superior, whom they did not know: a party structure that was effectively adopted by some later groups.
Weishaupt was initiated into the Masonic Lodge "Theodor zum guten Rath", at Munich in 1777. His project of "illumination, enlightening the understanding by the sun of reason, which will dispel the clouds of superstition and of prejudice" was an unwelcome reform. He used Freemasonry to recruit for his own quasi-masonic society, with the goal of "perfecting human nature" through re-education to achieve a communal state with nature, freed of government and organized religion. Presenting their own system as pure masonry, Weishaupt and Adolph Freiherr Knigge, who organised his ritual structure, greatly expanded the secret organisation.
Contrary to Immanuel Kant's famous dictum that Enlightenment (and Weishaupt's Order was in some respects an expression of the Enlightenment Movement) was the passage by man out of his 'self-imposed immaturity' through daring to 'make use of his own reason, without the guidance of another,' Weishaupt's Order of Illuminati prescribed in great detail everything which the members had obediently to read and think, so that Dr. Wolfgang Riedel has commented that this approach to illumination or enlightenment constituted a degradation and twisting of the Kantian principle of Enlightenment. Riedel writes:
'The independence of thought and judgement required by Kant ... was specifically prevented by the Order of the Illuminati's rules and regulations. Enlightenment takes place here, if it takes place at all, precisely "under" the direction of another, namely under that of the "Superiors" [of the Order].
Weishaupt's radical rationalism and vocabulary was not likely to succeed. Writings that were intercepted in 1784 were interpreted as seditious, and the Society was banned by the government of Karl Theodor, Elector of Bavaria, in 1784. Weishaupt lost his position at the University of Ingolstadt and fled Bavaria.
Activities in exile.
He received the assistance of Duke Ernest II of Saxe-Gotha-Altenburg (1745–1804), and lived in Gotha writing a series of works on illuminism, including "A Complete History of the Persecutions of the Illuminati in Bavaria" (1785), "A Picture of Illuminism" (1786), "An Apology for the Illuminati" (1786), and "An Improved System of Illuminism" (1787). Adam Weishaupt died in Gotha on 18 November 1830. He was survived by his second wife, Anna Maria (née Sausenhofer), and his children Nanette, Charlotte, Ernst, Karl, Eduard, and Alfred. Weishaupt was buried next to his son Wilhelm who preceded him in death in 1802.
After Weishaupt's Order of Illuminati was banned and its members dispersed, it left behind no enduring traces of an influence, not even on its own erstwhile members, who went on in the future to develop in quite different directions.
Assessment of Character and Intentions.
Weishaupt's character and intentions have been variously assessed: from those such as the Abbé Barruel and John Robison who regarded him as a 'human devil' and saw his mission as one of malevolent destructiveness, to those who view him as a humane and benign, albeit wilful, social reformer. Writing on this topic, Dr. Tony Page comments:
'Weishaupt’s plan was to educate Illuminati followers in the highest levels of humanity and morality (basing his teachings on the supremacy of Reason, allied with the spirit of the Golden Rule of not doing to others what one would not wish done to oneself), so that if Illuminati alumni subsequently attained positions of significance and power (such as in the fields of education and politics), they could exert a benevolent and uplifting influence upon society at large. His project was utopian and naively optimistic, and he himself was certainly not without flaws of character – but neither he nor his plan was evil or violent in and of themselves. It is one of the deplorable and tragic ironies of history that a man who tried to inculcate virtue, philanthropy, social justice and morality has become one of the great hate-figures of 21st-century ‘conspiracy’ thinking.'
Adam Weishaupt in pop culture.
Adam Weishaupt is referred to repeatedly in The Illuminatus! Trilogy, written by Robert Shea and Robert Anton Wilson, as the founder of the Illuminati and as an imposter who killed George Washington and took his place as the first president of the United States. Washington's portrait on the U.S. one-dollar bill is said to actually be Weishaupt's.
Another version of Adam Weishaupt appears in the extensive comic book novel Cerebus the Aardvark by Dave Sim, as a combination of Weishaupt and George Washington. He appears primarily in the Cerebus and Church & State I volumes. His motives are republican confederalizing of city-states in Estarcion (a pseudo-Europe) and the accumulation of capital unencumbered by government or church.
Weishaupt's name is one of many references made to the Illuminati and other conspiracies in the 2000 PC game Deus Ex. During JC Denton's escape from Versalife labs in Hong Kong, he recovers a virus engineered with the molecular structure in multiples of 17 and 23. Tracer Tong notes "1723... the birthdate of Adam Weishaupt" even though this reference is actually incorrect: Weishaupt was born in 1748.
Adam Weishaupt is also mentioned ("Bush got a ouija to talk to Adam Weishaupt") by the New York rapper Cage in El-P's "Accidents Don't Happen", the ninth track on his album Fantastic Damage (2002).
Adam Weishaupt is briefly mentioned in Umberto Eco's novel The Prague Cemetery.[21]
Works.
Works by Adam Weishaupt in English Translation.
(2008) "Diogenes’ Lamp, or an Examination of Our Present Day Morality and Enlightenment", translated by Amelia Gill, The Masonic Bookclub
(2014) "A Brief Justification of My Intentions: Casting Light on the Latest Original Writings", translated by Dr. Tony Page, Justice Publications, Amazon Kindle
(2014) "Supplement to the Justification of My Intentions", translated by Dr. Tony Page, Justice Publications, Amazon Kindle

</doc>
