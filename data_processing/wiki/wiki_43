<doc id="6286" url="http://en.wikipedia.org/wiki?curid=6286" title="Commuter rail">
Commuter rail

Commuter rail, also called suburban rail, is a passenger rail transport service that primarily operates between a city center, and the middle to outer suburbs beyond 15 km (10 miles) and commuter towns or other locations that draw large numbers of commuters — people who travel on a daily basis. Trains operate following a schedule, at speeds varying from 50 to 200 km/h (30 to 125 mph). Distance charges or zone pricing may be used.
Non-English names include "Treno suburbano" in Italian, "Cercanías" in Spanish, "Rodalies" in Catalan, "Proastiakos" in Greek, "Nahverkehrszug" (and in larger cities "S-Bahn", though these trains may include city centre metro sections and/or circular or partly circular lines) in German, "Train de banlieue" in French, "Příměstský vlak" in Czech, "Elektrichka" in Russian, and "Pendeltåg" in Sweden. The development of commuter rail services has become popular today, with the increased public awareness of congestion, dependence on fossil fuels, and other environmental issues, as well as the rising costs of owning, operating and parking automobiles.
Characteristics.
Most commuter (or suburban) trains are built to main line rail standards, differing from light rail or rapid transit (metro rail) systems by:
Train schedule.
Compared to rapid transit (or metro rail), commuter/suburban rail has lower frequency, following a schedule rather than fixed intervals, and fewer stations spaced further apart. 
They primarily serve lower density suburban areas (non inner-city), and often share right-of-way with intercity or freight trains. Some services operate only during peak hours and others uses fewer departures during off peak hours and weekends. 
Average speeds are high, often 50 km/h (30 mph) or higher. These higher speeds better serve the longer distances involved.
Some services include express services which skip some stations in order to run faster and separate longer distance riders from short-distance ones.
The general range of commuter trains' distance varies between 15 and 200 km (10 and 125 miles). Sometimes long distances can be explained by that the train runs between two or several cities (e.g. S-Bahn in the Ruhr area of Germany)
Distances between stations may vary, but are usually much longer compared with urban rail system. In the city center the trains either has a terminal station or pass through the city centre with notably fewer station stops compared with urban rail system. Toilets are often available on board trains and in stations.
Track.
Their ability to coexist with freight or intercity services in the same right-of-way can drastically reduce system construction costs. However, frequently they are built with dedicated tracks within that right-of-way to prevent delays, especially where service densities have converged in the inner parts of the network.
Most such trains run on the local standard gauge track. Some light rail systems may run on a narrower gauge. Examples of narrow gauge systems are found in Japan, Switzerland, in the Brisbane (Citytrain) and Perth (Transperth) systems in Australia, in some commuter rail systems in Sweden, and on the in Italy.
Some countries, including Finland, India, Pakistan, Russia, Brazil and Sri Lanka, as well as San Francisco (BART) in the USA and Melbourne and Adelaide in Australia, use broad gauge track.
Distinction between other modes of rail.
Metro
Metro rail or rapid transit usually covers a smaller inner-urban area ranging outwards to between 12 km to 20 km (or 8 to 14 miles), has a higher train frequency and runs on separate tracks (underground or elevated), whereas commuter rail often shares tracks, technology and the legal framework within mainline railway systems.
However, the classification as a metro or rapid rail can be difficult as both may typically cover a metropolitan area exclusively, run on separate tracks in the centre, and often feature purpose-built rolling stock. The fact that the terminology is not standardised across countries (even across English-speaking countries) further complicates matters. This distinction is most easily made when there are two (or more) systems such as New York's subway and the LIRR, Metro-North along with PATH, Paris' Métro and RER along with Transilien, London's tube lines of the Underground and the Overground, (future) Crossrail, Thameslink along with other commuter rail operators, Madrid's Metro and Cercanías, Barcelona's Metro and Rodalies, and Tokyo's subway and the JR lines along with various privately owned and operated commuter rail systems.
S-Bahn/S-train
In Germany the S-Bahn is considered as a train category of its own, and exists in many of the large cities and in some other areas. They can be divided into two major types. In Berlin and Hamburg the S-Bahn systems do fulfill all considerations of a true metro system (despite the existence of U-Bahns as well). The trains run on tracks that are entirely separated from other trains, they have most of their stations within highly populated urban areas, has short distances between stations, has high frequency departures (all day) at fixed minutes and uses tunnels. The main difference between the S-Bahn systems of Berlin and Hamburg compared to the U-Bahns of the same cities are most notable at major railroad stations, where their (track-separated) platforms are located parallel to common railroad platforms. Some S-Bahn lines do run a bit further out from the city centre, compared with U-Bahn. This type of S-train also exists in Copenhagen (where a metro system also exists) and in Vienna (where the S-Bahn and U-Bahn constitute a common system).
In Hamburg and Copenhagen, other, diesel driven trains, do continue where the S-Bahn ends ("A-Bahn" in Hamburg area, and "L-tog" in Copenhagen). In both Berlin and Copenhagen a ring line (circle line) is run by S-trains through highly populated boroughs, but outside the city centre core. (In Copenhagen the circle isn't complete, due to the city's location by the sea)
The second type, found in the Ruhr area, has longer lines and lacks a separate track system, and the trains runs between cities rather than within a city, although cities like Dortmund, Essen, Gelsenkirchen and Düsseldorf are almost agglomerated together. This type of S-Bahn also applies to Munich and Frankfurt. S-Bahns does also exist in some mid-size cities like Rostock and Magdeburg, but in that case the S-trains do not depart as often as metro systems do, the tracks are not separated from other trains and the number of lines are few. The distances between stations however are usually short.
S-trains (S-Bahns) are a rather wide concept but only in a number of cases can they be truly considered as commuter rail. The consideration for this is open to subjective thoughts and different opinions however, especially since such S-trains only exists in a few countries (Germany, Austria, Denmark, Italy and Romania) and do differ from city to city even within these countries.
Regional rail
Regional rail usually provides rail services between towns and cities, rather than purely linking major population hubs in the way inter-city rail does. Regional rail operates outside major cities. Unlike Inter-city, it stops at most or all stations between cities. It provides a service between smaller communities along the line, and also connections with long-distance services at interchange stations located at junctions or at larger towns along the line. Alternative names are "local train" or "stopping train".
Examples include the former BR's Regional Railways, France's TER ("Transport express régional"), Germany's DB Regio and South Korea's Tonggeun services.
Regional rail does not exist in this sense in the United States, so the term "regional rail" has become synonymous with commuter rail there, although the two are more clearly defined in Europe.
Inter-city rail
In some European countries the distinction between commuter trains and long-distance/intercity trains is very hard to make, because of the relatively short distances involved. For example, so-called "intercity" trains in Belgium and the Netherlands carry many commuters and their equipment, range and speeds are similar to those of commuter trains in some larger countries. In the United Kingdom there is no real division of organisation and brand name between commuter, regional and inter-city trains, making it hard to categorize train connections.
Russian commuter trains, on the other hand, frequently cover areas larger than Belgium itself, although these are still short distances by Russian standards. They have a different ticketing system from long-distance trains, and in major cities they often operate from a separate section of the train station.
The easiest way to identify these "inter-city" services is that they tend to operate as express services - only linking the main stations in the cities they link, not stopping at any other stations. However, this term is used in Australia (Sydney for example) to describe the regional trains operating beyond the boundaries of the suburban services, even though some of these "inter-city" services stop all stations similar to German regional services. In this regard, the German service delineations and corresponding naming conventions are clearer and better used for academic purposes.
High-speed rail
Sometimes high-speed rail can serve daily use of commuters. The Japanese Shinkansen high speed rail system is heavily used by commuters in the Greater Tokyo Area. They commute between 100 and 200 km by Shinkansen. To meet the demand of commuters, JR sells commuter discount passes and operates 16-car bilevel E4 Series Shinkansen trains at rush hour, providing a capacity of 1,600 seats. Several lines in China such as the Beijing–Tianjin Intercity Railway, and the Shanghai–Nanjing High-Speed Railway, serve a similar role with many more under construction or planned.
The high-speed services linking Zurich, Bern and Basel in Switzerland have brought the Central Business Districts (CBDs) of these three cities within 1 hour of each other. This has resulted in unexpectedly high demand for new commuter trips between the three cities and a corresponding increase in suburban rail passengers accessing the high-speed services at the main city-centre stations (or Hauptbahnhof).
Train types.
Commuter/suburban trains are usually optimized for maximum passenger volume, in most cases without sacrificing too much comfort and luggage space, though they seldom have all the amenities of long-distance trains. Cars may be single- or double-level, and aim to provide seating for all. Compared to intercity trains, they have less space, fewer amenities and limited baggage areas.
Multiple unit type.
Commuter rail trains are usually composed of multiple units, which are self-propelled, bidirectional, articulated passenger rail cars with driving motors on each (or every other) bogie. Depending on local circumstances and tradition they may be powered either by diesel engines located below the passenger compartment (diesel multiple units) or by electricity picked up from third rails or overhead lines (electric multiple units). Multiple units are almost invariably equipped with control cabs at both ends, which is why such units are so frequently used to provide commuter services, due to the associated short turn-around time.
Locomotive hauled services.
Locomotive hauled services are used in some countries or locations. This is often a case of asset sweating, by using a single large combined fleet for intercity and regional services. Loco hauled services are usually run in push-pull formation, that is, the train can run with the locomotive at the "front" or "rear" of the train (pushing or pulling). Trains are often equipped with a control cab at the other end of the train from the locomotive, allowing the train operator to operate the train from either end. The motive power for locomotive-hauled commuter trains may be either electric or Diesel-electric, although some countries, such as Germany and some of the former Soviet-bloc countries, also use diesel-hydraulic locomotives.
Seat plans.
In the USA and some other countries, a three-and-two seat plan is used. However, few people sit in the middle seat on these trains because they feel crowded and uncomfortable. It is said one industrial designer for one of New York City's commuter railroads, Metro-North, told people: "I designed the aisle seat with a half-back and no upholstery, so it will be very uncomfortable to sit there. They'll move in and take the center seat!" (This seating design can also be found on older New Jersey Transit and Long Island Rail Road rolling stock.)
In Japan, longitudinal (sideways window-lining) seating is widely used in many commuter rail trains to increase capacity in rush hours. Carriages are usually not organized to increase seating capacity (although in some trains at least one carriage would feature more doors to facilitate easier boarding and alighting and bench seats so that they can be folded up during rush hour to provide more standing room) even in the case of commuting longer than 50 km and commuters in the Greater Tokyo Area have to stand in the train for more than an hour.
Commuter rail systems around the world.
Africa.
Currently there are not many examples of commuter rail in Africa. Metrorail operates in the major cities of South Africa, and there are some commuter rail services in Algeria, Kenya, Morocco, Alexandria, Egypt and Tunisia.
In Algeria, SNTF operates commuter-rail lines between the capital Algiers and its southern and eastern suburbs. They also serve to connect Algiers' main universities to each other. The Dar es Salaam commuter rail offers intracity services in Dar es Salaam, Tanzania.
Asia.
In Japan, commuter rail systems have extensive network and frequent service, and are heavily used. In many cases, Japanese commuter rail is operationally more like a typical metro system (with very high operating frequencies, an emphasis on standing passengers, short station spacing, and dedicated rights-of-way) than it is like commuter rail in other countries. Japanese commuter rail also tends to be heavily interlined with subway lines, with commuter rail trains continuing into the subway network, and then out onto different commuter rail systems on the other side of the city. Many Japanese commuter systems operate several levels of express trains to reduce the travel time to distant locations, often using station bypass tracks instead of dedicated express tracks. It is notable that the majority of Japanese commuter rail systems are owned and operated by private railway companies, without public subsidy.
In India, commuter rail systems are present in major cities. Mumbai Suburban Railway, the oldest suburban rail system in Asia, carries more than 7.24 million commuters on a daily basis which constitutes more than half of the total daily passenger capacity of the Indian Railways itself. Kolkata Suburban Railway is huge and extensive and covers large areas in Kolkata's hinterland. The Chennai Suburban Railway along with MRTS is another railway of comparison where almost 2 million people travel daily to different areas in Chennai. In Hyderabad, the MMTS mainly transports people from the city centre to HI-TEC city, the city's Information Technology hub. Other commuter railways in India include Delhi Suburban Railway, Pune Suburban Railway and Lucknow-Kanpur Suburban Railway.
Commuter trains are relatively uncommon in China, although small systems have been inaugurated in Beijing in 2008 and in Shanghai in 2012. Other systems have been built to high speed standards such as the Guangzhu MRT and Chengdu–Dujiangyan ICL.
Commuter rail systems are also planned for Nanjing, Tianjin, and around the Pearl River Delta region.
In Iran, SYSTRA has done a "Tehran long term urban rail study". SYSTRA proposed 4 express lines which are similar to RER suburban lines in Paris.
Tehran Metro is going to construct express lines. For instance, the Rahyab Behineh, a consultant for Tehran Metro, is studying Tehran Express Line 2. Tehran Metro currently has a commuter line between Tehran and Karaj. Esfahan has two lines to its suburbs Baharestan and Fuladshahr under construction, and a third line to Shahinshahr is planned.
In Taiwan, Western Line in Taipei-Taoyuan Metropolitan Area, Taichung Metropolitan Area, Tainan-Kaohsiung Metropolitan Area as well as Neiwan-Liujia Line in Hsinchu Area is considered commuter rail.
Other examples in Asia include Seoul Metropolitan Subway of which some lines are suburban lines operated by Korail in South Korea, KTM Komuter in Malaysia, the Philippine National Railways orange line in Metro Manila, Philippines and KRL Jabotabek in Jakarta Metropolitan area, Indonesia.
Europe.
Major metropolitan areas in most European countries are usually served by extensive commuter/suburban rail systems. Well-known examples include Beovoz in Belgrade, Serbia, S-Bahn in Germany, German-speaking areas of Switzerland and Austria, Proastiakos in Greece, RER in France, suburban lines in Milan (Italy), Cercanías in Spain, HÉV in Budapest, Hungary and DART in Dublin, Ireland.
In Russia, Ukraine and some other countries of the former Soviet Union, electrical multiple unit passenger suburban trains called Elektrichka are widespread.
In Sweden, electrified commuter rail systems known as "Pendeltåg" are present in the cities of Stockholm and Gothenburg. The Stockholm commuter rail system, which began in 1968, is similar to the S-Bahn train systems of Munich and Frankfurt such that it may shares railway tracks with inter-city trains and freight trains, but for the most part run on its own dedicated tracks, and that it is mainly used to transport passengers from nearby towns and other suburban areas into the city centre, not for transportation inside the city centre. The Gothenburg commuter rail system, which began in 1960, is similar to the Stockholm system, but does fully share tracks with long-distance trains. Other train systems that are also considered as commuter rail but not counted as "pendeltåg" include Roslagsbanan and Saltsjöbanan in Stockholm, Upptåget in Uppsala County and Skåne Commuter Rail ("Pågatågen") in Skåne County which also acts as a regional rail system, as it serves other cities over 100 km (62 miles) from the principal city of Malmö, and some trains may also cross the Øresund Bridge to reach the city of Copenhagen in Denmark.
North and Central America.
In the United States, Canada, Costa Rica, El Salvador and Mexico regional passenger rail services are provided by governmental or quasi-governmental agencies, with a limited number of metropolitan areas served.
South America.
Examples include an commuter system in the Buenos Aires metropolitan area, the long Supervia in Rio de Janeiro, and the Metrotrén in Santiago, Chile. Another example is Companhia Paulista de Trens Metropolitanos (CPTM) in Greater São Paulo, Brazil. CPTM has 93 stations with six lines, numbered starting on 7 (the lines 1 to 6 belong to the São Paulo Metro), with a total length of .
Oceania.
Major cities in Australia have suburban railway systems in their metropolitan areas. As with Japanese suburban railways or Germany's and Switzerland's S-Bahns, these Australian networks have far more frequent services and far higher ridership per capita than US 'commuter rail' in the usual sense of the term. To some US observers these networks may appear to operate as commuter/metro hybrids, however, they are simply the result of full utilisation of the available track capacity in the core of the suburban rail network, this being fed from multiple feeder lines. This is particularly so in Sydney and Melbourne, where headways on many lines in the core of the network reach 3–5 minutes in peaks and 10–20 minutes off peak (about 18 hours a day) and enter an underground loop for passenger distribution in the city centre; and where ridership per capita exceeds the sum of metro and commuter rail in comparable North American urban areas such as Toronto, Boston or the San Francisco Bay Area. All systems, however, are based on established main line rail systems, and track sharing with inter-city and freight services on parts of the network inhibit higher frequencies on some tracks. The main systems include:
New Zealand has two commuter rail systems, one in Auckland and one in Wellington.

</doc>
<doc id="6288" url="http://en.wikipedia.org/wiki?curid=6288" title="Cambridgeshire">
Cambridgeshire

Cambridgeshire ( or ; also known, archaically, as the County of Cambridge; abbreviated Cambs.) is a county in England, bordering Lincolnshire to the north, Norfolk to the north-east, Suffolk to the east, Essex and Hertfordshire to the south, and Bedfordshire and Northamptonshire to the west. The city of Cambridge is the county town. Modern Cambridgeshire was formed on 1 April 1974 as an amalgamation of the counties of Cambridgeshire and Isle of Ely and Huntingdon and Peterborough, which had been created on 1 April 1965 from the historic counties of Cambridgeshire, Huntingdonshire, the Isle of Ely and the Soke of Peterborough. It contains most of the region known as Silicon Fen. Cambridgeshire is twinned with Kreis Viersen in Germany.
History.
Cambridgeshire is noted as the site of Flag Fen in Fengate, one of the earliest-known Neolithic permanent settlements in the United Kingdom, compared in importance to Balbridie in Aberdeen, Scotland. A great quantity of archaeological finds from the Stone Age, the Bronze Age and the Iron Age were made in East Cambridgeshire. Most items were found in Isleham.
Cambridgeshire was recorded in the Domesday Book as "Grantbridgeshire" (or rather "Grentebrigescire") (related to the river Granta).
Covering a large part of East Anglia, Cambridgeshire today is the result of several local government unifications. In 1888 when county councils were introduced, separate councils were set up, following the traditional division of Cambridgeshire, for
In 1965, these two administrative counties were merged to form Cambridgeshire and the Isle of Ely.
Under the Local Government Act 1972 this merged with the county to the west, Huntingdon and Peterborough. (The latter had been organized in 1965 by the merger of Huntingdonshire with the Soke of Peterborough – previously a part of Northamptonshire which had its own county council). The resulting county was called simply Cambridgeshire.
Since 1998, the City of Peterborough has been a separately administered area, as a unitary authority. It is associated with Cambridgeshire for ceremonial purposes such as Lieutenancy, and functions such as policing and the fire service.
In 2002, the conservation charity Plantlife unofficially designated Cambridgeshire's county flower as the Pasqueflower.
The Cambridgeshire Regiment (or Fen Tigers), the county-based army unit, fought in the Boer War of South Africa, the First World War and Second World War.
Due to the county's flat terrain and proximity to the continent, during the Second World War the military built many airfields here for RAF Bomber Command, RAF Fighter Command, and the allied USAAF. In recognition of this collaboration, the Cambridge American Cemetery and Memorial is located in Madingley. It is the only WWII burial ground in England for American servicemen who died during that event. 
Most English counties have nicknames for their people, such as a "Tyke" from Yorkshire and a "Yellowbelly" from Lincolnshire. The traditional nicknames for people from Cambridgeshire are "Cambridgeshire Camel" or "Cambridgeshire Crane", referring to the wildfowl that were once abundant in the fens. The term "Fenners" was often applied to those who come from the flat country to the north of Cambridge. Since the late 20th century, this term is considered to be derogatory and has been discouraged in use. 
Original historical documents relating to Cambridgeshire are held by Cambridgeshire Archives and Local Studies.
Geography.
Large areas of the county are extremely low-lying and Holme Fen is notable for being the UK's lowest physical point at 2.75 m (9 ft) below sea level. The highest point is in the village of Great Chishill at 146 m (480 ft) above sea level. Other prominent hills are Little Trees Hill and Wandlebury Hill in the Gog Magog Downs, Rivey Hill above Linton, Rowley's Hill and the Madingley Hills.
Politics.
Cambridgeshire contains seven Parliamentary constituencies:
Economy.
This is a chart of trend of regional gross value added of Cambridgeshire at current basic prices (pp. 240–253) by "Office for National Statistics" with figures in millions of English Pounds Sterling.
AWG plc is based in Huntingdon. The RAF has several stations in the Huntingdon and St Ives area. RAF Waterbeach, 6 miles north of Cambridge, is a former RAF airfield, now used as an army barracks. RAF Alconbury, 3 miles north of Huntingdon, is being reorganised after a period of obsolescence following the departure of the USAF, to be the focus of RAF/USAFE intelligence operations, with activities at Upwood and Molesworth being transferred there. Most of Cambridgeshire is agricultural. Close to Cambridge is the so-called Silicon Fen area of high-technology (electronics, computing and biotechnology) companies. ARM Limited is based in Cherry Hinton.
Education.
Primary and secondary.
Cambridgeshire has a completely comprehensive education system with 12 independent schools and over 240 state schools, not including sixth form colleges.
Some of the secondary schools act as Village Colleges, institutions unique to Cambridgeshire. For example Bottisham Village College.
Tertiary.
Cambridgeshire is home to a number of institutes of higher education:
In addition, Cambridge Regional College and Huntingdonshire Regional College both offer a limited range of higher education courses in conjunction with partner universities.
Settlements.
These are the settlements in Cambridgeshire with a town charter, city status or a population over 5,000; for a complete list of settlements see list of places in Cambridgeshire.
The town of Newmarket is surrounded on three sides by Cambridgeshire, being connected by a narrow strip of land to the rest of Suffolk.
Cambridgeshire has seen 32,869 dwellings created from 2002-2013 and there are a further 35,360 planned new dwellings between now and 2023.
Climate.
Cambridgeshire has a maritime temperate climate which is broadly similar to the rest of the United Kingdom, though it is drier than the UK average due to its low altitude and easterly location, the prevailing southwesterly winds having already deposited moisture on higher ground further west. Average winter temperatures are cooler than the English average, due to Cambridgeshire's inland location and relative nearness to continental Europe, which results in the moderating maritime influence being less strong. Snowfall is slightly more common than in western areas, due to the relative winter coolness and easterly winds bringing occasional snow from the North Sea. In summer temperatures are average or slightly above, due to less cloud cover. It reaches 25°C on around 10 days each year, and is comparable to parts of Kent and East Anglia.
Culture.
Sports.
Association Football (the biggest sport in the world) was invented in Cambridge, Cambridgeshire on what is now known as Parker's Piece in the middle of town. This is the earliest version of Association Football that has ever existed and the rules still exist today. Folklore dictates that there are 11 men on each team because when the game was invented, there were eleven trees on either side of Parker's Piece. In commemoration of the creation of Football; a statue is to be raised in the middle of the park where the game was invented. Despite this however, the "home" of football is said to be Wembley, London for two reasons. 1) It is in the capital city of England and 2) It is where England's national team play.
Cambridgeshire is the birthplace of bandy, now an IOC accepted sport. According to documents from 1813 Bury Fen Bandy Club was undefeated for 100 years. A member of the club, Charles Tebbutt, wrote down the first official rules in 1882. Tebbutt was instrumental in spreading the sport to many countries. Bandy Federation of England is based in Cambridgeshire.
Contemporary Art.
Cambridge is home to the Kettle's Yard gallery and the artist run Aid and Abet project Space. Nine miles west of Cambridge next to the village of Bourn is Wysing Arts Centre.
Famous people from Cambridgeshire.
As well as those born in the county there are many notable people from, or associated with, Cambridgeshire who moved there, particularly due to the presence of Cambridge University.
Cambridgeshire lays claim to Lord Protector Oliver Cromwell, Prime Minister John Major, businessmen Henry Royce and Peter Boizot, social reformers Octavia Hill and Thomas Clarkson, and economist John Maynard Keynes. Scientists include Brian J. Ford and Stephen Hawking, and Nobel laureate Harold Kroto. Literary figures who hail from Cambridgeshire include John Clare, Samuel Pepys, Lucy M. Boston, Jeffrey Archer, Douglas Adams, and Olaudah Equiano.
In entertainment, cartoonist Ronald Searle, comedian Rory McGrath, television presenter Sarah Cawood, and radio sports presenter Adrian Durham are all from Cambridgeshire. Paul Nicholas, Richard Attenborough, Jeremy Irvine and Warwick Davis are all associated with film, while musicians include Andrew Eldritch, lead singer of The Sisters of Mercy; Andy Bell, lead singer for Erasure; David Gilmour, Roger Waters, Bob Klose and Roger Keith "Syd" Barrett of Pink Floyd; Don Airey, keyboardist in the rock band Deep Purple; trombonist Don Lusher; Keith Palmer, of dance music band The Prodigy; Nigel Sixsmith, founding member of The Art Of Sound and well known Keytar player; singer Aston Merrygold of JLS; the members of Britain's Got Talent Popera band The Arrangement and Matt Bellamy. Athletes Joe Bugner, Sir Jack Hobbs, Louis Smith and Marty Scurll are also from the county.
Richard Garriott, and Hereward the Wake are all from Cambridgeshire.

</doc>
<doc id="6290" url="http://en.wikipedia.org/wiki?curid=6290" title="Christian Goldbach">
Christian Goldbach

Christian Goldbach (March 18, 1690 – November 20, 1764) was a German mathematician who also studied law. He is remembered today for Goldbach's conjecture.
Biography.
Born in the Duchy of Prussia's capital Königsberg, part of Brandenburg-Prussia, Goldbach was the son of a pastor. He studied at the Royal Albertus University.
After finishing his studies he went on long educational voyages from 1710 to 1724 through Europe, visiting other German states, England, Holland, Italy, and France, meeting with many famous mathematicians, such as Gottfried Leibniz, Leonhard Euler, and Nicholas I Bernoulli. Back in Königsberg he got acquainted with Georg Bernhard Bilfinger and Jakob Hermann.
He went on to work at the newly opened St Petersburg Academy of Sciences in 1725. He was a tutor to Peter II who in 1728 became Tsar. In 1742 he entered the Russian Ministry of Foreign Affairs.
He died on November 20, 1764 at age of 74, at Moscow.
Contributions.
Goldbach is most noted for his correspondence with Leibniz, Euler, and Bernoulli, especially in his 1742 letter to Euler stating his Goldbach's conjecture. He also studied and proved some theorems on perfect powers, such as the Goldbach–Euler theorem, and made several notable contributions to analysis. He also proved a result concerning Fermat numbers that is called Goldbach's theorem.

</doc>
<doc id="6291" url="http://en.wikipedia.org/wiki?curid=6291" title="Roman censor">
Roman censor

The censor was an officer in ancient Rome who was responsible for maintaining the census, supervising public morality, and overseeing certain aspects of the government's finances.
The censors' regulation of public morality is the origin of the modern meaning of the words "censor" and "censorship".
Creation of the rank.
The "census" was first instituted by Servius Tullius, sixth king of Rome. After the abolition of the monarchy and the founding of the Republic, the consuls had responsibility for the census until 443 BC. In 442 BC, no consuls were elected, but tribunes with consular power were appointed instead; this was a move by the plebeians to try to attain higher magistracies: only patricians could be elected consuls, while some military tribunes were plebeians. To avoid the possibility of plebeians obtaining control of the census, the patricians removed the right to take the census from the consuls and tribunes, and appointed for this duty two magistrates, called "censores" (censors), elected exclusively from the patricians in Rome. 
The magistracy continued to be controlled by patricians until 351 BC, when Gaius Marcius Rutilus was appointed the first plebeian censor. Twelve years later, in 339 BC, one of the Publilian laws required that one censor had to be a plebeian. Despite this, no plebeian censor performed the solemn purification of the people (the "lustrum"; "Livy" Periochae 13) until 280 BC. In 131 BC, for the first time, both censors were plebeians.
The reason for two censors was that the two consuls had previously taken the census together. If one of the censors died during his term of office, another was chosen to replace him, just as with consuls. This happened only once, in 393 BC. However, the Gauls captured Rome in that "lustrum" (five-year period), and the Romans thereafter regarded such replacement as "an offense against religion". From then on, if one of the censors died, his colleague resigned, and two new censors were chosen to replace them.
Election.
The censors were elected in the Centuriate Assembly, which met under the presidency of a consul. Barthold Niebuhr suggests that the censors were at first elected by the Curiate Assembly, and that the Assembly's selections were confirmed by the Centuriate, but William Smith believes that "there is no authority for this supposition, and the truth of it depends entirely upon the correctness of [Niebuhr's] views respecting the election of the consuls". Both censors had to be elected on the same day, and accordingly if the voting for the second was not finished in the same day, the election of the first was invalidated, and a new assembly had to be held.
The assembly for the election of the censors was held under different auspices from those at the election of the consuls and praetors, so the censors were not regarded as their colleagues, although they likewise possessed the "maxima auspicia". The assembly was held by the new consuls shortly after they began their term of office; and the censors, as soon as they were elected and the censorial power had been granted to them by a decree of the Centuriate Assembly ("lex centuriata"), were fully installed in their office.
As a general principle, the only ones eligible for the office of censor were those who had previously been consuls, but there were a few exceptions. At first, there was no law to prevent a person being censor twice, but the only person who was elected to the office twice was Gaius Marcius Rutilus in 265 BC. In that year, he originated a law stating that no one could be elected censor twice. In consequence of this, he received the cognomen of "Censorinus".
Attributes.
The censorship differed from all other Roman magistracies in the length of office. The censors were originally chosen for a whole "lustrum" (the period of five years), but as early as ten years after its institution (433 BC) their office was limited to eighteen months by a law of the dictator Mamercus Aemilius Mamercinus. The censors were also unique with respect to rank and dignity. They had no "imperium", and accordingly no lictors. Their rank was granted to them by the Centuriate Assembly, and not by the "curiae", and in that respect they were inferior in power to the consuls and praetors.
Notwithstanding this, the censorship was regarded as the highest dignity in the state, with the exception of the dictatorship; it was a "sacred magistracy" ("sanctus magistratus"), to which the deepest reverence was due. The high rank and dignity which the censorship obtained was due to the various important duties gradually entrusted to it, and especially to its possessing the "regimen morum", or general control over the conduct and the morals of the citizens. In the exercise of this power, they were regulated solely by their own views of duty, and were not responsible to any other power in the state.
The censors possessed of course the "curule chair" ("sella curulis"), but some doubt exists with respect to their official dress. A well-known passage of Polybius describes the use of the "imagines" at funerals; we may conclude that a consul or praetor wore the purple-bordered "toga praetexta", one who triumphed the embroidered "toga picta", and the censor a purple toga peculiar to him, but other writers speak of their official dress as being the same as that of the other higher magistrates. The funeral of a censor was always conducted with great pomp and splendour, and hence a "censorial funeral" ("funus censorium") was voted even to the emperors.
Abolition.
The censorship continued in existence for 421 years, from 443 BC to 22 BC, but during this period, many "lustra" passed by without any censor being chosen at all. According to one statement, the office was abolished by Lucius Cornelius Sulla. Although the authority on which this statement rests is not of much weight, the fact itself is probable, since there was no census during the two "lustra" which elapsed from Sulla's dictatorship to Gnaeus Pompeius Magnus (Pompey)'s first consulship (82–70 BC), and any strict "imposition of morals" would have been found inconvenient to the aristocracy that supported Sulla.
If the censorship had been done away with by Sulla, it was at any rate restored in the consulship of Pompey and Marcus Licinius Crassus. Its power was limited by one of the laws of the tribune Publius Clodius Pulcher (58 BC), which prescribed certain regular forms of proceeding before the censors in expelling a person from the Roman Senate, and required that the censors be in agreement to exact this punishment. This law, however, was repealed in the third consulship of Pompey in 52 BC, on the urging of his colleague Caecilius Metellus Scipio, but the office of the censorship never recovered its former power and influence.
During the civil wars which followed soon afterwards, no censors were elected; it was only after a long interval that they were again appointed, namely in 22 BC, when Augustus caused Lucius Munatius Plancus and Aemilius Lepidus Paullus to fill the office. This was the last time that such magistrates were appointed; the emperors in future discharged the duties of their office under the name of Praefectura Morum ("prefect of the morals").
Some of the emperors sometimes took the name of censor when they held a census of the Roman people; this was the case with Claudius, who appointed the elder Vitellius as his colleague, and with Vespasian, who likewise had a colleague in his son Titus. Domitian assumed the title of "perpetual censor" ("censor perpetuus"), but this example was not imitated by succeeding emperors. In the reign of Decius, we find the elder Valerian nominated to the censorship, but Valerian was never actually elected censor.
Duties.
The duties of the censors may be divided into three classes, all of which were closely connected with one another:
The original business of the censorship was at first of a much more limited kind, and was restricted almost entirely to taking the census, but the possession of this power gradually brought with it fresh power and new duties, as is shown below. A general view of these duties is briefly expressed in the following passage of Cicero: "Censores populi aevitates, soboles, familias pecuniasque censento: urbis templa, vias, aquas, aerarium, vectigalia tuento: populique partes in tribus distribunto: exin pecunias, aevitates, ordines patiunto: equitum, peditumque prolem describunto: caelibes esse prohibento: mores populi regunto: probrum in senatu ne relinquunto." This can be translated roughly as: "The Censors are to determine the generations, origins, families, and properties of the people; they are to (watch over/protect) the city's temples, roads, waters, treasury, and taxes; they are to divide the people into three parts; next, they are to (allow/approve) the properties, generations, and ranks [of the people]; they are to describe the offspring of knights and footsoldiers; they are to forbid being unmarried; they are to guide the behavior of the people; they are not to overlook abuse in the Senate." 
Census.
The Census, the first and principal duty of the censors, was always held in the Campus Martius, and from the year 435 BC onwards, in a special building called Villa Publica, which was erected for that purpose by the second pair of censors, Gaius Furius Pacilus and Marcus Geganius Macerinus.
An account of the formalities with which the census was opened is given in a fragment of the "Tabulae Censoriae", preserved by Varro. After the auspices had been taken, the citizens were summoned by a public crier to appear before the censors. Each tribe was called up separately, and the names in each tribe were probably taken according to the lists previously made out by the tribunes of the tribes. Every paterfamilias had to appear in person before the censors, who were seated in their curule chairs, and those names were taken first which were considered to be of good omen, such as Valerius, Salvius, Statorius, etc.
The census was conducted according to the judgment of the censor ("ad arbitrium censoris"), but the censors laid down certain rules, sometimes called "leges censui censendo", in which mention was made of the different kinds of property subject to the census, and in what way their value was to be estimated. According to these laws, each citizen had to give an account of himself, of his family, and of his property upon oath, "declared from the heart".
First he had to give his full name (praenomen, nomen, and cognomen) and that of his father, or if he were a "Libertus" ("freedman") that of his patron, and he was likewise obliged to state his age. He was then asked, "You, declaring from your heart, do you have a wife?" and if married he had to give the name of his wife, and likewise the number, names, and ages of his children, if any. Single women and orphans were represented by their guardians; their names were entered in separate lists, and they were not included in the sum total of heads.
After a citizen had stated his name, age, family, etc., he then had to give an account of all his property, so far as it was subject to the census. Only such things were liable to the census ("censui censendo") as were property according to the Quiritarian law. At first, each citizen appears to have merely given the value of his whole property in general without entering into details; but it soon became the practice to give a minute specification of each article, as well as the general value of the whole.
Land formed the most important article of the census, but public land, the possession of which only belonged to a citizen, was excluded as not being Quiritarian property. If we may judge from the practice of the imperial period, it was the custom to give a most minute specification of all such land as a citizen held according to the Quiritarian law. He had to state the name and location of the land, and to specify what portion of it was arable, what meadow, what vineyard, and what olive-ground: and of the land thus described, he had to give his assessment of its value.
Slaves and cattle formed the next most important item. The censors also possessed the right of calling for a return of such objects as had not usually been given in, such as clothing, jewels, and carriages. It has been doubted by some modern writers whether the censors possessed the power of setting a higher valuation on the property than the citizens themselves gave, but when we recollect the discretionary nature of the censors' powers, and the necessity almost that existed, in order to prevent fraud, that the right of making a surcharge should be vested in somebody's hands, we can hardly doubt that the censors had this power. It is moreover expressly stated that on one occasion they made an extravagant surcharge on articles of luxury; and even if they did not enter in their books the property of a person at a higher value than he returned it, they accomplished the same end by compelling him to pay a tax upon the property at a higher rate than others. The tax was usually one per thousand upon the property entered in the books of the censors, but on one occasion the censors compelled a person to pay eight per thousand as a punishment.
A person who voluntarily absented himself from the census was considered "incensus" and subject to the severest punishment. Servius Tullius is said to have threatened such individuals with imprisonment and death, and in the Republican period he might be sold by the state as a slave In the later times of the republic, a person who was absent from the census might be represented by another, and be thus registered by the censors. Whether the soldiers who were absent on service had to appoint a representative is uncertain. In ancient times, the sudden outbreaks of war prevented the census from being taken, because a large number of the citizens would necessarily be absent. It is supposed from a passage in Livy that in later times the censors sent commissioners into the provinces with full powers to take the census of the Roman soldiers there, but this seems to have been a special case. It is, on the contrary, probable from the way in which Cicero pleads the absence of Archias from Rome with the army under Lucullus, as a sufficient reason for his not having been enrolled in the census, that service in the army was a valid excuse for absence.
After the censors had received the names of all the citizens with the amount of their property, they then had to make out the lists of the tribes, and also of the classes and centuries; for by the legislation of Servius Tullius the position of each citizen in the state was determined by the amount of his property (Comitia Centuriata). These lists formed a most important part of the Tabulae Censoriae, under which name were included all the documents connected in any way with the discharge of the censors' duties. These lists, insofar as they were connected with the finances of the state, were deposited in the aerarium, which was the temple of Saturn; but the regular depositary for all the archives of the censors was in earlier times the Atrium Libertatis, near the Villa publica, and in later times the temple of the Nymphs.
Besides the division of the citizens into tribes, centuries, and classes, the censors had also to make out the lists of the senators for the ensuing five years, or until new censors were appointed; striking out the names of such as they considered unworthy, and making additions to the body from those who were qualified. In the same manner they held a review of the Equestrians who received a horse from public funds ("equites equo publico"), and added and removed names as they judged proper. They also confirmed the princeps senatus, or appointed a new one. The princeps himself had to be a former censor.
After the lists had been completed, the number of citizens was counted up, and the sum total announced. Accordingly, we find that in the account of a census, the number of citizens is likewise usually given. They are in such cases spoken of as "capita" ("heads"), sometimes with the addition of the word "civium" ("of the citizens"), and sometimes not. Hence, to be registered in the census was the same thing as "having a head" ("caput habere").
Census beyond Rome.
A census was sometimes taken in the provinces, even under the republic. The Emperor sent into the provinces special officers called Censitores to take the census; but the duty was sometimes discharged by the Imperial legati. The Censitores were assisted by subordinate officers, called Censuales, who made out the lists, &c. In Rome, the census was still taken under the empire, but the old ceremonies connected with it were no longer performed, and the ceremony of the lustration was not performed after the time of Vespasian. The jurists Paulus and Ulpian each wrote works on the census in the imperial period; and several extracts from these works are given in a chapter in the "Digest" (50 15). 
Other uses of census.
The word "census", besides the conventional meaning of "valuation" of a person's estate, has other meaning in Rome; it could refer to: 
"Regimen morum".
Keeping the public morals ("regimen morum", or in the empire "cura morum" or "praefectura morum") was the second most important branch of the censors' duties, and the one which caused their office to be one of the most revered and the most dreaded in the Roman state; hence they were also known as "Castigatores" ("chastisers"). It naturally grew out of the right which they possessed of excluding persons from the lists of citizens; for, as has been well remarked, "they would, in the first place, be the sole judges of many questions of fact, such as whether a citizen had the qualifications required by law or custom for the rank which he claimed, or whether he had ever incurred any judicial sentence, which rendered him infamous: but from thence the transition was easy, according to Roman notions, to the decisions of questions of right; such as whether a citizen was really worthy of retaining his rank, whether he had not committed some act as justly degrading as those which incurred the sentence of the law." 
In this manner, the censors gradually assumed at least nominal complete superintendence over the whole public and private life of every citizen. They were constituted as the conservators of public morality; they were not simply to prevent crime or particular acts of immorality, but rather to maintain the traditional Roman character, ethics, and habits ("mos majorum")—"regimen morum" also encompassed this protection of traditional ways, which was called in the times of the empire "cura" ("supervision") or "praefectura" ("command"). The punishment inflicted by the censors in the exercise of this branch of their duties was called "nota" ("mark, letter") or "notatio", or "animadversio censoria" ("censorial reproach"). In inflicting it, they were guided only by their conscientious convictions of duty; they had to take an oath that they would act biased by neither partiality nor favour; and, in addition to this, they were bound in every case to state in their lists, opposite the name of the guilty citizen, the cause of the punishment inflicted on him, "Subscriptio censoria".
This part of the censors' office invested them with a peculiar kind of jurisdiction, which in many respects resembled the exercise of public opinion in modern times; for there are innumerable actions which, though acknowledged by every one to be prejudicial and immoral, still do not come within the reach of the positive laws of a country; as often said, "immorality does not equal illegality". Even in cases of real crimes, the positive laws frequently punish only the particular offence, while in public opinion the offender, even after he has undergone punishment, is still incapacitated for certain honours and distinctions which are granted only to persons of unblemished character.
Hence the Roman censors might brand a man with their "censorial mark" ("nota censoria") in case he had been convicted of a crime in an ordinary court of justice, and had already suffered punishment for it. The consequence of such a nota was only "ignominia" and not "infamia". "Infamia" and the censorial verdict was not a "judicium" or "res judicata", for its effects were not lasting, but might be removed by the following censors, or by a "lex" (roughly "law"). A censorial mark was moreover not valid unless both censors agreed. The "ignominia" was thus only a transitory reduction of status, which does not even appear to have deprived a magistrate of his office, and certainly did not disqualify persons labouring under it for obtaining a magistracy, for being appointed as "judices" by the praetor, or for serving in the Roman armies. Mamercus Aemilius was thus, notwithstanding the reproach of the censors ("animadversio censoria"), made dictator.
A person might be branded with a censorial mark in a variety of cases, which it would be impossible to specify, as in a great many instances it depended upon the discretion of the censors and the view they took of a case; and sometimes even one set of censors would overlook an offence which was severely chastised by their successors. But the offences which are recorded to have been punished by the censors are of a threefold nature.
A person who had been branded with a "nota censoria", might, if he considered himself wronged, endeavour to prove his innocence to the censors, and if he did not succeed, he might try to gain the protection of one of the censors, that he might intercede on his behalf.
Punishments.
The punishments inflicted by the censors generally differed according to the station which a man occupied, though sometimes a person of the highest rank might suffer all the punishments at once, by being degraded to the lowest class of citizens. But they are generally divided into four classes:
It was this authority of the Roman censors which eventually developed into the modern meaning of "censor" and "censorship"—i.e., officials who review published material and forbid the publication of material judged to be contrary to "public morality" as the term is interpreted in a given political and social environment.
Administration of the finances of the state.
The administration of the state's finances was another part of the censors' office. In the first place the "tributum", or property-tax, had to be paid by each citizen according to the amount of his property registered in the census, and, accordingly, the regulation of this tax naturally fell under the jurisdiction of the censors. They also had the superintendence of all the other revenues of the state, the "vectigalia", such as the tithes paid for the public lands, the salt works, the mines, the customs, etc.
The censors typically auctioned off to the highest bidder for the space of a "lustrum" the collection of the tithes and taxes (tax farming). This auctioning was called "venditio" or "locatio", and seems to have taken place in the month of March, in a public place in Rome The terms on which they were let, together with the rights and duties of the purchasers, were all specified in the "leges censoriae", which the censors published in every case before the bidding commenced. For further particulars see Publicani.
The censors also possessed the right, though probably not without the assent of the Senate, of imposing new "vectigalia", and even of selling the land belonging to the state. It would thus appear that it was the duty of the censors to bring forward a budget for a five-year period, and to take care that the income of the state was sufficient for its expenditure during that time. In part, their duties resembled those of a modern minister of finance. The censors, however, did not receive the revenues of the state. All the public money was paid into the "aerarium", which was entirely under the jurisdiction of the senate; and all disbursements were made by order of this body, which employed the quaestors as its officers.
In one important department the censors were entrusted with the expenditure of the public money, though the actual payments were no doubt made by the quaestors. The censors had the general superintendence of all the public buildings and works ("opera publica"), and to meet the expenses connected with this part of their duties, the senate voted them a certain sum of money or certain revenues, to which they were restricted, but which they might at the same time employ according to their discretion. They had to see that the temples and all other public buildings were in a good state of repair, that no public places were encroached upon by the occupation of private persons, and that the aqueduct, roads, drains, etc. were properly attended to.
The repairs of the public works and the keeping of them in proper condition were let out by the censors by public auction to the lowest bidder, just as the "vectigalia" were let out to the highest bidder. These expenses were called "ultrotributa", and hence we frequently find "vectigalia" and "ultrotributa" contrasted with one another. The persons who undertook the contract were called "conductores", "mancipes", "redemptores", "susceptores", etc.; and the duties they had to discharge were specified in the Leges Censoriae. The censors had also to superintend the expenses connected with the worship of the gods, even for instance the feeding of the sacred geese in the Capitol; these various tasks were also let out on contract.
Besides keeping existing public buildings and facilities in a proper state of repair, the censors were also in charge of constructing new ones, either for ornament or utility, both in Rome and in other parts of Italy, such as temples, basilicae, theatres, porticoes, fora, walls of towns, aqueducts, harbours, bridges, cloacae, roads, etc. These works were either performed by them jointly, or they divided between them the money, which had been granted to them by the senate. They were let out to contractors, like the other works mentioned above, and when they were completed, the censors had to see that the work was performed in accordance with the contract: this was called "opus probare" or "in acceptum referre".
The aediles had likewise a superintendence over the public buildings, and it is not easy to define with accuracy the respective duties of the censors and aediles, but it may be remarked in general that the superintendence of the aediles had more of a police character, while that of the censors were more financial in subject matter.
Lustrum.
After the censors had performed their various duties and taken the five-yearly census, the "lustrum", a solemn purification of the people, followed. When the censors entered upon their office, they drew lots to see which of them should perform this purification; but both censors were of course obliged to be present at the ceremony.
Long after the Roman census was no longer taken, the Latin word "lustrum" has survived, and been adopted in some modern languages, in the derived sense of a period of five years, i.e. half a decennium.
Census statistics.
Andrea Doria as "perpetual censor".
Andrea Doria, the famous 16th Century Genoese admiral, was rewarded for his services to his city with the title of "perpetual censor"—inspired by, though not precisely identical with, the Roman one.

</doc>
<doc id="6292" url="http://en.wikipedia.org/wiki?curid=6292" title="Convex set">
Convex set

In Euclidean space, an object is convex if for every pair of points within the object, every point on the straight line segment that joins the pair of points is also within the object. For example, a solid cube is convex, but anything that is hollow or has a dent in it, for example, a crescent shape, is not convex. A convex curve forms the boundary of a convex set.
The notion of a convex set can be generalized to other spaces as described below.
In vector spaces.
Let be a vector space over the real numbers, or, more generally, some ordered field. This includes Euclidean spaces. A set in is said to be convex if, for all and in and all in the interval , the point also belongs to . In other words, every point on the line segment connecting and is in . This implies that a convex set in a real or complex topological vector space is path-connected, thus connected.
A set is called absolutely convex if it is convex and balanced.
The convex subsets of (the set of real numbers) are simply the intervals of . Some examples of convex subsets of the Euclidean plane are solid regular polygons, solid triangles, and intersections of solid triangles. Some examples of convex subsets of a Euclidean 3-dimensional space are the Archimedean solids and the Platonic solids. The Kepler-Poinsot polyhedra are examples of non-convex sets.
Properties.
If is a convex set in -dimensional space, then for any collection of , , -dimensional vectors in , and for any nonnegative numbers such that , then one has:
A vector of this type is known as a convex combination of .
Intersections and unions.
The collection of convex subsets of a vector space has the following properties:
Convex hulls.
Every subset of the vector space is contained within a smallest convex set (called the convex hull of ), namely the intersection of all convex sets containing . The convex-hull operator Conv() has the characteristic properties of a hull operator:
The convex-hull operation is needed for the set of convex sets to form a lattice, in which the "join" operation is the convex hull of the union of two convex sets
The intersection of any collection of convex sets is itself convex, so the convex subsets of a (real or complex) vector space form a complete lattice.
Minkowski addition.
In a real vector-space, the "Minkowski sum" of two (non-empty) sets, and , is defined to be the set formed by the addition of vectors element-wise from the summand-sets
More generally, the "Minkowski sum" of a finite family of (non-empty) sets is the set formed by element-wise addition of vectors
For Minkowski addition, the "zero set"  containing only the zero vector  has special importance: For every non-empty subset S of a vector space
in algebraic terminology, is the identity element of Minkowski addition (on the collection of non-empty sets).
Convex hulls of Minkowski sums.
Minkowski addition behaves well with respect to the operation of taking convex hulls, as shown by the following proposition:
Let be subsets of a real vector-space, the convex hull of their Minkowski sum is the Minkowski sum of their convex hulls
This result holds more generally for each finite collection of non-empty sets:
In mathematical terminology, the operations of Minkowski summation and of forming convex hulls are commuting operations.
Closed convex sets.
Closed convex sets can be characterised as the intersections of "closed half-spaces" (sets of point in space that lie on and to one side of a hyperplane). From what has just been said, it is clear that such intersections are convex, and they will also be closed sets. To prove the converse, i.e., every convex set may be represented as such intersection, one needs the supporting hyperplane theorem in the form that for a given closed convex set and point outside it, there is a closed half-space that contains and not . The supporting hyperplane theorem is a special case of the Hahn–Banach theorem of functional analysis.
The Minkowski sum of two compact convex sets is compact, the sum of a compact convex set and a closed convex set is closed.
Generalizations and extensions for convexity.
The notion of convexity in the Euclidean space may be generalized by modifying the definition in some or other aspects. The common name "generalized convexity" is used, because the resulting objects retain certain properties of convex sets.
Star-convex sets.
Let be a set in a real or complex vector space. is star convex if there exists an in such that the line segment from to any point in is contained in . Hence a non-empty convex set is always star-convex but a star-convex set is not always convex.
Orthogonal convexity.
An example of generalized convexity is orthogonal convexity.
A set in the Euclidean space is called orthogonally convex or ortho-convex, if any segment parallel to any of the coordinate axes connecting two points of lies totally within . It is easy to prove that an intersection of any collection of orthoconvex sets is orthoconvex. Some other properties of convex sets are valid as well.
Non-Euclidean geometry.
The definition of a convex set and a convex hull extends naturally to geometries which are not Euclidean by defining a geodesically convex set to be one that contains the geodesics joining any two points in the set.
Order topology.
Convexity can be extended for a space endowed with the order topology, using the total order of the space.
Let . The subspace is a convex set if for each pair of points in such that , the interval is contained in . That is, is convex if and only if for all in , implies .
Convexity spaces.
The notion of convexity may be generalised to other objects, if certain properties of convexity are selected as axioms.
Given a set , a convexity over is a collection of subsets of satisfying the following axioms:
The elements of are called convex sets and the pair is called a convexity space. For the ordinary convexity, the first two axioms hold, and the third one is trivial.
For an alternative definition of abstract convexity, more suited to discrete geometry, see the "convex geometries" associated with antimatroids.

</doc>
<doc id="6293" url="http://en.wikipedia.org/wiki?curid=6293" title="Cairo">
Cairo

Cairo ( ; ) is the capital of Egypt and the largest city in the Middle-East and second-largest in Africa after Lagos. Its metropolitan area is the 16th largest in the world. Located near the Nile Delta, it was founded in AD 969. Nicknamed "the city of a thousand minarets" for its preponderance of Islamic architecture, Cairo has long been a center of the region's political and cultural life. Cairo was founded by the Fatimid dynasty in the 10th century CE, but the land composing the present-day city was the site of national capitals whose remnants remain visible in parts of Old Cairo. Cairo is also associated with Ancient Egypt as it is close to the ancient cities of Memphis, Giza and Fustat which are near the Great Sphinx and the pyramids of Giza.
Egyptians today often refer to Cairo as ' (, ), the Egyptian Arabic pronunciation of the name for Egypt itself, emphasizing the city's continued role in Egyptian influence. Its official name is ', means literally: "The defeater", in reference to the fact that the planet was rising at the time when the city was founded as well as, "the Vanquisher"; "the Conqueror"; , "the defeater" or, " "the victorious" (al-Qahira) in reference to the much awaited Caliph al-Mu'izz li Din Allah who arrived from the old Fatimid capital of Mahdia in 973 to the city. The Egyptian name for Cairo is said to be: Khere-Ohe, meaning: "The Place of Combat", supposedly, in reference to a battle which took place between the Gods Seth and Horus. Sometimes the city is informally also referred to as ' . It is also called "Umm al-Dunya", meaning "the mother of the world".
Cairo has the oldest and largest film and music industries in the Arab world, as well as the world's second-oldest institution of higher learning, al-Azhar University. Many international media, businesses, and organizations have regional headquarters in the city; the Arab League has had its headquarters in Cairo for most of its existence.
With a population of 6.76 million spread over , Cairo is by far the largest city in Egypt. With an additional 10 million inhabitants just outside the city, Cairo resides at the center of the largest metropolitan area in Africa and the Arab World as well as the tenth-largest urban area in the world. Cairo, like many other mega-cities, suffers from high levels of pollution and traffic. Cairo's metro, one of only two metros on the African continent, ranks among the fifteen busiest in the world, with over 1 billion annual passenger rides. The economy of Cairo was ranked first in the Middle East and 43rd globally by "Foreign Policy"'s 2010 Global Cities Index.
History.
Initial settlements.
The area around present-day Cairo, especially Memphis, had long been a focal point of Ancient Egypt due to its strategic location just upstream from the Nile Delta. However, the origins of the modern city are generally traced back to a series of settlements in the first millennium. Around the turn of the 4th century, as Memphis was continuing to decline in importance, the Romans established a fortress town along the east bank of the Nile. This fortress, known as Babylon, remains the oldest structure in the city. It is also situated at the nucleus of the Coptic Orthodox community, which separated from the Roman and Byzantine church in the late 4th century. Many of Cairo's oldest Coptic churches, including the Hanging Church, are located along the fortress walls in a section of the city known as Coptic Cairo.
Foundation and expansion.
In 968, the Fatimids were led by General Gawhar al-Siqilli with his Kotama army, to establish a new capital for the Fatimid dynasty. Egypt was conquered from their base in Ifriqiya and a new fortified city northeast of Fustat was established. It took four years for Gawhar to build the city, initially known as al-Manṣūriyyah, which was to serve as the new capital of the caliphate. During that time, Jawhar also commissioned the construction of al-Azhar Mosque, which developed into the third-oldest university in the world. Cairo would eventually become a centre of learning, with the library of Cairo containing hundreds of thousands of books. When Caliph al-Mu'izz li Din Allah finally arrived from the old Fatimid capital of Mahdia in Tunisia in 973, he gave the city its present name, "al-Qahira" ("The Victorious").
For nearly 200 years after Cairo was established, the administrative centre of Egypt remained in Fustat. However, in 1168 the Fatimids under the leadership of Vizier Shawar set fire to Fustat to prevent Cairo's capture by the Crusaders. Egypt's capital was permanently moved to Cairo, which was eventually expanded to include the ruins of Fustat and the previous capitals of al-Askar and al-Qatta'i. While the Fustat fire successfully protected the city of Cairo, a continuing power struggle between Shawar, King Amalric I of Jerusalem, and the Zengid general Shirkuh led to the downfall of the Fatimid establishment.
In 1169 Saladin was appointed as the new vizier of Egypt by the Fatimids and two years later he would seize power from the family of the last Fatimid caliph, al-'Āḍid. As the first Sultan of Egypt, Saladin established the Ayyubid dynasty, based in Cairo, and aligned Egypt with the Abbasids, who were based in Baghdad. During his reign, Saladin also constructed the Cairo Citadel, which served as the seat of the Egyptian government until the mid-19th century.
In 1250 slave soldiers, known as the Mamluks, seized control of Egypt and like many of their predecessors established Cairo as the capital of their new dynasty. Continuing a practice started by the Ayyubids, much of the land occupied by former Fatimid palaces was sold and replaced by newer buildings. Construction projects initiated by the Mamluks pushed the city outward while also bringing new infrastructure to the centre of the city. Meanwhile, Cairo flourished as a centre of Islamic scholarship and a crossroads on the spice trade route among the civilisations in Afro-Eurasia. By 1340, Cairo had a population of close to half a million, making it the largest city west of China.
Ottoman rule.
Although Cairo avoided Europe's stagnation during the Late Middle Ages, it could not escape the Black Death, which struck the city more than fifty times between 1348 and 1517. During its initial, and most deadly waves, approximately 200,000 people were killed by the plague, and, by the 15th century, Cairo's population had been reduced to between 150,000 and 300,000. The city's status was further diminished after Vasco da Gama discovered a sea route around the Cape of Good Hope between 1497 and 1499, thereby allowing spice traders to avoid Cairo.
Cairo's political influence diminished significantly after the Ottomans supplanted Mamluk power over Egypt in 1517. Ruling from Constantinople, Sultan Selim I relegated Egypt to a mere province, with Cairo as its capital. For this reason, the history of Cairo during Ottoman times is often described as inconsequential, especially in comparison to other time periods. However, during the 16th and 17th centuries, Cairo remained an important economic and cultural centre. Although no longer on the spice route, the city facilitated the transportation of Yemeni coffee and Indian textiles, primarily to Anatolia, North Africa, and the Balkans. Cairene merchants were instrumental in bringing goods to the barren Hejaz, especially during the annual hajj to Mecca. It was during this same period that al-Azhar University reached the predominance among Islamic schools that it continues to hold today; pilgrims on their way to hajj often attested to the superiority of the institution, which had become associated with Egypt's body of Islamic scholars. By the 16th century, Cairo also had high-rise apartment buildings where the two lower floors were for commercial and storage purposes and the multiple stories above them were rented out to tenants.
Under the Ottomans, Cairo expanded south and west from its nucleus around the Citadel. The city was the second-largest in the empire, behind only Constantinople, and, although migration was not the primary source of Cairo's growth, twenty percent of its population at the end of the 18th century consisted of religious minorities and foreigners from around the Mediterranean. Still, when Napoleon arrived in Cairo in 1798, the city's population was less than 300,000, forty percent lower than it was at the height of Mamluk—and Cairene—influence in the mid-14th century.
The French occupation was short-lived as British and Ottoman forces, including a sizable Albanian contingent, recaptured the country in 1801. The British vacated Egypt two years later, leaving the Ottomans, the Albanians, and the long-weakened Mamluks jostling for control of the country. Continued civil war allowed an Albanian named Muhammad Ali Pasha to ascend to the role of commander and eventually, with the approval of the religious establishment, viceroy of Egypt in 1805.
Modern era.
Until his death in 1848, Muhammad Ali Pasha instituted a number of social and economic reforms that earned him the title of founder of modern Egypt. However, while Muhammad Ali initiated the construction of public buildings in the city, those reforms had minimal effect on Cairo's landscape. Bigger changes came to Cairo under Isma'il Pasha (r. 1863–1879), who continued the modernisation processes started by his grandfather. Drawing inspiration from Paris, Isma'il environs a city of maidans and wide avenues; due to financial constraints, only some of them, in the area now composing Downtown Cairo, came to fruition. Isma'il also sought to modernize the city, which was merging with neighboring settlements, by establishing a public works ministry, bringing gas and lighting to the city, and opening a theater and opera house.
The immense debt resulting from Isma'il's projects provided a pretext for increasing European control, which culminated with the British invasion in 1882. The city's economic centre quickly moved west toward the Nile, away from the historic Islamic Cairo section and toward the contemporary, European-style areas built by Isma'il. Europeans accounted for five percent of Cairo's population at the end of the 19th century, by which point they held most top governmental positions.
The British occupation was intended to be temporary, but it lasted well into the 20th century. Nationalists staged large-scale demonstrations in Cairo in 1919, five years after Egypt had been declared a British protectorate. Nevertheless, while this led to Egypt's independence in 1922, British troops remained in the country until 1956. During this time, urban Cairo, spurred by new bridges and transport links, continued to expand to include the upscale neighbourhoods of Garden City, Zamalek, and Heliopolis. Between 1882 and 1937, the population of Cairo more than tripled—from 347,000 to 1.3 million—and its area increased from .
The city was devastated during the 1952 Cairo Fire, also known as Black Saturday, which saw the destruction of nearly 700 shops, movie theatres, casinos and hotels in Downtown Cairo. The British departed Cairo following the Egyptian Revolution of 1952, but the city's rapid growth showed no signs of abating. Seeking to accommodate the increasing population, President Gamal Abdel Nasser redeveloped Midan Tahrir and the Nile Corniche, and improved the city's network of bridges and highways. Meanwhile, additional controls of the Nile fostered development within Gezira Island and along the city's waterfront. The metropolis began to encroach on the fertile Nile Delta, prompting the government to build desert satellite towns and devise incentives for city-dwellers to move to them.
Despite these efforts, Cairo's population has doubled since the 1960s, reaching close to seven million (with an additional ten million in its urban area). Concurrently, Cairo has established itself as a political and economic hub for North Africa and the Arab World, with many multinational businesses and organisations, including the Arab League, operating out of the city.
In 1992, Cairo was hit by a damaging earthquake, that caused 545 deaths, 6512 injuries and left 50,000 people homeless.
Cairo during 2011 Egyptian revolution.
Cairo's Tahrir Square was the focal point of the 2011 Egyptian Revolution against former president Hosni Mubarak. Over 2 million protesters at Cairo's Tahrir square. More than 50,000 protesters first occupied the square on 25 January, during which the area's wireless services were reported to be impaired. In the following days Tahrir Square continued to be the primary destination for protests in Cairo. as it took place following a popular uprising that began on Tuesday, 25 January 2011 and is still continuing as of February 2012. The uprising was mainly a campaign of non-violent civil resistance, which featured a series of demonstrations, marches, acts of civil disobedience, and labour strikes. Millions of protesters from a variety of socio-economic and religious backgrounds demanded the overthrow of the regime of Egyptian President Hosni Mubarak. Despite being predominantly peaceful in nature, the revolution was not without violent clashes between security forces and protesters, with at least 846 people killed and 6,000 injured. The uprising took place in Cairo, Alexandria, and in other cities in Egypt, following the Tunisian revolution that resulted in the overthrow of the long-time Tunisian president. On 11 February, following weeks of determined popular protest and pressure, Hosni Mubarak resigned from office.
Satellite cities.
6th of October City, west of Cairo, and New Cairo, east of Cairo, are major urban developments which have been built to accommodate additional growth and development of the Cairo area. New development includes several high-end residential developments.
Geography.
Cairo is located in northern Egypt, known as Lower Egypt, south of the Mediterranean Sea and west of the Gulf of Suez and Suez Canal. The city is along the Nile River, immediately south of the point where the river leaves its desert-bound valley and branches into the low-lying Nile Delta region. Although the Cairo metropolis extends away from the Nile in all directions, the city of Cairo resides only on the east bank of the river and two islands within it on a total area of .
Until the mid-19th century, when the river was tamed by dams, levees, and other controls, the Nile in the vicinity of Cairo was highly susceptible to changes in course and surface level. Over the years, the Nile gradually shifted westward, providing the site between the eastern edge of the river and the Mokattam highlands on which the city now stands. The land on which Cairo was established in 969 (present-day Islamic Cairo) was located underwater just over three hundred years earlier, when Fustat was first built.
Low periods of the Nile during the 11th century continued to add to the landscape of Cairo; a new island, known as "Geziret al-Fil", first appeared in 1174, but eventually became connected to the mainland. Today, the site of "Geziret al-Fil" is occupied by the Shubra district. The low periods created another island at the turn of the 14th century that now composes Zamalek and Gezira. Land reclamation efforts by the Mamluks and Ottomans further contributed to expansion on the east bank of the river.
Because of the Nile's movement, the newer parts of the city—Garden City, Downtown Cairo, and Zamalek—are located closest to the riverbank. The areas, which are home to most of Cairo's embassies, are surrounded on the north, east, and south by the older parts of the city. Old Cairo, located south of the centre, holds the remnants of Fustat and the heart of Egypt's Coptic Christian community, Coptic Cairo. The Boulaq district, which lies in the northern part of the city, was born out of a major 16th-century port and is now a major industrial centre. The Citadel is located east of the city centre around Islamic Cairo, which dates back to the Fatimid era and the foundation of Cairo. While western Cairo is dominated by wide boulevards, open spaces, and modern architecture of European influence, the eastern half, having grown haphazardly over the centuries, is dominated by small lanes, crowded tenements, and Islamic architecture.
Northern and extreme eastern parts of Cairo, which include satellite towns, are among the most recent additions to the city, as they developed in the late-20th and early-21st centuries to accommodate the city's rapid growth. The western bank of the Nile is commonly included within the urban area of Cairo, but it composes the city of Giza and the Giza Governorate. Giza has also undergone significant expansion over recent years, and today the city, although still a suburb of Cairo, has a population of 2.7 million. The Cairo Governorate was just north of the Helwan Governorate from 2008 when some Cairo's southern districts, including Maadi and New Cairo, were split off and annexed into the new governorate, to 2011 when the Helwan Governorate was reincorporated into the Cairo Governorate.
Climate.
In Cairo, and along the Nile River Valley, the climate is a hot desert climate ("BWh" according to the Köppen climate classification system), but often with high humidity due to the river valley's effects. Wind storms can be frequent, bringing Saharan dust into the city during the months of March and April (see Khamasin). High temperatures in winter range from , while night-time lows drop to below , often to . In summer, the highs rarely surpass , and lows drop to about . Rainfall is sparse and only happens in the colder months, but sudden showers do cause harsh flooding. Snowfall is extremely rare; a small amount of graupel, widely believed to be snow, fell on Cairo's easternmost suburbs on 13 December 2013, the first time Cairo's area received this kind of precipitation in many decades.
Division.
The Greater Cairo is the largest metropolitan area in Egypt and in Africa. It consists of Cairo Governorate, parts of Giza Governorate, and parts of Qalyubia Governorate.
Infrastructure.
Health.
Cairo, as well as neighbouring, has been established as Egypt's main centre for medical treatment, and despite some exceptions, has the most advanced level of medical care in the country. Cairo's hospitals include the JCI-accredited As-Salaam International Hospital—Corniche El Nile, Maadi (Egypt's largest private hospital with 350 beds), Ain Shams University Hospital, Dar El Fouad Hospital, as well as Kasr El Aini Hospital.
Education.
Greater Cairo has long been the hub of education and educational services for Egypt and the region.
Today, Greater Cairo is the centre for many government offices governing the Egyptian educational system, has the largest number of educational schools, and higher learning institutes among other cities and governorates of Egypt.
Some of the International Schools found in Cairo:
Universities in Greater Cairo:
Transportation.
Cairo has an extensive road network, rail system, subway system and maritime services. Road transport is facilitated by personal vehicles, taxi cabs, privately owned public buses and Cairo microbuses. Cairo, specifically Ramses Square, is the centre of almost the entire Egyptian transportation network.
The subway system, officially called "Metro (مترو)", is a fast and efficient way of getting around Cairo. Metro network covers Helwan and other suburbs. It can get very crowded during rush hour. Two train cars (the fourth and fifth ones) are reserved for women only, although women may ride in any car they want.
Trams in Greater Cairo (Heliopolis and Nasr City) exists now, while Cairo trolleybus was closed.
An extensive road network connects Cairo with other Egyptian cities and villages. There is a new Ring Road that surrounds the outskirts of the city, with exits that reach outer Cairo districts. There are flyovers and bridges, such as the Sixth of October bridge that, when the traffic is not heavy, allow fast means of transportation from one side of the city to the other.
Cairo traffic is known to be overwhelming and overcrowded. Traffic moves at a relatively fluid pace. Drivers tend to be aggressive, but are more courteous at junctions, taking turns going, with police aiding in traffic control of some congested areas.
On 25 October 2009 a passenger train ran into another one near Giza, just outside Cairo. Local news agencies reported at least 25 people dead. A local resident, Samhi Saleh Abdel Al, told reporters that "the first train stopped after hitting a cow and 10 minutes later the second train arrived at full speed." One of the two trains was travelling from Cairo to Assiut, while the other was said to have been en route to Fayoum from Giza. Around 55 people were injured.
Sports.
Football is the most popular sport in Egypt, and Cairo has a number of sporting teams that compete in national and regional leagues. The best known teams are Al-Ahly, El Zamalek and Al-Ismaily. Al-Ahly and El Zamalek annual football tournament is perhaps the most watched sports event in Egypt as well as the African-Arab region. Both teams are known as the "rivals" of Egyptian football, and are the first and the second champions in Africa and the Arab World. They play their home games at Cairo International Stadium or Naser Stadium, which is Egypt's 2nd largest stadium, Cairo's largest one and one of the largest stadiums in the world.
The Cairo International Stadium was built in 1960 and its multi-purpose sports complex that houses the main football stadium, an indoor stadium, several satellite fields that held several regional, continental and global games, including the African Games, U17 Football World Championship and was one of the stadiums scheduled that hosted the 2006 Africa Cup of Nations which was played in January 2006. Egypt later won the competition and went on to win the next edition In Ghana (2008) making the Egyptian and Ghanaian national teams the only teams to win the African Nations Cup Back to back which resulted in Egypt winning the title for a record number of six times in the history of African Continental Competition. This was followed by a third consecutive win in Angola 2010, making Egypt the only country with a record 3-consecutive and 7-total Continental Football Competition winner. This achievement had also placed the Egyptian football team as the #12 best team in the world's FIFA rankings.
Cairo failed at the applicant stage when bidding for the 2008 Summer Olympic Games, which was hosted in Beijing, China. However, Cairo did host the 2007 Pan Arab Games.
There are several other sports teams in the city that participate in several sports including el Gezira Sporting Club, el Shams Club, el Seid Club, Heliopolis Club and several smaller clubs, but the biggest clubs in Egypt (not in area but in sports) are Al Ahly and Al Zamalek. They have the two biggest football teams in Egypt.
Most of the sports federations of the country are also located in the city suburbs, including the Egyptian Football Association. The headquarters of the Confederation of African Football (CAF) was previously located in Cairo, before relocating to its new headquarters in 6 October City, a small city away from Cairo's crowded districts.
On October 2008, the Egyptian Rugby Federation was officially formed and granted membership into the International Rugby Board.
Egypt is internationally known for the excellence of its squash players who excel in both professional and junior divisions. Gizira Club in Zamalek is where former world #1 Amr Shabana and former world #1 Karim Darwish practice. The Heliopolis Club in Heliopolis is the home of current world #1 Ramy Ashour and his brother, world #24, Hisham Ashour. Other major squash-playing venues are The Shooting Club (Nadi el Seid) in Dokki, The Maadi Club in Maadi and Wadi Degla in Degla.
Culture.
Over the ages, and as far back as four thousand years, Egypt stood as the land where many civilizations have met. The Pharaohs together with the Greeks, Babylonians and the Romans have left their imprints here. Muslims from the Arabian Peninsula, led by Amr ibn al-A'as, introduced Islam into Egypt. Khedive Mohammad Ali, with his Albanian family roots, put Egypt on the road to modernity. The cultural mixture in this city is only natural, considering its heritage. Egypt can be likened to an open museum with monuments of the different historical periods on display everywhere.
Cairo Opera House.
President Mubarak inaugurated the new Cairo Opera House of the Egyptian National Cultural Centres on 10 October 1988, 17 years after the Royal Opera House had been destroyed by fire. The National Cultural Centre was built with the help of JICA, the Japan International Co-operation Agency and stands as a prominent feature for the Japanese-Egyptian co-operation and the friendship between these two nations.
Khedivial Opera House.
The Khedivial Opera House or Royal Opera House was the original opera house in Cairo, Egypt. It was dedicated on 1 November 1869 and burned down on 28 October 1971. After the original opera house was destroyed, Cairo was without an opera house for nearly two decades until the opening of the new Cairo Opera House in 1988.
Cairo International Film Festival.
Egypt's love of the arts in general can be traced back to the rich heritage bequeathed by the Pharaohs. In modern times, Egypt has enjoyed a strong cinematic tradition since the art of filmmaking was first developed, early in the 20th century. A natural progression from the active theatre scene of the time, cinema rapidly evolved into a vast motion picture industry. This together with the much older music tradition, raised Egypt to become Hollywood Middle East and the cultural capital of the Arab world.
For more than 500 years of recorded history, Egypt has fascinated the West and inspired its creative talents from play writer William Shakespeare, poet and dramatist John Dryden, and novelist and poet Lawrence Durrell to film producer Cecil B. DeMille. Since the silent movies Hollywood has been capitalising on the box-office returns that come from combining Egyptian stories with visual effects.
Egypt has also been a fount of Arabic literature, producing some of the 20th century's greatest Arab writers such as Taha Hussein and Tawfiq al-Hakim to Nobel Laureate, novelist Naguib Mahfouz. Each of them has written for the cinema.
With these credentials, it was clear that Cairo should aim to hold an international film festival. This dream came true on Monday 16 August 1976, when the first Cairo International Film Festival was launched by the Egyptian Association of Film Writers and Critics, headed by Kamal El-Mallakh. The Association ran the festival for seven years until 1983.
This achievement lead to the President of the Festival again contacting the FIAPF with the request that a competition should be included at the 1991 Festival. The request was granted.
In 1998, the Festival took place under the presidency of one of Egypt's leading actors, Hussein Fahmy, who was appointed by the Minister of Culture, Farouk Hosni, after the death of Saad El-Din Wahba.
Four years later, the journalist and writer Cherif El-Shoubashy became president.
For 33 years The International Festival has awarded dozens of international superstars, including John Malkovich, Nicolas Cage, Morgan Freeman, Bud Spencer, Gina Lollobrigida, Ornella Muti, Sophia Loren, Claudia Cardinale, Victoria Abril, Elizabeth Taylor, Shashi Kapoor, Alain Delon, Goldie Hawn, Kurt Russell, Susan Sarandon, Greta Scacchi, Catherine Deneuve, Peter O'Toole, Charlize Theron, Julia Ormond, Mira Sorvino, Stuart Townsend, Alicia Silverstone, Priscilla Presley, Christopher Lee, Irene Papas, Marcello Mastroianni, Salma Hayek, Lucy Liu, Samuel L. Jackson, Tom Berenger and Omar Sharif, as well as directors like Robert Wise, Elia Kazan, Vanessa Redgrave, Oliver Stone, Roland Joffé, Carlos Saura, Ismail Merchant and Michelangelo Antonioni, in an annual celebration and examination of the state of cinema in the world today. The presidents of the Festival since it was founded in 1976 are Saad El-Din Wahba, Hussein Fahmy and Sherif El Shoubashy. This year the festival a milestone of 30 years in an annual celebration and examination of the state of cinema in the world today.
Cairo Geniza.
The Cairo Geniza is an accumulation of almost 200,000 Jewish manuscripts that were found in the genizah of the Ben Ezra synagogue (built 882) of Fustat, Egypt (now Old Cairo), the Basatin cemetery east of Old Cairo, and a number of old documents that were bought in Cairo in the later 19th century. These documents were written from about 870 to as late as 1880 AD and have now been archived in various American and European libraries. The Taylor-Schechter collection in the University of Cambridge runs to 140,000 manuscripts, a further 40,000 manuscripts are at the Jewish Theological Seminary of America.
Religions.
Most residents are Sunni Muslim. Al-Azhar University is the leading authority of Sunni Islam. The number of mosques in the city is growing. Most Christians are Copts. Until his death in March 2012, Pope Shenouda III of Alexandria was the leader of the Coptic Orthodox Church, whose residence is in Cairo. Cairo has several synagogues, but only few Jews remain after Israel was established, and persecution intensified. Tension between members of different religions has increased recently.
Nightlife.
Cairo was ranked as the "world's most 24-hour city" in a 2011 study conducted by the social networking site Badoo, placing it well ahead of other famous big cities such as New York, London or Paris. The study's rankings were determined by measuring the amount of online activity at night versus during the day and by comparing peak-times for such activity in cities across the world. Cairo's highly nocturnal lifestyle is attributed not only to young people in nightclubs but also to the importance of cafés, which remain very active at night as social gathering places to smoke shisha, and even to the late-night public activeness of families with children.
Economy.
Cairo is also in every respect the centre of Egypt, as it has been almost since its founding in 969 AD. The majority of the nation's commerce is generated there, or passes through the city. The great majority of publishing houses and media outlets and nearly all film studios are there, as are half of the nation's hospital beds and universities. This has fueled rapid construction in the city—one building in five is less than 15 years old.
This astonishing growth until recently surged well ahead of city services. Homes, roads, electricity, telephone and sewer services were all suddenly in short supply. Analysts trying to grasp the magnitude of the change coined terms like "hyper-urbanization".
Historical sites and landmarks.
Tahrir Square.
Tahrir Square was founded during the mid 19th century with the establishment of modern downtown Cairo. It was first named Ismailia Square, after the 19th-century ruler Khedive Ismail, who commissioned the new downtown district's 'Paris on the Nile' design. After the Egyptian Revolution of 1919 the square became widely known as Tahrir (Liberation) Square, though it was not officially renamed as such until after the 1952 Revolution which eliminated the monarchy. Several notable buildings surround the square including, the American University in Cairo's downtown campus, the Mogamma governmental administrative Building, the headquarters of the Arab League, the Nile Ritz Carlton Hotel, and the Egyptian Museum. Being at the heart of Cairo, the square witnessed several major protests over the years. However, the most notable event in the square was being the focal point of the 2011 Egyptian Revolution against former president Hosni Mubarak.
The Egyptian Museum.
The Museum of Egyptian Antiquities, known commonly as the Egyptian Museum, is home to the most extensive collection of ancient Egyptian antiquities in the world. It has 136,000 items on display, with many more hundreds of thousands in its basement storerooms. Among its most famous collections on display are the finds from the Tomb of Tutankhamun.
Cairo Tower.
The Cairo Tower is a free-standing tower with a revolving restaurant at the top. It provides a bird's eye view of Cairo to the restaurant patrons. It stands in the Zamalek district on Gezira Island in the Nile River, in the city centre. At 187 meters, it is 43 meters higher than the Great Pyramid of Giza, which stands some to the southwest.
Old Cairo.
This area of Cairo is so-named as it contains the remains of the ancient Roman fortress of Babylon and also overlaps the original site of Fustat, the first Arab settlement in Egypt (7th century AD) and the predecessor of later Cairo. The area is also known as Coptic Cairo as it holds a high concentration of old Christian churches including the Hanging Church, the Greek Orthodox Church of St. George, and other Christian or Coptic buildings, most of which are located over the site of the ancient Roman fortress. It is also the location of the Coptic Museum, which showcases the history of Coptic art from Greco-Roman to Islamic times, and of the Ben Ezra Synagogue, the oldest and best-known synagogue in Cairo, where the important collection of Geniza documents were discovered in the 19th century. To the north of this Coptic enclave is the Amr ibn al-'As Mosque, the first mosque in Egypt and the most important religious center of former Fustat, founded in 642 AD right after the Arab conquest but rebuilt many times since.
Islamic Cairo.
Cairo holds one of the greatest concentrations of historical monuments of Islamic architecture in the world. The areas around the old walled city and around the Citadel are characterized by hundreds of mosques, tombs, madrasas, mansions, caravanserais, and fortifications dating from the Islamic era and are often referred to as "Islamic Cairo", especially in English travel literature. It is also the location of several important religious shrines such as the al-Hussein Mosque (whose shrine is believed to hold the head of Husayn ibn Ali), the Mausoleum of Imam al-Shafi'i (founder of the Shafi'i madhhab, one of the primary schools of thought in Sunni Islamic jurisprudence), the Tomb of Sayyida Ruqayya, the Mosque of Sayyida Nafisa, and others.
While the first mosque in Egypt was the Mosque of Amr ibn al-As in Fustat, the Mosque of Ibn Tulun is the oldest mosque to retain its original form and is a rare example of Abbasid architecture, from the classical period of Islamic civilization. It was built in 876-879 AD in a style inspired by the Abbasid capital of Samarra in Iraq. It is one of the largest mosques in Cairo and is often cited as one of the most beautiful. Another Abbasid construction, the Nilometer on Rhoda Island, is the oldest original structure in Cairo, built in 862 AD. It was designed to measure the level of the Nile, which was important for agricultural and administrative purposes.
The city named Cairo (Arabic: "al-Qahira") was founded to the northeast of Fustat in 959 AD by the victorious Fatimid army. The Fatimids built a separate palatial city which contained their palaces and institutions of government. It was enclosed by a circuit of walls, which were rebuilt in stone in the late 11th century AD by the vizir Badr al-Gamali, parts of which survive today at Bab Zuwayla in the south and Bab al-Futuh and Bab al-Nasr in the north.
One of the most important and lasting institutions founded in the Fatimid period was the Mosque of al-Azhar, founded in 970 AD, which competes with the Qarawiyyin in Fes for the title of oldest university in the world. Today, al-Azhar University is the foremost center of Islamic learning in the world and one of Egypt's largest universities with campuses across the country. The mosque itself retains significant Fatimid elements but has been added to and expanded in subsequent centuries, notably by the Mamluk sultans Qaitbay and al-Ghuri and by Abd al-Rahman Katkhuda in the 18th century.
Other extant monuments from the Fatimid era include the large Mosque of al-Hakim, the al-Aqmar mosque, and the Mosque of Salih Tala'i.
The most prominent architectural heritage of medieval Cairo, however, dates from the Mamluk period, from 1250 to 1517 AD. The Mamluk sultans and elites were eager patrons of religious and scholarly life, commonly building religious or funerary complexes whose functions could include a mosque, madrasa, khanqah (for Sufis), water distribution centers (sabils), and mausoleum for themselves and their families. 
Among the best-known examples of Mamluk monuments in Cairo are the huge Mosque-Madrasa of Sultan Hasan, the Mosque of Amir al-Maridani, the Mosque of Sultan al-Mu'ayyad (whose twin minarets were built above the gate of Bab Zuwayla), the Sultan Al-Ghuri complex, the funerary complex of Sultan Qaytbay in the Northern Cemetery, and the trio of monuments in the Bayn al-Qasrayn area comprising the complex of Sultan al-Mansur Qalawun, the Madrasa of al-Nasir Muhammad, and the Madrasa of Sultan Barquq.
The Mamluks, and the later Ottomans, also built wikalas or caravanserais to house merchants and goods due to the important role of trade and commerce in Cairo's economy. The most famous example still intact today is the Wikala al-Ghuri, which nowadays also hosts regular performances by the Al-Tannoura Egyptian Heritage Dance Troupe. The famous Khan al-Khalili (see below) is a commercial hub which also integrated caravanserais (also known as khans).
The Citadel of Cairo.
The Citadel is a fortified enclosure begun by Salah al-Din in 1176 AD on an outcrop of the Muqattam Hills as part of a large defensive system to protect both Cairo to the north and Fustat to the southwest. It was the center of Egyptian government and residence of its rulers until 1874, when Khedive Isma'il moved to 'Abdin Palace. It is still occupied by the military today, but is now open as a tourist attraction comprising, notably, the National Military Museum, the 14th century Mosque of al-Nasir Muhammad, and the 19th century Mosque of Muhammad Ali which commands a dominant position on Cairo's skyline.
Khan El-Khalili.
Khan el-Khalili is an ancient bazaar, or marketplace. It dates back to 1385, when Amir Jarkas el-Khalili built a large caravanserai, or khan. (A caravanserai is a hotel for traders, and usually the focal point for any surrounding area.) This original carvanserai building was demolished by Sultan al-Ghuri, who rebuilt it as a new commercial complex in the early 16th century, forming the basis for the network of souqs existing today. Many medieval elements remain today, including the ornate Mamluk-style gateways. Today, the Khan el-Khalili is a major tourist attraction and popular stop for tour groups.
Pollution.
Cairo is an expanding city, which has led to many environmental problems. The air pollution in Cairo is a matter of serious concern. Greater Cairo's volatile aromatic hydrocarbon levels are higher than many other similar cities. Air quality measurements in Cairo have also been recording dangerous levels of lead, carbon dioxide, sulphur dioxide, and suspended particulate matter concentrations due to decades of unregulated vehicle emissions, urban industrial operations, and chaff and trash burning. There are over 4,500,000 cars on the streets of Cairo, 60% of which are over 10 years old, and therefore lack modern emission cutting features like catalytic converters. Cairo has a very poor dispersion factor because of lack of rain and its layout of tall buildings and narrow streets, which create a bowl effect.
In recent years, a mysterious black cloud (as Egyptians refer to it) appeared over Cairo every Autumn and causes serious respiratory diseases and eye irritations for the city's citizens. Tourists who are not familiar with such high levels of pollution must take extra care.
Cairo also has many unregistered lead and copper smelters which heavily pollute the city. The results of this has been a permanent haze over the city with particulate matter in the air reaching over three times normal levels. It is estimated that 10,000 to 25,000 people a year in Cairo die due to air pollution-related diseases. Lead has been shown to cause harm to the central nervous system and neurotoxicity particularly in children. In 1995, the first environmental acts were introduced and the situation has seen some improvement with 36 air monitoring stations and emissions tests on cars. Twenty thousand buses have also been commissioned to the city to improve congestion levels, which are very high.
The city also suffers from a high level of land pollution. Cairo produces 10,000 tons of waste material each day, 4,000 tons of which is not collected or managed. This once again is a huge health hazard and the Egyptian Government is looking for ways to combat this. The Cairo Cleaning and Beautification Agency was founded to collect and recycle the waste; however, they also work with the Zabbaleen (or Zabaleen), a community that has been collecting and recycling Cairo's waste since the turn of the 20th century and live in an area known locally as Manshiyat naser. Both are working together to pick up as much waste as possible within the city limits, though it remains a pressing problem.
The city also suffers from water pollution as the sewer system tends to fail and overflow. On occasion, sewage has escaped onto the streets to create a health hazard. This problem is hoped to be solved by a new sewer system funded by the European Union, which could cope with the demand of the city. The dangerously high levels of mercury in the city's water system has global health officials concerned over related health risks.
International relations.
Twin towns — Sister cities.
Cairo is twinned with:

</doc>
<doc id="6295" url="http://en.wikipedia.org/wiki?curid=6295" title="Chaos theory">
Chaos theory

Chaos theory is a field of study in mathematics, with applications in several disciplines including meteorology, sociology, physics, engineering, economics, biology, and philosophy. Chaos theory studies the behavior of dynamical systems that are highly sensitive to initial conditions—a response popularly referred to as the butterfly effect. Small differences in initial conditions (such as those due to rounding errors in numerical computation) yield widely diverging outcomes for such dynamical systems, rendering long-term prediction impossible in general. This happens even though these systems are deterministic, meaning that their future behavior is fully determined by their initial conditions, with no random elements involved. In other words, the deterministic nature of these systems does not make them predictable. This behavior is known as "deterministic chaos", or simply "chaos". The theory was summarized by Edward Lorenz as follows:
Chaos: When the present determines the future, but the approximate present does not approximately determine the future.
Chaotic behavior can be observed in many natural systems, such as weather and climate. This behavior can be studied through analysis of a chaotic mathematical model, or through analytical techniques such as recurrence plots and Poincaré maps.
Introduction.
Chaos theory concerns deterministic systems whose behavior can in principle be predicted. Chaotic systems are predictable for a while and then "appear" to become random. The amount of time for which the behavior of a chaotic system can be effectively predicted depends on three things: How much uncertainty we are willing to tolerate in the forecast; how accurately we are able to measure its current state; and a time scale depending on the dynamics of the system, called the Lyapunov time. Some examples of Lyapunov times are: chaotic electrical circuits, ~1 millisecond; weather systems, a couple of days (unproven); the solar system, 50 million years. In chaotic systems the uncertainty in a forecast increases exponentially with elapsed time. Hence doubling the forecast time squares the proportional uncertainty in the forecast. This means that in practice a meaningful prediction cannot be made over an interval of more than two or three times the Lyapunov time. When meaningful predictions cannot be made, the system appears to be random.
Chaotic dynamics.
In common usage, "chaos" means "a state of disorder". However, in chaos theory, the term is defined more precisely. Although there is no universally accepted mathematical definition of chaos, a commonly used definition says that, for a dynamical system to be classified as chaotic, it must have the following properties:
Sensitivity to initial conditions.
"Sensitivity to initial conditions" means that each point in a chaotic system is arbitrarily closely approximated by other points with significantly different future paths, or trajectories. Thus, an arbitrarily small change, or perturbation, of the current trajectory may lead to significantly different future behavior.
It has been shown that in some cases the last two properties in the above actually imply sensitivity to initial conditions, and if attention is restricted to intervals, the second property implies the other two (an alternative, and in general weaker, definition of chaos uses only the first two properties in the above list). It is interesting that the most practically significant property, that of sensitivity to initial conditions, is redundant in the definition, being implied by two (or for intervals, one) purely topological properties, which are therefore of greater interest to mathematicians.
Sensitivity to initial conditions is popularly known as the "butterfly effect", so called because of the title of a paper given by Edward Lorenz in 1972 to the American Association for the Advancement of Science in Washington, D.C., entitled "Predictability: Does the Flap of a Butterfly’s Wings in Brazil set off a Tornado in Texas?". The flapping wing represents a small change in the initial condition of the system, which causes a chain of events leading to large-scale phenomena. Had the butterfly not flapped its wings, the trajectory of the system might have been vastly different.
A consequence of sensitivity to initial conditions is that if we start with only a finite amount of information about the system (as is usually the case in practice), then beyond a certain time the system will no longer be predictable. This is most familiar in the case of weather, which is generally predictable only about a week ahead. Of course this does not mean that we cannot say anything about events far in the future; there are some restrictions on the system. With weather, we know that the temperature will never reach 100 degrees Celsius or fall to -130 degrees Celsius on earth, but we are not able to say exactly what day we will have the hottest temperature of the year.
In more mathematical terms, the Lyapunov exponent measures the sensitivity to initial conditions. Given two starting trajectories in the phase space that are infinitesimally close, with initial separation formula_1 end up diverging at a rate given by
where t is the time and λ is the Lyapunov exponent. The rate of separation depends on the orientation of the initial separation vector, so there is a whole spectrum of Lyapunov exponents. The number of Lyapunov exponents is equal to the number of dimensions of the phase space, though it is common to just refer to the largest one. For example, the maximal Lyapunov exponent (MLE) is most often used because it determines the overall predictability of the system. A positive MLE is usually taken as an indication that the system is chaotic.
There are also other properties that relate to sensitivity of initial conditions, such as measure-theoretical mixing (as discussed in ergodic theory) and properties of a K-system.
Topological mixing.
"Topological mixing" (or "topological transitivity") means that the system will evolve over time so that any given region or open set of its phase space will eventually overlap with any other given region. This mathematical concept of "mixing" corresponds to the standard intuition, and the mixing of colored dyes or fluids is an example of a chaotic system.
Topological mixing is often omitted from popular accounts of chaos, which equate chaos with only sensitivity to initial conditions. However, sensitive dependence on initial conditions alone does not give chaos. For example, consider the simple dynamical system produced by repeatedly doubling an initial value. This system has sensitive dependence on initial conditions everywhere, since any pair of nearby points will eventually become widely separated. However, this example has no topological mixing, and therefore has no chaos. Indeed, it has extremely simple behavior: all points except 0 will tend to positive or negative infinity.
Density of periodic orbits.
For a chaotic system to have a "dense periodic orbit" means that every point in the space is approached arbitrarily closely by periodic orbits. The one-dimensional logistic map defined by "x" → 4 "x" (1 – "x") is one of the simplest systems with density of periodic orbits. For example, formula_3 → formula_4 → formula_3 (or approximately 0.3454915 → 0.9045085 → 0.3454915) is an (unstable) orbit of period 2, and similar orbits exist for periods 4, 8, 16, etc. (indeed, for all the periods specified by Sharkovskii's theorem).
Sharkovskii's theorem is the basis of the Li and Yorke (1975) proof that any one-dimensional system that exhibits a regular cycle of period three will also display regular cycles of every other length as well as completely chaotic orbits.
Strange attractors.
Some dynamical systems, like the one-dimensional logistic map defined by "x" → 4 "x" (1 – "x"), are chaotic everywhere, but in many cases chaotic behavior is found only in a subset of phase space. The cases of most interest arise when the chaotic behavior takes place on an attractor, since then a large set of initial conditions will lead to orbits that converge to this chaotic region.
An easy way to visualize a chaotic attractor is to start with a point in the basin of attraction of the attractor, and then simply plot its subsequent orbit. Because of the topological transitivity condition, this is likely to produce a picture of the entire final attractor, and indeed both orbits shown in the figure on the right give a picture of the general shape of the Lorenz attractor. This attractor results from a simple three-dimensional model of the Lorenz weather system. The Lorenz attractor is perhaps one of the best-known chaotic system diagrams, probably because it was not only one of the first, but it is also one of the most complex and as such gives rise to a very interesting pattern, that with a little imagination, looks like the wings of a butterfly.
Unlike fixed-point attractors and limit cycles, the attractors that arise from chaotic systems, known as "strange attractors", have great detail and complexity. Strange attractors occur in both continuous dynamical systems (such as the Lorenz system) and in some discrete systems (such as the Hénon map). Other discrete dynamical systems have a repelling structure called a Julia set which forms at the boundary between basins of attraction of fixed points – Julia sets can be thought of as strange "repellers". Both strange attractors and Julia sets typically have a fractal structure, and the fractal dimension can be calculated for them.
Minimum complexity of a chaotic system.
Discrete chaotic systems, such as the logistic map, can exhibit strange attractors whatever their dimensionality. In contrast, for continuous dynamical systems, the Poincaré–Bendixson theorem shows that a strange attractor can only arise in three or more dimensions. Finite-dimensional linear systems are never chaotic; for a dynamical system to display chaotic behavior, it has to be either nonlinear or infinite-dimensional.
The Poincaré–Bendixson theorem states that a two-dimensional differential equation has very regular behavior. The Lorenz attractor discussed above is generated by a system of three differential equations such as:
where formula_7, formula_8, and formula_9 make up the system state, formula_10 is time, and formula_11, formula_12, formula_13 are the system parameters. Five of the terms on the right hand side are linear, while two are quadratic; a total of seven terms. Another well-known chaotic attractor is generated by the Rossler equations which have only one nonlinear term out of seven. Sprott found a three-dimensional system with just five terms, that had only one nonlinear term, which exhibits chaos for certain parameter values. Zhang and Heidel showed that, at least for dissipative and conservative quadratic systems, three-dimensional quadratic systems with only three or four terms on the right-hand side cannot exhibit chaotic behavior. The reason is, simply put, that solutions to such systems are asymptotic to a two-dimensional surface and therefore solutions are well behaved.
While the Poincaré–Bendixson theorem shows that a continuous dynamical system on the Euclidean plane cannot be chaotic, two-dimensional continuous systems with non-Euclidean geometry can exhibit chaotic behavior. Perhaps surprisingly, chaos may occur also in linear systems, provided they are infinite dimensional. A theory of linear chaos is being developed in a branch of mathematical analysis known as functional analysis.
Jerk systems.
In physics, jerk is the third derivative of position, and such, in mathematics differential equations of the form
are sometimes called "Jerk equations". It has been shown, that a jerk equation, which is equivalent to a system of three first order, ordinary, non-linear differential equation is in a certain sense the minimal setting for solutions showing chaotic behaviour. This motivates mathematical interest in "jerk systems". Systems involving a fourth or higher derivative are called accordingly "hyperjerk systems".
A "jerk system" is a system whose behavior is described by a "jerk equation", and for certain jerk equations simple electronic circuits may be designed which model the solutions to this equation. These circuits are known as "jerk circuits".
One of the most interesting properties of jerk circuits is the possibility of chaotic behavior. In fact, certain well-known chaotic systems, such as the Lorenz attractor and the Rössler map, are conventionally described as a system of three first-order differential equations, but which may be combined into a single (although rather complicated) jerk equation. It has been shown, that non-linear jerk systems are in a sense minimally complex systems to show chaotic behaviour, there is no chaotic system involving only "two" first order, ordinary differential equations (the system resulting in an equation of "second" order only).
An example of a jerk equation with non-linearity in the magnitude of formula_7, is:
Here "A" is an adjustable parameter. This equation has a chaotic solution for A=3/5 and can be implemented with the following jerk circuit; the required non-linearity is brought about by the two diodes:
In the above circuit, all resistors are of equal value, except formula_17, and all capacitors are of equal size. The dominant frequency will be formula_18. The output of op amp 0 will correspond to the x variable, the output of 1 will correspond to the first derivative of x and the output of 2 will correspond to the second derivative.
Spontaneous order.
Under the right conditions chaos will spontaneously evolve into a lockstep pattern. In the Kuramoto model, four conditions suffice to produce synchronization in a chaotic system.
Examples include the coupled oscillation of Christiaan Huygens' pendulums, fireflies, neurons, the London Millenium Bridge resonance, and large arrays of Josephson junctions.
History.
An early proponent of chaos theory was Henri Poincaré. In the 1880s, while studying the three-body problem, he found that there can be orbits that are nonperiodic, and yet not forever increasing nor approaching a fixed point. In 1898 Jacques Hadamard published an influential study of the chaotic motion of a free particle gliding frictionlessly on a surface of constant negative curvature, called "Hadamard's billiards". Hadamard was able to show that all trajectories are unstable, in that all particle trajectories diverge exponentially from one another, with a positive Lyapunov exponent.
Chaos Theory got its start in the field of ergodic theory. Later studies, also on the topic of nonlinear differential equations, were carried out by George David Birkhoff, , Mary Lucy Cartwright and John Edensor Littlewood, and Stephen Smale. Except for Smale, these studies were all directly inspired by physics: the three-body problem in the case of Birkhoff, turbulence and astronomical problems in the case of Kolmogorov, and radio engineering in the case of Cartwright and Littlewood. Although chaotic planetary motion had not been observed, experimentalists had encountered turbulence in fluid motion and nonperiodic oscillation in radio circuits without the benefit of a theory to explain what they were seeing.
Despite initial insights in the first half of the twentieth century, chaos theory became formalized as such only after mid-century, when it first became evident to some scientists that linear theory, the prevailing system theory at that time, simply could not explain the observed behavior of certain experiments like that of the logistic map. What had been attributed to measure imprecision and simple "noise" was considered by chaos theorists as a full component of the studied systems.
The main catalyst for the development of chaos theory was the electronic computer. Much of the mathematics of chaos theory involves the repeated iteration of simple mathematical formulas, which would be impractical to do by hand. Electronic computers made these repeated calculations practical, while figures and images made it possible to visualize these systems. As a graduate student in Chihiro Hayashi's laboratory at Kyoto University, Yoshisuke Ueda was experimenting with analog computers and noticed, on Nov. 27, 1961, what he called "randomly transitional phenomena". Yet his advisor did not agree with his conclusions at the time, and did not allow him to report his findings until 1970.
An early pioneer of the theory was Edward Lorenz whose interest in chaos came about accidentally through his work on weather prediction in 1961. Lorenz was using a simple digital computer, a Royal McBee LGP-30, to run his weather simulation. He wanted to see a sequence of data again and to save time he started the simulation in the middle of its course. He was able to do this by entering a printout of the data corresponding to conditions in the middle of his simulation which he had calculated last time. To his surprise the weather that the machine began to predict was completely different from the weather calculated before. Lorenz tracked this down to the computer printout. The computer worked with 6-digit precision, but the printout rounded variables off to a 3-digit number, so a value like 0.506127 was printed as 0.506. This difference is tiny and the consensus at the time would have been that it should have had practically no effect. However, Lorenz had discovered that small changes in initial conditions produced large changes in the long-term outcome. Lorenz's discovery, which gave its name to Lorenz attractors, showed that even detailed atmospheric modelling cannot, in general, make precise long-term weather predictions.
In 1963, Benoît Mandelbrot found recurring patterns at every scale in data on cotton prices. Beforehand he had studied information theory and concluded noise was patterned like a Cantor set: on any scale the proportion of noise-containing periods to error-free periods was a constant – thus errors were inevitable and must be planned for by incorporating redundancy. Mandelbrot described both the "Noah effect" (in which sudden discontinuous changes can occur) and the "Joseph effect" (in which persistence of a value can occur for a while, yet suddenly change afterwards). This challenged the idea that changes in price were normally distributed. In 1967, he published "How long is the coast of Britain? Statistical self-similarity and fractional dimension", showing that a coastline's length varies with the scale of the measuring instrument, resembles itself at all scales, and is infinite in length for an infinitesimally small measuring device. Arguing that a ball of twine appears to be a point when viewed from far away (0-dimensional), a ball when viewed from fairly near (3-dimensional), or a curved strand (1-dimensional), he argued that the dimensions of an object are relative to the observer and may be fractional. An object whose irregularity is constant over different scales ("self-similarity") is a fractal (examples include the Menger sponge, the Sierpiński gasket, and the Koch curve or "snowflake", which is infinitely long yet encloses a finite space and has a fractal dimension of circa 1.2619). In 1982 Mandelbrot published "The Fractal Geometry of Nature", which became a classic of chaos theory. Biological systems such as the branching of the circulatory and bronchial systems proved to fit a fractal model.
In December 1977, the New York Academy of Sciences organized the first symposium on Chaos, attended by David Ruelle, Robert May, James A. Yorke (coiner of the term "chaos" as used in mathematics), Robert Shaw, and the meteorologist Edward Lorenz. The following year, independently Pierre Coullet and Charles Tresser with the article "Iterations d'endomorphismes et groupe de renormalisation" and Mitchell Feigenbaum with the article "Quantitative Universality for a Class of Nonlinear Transformations" described logistic maps. They notably discovered the universality in chaos, permitting an application of chaos theory to many different phenomena.
In 1979, Albert J. Libchaber, during a symposium organized in Aspen by Pierre Hohenberg, presented his experimental observation of the bifurcation cascade that leads to chaos and turbulence in Rayleigh–Bénard convection systems. He was awarded the Wolf Prize in Physics in 1986 along with Mitchell J. Feigenbaum for their inspiring achievements.
In 1986, the New York Academy of Sciences co-organized with the National Institute of Mental Health and the Office of Naval Research the first important conference on chaos in biology and medicine. There, Bernardo Huberman presented a mathematical model of the eye tracking disorder among schizophrenics. This led to a renewal of physiology in the 1980s through the application of chaos theory, for example, in the study of pathological cardiac cycles.
In 1987, Per Bak, Chao Tang and Kurt Wiesenfeld published a paper in "Physical Review Letters" describing for the first time self-organized criticality (SOC), considered to be one of the mechanisms by which complexity arises in nature.
Alongside largely lab-based approaches such as the Bak–Tang–Wiesenfeld sandpile, many other investigations have focused on large-scale natural or social systems that are known (or suspected) to display scale-invariant behavior. Although these approaches were not always welcomed (at least initially) by specialists in the subjects examined, SOC has nevertheless become established as a strong candidate for explaining a number of natural phenomena, including earthquakes (which, long before SOC was discovered, were known as a source of scale-invariant behavior such as the Gutenberg–Richter law describing the statistical distribution of earthquake sizes, and the Omori law describing the frequency of aftershocks), solar flares, fluctuations in economic systems such as financial markets (references to SOC are common in econophysics), landscape formation, forest fires, landslides, epidemics, and biological evolution (where SOC has been invoked, for example, as the dynamical mechanism behind the theory of "punctuated equilibria" put forward by Niles Eldredge and Stephen Jay Gould). Given the implications of a scale-free distribution of event sizes, some researchers have suggested that another phenomenon that should be considered an example of SOC is the occurrence of wars. These investigations of SOC have included both attempts at modelling (either developing new models or adapting existing ones to the specifics of a given natural system), and extensive data analysis to determine the existence and/or characteristics of natural scaling laws.
In the same year, James Gleick published "", which became a best-seller and introduced the general principles of chaos theory as well as its history to the broad public, though his history under-emphasized important Soviet contributions. Initially the domain of a few, isolated individuals, chaos theory progressively emerged as a transdisciplinary and institutional discipline, mainly under the name of nonlinear systems analysis. Alluding to Thomas Kuhn's concept of a paradigm shift exposed in "The Structure of Scientific Revolutions" (1962), many "chaologists" (as some described themselves) claimed that this new theory was an example of such a shift, a thesis upheld by Gleick.
The availability of cheaper, more powerful computers broadens the applicability of chaos theory. Currently, chaos theory continues to be a very active area of research, involving many different disciplines (mathematics, topology, physics, social systems, population modeling, biology, meteorology, astrophysics, information theory, computational neuroscience, etc.).
Distinguishing random from chaotic data.
It can be difficult to tell from data whether a physical or other observed process is random or chaotic, because in practice no time series consists of a pure "signal". There will always be some form of corrupting noise, even if it is present as round-off or truncation error. Thus any real time series, even if mostly deterministic, will contain some randomness.
All methods for distinguishing deterministic and stochastic processes rely on the fact that a deterministic system always evolves in the same way from a given starting point. Thus, given a time series to test for determinism, one can
Define the error as the difference between the time evolution of the test state and the time evolution of the nearby state. A deterministic system will have an error that either remains small (stable, regular solution) or increases exponentially with time (chaos). A stochastic system will have a randomly distributed error.
Essentially, all measures of determinism taken from time series rely upon finding the closest states to a given test state (e.g., correlation dimension, Lyapunov exponents, etc.). To define the state of a system, one typically relies on phase space embedding methods.
Typically one chooses an embedding dimension and investigates the propagation of the error between two nearby states. If the error looks random, one increases the dimension. If the dimension can be increased to obtain a deterministically looking error, then analysis is done. Though it may sound simple, one complication is that as the dimension increases, the search for a nearby state requires a lot more computation time and a lot of data (the amount of data required increases exponentially with embedding dimension) to find a suitably close candidate. If the embedding dimension (number of measures per state) is chosen too small (less than the "true" value), deterministic data can appear to be random, but in theory there is no problem choosing the dimension too large – the method will work.
When a nonlinear deterministic system is attended by external fluctuations, its trajectories present serious and permanent distortions. Furthermore, the noise is amplified due to the inherent nonlinearity and reveals totally new dynamical properties. Statistical tests attempting to separate noise from the deterministic skeleton or inversely isolate the deterministic part risk failure. Things become worse when the deterministic component is a nonlinear feedback system. In presence of interactions between nonlinear deterministic components and noise, the resulting nonlinear series can display dynamics that traditional tests for nonlinearity are sometimes not able to capture.
The question of how to distinguish deterministic chaotic systems from stochastic systems has also been discussed in philosophy. It has been shown that they might be
observationally equivalent.
Applications.
Chaos theory was born from observing weather patterns, but it has become applicable to a variety of other situations. Some areas benefiting from chaos theory today are geology, mathematics, microbiology, biology, computer science, economics, engineering, finance, algorithmic trading, meteorology, philosophy, physics, politics, population dynamics, psychology, and robotics. A few categories are listed below with examples, but this is by no means a comprehensive list as new applications are appearing every day.
Computer science.
Chaos theory is not new to computer science and has been used for many years in cryptography. One type of encryption, secret key or symmetric key, relies on diffusion and confusion, which is modeled well by chaos theory. Another type of computing, DNA computing, when paired with chaos theory, offers a more efficient way to encrypt images and other information. Robotics is another area that has recently benefited from chaos theory. Instead of robots acting in a trial-and-error type of refinement to interact with their environment, chaos theory has been used to build a predictive model.
Biology.
For over a hundred years, biologists have been keeping track of populations of different species with population models. Most models are deterministic systems, but recently scientists have been able to implement chaotic models in certain populations. For example, a study on models of Canadian lynx showed there was chaotic behavior in the population growth. Chaos can also be found in ecological systems, such as hydrology. While a chaotic model for hydrology has its shortcomings, there is still much to be learned from looking at the data through the lens of chaos theory. Another biological application is found in cardiotocography. Fetal surveillance is a delicate balance of obtaining accurate information while being as noninvasive as possible. Better models of warning signs of fetal hypoxia can be obtained through chaotic modeling.
Other areas.
In chemistry, predicting gas solubility is essential to manufacturing polymers, but models using particle swarm optimization (PSO) tend to converge to the wrong points. An improved version of PSO has been created by introducing chaos, which keeps the simulations from getting stuck. In celestial mechanics, especially when observing asteroids, applying chaos theory leads to better predictions about when these objects will come in range of Earth and other planets. In Quantum Physics and Electrical Engineering, the study of large arrays of Josephson junctions benefitted greatly from Chaos theory. Closer to home, coal mines have always been dangerous places where frequent natural gas leaks cause many deaths. Until recently, there was no reliable way to predict when they would occur. But these gas leaks have chaotic tendencies that, when properly modeled, can be predicted fairly accurately.
Chaos theory can be applied outside of the natural sciences. By adapting a model of career counseling to include a chaotic interpretation of the relationship between employees and the job market, better suggestions can be made to people struggling with career decisions.: Modern organizations are increasingly seen as open complex adaptive systems, with fundamental natural nonlinear structures, subject to internal and external forces which may be sources of chaos. The chaos metaphor—used in verbal theories—grounded on mathematical models and psychological aspects of human behavior
provides helpful insights to describing the complexity of small work groups, that go beyond the metaphor itself. It is possible that economic models can also be improved through an application of chaos theory, but predicting the health of an economic system and what factors influence it most is an extremely complex task. Economic and financial systems are fundamentally different from those in the physical and natural sciences since the former are inherently stochastic in nature, as they result from the interactions of people, and thus pure deterministic models are unlikely to provide accurate representations of the data. The empirical literature that tests for chaos in economics and finance presents very mixed results, in part due to confusion between specific tests for chaos and more general tests for non-linear relationships. Traffic forecasting is another area that greatly benefits from applications of chaos theory. Better predictions of when traffic will occur would allow measures to be taken for it to be dispersed before the traffic starts, rather than after. Combining chaos theory principles with a few other methods has led to a more accurate short-term prediction model. Chaos theory can find an application also in Psychology. For example, modeling a group behavior in which heterogeneous members may behave as if shared to different degrees what in Wilfred Bion's theory is a basic assumption, the group dynamics is the result of the individual dynamics of the members: each individual reproduces the group dynamics in a different scale, and the chaotic behavior of the group is reflected in each member.

</doc>
<doc id="6298" url="http://en.wikipedia.org/wiki?curid=6298" title="Cupola">
Cupola

In architecture, a cupola is a small, most often dome-like, structure on top of a building. Often used to provide a lookout or to admit light and air, it usually crowns a larger roof or dome. 
The word derives, via Italian, from the lower Latin "cupula" (classical Latin "cupella" from the Greek κύπελλον "kupellon") "small cup" (Latin "cupa") indicating a vault resembling an upside down cup.
Cupolas often appear as small buildings in their own right. They often serve as a lantern, belfry, or belvedere above a main roof. In other cases they may crown a tower, spire, or turret. The chhatri, seen in Indian architecture, fits the definition of a cupola when it is used atop a larger structure.
The cupola is a development during the Renaissance of the oculus, an ancient device found in Roman architecture, but being weatherproof was superior for the wetter climates of northern Europe.
The square dome-like segment of a North American railroad train caboose is also called a cupola. The cupola is used on barns as a vent for heat and moisture.

</doc>
<doc id="6299" url="http://en.wikipedia.org/wiki?curid=6299" title="Chupacabra">
Chupacabra

The chupacabra or chupacabras (, from "chupar" "to suck" and "cabra" "goat", literally "goat sucker") is a legendary cryptid rumored to inhabit parts of the Americas, with the first sightings reported in Puerto Rico. The name comes from the animal's reported habit of attacking and drinking the blood of livestock, especially goats.
Physical descriptions of the creature vary. It is purportedly a heavy creature, the size of a small bear, with a row of spines reaching from the neck to the base of the tail.
Eyewitness sightings have been claimed as early as 1995 in Puerto Rico, and have since been reported as far north as Maine, and as far south as Chile, and even being spotted outside the Americas in countries like Russia and The Philippines, but many of the reports have been disregarded as uncorroborated or lacking evidence. Sightings in northern Mexico and the southern United States have been verified as canids afflicted by mange. Biologists and wildlife management officials view the chupacabra as a contemporary legend.
History.
The first reported attacks occurred in March 1995 in Puerto Rico. In this attack, eight sheep were discovered dead, each with three puncture wounds in the chest area and completely drained of blood. A few months later, in August, an eyewitness, Madelyne Tolentino, reported seeing the creature in the Puerto Rican town of Canóvanas, when as many as 150 farm animals and pets were reportedly killed. In 1975, similar killings in the small town of Moca were attributed to "El Vampiro de Moca" (The Vampire of Moca). Initially, it was suspected that the killings were committed by a Satanic cult; later more killings were reported around the island, and many farms reported loss of animal life. Each of the animals was reported to have had its body bled dry through a series of small circular incisions.
Puerto Rican comedian and entrepreneur Silverio Pérez is credited with coining the term "chupacabras" soon after the first incidents were reported in the press. Shortly after the first reported incidents in Puerto Rico, other animal deaths were reported in other countries, such as the Dominican Republic, Argentina, Bolivia, Chile, Colombia, Honduras, El Salvador, Nicaragua, Panama, Peru, Brazil, United States, and Mexico.
Possible origin.
A five-year investigation by Benjamin Radford concluded that the description given by the original eyewitness in Puerto Rico, Madelyne Tolentino, was based on the creature Sil in the science-fiction horror film "Species". The alien creature Sil is nearly identical to Tolentino’s chupacabra eyewitness account and she had seen the movie before her report: "It was a creature that looked like the chupacabra, with spines on its back and all... The resemblance to the chupacabra was really impressive," Tolentino reported. Radford revealed that Tolentino "believed that the creatures and events she saw in "Species" were actually happening in reality in Puerto Rico at the time," and therefore concludes that "the most important chupacabra description cannot be trusted." This, Radford believes, seriously undermines the credibility of the chupacabra as a real animal.
In addition, the reports of blood-sucking by the chupacabra were never confirmed by a necropsy, the only way to conclude that the animal was drained of blood. An analysis by a veterinarian of 300 reported victims of the chupacabra found that they had not been bled dry.
Radford divided the chupacabra reports into two categories:
In late October 2010, University of Michigan biologist Barry O'Connor concluded that all the chupacabra reports in the United States were simply coyotes infected with the parasite Sarcoptes scabiei, the symptoms of which would explain most of the features of the chupacabra: they would be left with little fur, thickened skin, and rank odour. O'Connor theorized the attacks on goats occurred "because these animals are greatly weakened, they're going to have a hard time hunting. So they may be forced into attacking livestock because it's easier than running down a rabbit or a deer." 
Although several witnesses came to the conclusion that the attacks could not be the work of dogs or coyotes because they had not eaten the victim, this conclusion is incorrect. Both dogs and coyotes can kill and not consume the prey, either because they are inexperienced, or due to injury or difficulty in killing the prey. The prey can survive the attack and die afterwards from internal bleeding or circulatory shock. The presence of two holes in the neck, corresponding with the canine teeth, are to be expected since this is the only way that most land carnivores have to catch their prey.
Reported sightings.
Numerous sightings of the creature were reported during the mid-1990s in Mexico, the U.S. Southwest and China. The first reported sightings were in Puerto Rico, US, where more than 200 original reports were made in 1995.
In July 2004, a rancher near San Antonio, Texas, killed a hairless dog-like creature which was attacking his livestock. This animal, initially given the name the Elmendorf Beast, was later determined by DNA assay conducted at University of California, Davis to be a coyote with demodectic or sarcoptic mange. In October 2004, two more carcasses were found in the same area. Biologists in Texas examined samples from the two carcasses and determined they were also coyotes suffering from very severe cases of mange. In Coleman, Texas, a farmer named Reggie Lagow caught an animal in a trap he set up after the deaths of a number of his chickens and turkeys. The animal was described as resembling a mix of hairless dog, rat, and kangaroo. Lagow provided the animal to Texas Parks and Wildlife officials for identification, but Lagow reported in a September 17, 2006, phone interview with John Adolfi, founder of the Lost World Museum, that the "critter was caught on a Tuesday and thrown out in Thursday's trash."
In April 2006, "MosNews" reported that the chupacabra was spotted in Russia for the first time. Reports from Central Russia beginning in March 2005 tell of a beast that kills animals and sucks out their blood. 32 turkeys were killed and drained overnight. Reports later came from neighboring villages when 30 sheep were killed and had their blood drained. Finally, eyewitnesses were able to describe the chupacabra. In May 2006, experts were determined to track the animal down. According to Russian paranormal researcher Vadim Chernobrov, the territory allegedly frequented by chupacabras lies in the Kharkov region of Ukraine and neighboring regions of Russia, but also in parts of Belarus and Poland. Recently the reports appeared of chupacabra-like attacks in the Moscow region of Russia with dozens of birds and animals found bloodless, with strange incisions. At least twice the mysterious kangaroo-like creature ("with a crocodile head") attacked humans, causing no serious damage, though. According to Chernobrov, the two extraordinary things about the chupacabras' ways are that the thing leaves a 'vanishing' line of footprints, looking as if it takes off as a bird, and also it tends occasionally to assort its victim's bodies 'aesthetically', often by colour and size, or build pyramids with killed bodies.
In mid-August 2006, Michelle O'Donnell of Turner, Maine, described an "evil looking" rodent-like animal with fangs that had been found dead alongside a road. The animal was apparently struck by a car, and was unidentifiable. Photographs were taken and witness reports seem to be in relative agreement that the creature was canine in appearance, but in widely published photos seemed unlike any dog or wolf in the area. Photos from other angles seem to show a chow or akita mixed-breed dog. It was reported that "the carcass was picked clean by vultures before experts could examine it". For years, residents of Maine have reported a mysterious creature and a string of dog maulings.
In May 2007, a series of reports on national Colombia news reported more than 300 dead sheep in the region of Boyaca, and the capture of a possible specimen to be analyzed by zoologists at the National University of Colombia.
In August 2007, Phylis Canion found three animals in Cuero, Texas. She and her neighbors reported to have discovered three strange animal carcasses outside Canion's property. She took photographs of the carcasses and preserved the head of one in her freezer before turning it over for DNA analysis. Canion reported that nearly 30 chickens on her farm had been exsanguinated over a period of years, a factor which led her to connect the carcasses with the chupacabra legend. State Mammologist John Young estimated that the animal in Canion's pictures was a Gray Fox suffering from an extreme case of mange. In November 2007, biology researchers at Texas State University–San Marcos determined from DNA samples that the suspicious animal was a coyote. The coyote, however, had grayish-blue, mostly hairless skin and large fanged teeth, attributes which caused it to appear different from a normal coyote. Additional skin samples were taken to attempt to determine the cause of the hair loss.
On January 11, 2008, a sighting was reported at the province of Capiz in the Philippines. Some of the residents from the barangay believed that it was the chupacabra that killed eight chickens. The owner of the chickens saw a dog-like animal attacking his chickens.
On August 8, 2008, a DeWitt County deputy, Brandon Riedel, filmed an unidentifiable animal along back roads near Cuero, Texas, on his dashboard camera. The animal was about the size of a coyote but was hairless with a long snout, short front legs and long back legs. However, Reiter's boss, Sheriff Jode Zavesky, believes it may be the same species of coyote identified by Texas State University–San Marcos researchers in November 2007. The video footage was shown on an April 2011 episode of the Syfy television series "" where an investigative team tried to recreate the dashboard video footage using a miniature horse and a Mexican Hairless Dog (both of which were bred locally). Neither test animal matched the creature in the video. The team had also tested a DNA sample taken from an alleged carcass of one of the creatures found by a local rancher and later identified as being a hybrid wolf/coyote.
In September 2009, CNN aired a report showing closeup video footage of an unidentified dead animal. The same CNN report stated that locals have begun speculating the possibility that this might be a chupacabra. A Blanco, Texas, taxidermist reported that he received the body from a former student whose cousin had discovered the animal in his barn, where it had succumbed to poison left out for rodents. The taxidermist expressed his belief that this is a genetically mutated coyote.
On September 18, 2009, taxidermist Jerry Ayer sold the Blanco Texas Chupacabra to the Lost World Museum. The museum, as reported in the Syracuse Post Standard on 9/26/09, is placing the creature on display as it works with an unnamed university to have the remains tested.
In July 2010, there were reports of chupacabras being shot dead by animal control officers in Hood County, Texas. A second creature was also reportedly spotted and killed several miles away. However, an officer of Hood County animal control said Texas A&M University scientists conducted tests and identified the corpse as a "coyote-dog hybrid" with signs of mange and internal parasites. The second reported chupacabra, shot July 9 about 8 miles south of Cresson, was eaten by vultures before it could be taken for testing.
On December 18, 2010, in Nelson County, Kentucky, Mark Cothren shot and killed an animal that he could not recognize and feared. Many pictures of the Chupacabra were taken and the story was well documented by various news organizations. Cothren described the creature as having large ears, whiskers, a long tail, and about the size of a house cat. Cothren says he spoke with the Kentucky Department of Fish and Wildlife Resources and handed over the preserved animal for further analysis.
On July 4, 2011, Jack (Jeff) Crabtree, of Lake Jackson, Texas, reported seeing a chupacabra in his back yard. At first, Crabtree stood firm on his original theory of the chupacabra, but after the local newspaper and several other media reporters wrote his story on July 11, he quickly backed down, agreeing with wildlife experts that it was most likely a coyote with mange. "It was a spoof or a practical joke," Crabtree said. "...I really didn't believe it." His story appeared on CNN, as well as MSNBC. On July 15, 2011, local authorities caught what Crabtree saw. Experts confirmed that the animal was definitely a coyote with mange.
On September 17, 2013, the Fox 2 News affiliate in Saint Louis, Missouri, posted on its website a report of two sightings. In the first, a woman spotted a "small grey dog-like animal" near the front gate of the Old Lake Hill Speedway in Saint Louis. A week previously, a hunter claimed to have killed a chupacabra while "coon hunting". The Mississippi Department of Wildlife said that it was a dog with mange.
A Texan couple who reside on a ranch in Victoria County, Texas informed the media that they had shot and killed a chupacabra on their property during the evening of February 23, 2014. A wildlife biologist with the Texas Parks and Wildlife organization also spoke with the media and stated: "I've seen squirrels, raccoons and coyotes in this area with the same features. They're [chupacabra] a mythical creature that most people see, but what it really is sarcoptic mange which is caused by a mite that bites the animal and it can be on any mammal - dogs, cats, coyotes foxes, and humans can get another version of it as well."
On April 3, 2014, a Texan couple claimed to have captured a chupacabra in Ratcliffe, Texas on March 29, 2014 Livescience's Benjamin Radford suggested the animal is a raccoon suffering from sarcoptic mange.
Appearance.
The most common description of the chupacabra is that of a reptile-like creature, said to have leathery or scaly greenish-gray skin and sharp spines or quills running down its back. It is said to be approximately 3 to 4 feet (1 to 1.2 m) high, and stands and hops in a fashion similar to that of a kangaroo.
Another less common description of the chupacabra is of a strange breed of wild dog. This form is mostly hairless and has a pronounced spinal ridge, unusually pronounced eye sockets, fangs, and claws.Unlike conventional predators, the chupacabra is said to drain all of the animal's blood (and sometimes organs) usually through three holes in the shape of an upside-down triangle or through one or two holes.
Naming convention.
"Chupacabras" can be translated as "goat-sucker". It is known as both "chupacabras" and "chupacabra" throughout the Americas, with the former being the original word, and the latter a regularization of it. The name in Spanish can be preceded by a singular masculine article ("el chupacabras"), or the plural masculine article ("los chupacabras").
Related legends.
A popular legend in New Orleans concerns a popular lovers' lane called Grunch Road, which was said to be inhabited by "grunches", creatures similar in appearance to the "Chupacabra".
The Peuchen of Chile also share similarities in their supposed habits, but instead of being dog-like they are described as winged snakes. This legend may have originated from the vampire bat, an animal endemic to the region.
In the Philippines, another legendary creature called the Sigbin shares many of the same descriptions as the "Chupacabra". The recent discovery of the cat-fox in Southeast Asia suggests that it could also have been simply sightings of this once unknown animal.
In popular culture.
The popularity of the chupacabra has resulted in its being featured in several types of media.
References.
Notes

</doc>
<doc id="6309" url="http://en.wikipedia.org/wiki?curid=6309" title="Cayuga Lake">
Cayuga Lake

Cayuga Lake ( or )  is the longest of central New York's glacial Finger Lakes, and is the second largest in surface area (marginally smaller than Seneca Lake) and second largest in volume. It is just under 40 miles (64 km) long. Its average width is 1.7 miles (2.7 km), and it is at its widest point near Aurora. It is approximately at its deepest point.
Location.
The city of Ithaca, New York, site of Ithaca College and Cornell University, is located at the southern end of Cayuga Lake.
Villages and settlements along the east shore of Cayuga Lake include Myers, King Ferry, Aurora, Levanna, Union Springs, and Cayuga. Settlements along the west shore of the lake include Sheldrake, Poplar Beach, and Canoga.
The lake has one small island near Union Springs, Frontenac Island. It is one of only two islands in the Finger Lakes, the other being Squaw Island in Lake Canandaigua.
Geographical characteristics.
Cayuga Lake is located at ; above sea level. Its depth, steep east and west sides with shallow north and south ends is typical of the Finger Lakes, as they were carved by glaciers during the last ice age.
The water level is regulated by the Mud Lock at the north end of the lake. It is connected to Lake Ontario by the Erie Canal and Seneca Lake by the Seneca River. The lake is drawn down as winter approaches, to minimize ice damage and to maximize its capacity to store heavy spring runoff.
The north end is dominated by shallow mudflats. An important stopover for migratory birds, the mudflats and marsh are the location of the Montezuma National Wildlife Refuge.
The southern end is also shallow and often freezes during the winter.
Human impact.
The fish population is managed and substantial sport fishing is practiced, including smelt, lake trout and smallmouth bass fishing.
Cayuga Lake is very popular among recreational boaters. A large state marina and boat launch is located at the southern end of the lake in Ithaca (Allan H. Treman State Marine Park, the largest inland marina in New York). There are two yacht clubs on the western shore: Ithaca Yacht Club a few miles north of Ithaca, and Red Jacket Yacht Club just south of Canoga. There are several other marinas and boat launches scattered along the lake shore.
Cayuga Lake is the source of drinking water for several communities, including Lansing near the southern end of the lake along the east side, which draws water through the Bolton Point Municipal Water system. There are also several lake source cooling systems that are in operation on the lake, whereby cooler water is pumped from the depths of the lake, warmed, and circulated in a closed system back to the surface. One of these systems, which is operated by Cornell University and began operation in 2000, was controversial during the planning and building states for potential negative environmental impact. All the environmental impact reports and scientific studies have shown that the Cornell lake source cooling system has not yet had and will not likely have any measurably significant environmental impact. Furthermore, Cornell's system pumps significantly less warm water back into the lake than others further north which have been operating for decades, including the coal-fired power plant on the eastern shore.
The AES Cayuga electrical generating station operates in the Town of Lansing, on the east shore of Cayuga Lake. This coal-fired plant uses Cayuga Lake as a cooling source. In the late 1960s, citizens successfully opposed the construction of an 830-MW nuclear power plant on the shore of Cayuga Lake.
Rod Serling named his production company Cayuga Productions during the years of his TV series, "The Twilight Zone". Serling and his family had a summer home at Cayuga Lake.
Folklore.
The lake is the subject of local folklore. Cornell's alma mater makes reference to its position "Far Above Cayuga's Waters", while that of Ithaca College references "Cayuga’s shore".
A tradition at Wells College in Aurora holds that if the lake completely freezes over, classes are canceled (though for only one day). According to Wells College records, this last happened in 1979. However, other sources suggest that the only time the entire lake froze over solid end to end in the 20th century was in 1912.,
Cayuga Lake, like nearby Seneca Lake, is also the site of a phenomenon known as the Guns of the Seneca, mysterious cannon-like booms heard in the surrounding area. Many of these booms may be attributable to bird-scarers, automated cannon-like devices used by farmers to scare birds away from the many vineyards, orchards and crops. There is however no proof of this.
Wine.
Cayuga Lake is included in the American Viticultural Area with which it shares its name. Established in 1988, the AVA now boasts over a dozen wineries, four distilleries, a cidery, and a meadery.

</doc>
<doc id="6310" url="http://en.wikipedia.org/wiki?curid=6310" title="Columbia University">
Columbia University

Columbia University in the City of New York, commonly referred to as Columbia University, is an American private Ivy League research university located in the Morningside Heights neighborhood of Upper Manhattan in New York City. It is the oldest institution of higher learning in the State of New York, the fifth oldest in the United States, and one of the country's nine Colonial Colleges founded before the American Revolution. Today the university operates Columbia Global Centers overseas in Amman, Beijing, Istanbul, Paris, Mumbai, Rio de Janeiro, Santiago and Nairobi.
The university was founded in 1754 as King's College by royal charter of George II of Great Britain. After the American Revolutionary War, King's College briefly became a state entity, and was renamed Columbia College in 1784. The University now operates under a 1787 charter that places the institution under a private board of trustees, and in 1896 it was further renamed Columbia University. That same year, the university's campus was moved from Madison Avenue to its current location in Morningside Heights, where it occupies more than six city blocks, or . The university encompasses twenty schools and is affiliated with numerous institutions, including Teachers College (which is Columbia University's Graduate School of Education), Barnard College, and the Union Theological Seminary, with joint undergraduate programs available through the Jewish Theological Seminary of America as well as the Juilliard School.
Columbia annually administers the Pulitzer Prize. 101 Nobel Prize laureates have been affiliated with the university as students, faculty, or staff, the second most of any institution in the world. Columbia is one of the fourteen founding members of the Association of American Universities, and was the first school in the United States to grant the M.D. degree. Notable alumni and former students of the university and its predecessor, King's College, include five Founding Fathers of the United States; nine Justices of the United States Supreme Court; 43 Nobel Prize laureates; 20 living billionaires; 28 Academy Award winners; and 29 heads of state, including three United States Presidents.
History.
King's College (1754–1784).
Discussions regarding the founding of a college in the Province of New York began as early as 1704, when Colonel Lewis Morris wrote to the Society for the Propagation of the Gospel in Foreign Parts, the missionary arm of the Church of England, persuading the society that New York City was an ideal community in which to establish a college; however, not until the founding of Princeton University across the Hudson River in New Jersey did the City of New York seriously consider founding a college. In 1746 an act was passed by the general assembly of New York to raise funds for the foundation of a new college. In 1751, the assembly appointed a commission of ten New York residents, seven of whom were members of the Church of England, to direct the funds accrued by the state lottery towards the foundation of a college.
Classes were initially held in July 1754 and were presided over by the college's first president, Dr. Samuel Johnson. Dr. Johnson was the only instructor of the college's first class, which consisted of a mere eight students. Instruction was held in a new schoolhouse adjoining Trinity Church, located on what is now lower Broadway in Manhattan. The college was officially founded on October 31, 1754, as King's College by royal charter of King George II, making it the oldest institution of higher learning in the state of New York and the fifth oldest in the United States.
In 1763, Dr. Johnson was succeeded in the presidency by Myles Cooper, a graduate of The Queen's College, Oxford, and an ardent Tory. In the charged political climate of the American Revolution, his chief opponent in discussions at the College was an undergraduate of the class of 1777, Alexander Hamilton. The American Revolutionary War broke out in 1776, and was catastrophic for the operation of King's College, which suspended instruction for eight years beginning in 1776 with the arrival of the Continental Army. The suspension continued through the military occupation of New York City by British troops until their departure in 1783. The college's library was looted and its sole building requisitioned for use as a military hospital first by American and then British forces. Loyalists were forced to abandon their King's College in New York, which was seized by the rebels and renamed Columbia University. The Loyalists, led by Bishop Charles Inglis fled to Windsor, Nova Scotia, where they founded what is now the University of King's College.
Columbia College (1784–1896).
After the Revolution, the college turned to the State of New York in order to restore its vitality, promising to make whatever changes to the schools charter the state might demand. The Legislature agreed to assist the college, and on May 1, 1784, it passed "an Act for granting certain privileges to the College heretofore called King's College." The Act created a Board of Regents to oversee the resuscitation of King's College, and, in an effort to demonstrate its support for the new Republic, the Legislature stipulated that "the College within the City of New York heretofore called King's College be forever hereafter called and known by the name of Columbia College," a reference to Columbia, an alternative name for America. The Regents finally became aware of the college's defective constitution in February 1787 and appointed a revision committee, which was headed by John Jay and Alexander Hamilton. In April of that same year, a new charter was adopted for the college, still in use today, granting power to a private board of 24 Trustees.
On May 21, 1787, William Samuel Johnson, the son of Dr. Samuel Johnson, was unanimously elected President of Columbia College. Prior to serving at the university, Johnson had participated in the First Continental Congress and been chosen as a delegate to the Constitutional Convention. For a period in the 1790s, with New York City as the federal and state capital and the country under successive Federalist governments, a revived Columbia thrived under the auspices of Federalists such as Hamilton and Jay. Both President George Washington and Vice President John Adams attended the college's commencement on May 6, 1789, as a tribute of honor to the many alumni of the school that had been involved in the American Revolution.
The college's enrollment, structure, and academics stagnated for the majority of the 19th century, with many of the college presidents doing little to change the way that the College functioned. In 1857, the College moved from Park Place to a primarily Gothic Revival campus on 49th Street and Madison Avenue, where it remained for the next fifty years. During the last half of the 19th century, under the leadership of President F.A.P. Barnard, the institution rapidly assumed the shape of a modern university. By this time, the College's investments in New York real estate became a primary source of steady income for the school, mainly owing to the city's rapidly expanding population.
Columbia University (1896–present).
In 1896, the trustees officially authorized the use of yet another new name, Columbia University, and today the institution is officially known as "Columbia University in the City of New York." At the same time, university president Seth Low moved the campus again, from 49th Street to its present location, a more spacious campus in the developing neighborhood of Morningside Heights. Under the leadership of Low's successor, Nicholas Murray Butler, who served for over four decades, Columbia rapidly became the nation's major institution for research, setting the "multiversity" model that later universities would adopt.
Research into the atom by faculty members John R. Dunning, I. I. Rabi, Enrico Fermi and Polykarp Kusch placed Columbia's Physics Department in the international spotlight in the 1940s after the first nuclear pile was built to start what became the Manhattan Project. In 1947, to meet the needs of GIs returning from World War II, University Extension was reorganized as an undergraduate college and designated the Columbia University School of General Studies.
During the 1960s Columbia experienced large-scale student activism, which reached a climax in the spring of 1968 when hundreds of students occupied various buildings on campus. The incident forced the resignation of Columbia's then President, Grayson Kirk and the establishment of the University Senate.
Though several schools within the university had admitted women for years, Columbia College first admitted women in the fall of 1983, after a decade of failed negotiations with Barnard College, an all-female institution affiliated with the university, to merge the two schools. Barnard College still remains affiliated with Columbia, and all Barnard graduates are issued diplomas authorized by both Columbia University and Barnard College.
Campus.
Morningside Heights.
The majority of Columbia's graduate and undergraduate studies are conducted in Morningside Heights on Seth Low's late-19th century vision of a university campus where all disciplines could be taught in one location. The campus was designed along Beaux-Arts principles by architects McKim, Mead, and White. Columbia's main campus occupies more than six city blocks, or , in Morningside Heights, New York City, a neighborhood that contains a number of academic institutions. The university owns over 7,800 apartments in Morningside Heights, housing faculty, graduate students, and staff. Almost two dozen undergraduate dormitories (purpose-built or converted) are located on campus or in Morningside Heights. Columbia University has an extensive underground tunnel system more than a century old, with the oldest portions predating the present campus. Some of these remain accessible to the public, while others have been cordoned off.
The Nicholas Murray Butler Library, commonly known simply as Butler Library, is the largest single library in the Columbia University Library System, and is one of the largest buildings on the campus. Proposed as "South Hall" by the university's former President Nicholas Murray Butler as expansion plans for Low Memorial Library stalled, the new library was funded by Edward Harkness, benefactor of Yale's residential college system, and designed by his favorite architect, James Gamble Rogers. It was completed in 1934 and renamed for Butler in 1946. The library's design is neo-classical in style. Its facade features an arcade of columns in the Ionic order above which are inscribed the names of great writers, philosophers, and thinkers, most of whom are read by students engaged in the Core Curriculum of Columbia College. As of 2012, Columbia's library system includes over 11.9  million volumes, making it the eighth largest library system and fifth largest collegiate library system in the United States.
Several buildings on the Morningside Heights campus are listed on the National Register of Historic Places. Low Memorial Library, a National Historic Landmark and the centerpiece of the campus, is listed for its architectural significance. Philosophy Hall is listed as the site of the invention of FM radio. Also listed is Pupin Hall, another National Historic Landmark, which houses the physics and astronomy departments. Here the first experiments on the fission of uranium were conducted by Enrico Fermi. The uranium atom was split there ten days after the world's first atom-splitting in Copenhagen, Denmark.
A statue by sculptor Daniel Chester French called "Alma Mater" is centered on the front steps of Low Memorial Library. McKim, Mead & White invited French to build the sculpture in order to harmonize with the larger composition of the court and library in the center of the campus. Draped in an academic gown, the female figure of Alma Mater wears a crown of laurels and sits on a throne. The scroll-like arms of the throne end in lamps, representing sapientia and doctrina. A book signifying knowledge, balances on her lap, and an owl, the attribute of wisdom, is hidden in the folds of her gown. Her right hand holds a scepter composed of four sprays of wheat, terminating with a crown of King's College which refers to Columbia's origin as a Royalist institution in 1754. A local actress named Mary Lawton was said to have posed for parts of the sculpture. The statue was dedicated on September 23, 1903, as a gift of Mr. & Mrs. Robert Goelet, and was originally covered in golden leaf. During the Columbia University protests of 1968 a bomb damaged the sculpture, but it has since been repaired. The small hidden owl on the sculpture is also the subject of many Columbia legends, the main legend being that the first student in the freshmen class to find the hidden owl on the statue will be valedictorian, and that any subsequent Columbia male who finds it will marry a Barnard student, given that Barnard is a women's college.
"The Steps", alternatively known as "Low Steps" or the "Urban Beach", are a popular meeting area for Columbia students. The term refers to the long series of granite steps leading from the lower part of campus (South Field) to its upper terrace. With a design inspired by the City Beautiful movement, the steps of Low Library provides Columbia University and Barnard College students, faculty, and staff with a comfortable and spacious outdoor platform and space for informal gatherings, events, and ceremonies. McKim's classical facade epitomizes late 19th century new-classical designs, with its columns and portico marking the entrance to an important structure. On warm days when the weather is favorable, the Low Steps often become a popular gathering place for students to sunbathe, eat lunch, or play frisbee.
Other campuses.
In April 2007, the university purchased more than two-thirds of a site for a new campus in Manhattanville, an industrial neighborhood to the north of the Morningside Heights campus. Stretching from 125th Street to 133rd Street, the new campus will house buildings for Columbia's Business School, School of International and Public Affairs, and the Jerome L. Greene Center for Mind, Brain, and Behavior, where research will occur on neurodegenerative diseases such as Parkinson's and Alzheimer's. The $7 billion expansion plan includes demolishing all buildings, except three that are historically significant, eliminating the existing light industry and storage warehouses, and relocating tenants in 132 apartments. Replacing these buildings will be of space for the university. Community activist groups in West Harlem fought the expansion for reasons ranging from property protection and fair exchange for land, to residents' rights. Subsequent public hearings drew neighborhood opposition. Most recently, as of December 2008, the State of New York's Empire State Development Corporation approved use of eminent domain, which, through declaration of Manhattanville's "blighted" status, gives governmental bodies the right to appropriate private property for public use. On May 20, 2009, the New York State Public Authorities Control Board approved the Manhanttanville expansion plan and the first buildings are under construction.
New York-Presbyterian Hospital is affiliated with the medical schools of both Columbia University and Cornell University. According to "US News and World Report"s "America's Best Hospitals 2009", it is ranked sixth overall and third among university hospitals. Columbia Medical School has a strategic partnership with New York State Psychiatric Institute, and is affiliated with 19 other hospitals in the U.S. and four hospitals overseas. Health-related schools are located at the Columbia University Medical Center, a campus located in the neighborhood of Washington Heights, fifty blocks uptown. Other teaching hospitals affiliated with Columbia through the New York-Presbyterian network include the Payne Whitney Clinic in Manhattan, and the Payne Whitney Westchester, a psychiatric institute located in White Plains, New York. On the northern tip of Manhattan island (in the neighborhood of Inwood), Columbia owns Baker Field, which includes the Lawrence A. Wien Stadium as well as facilities for field sports, outdoor track, and tennis. There is a third campus on the west bank of the Hudson River, the Lamont-Doherty Earth Observatory and Earth Institute in Palisades, New York. A fourth is the Nevis Laboratories in Irvington, New York for the study of particle and motion physics. A satellite site in Paris, France holds classes at Reid Hall.
Sustainability.
In 2006, the university established the Office of Environmental Stewardship to initiate, coordinate and implement programs to reduce the university's environmental footprint. The U.S. Green Building Council selected the university's Manhattanville plan for the Leadership in Energy and Environmental Design (LEED) Neighborhood Design pilot program. The plan commits to incorporating smart growth, new urbanism and "green" building design principles. Columbia is one of the 2030 Challenge Partners, a group of nine universities in the city of New York that have pledged to reduce their greenhouse emissions by 30% within the next ten years. Columbia University adopts LEED standards for all new construction and major renovations. The University requires a minimum of Silver, but through its design and review process seeks to achieve higher levels. This is especially challenging for lab and research buildings with their intensive energy use; however, the university also uses lab design guidelines that seek to maximize energy efficiency while protecting the safety of researchers.
Every Thursday and Sunday of the month, Columbia hosts a greenmarket where local farmers can sell their produce to residents of the city. In addition, from April to November Hodgson's farm, a local New York gardening center, joins the market bringing a large selection of plants and blooming flowers. The market is one of the many operated at different points throughout the city by the non-profit group GrowNYC. Dining services at Columbia spends 36 percent of its food budget on local products, in addition to serving sustainably harvested seafood and fair trade coffee on campus. Columbia has been rated "B+" by the 2011 College Sustainability Report Card for its environmental and sustainability initiatives.
Academics.
Undergraduate admissions and financial aid.
Columbia University's acceptance rate for the class of 2017 (Columbia College and Engineering) is 6.89%, making Columbia the fourth most selective college in the United States by admission rate behind Stanford, Harvard and Yale. The undergraduate yield rate for the class of 2015 is 63%. According to the 2012 college selectivity ranking by U.S. News & World Report, which factors admission and yield rates among other criteria, Columbia is tied with Yale, Caltech and MIT as the most selective colleges in the country. Columbia is a racially diverse school, with approximately 52% of all students identifying themselves as persons of color. Additionally, 56% of all undergraduates in the Class of 2016 receive financial aid. The average financial aid package for these students exceeds $30,000, with an average grant size of over $20,000. In 2012-2013 annual undergraduate tuition at Columbia was $45,028 with a total cost of attendance of $61,540 (including room and board).
On April 11, 2007, Columbia University announced a $400m to $600m donation from media billionaire alumnus John Kluge to be used exclusively for undergraduate financial aid. The donation is among the largest single gifts to higher education. Its exact value will depend on the eventual value of Kluge's estate at the time of his death; however, the generous donation has helped change financial aid policy at Columbia. Annual gifts, fund-raising, and an increase in spending from the university's endowment have allowed Columbia to extend generous financial aid packages to qualifying students. As of 2008, undergraduates from families with incomes as high as $60,000 a year will have the projected cost of attending the university, including room, board, and academic fees, fully paid for by the university. That same year, the university ended loans for incoming and current students who were on financial aid, replacing loans that were traditionally part of aid packages with grants from the university. However, this does not apply to international students, transfer students, visiting students, or students in the School of General Studies. In the fall of 2010, admission to Columbia's undergraduate colleges Columbia College and Columbia Engineering, formerly known as SEAS, began accepting the Common Application. The policy change made Columbia one of the last major academic institutions and the last Ivy League university to switch to the Common Application.
Scholarships are also given to undergraduate students by the admissions committee. Designations include John W. Kluge Scholars, John Jay Scholars, C. Prescott Davis Scholars, Global Scholars, Egleston Scholars, and Science Research Fellows. Named scholars are selected by the admission committee from first-year applicants. According to Columbia, the first four designated scholars "distinguish themselves for their remarkable academic and personal achievements, dynamism, intellectual curiosity, the originality and independence of their thinking, and the diversity that stems from their different cultures and their varied educational experiences."
Organization.
Columbia University is an independent, privately supported, nonsectarian institution of higher education. Its official corporate name is "The Trustees of Columbia University in the City of New York." The university's first Charter was granted in 1754 by King George II; however, its modern Charter was first enacted in 1787 and last amended in 1810 by the New York State Legislature. The university is governed by 24 Trustees, customarily including the President, who serves ex officio. The Trustees themselves are responsible for choosing their successors. Six of the 24 are nominated from a pool of candidates recommended by the Columbia Alumni Association. Another six are nominated by the Board in consultation with the Executive Committee of the University Senate. The remaining 12, including the President, are nominated by the Trustees themselves through their internal processes. The term of office for Trustees is six years. Generally, they serve for no more than two consecutive terms. The Trustees appoint the President and other senior administrative officers of the university, and review and confirm faculty appointments as required. They determine the university's financial and investment policies, authorize the budget, supervise the endowment, direct the management of the university's real estate and other assets, and otherwise oversee the administration and management of the university.
The University Senate was established by the Trustees after a university-wide referendum in 1969. It succeeded to the powers of the University Council, which was created in 1890 as a body of faculty, deans, and other administrators to regulate inter-Faculty affairs and consider issues of university-wide concern. The University Senate is a unicameral body consisting of 107 members drawn from all constituencies of the university. These include the president of the university, the Provost, the Deans of Columbia College and the Graduate School of Arts and Sciences, all who serve ex officio, and five additional representatives, appointed by the President, from the university's administration. The President serves as the Senate's presiding officer. The Senate is charged with reviewing the educational policies, physical development, budget, and external relations of the university. It oversees the welfare and academic freedom of the faculty and the welfare of students.
The President of Columbia University, who is selected by the Trustees in consultation with the Executive Committee of the University Senate and who serves at the Trustees' pleasure, is the chief executive officer of the university. Assisting the President in administering the University are the Provost, the Senior Executive Vice President, the Executive Vice President for Health and Biomedical Sciences, several other vice presidents, the General Counsel, the Secretary of the University, and the deans of the Faculties, all of whom are appointed by the Trustees on the nomination of the President and serve at their pleasure. Lee C. Bollinger became the 19th President of Columbia University on June 1, 2002. A prominent advocate of affirmative action, he played a leading role in the twin Supreme Court cases—Grutter v Bollinger and Gratz v Bollinger—that upheld and clarified the importance of diversity as a compelling justification for affirmative action in higher education. A leading First Amendment scholar, he is widely published on freedom of speech and press, and currently serves on the faculty of Columbia Law School.
Columbia has three official undergraduate colleges: Columbia College (CC), the liberal arts college offering the Bachelor of Arts degree, Columbia Engineering, formerly known as SEAS, is the engineering and applied science school offering the Bachelor of Science degree, and The School of General Studies (GS), in which nontraditional students obtain a Bachelor of Arts or a Bachelor of Science through either full-time or part-time study. The university is affiliated with Teachers College, Barnard College, the Union Theological Seminary, and the Jewish Theological Seminary of America, all located nearby in Morningside Heights. Joint undergraduate programs are available through the Jewish Theological Seminary of America as well as through the Juilliard School. Two affiliated institutions – Barnard College and Teachers College – are also Faculties of the university. One affiliated institute—Teachers College—is likewise an academic department of the university.
Research and rankings.
Columbia was the first North American site where the uranium atom was split. It was the birthplace of FM radio and the laser. The MPEG-2 algorithm of transmitting high quality audio and video over limited bandwidth was developed by Dimitris Anastassiou, a Columbia professor of electrical engineering. Biologist Martin Chalfie was the first to introduce the use of Green Fluorescent Protein (GFP) in labelling cells in intact organisms. Other inventions and products related to Columbia include Sequential Lateral Solidification (SLS) technology for making LCDs, System Management Arts (SMARTS), Session Initiation Protocol (SIP) (which is used for audio, video, chat, instant messaging and whiteboarding), pharmacopeia, Macromodel (software for computational chemistry), a new and better recipe for glass concrete, Blue LEDs, and Beamprop (used in photonics).
Columbia scientists have been credited with about 175 new inventions in the health sciences each year. More than 30 pharmaceutical products based on discoveries and inventions made at Columbia are on the market today. These include Remicade (for arthritis), Reopro (for blood clot complications), Xalatan (for glaucoma), Benefix, Latanoprost (a glaucoma treatment), shoulder prosthesis, homocysteine (testing for cardiovascular disease), and Zolinza (for cancer therapy). (formerly Science and Technology Ventures) currently manages some 600 patents and more than 250 active license agreements. Patent-related deals earned Columbia more than $230 million in the 2006 fiscal year, according to the university, more than any university in the world.
Columbia University was ranked fourth amongst the top U.S. national universities for 2014 as per "U.S. News & World Report". In the Center for Measuring University Performance, administered by Arizona State University, Columbia has been ranked first (tied with MIT, Stanford University and Penn) in the United States. The ranking takes into account total research, federal research, endowment assets, annual giving, National Academy members, faculty awards, doctorates granted, postdoctoral appointees, and undergraduate SAT/ACT range. In 2012, Columbia was ranked #8 in "ARWU", #11 in QS, and #13 by "Times Higher Education" in the world. Prior national rankings include #6 by HRLR, #7 by ARWU, and #5 by "Forbes". Columbia's colleges and schools are also ranked by several independent bodies. For 2011, the College & School of Engineering (undergraduate) was ranked #4 nationally by "U.S. News & World Report", the Graduate School of Arts #10, the Columbia Business School #3 by "The Wall Street Journal" the Teachers College #2 by "U.S. News & World Report", the Fu Foundation School of Engineering and Applied Science (graduate) #14, the Columbia Law School #3, the College of Physicians and Surgeons #8 for research and #43 for primary care, the Mailman School of Public Health #5, and the School of International and Public Affairs #8. Additionally, Columbia's School of Social Work is ranked #4, its Graduate School of Architecture, Planning and Preservation #2, and its Graduate School of Journalism #1.
In the last 12 years (1996–2008), 18 Columbia affiliates have won Nobel Prizes, of whom nine are current faculty members while one is an adjunct senior research scientist (Daniel Tsui) and the other a Global Fellow (Kofi Annan). Columbia faculty awarded the Nobel Prize include Richard Axel, Martin Chalfie, Eric Kandel, Tsung-Dao Lee, Robert Mundell, Orhan Pamuk, Edmund S. Phelps, Joseph Stiglitz, and Horst L. Stormer. Other awards and honors won by faculty include 30 MacArthur Foundation Award winners, 4 National Medal of Science recipients, 43 National Academy of Sciences Award winners, 20 National Academy of Engineering Award winners, 38 Institute of Medicine of the National Academies Award recipients and 143 American Academy of Arts and Sciences Award winners.
Student life.
Students.
For the 2010 academic year, Columbia University's student population was 27,606, with 35% of the student population identifying themselves as a minority and 23% born outside of the United States. Columbia enrolled 7,934 students in undergraduate programs, 5,393 students in graduate programs, and 12,090 students in professional programs. 26% of students at Columbia have family incomes below $60,000, making it one of the most socioeconomically diverse top-tier colleges. 16% of students at Columbia receive Federal Pell Grants, which mostly go to students whose family incomes are below $40,000. 15% of students are the first member of their family to attend a four-year college.
On-campus housing is guaranteed for all four years as an undergraduate. Columbia College and Columbia Engineering, formerly known as SEAS, share housing in the on-campus residence halls. First-year students usually live in one of the large residence halls situated around South Lawn: Hartley Hall, Wallach Hall (originally Livingston Hall), John Jay Hall, Furnald Hall or Carman Hall. Upperclassmen participate in a room selection process, wherein students can pick to live in a mix of either corridor- or apartment-style housing with their friends. The Columbia University School of General Studies and graduate schools have their own apartment-style housing in the surrounding neighborhood.
Columbia University is home to many fraternities, sororities, and co-educational Greek organizations. Approximately 10–15% of undergraduate students are associated with Greek life. There has been a Greek presence on campus since the establishment in 1836 of the Delta Chapter of Alpha Delta Phi. The InterGreek Council is the self-governing student organization that provides guidelines and support to its member organizations within each of the three councils at Columbia, the Interfraternity Council, Panhellenic Council, and Multicultural Greek Council. The three council presidents bring their affiliated chapters together once a month to meet as one Greek community. The InterGreek Council meetings provide opportunity for member organizations to learn from each other, work together and advocate for community needs.
Publications.
Columbia University is home to a rich diversity of undergraduate, graduate, and professional publications. The "Columbia Daily Spectator" is the nation's second-oldest student newspaper; and "The Blue and White", a monthly literary magazine established in 1890, has recently begun to delve into campus life and local politics in print and on its daily blog, dubbed the "Bwog".
Political publications include "The Current", a journal of politics, culture and Jewish Affairs; the "Columbia Political Review", the multi-partisan political magazine of the Columbia Political Union; and "AdHoc", which denotes itself as the "progressive" campus magazine and deals largely with local political issues and arts events.
Arts and literary publications include the "Columbia Review", the nation's oldest college literary magazine; "Columbia", a nationally regarded literary journal; the "Columbia Journal of Literary Criticism"; and "The Mobius Strip", an online arts and literary magazine. "Inside New York" is an annual guidebook to New York City, written, edited, and published by Columbia undergraduates. Through a distribution agreement with Columbia University Press, the book is sold at major retailers and independent bookstores.
Columbia is home to numerous undergraduate academic publications. The "Journal of Politics & Society", is a journal of undergraduate research in the social sciences, published and distributed nationally by the Helvidius Group; ' is an undergraduate journal of politics established in 2008 and published biannually; the "Columbia East Asia Review" allows undergraduates throughout the world to publish original work on China, Japan, Korea, Tibet, and Vietnam and is supported by the Weatherhead East Asian Institute; and "The Birch", is an undergraduate journal of Eastern European and Eurasian culture that is the first national student-run journal of its kind; , the undergraduate magazine on politics operated by the Columbia Political Union; , the undergraduate economic journal on research and policy supported by the Columbia Economics Department; and the ' is a science magazine that prints general interest articles, faculty profiles, and student research papers.
"The Fed" a triweekly satire and investigative newspaper, and the "Jester of Columbia", the newly (and frequently) revived campus humor magazine both inject humor into local life. Other publications include "The Columbian", the undergraduate colleges' annually published yearbook the "Gadfly", a biannual journal of popular philosophy produced by undergraduates; and "Rhapsody in Blue", an undergraduate urban studies magazine. Professional journals published by academic departments at Columbia University include "Current Musicology" and "The Journal of Philosophy". During the spring semester, graduate students in the Journalism School publish ', a bi-weekly newspaper covering the South Bronx. Teachers College publishes the ', a journal of research, analysis, and commentary in the field of education, published continuously since 1900.
Founded in 1961 under the auspices of Columbia University's Graduate School of Journalism, Columbia Journalism Review (CJR) examines day-to-day press performance as well as the forces that affect that performance. The magazine is published six times a year, and offers a deliberative mix of reporting, analysis, criticism, and commentary. CJR.org, its Web site, delivers real-time criticism and reporting, giving CJR a vital presence in the ongoing conversation about the media. Both online and in print, Columbia Journalism Review is in conversation with a community of people who share a commitment to high journalistic standards in the U.S. and the world.
Broadcasting.
Columbia is home to two early pioneers in undergraduate campus radio broadcasting, WKCR-FM and CTV. WKCR, the student run radio station that broadcasts to the Tri-State area, claims to be the oldest FM radio station in the world, owing to the university's affiliation with Major Edwin Armstrong. The station went operational on July 18, 1939, from a 400-foot antenna tower in Alpine, New Jersey, broadcasting the very first FM transmission in the world. Initially, WKCR wasn't a radio station, but an organization concerned with the technology of radio communications. As membership grew, however, the nascent club turned its efforts to broadcasting. Armstrong helped the students in their early efforts, donating a microphone and turntables when they designed their first makeshift studio in a dorm room. The station has its studios on the second floor of Alfred Lerner Hall on the Morningside campus with its main transmitter tower at 4 Times Square in Midtown Manhattan. Columbia Television (CTV) is the nation's second oldest Student television station and home of CTV News, a weekly live news program produced by undergraduate students.
Speech and debate.
The Philolexian Society is a literary and debating club founded in 1802, making it the oldest student group at Columbia, as well as the third oldest collegiate literary society in the country. The society annually administers the Joyce Kilmer Bad Poetry Contest. The Columbia Parliamentary Debate Team competes in tournaments around the country as part of the American Parliamentary Debate Association, and hosts both high school and college tournaments on Columbia's campus, as well as public debates on issues affecting the university.
The Columbia International Relations Council and Association (CIRCA), oversees Columbia's Model United Nations activities. CIRCA hosts college and high school Model UN conferences, hosts speakers influential in international politics to speak on campus, trains students from underprivileged schools in New York in Model UN and oversees a competitive team, which travels to colleges around the country and to an international conference every year. The competitive team consistently wins best and outstanding delegation awards and is considered one of the top teams in the country.
Technology and entrepreneurship.
The Columbia University Organization of Rising Entrepreneurs (CORE) was founded in 1999. The student-run group aims to foster entrepreneurship on campus. Each year CORE hosts dozens of events, including a business plan competition and a series of seminars. Notable seminar speakers include Mark Cuban, owner of the Dallas Mavericks and Chairman of HDNet, and Blake Ross, creator of Mozilla Firefox. By 2006, CORE had awarded graduate and undergraduate students over $100,000 in seed capital. Events are possible through the contributions of various private and corporate groups; previous sponsors include Deloitte & Touche, Citigroup, and i-Compass.
CampusNetwork, an on-campus social networking site called Campus Network that preceded Facebook, was created and popularized by Columbia engineering student Adam Goldberg in 2003. Mark Zuckerberg later asked Goldberg to join him in Palo Alto to work on Facebook, but Goldberg declined the offer. The Fu Foundation School of Engineering and Applied Science offers a minor in Technical Entrepreneurship through its . SEAS' entrepreneurship activities focus on community building initiatives in New York and worldwide, made possible through partners such as Microsoft Corporation.
Columbia is a top supplier of young engineering entrepreneurs for New York City. Over the past 20 years, graduates of Columbia established over 100 technology companies. Mayor Bloomberg has provided over $6.7 million towards entrepreneurial programs that partner with Columbia and other universities in New York. Professor Chris Wiggins of Fu Foundation School of Engineering and Applied Science is working in conjunction with Professors Evan Korth of New York University and Hilary Mason, chief scientist at bit.ly to facilitate the growth of student tech-startups in an effort to transform a traditionally financially centered New York City into the next Silicon Valley. Their website is a gathering ground of ideas and discussions for New York's young entrepreneurial community, the Silicon Alley.
On June 14, 2010, Mayor Michael R. Bloomberg launched the NYC Media Lab to promote innovations in New York's media industry. Situated in the Polytechnic Institute of New York University, the lab is a consortium of Columbia University, New York University, and New York City Economic Development Corporation acting to connect companies with universities in new technology research. The Lab is modeled after similar ones at MIT and Stanford. A $250,000 grant from the New York City Economic Development Corporation was used to establish the NYC Media Lab. Each year, the lab will host a range of roundtable discussions between the private sector and academic institutions. It will support research projects on topics of content format, next-generation search technologies, computer animation for film and gaming, emerging marketing techniques, and new devices development. The lab will also create a media research and development database. Columbia University will coordinate the long-term direction of the media lab as well as the involvement of its faculty and those of other universities.
Athletics.
A member institution of the National Collegiate Athletic Association (Division I-AA FCS), Columbia fields varsity teams in 29 sports and is a member of the Ivy League. The football Lions play home games at the 17,000-seat Lawrence A. Wien Stadium at Baker Field. One hundred blocks north of the main campus at Morningside Heights, the Baker Athletics Complex also includes facilities for baseball, softball, soccer, lacrosse, field hockey, tennis, track and rowing, as well as the new Campbell Sports Center opened in January 2013. The basketball, fencing, swimming & diving, volleyball and wrestling programs are based at the Dodge Physical Fitness Center on the main campus.
Columbia University athletics has a long history, with many accomplishments in various athletic fields. In 1870, Columbia played against Rutgers University in the second football game in the history of the sport. Eight years later, Columbia crew won the famed Henley Royal Regatta in the first-ever defeat for an English crew rowing in English waters. In 1900, Olympian and Columbia College student Maxie Long set the first official world record in the 400 meters with a time of 47.8 seconds. In 1983, Columbia men's soccer went 18-0 and was ranked first in the nation, but losing to Indiana 1-0 in double overtime in the NCAA championship game; nevertheless, the team went further toward the NCAA title than any Ivy League soccer team in history. The football program unfortunately is best known for its record of futility set during the 1980s: between 1983 and 1988, the team lost 44 games in a row, which is still the record for the NCAA Football Championship Subdivision. The streak was broken on October 8, 1988, with a 16-13 victory over archrival Princeton. That was the Lions' first victory at Wien Stadium, which had been opened during the losing streak and was already four years old. A new tradition has developed with the Liberty Cup. The Liberty Cup is awarded annually to the winner of the football game between Fordham and Columbia Universities, two of the only three NCAA Division I football teams in New York City. The tradition began in 2002, a year after the Fordham-Columbia game was postponed due to the September 11 attacks.
Former students include Baseball Hall of Famers Lou Gehrig and Eddie Collins, football Hall of Famer Sid Luckman, Marcellus Wiley, and world champion women's weightlifter Karyn Marshall. On May 17, 1939, fledgling NBC broadcast a doubleheader between the Columbia Lions and the Princeton Tigers at Columbia's Baker Field, making it the first televised regular athletic event in history.
World Leaders Forum.
Established in 2003 by university president Lee C. Bollinger, the World Leaders Forum at Columbia University provides the opportunity for undergraduate and graduate students alike to listen to some of the most prominent world leaders in government, religion, industry, finance, and academia. The World Leaders Forum is a year-around event series that strives to provide a platform for uninhibited speech among nations and cultures, while educating students about the current problems as well as progress around the globe.
All Columbia undergraduates and graduates as well as students of Barnard College and other Columbia affiliated schools can register to participate in the World Leaders Forum using their student IDs. Even for individuals who do not have the privilege to attend the event live, they can watch the forum via online videos on Columbia University's website.
Past forum speakers include former President of the United States Bill Clinton, the Prime Minister of India Atal Bihari Vajpayee, Former President of Ghana John Agyekum Kufuor, President of Afghanistan Hamid Karzai, Prime Minister of Russia Vladimir Putin, President of the Republic of Mozambique Joaquim Alberto Chissano, President of the Republic of Bolivia Carlos Diego Mesa Gisbert, President of the Republic of Romania Ion Iliescu, President of the Republic of Latvia Vaira Vīķe-Freiberga, the first female President of Finland Tarja Halonen, President Yudhoyono of Indonesia, President Pervez Musharraf of the Islamic Republic of Pakistan, Iraq President Jalal Talabani, the 14th Dalai Lama, President of the Islamic Republic of Iran Mahmoud Ahmadinejad, financier George Soros, Mayor of New York City Michael R. Bloomberg, President Václav Klaus of the Czech Republic, President Cristina Fernández de Kirchner of Argentina, former Secretary-General of the United Nations Kofi Annan, and Al Gore.
Other.
The Columbia University Orchestra was founded by composer Edward MacDowell in 1896, and is the oldest continually operating university orchestra in the United States. Undergraduate student composers at Columbia may choose to become involved with Columbia New Music, which sponsors concerts of music written by undergraduate students from all of Columbia's schools.
There are a number of performing arts groups at Columbia dedicated to producing student theater, including the Columbia Players, King's Crown Shakespeare Troupe (KCST), Columbia Musical Theater Society (CMTS), NOMADS (New and Original Material Authored and Directed by Students), LateNite Theatre, Columbia University Performing Arts League (CUPAL), Black Theatre Ensemble (BTE), sketch comedy group Chowdah, and improvisational troupes Alfred and Fruit Paunch. The Columbia University Marching Band tells jokes during the campus tradition of Orgo Night.
The Columbia Queer Alliance is the central Columbia student organization that represents the lesbian, gay, transgender, and questioning student population. It is the oldest gay student organization in the world, founded as the Student Homophile League in 1967 by students including lifelong activist Stephen Donaldson. Columbia University campus military groups include the U.S. Military Veterans of Columbia University and Advocates for Columbia ROTC. In the 2005–06 academic year, the Columbia Military Society, Columbia's student group for ROTC cadets and Marine officer candidates, was renamed the Hamilton Society for "students who aspire to serve their nation through the military in the tradition of Alexander Hamilton".
The university also houses an independent nonprofit organization, Community Impact, which strives to serve disadvantaged people in the Harlem, Washington Heights, and Morningside Heights communities. From its earliest inception as a single service initiative formed in 1981 by Columbia University undergraduates, Community Impact has grown into Columbia University's largest student service organization. CI provides food, clothing, shelter, education, job training, and companionship for residents in its surrounding communities. CI consists of a dedicated corps of about 950 Columbia University student volunteers participating in 25 community service programs, which serve more than 8,000 people each year.
Student activism.
Protests of 1968.
Students initiated a major demonstration in 1968 over two main issues. The first was Columbia's proposed gymnasium in neighboring Morningside Park; this was seen by the protesters to be an act of aggression aimed at the black residents of neighboring Harlem. A second issue was the Columbia administration's failure to resign its institutional membership in the Pentagon's weapons research think-tank, the Institute for Defense Analyses (IDA). Students barricaded themselves inside Low Library, Hamilton Hall, and several other university buildings during the protests, and New York City police were called onto the campus to arrest or forcibly remove the students.
The protests achieved two of their stated goals. Columbia disaffiliated from the IDA and scrapped the plans for the controversial gym, building a subterranean physical fitness center under the north end of campus instead. The gym's plans were eventually used by Princeton University for the expansion of its athletic facilities. At least 30 Columbia students were suspended by the administration as a result of the protests. Many of the Class of '68 walked out of their graduation and held a countercommencement on Low Plaza with a picnic following at Morningside Park, the place where the protests began. The protests hurt Columbia financially as many potential students chose to attend other universities and some alumni refused to donate money to the school. Allan Bloom, a professor of philosophy at the University of Chicago,
believed that the protest efforts at Columbia were responsible for pushing higher education further toward the liberal left. As a result of the protests, Bloom stated, "American universities were no longer places of intellectual and academic debate, but rather places of 'political correctness' and liberalism." 
Protests against racism and apartheid.
Further student protests, including hunger strike and more barricades of Hamilton Hall and the Business School during the late 1970s and early 1980s, were aimed at convincing the university trustees to divest all of the university's investments in companies that were seen as active or tacit supporters of the apartheid regime in South Africa. A notable upsurge in the protests occurred in 1978, when following a celebration of the tenth anniversary of the student uprising in 1968, students marched and rallied in protest of university investments in South Africa. The Committee Against Investment in South Africa (CAISA) and numerous student groups including the Socialist Action Committee, the Black Student Organization and the Gay Students group joined together and succeeded in pressing for the first partial divestment of a U.S. university.
The initial (and partial) Columbia divestment,
focused largely on bonds and financial institutions directly involved with the South African regime. It followed a year long campaign first initiated by students who had worked together to block the appointment of former United States Secretary of State Henry Kissinger to an endowed chair at the university in 1977.
Broadly backed by a diverse array of student groups and many notable faculty members the Committee Against Investment in South Africa held numerous teach-ins and demonstrations through the year focused on the trustees ties to the corporations doing business with South Africa. Trustee meetings were picketed and interrupted by demonstrations culminating in May 1978 in the takeover of the Graduate School of Business.
Ahmadinejad speech controversy.
The School of International and Public Affairs traditionally extends invitations to many heads of state and heads of government who come to New York City for the opening of the fall session of the United Nations General Assembly. In 2007, Iranian President Mahmoud Ahmadinejad was one of those invited to speak on campus. Ahmadinejad accepted his invitation and spoke on September 24, 2007, as part of Columbia University's World Leaders Forum. The invitation proved to be highly controversial. Hundreds of demonstrators swarmed the campus on September 24 and the speech itself was televised worldwide. University President Lee C. Bollinger tried to assuage the controversy by letting Ahmadenijad speak, but with a negative introduction (given personally by Bollinger). This did not mollify those who were displeased with the fact that the Iranian leader had been invited onto the campus. Columbia students, though, turned out en masse to listen to the speech on the South Lawn. An estimated 2,500 undergraduates and graduates came out for the historic occasion.
During his speech, Ahmadinejad criticized Israel's policies towards the Palestinians; called for research on the historical accuracy of the Holocaust; raised questions as to who initiated the 9/11 attacks; defended Iran's nuclear power program, criticizing the UN's policy of sanctions on his country; and attacked U.S. foreign policy in the Middle East. In response to a question about Iran's treatment of women and homosexuals, he asserted that women are respected in Iran and that "In Iran, we don't have homosexuals like in your country... In Iran, we do not have this phenomenon. I don't know who told you this." The latter statement drew laughter from the audience. The Manhattan District Attorney's Office accused Columbia of accepting grant money from the Alavi Foundation to support faculty "sympathetic" to Iran's Islamic republic.
ROTC controversy.
Beginning in 1969, during the Vietnam War, the university did not allow the U.S. military to have Reserve Officers' Training Corps (ROTC) programs on campus, though Columbia students could participate in ROTC programs at other local colleges and universities. At a forum at the university during the 2008 presidential election campaign, both John McCain and Barack Obama said that the university should consider reinstating ROTC on campus. After the debate, the President of the University, Lee C. Bollinger, stated that he did not favor reinstating Columbia's ROTC program, because of the military's anti-gay policies. In November 2008, Columbia's undergraduate student body held a referendum on the question of whether or not to invite ROTC back to campus, and the students who voted were almost evenly divided on the issue. ROTC lost the vote (which would not have been binding on the administration, and did not include graduate students, faculty, or alumni) by a fraction of a percentage point. In April 2010 during Admiral Mike Mullen's address at Columbia, President Lee C. Bollinger stated that the ROTC would be readmitted to campus if the admiral's plans for revoking the don't ask, don't tell policy were successful. In February 2011 during one of three town-hall meetings on the ROTC ban, former Army staff sergeant Anthony Maschek, a purple heart recipient for injuries sustained during his service in Iraq, was booed and hissed at by some students during his speech promoting the idea of allowing the ROTC on campus. In April 2011 the Columbia University Senate voted to welcome the ROTC program back on campus. Secretary of the Navy Ray Mabus and Columbia University President Lee C. Bollinger signed an agreement to reinstate Naval Reserve Officers Training Corps (NROTC) programs at Columbia for the first time in more than 40 years on May 26, 2011. The agreement was signed at a ceremony on board the USS Iwo Jima, docked in New York for the Navy's annual Fleet Week.
Traditions.
Orgo Night.
On the day before the Organic Chemistry exam—which is often on the first day of finals—at precisely the stroke of midnight, the Columbia University Marching Band occupies Butler Library to distract diligent students from studying. After a forty-five minutes or so of jokes and music, the procession then moves out to the lawn in front of Hartley, Wallach and John Jay residence halls to entertain the residents there. The Band then plays at various other locations around Morningside Heights, including the residential quadrangle of Barnard College, where students of the all-women's school, in mock-consternation, rain trash – including notes and course packets – and water balloons upon them from their dormitories above. The Band tends to close their Orgo Night performances before Furnald Hall, known among students as the more studious and reportedly "anti-social" residence hall, where the underclassmen in the Band serenade the graduating seniors with an entertaining, though vulgar, mock-hymn to Columbia, composed of quips that poke fun at the various stereotypes about the Columbia student body.
Tree-Lighting and Yule Log ceremonies.
The campus Tree-Lighting Ceremony is a relatively new tradition at Columbia, inaugurated in 1998. It celebrates the illumination of the medium-sized trees lining College Walk in front of Kent and Hamilton Halls on the east end and Dodge and Journalism Halls on the west, just before finals week in early December. The lights remain on until February 28. Students meet at the sun-dial for free hot chocolate, performances by various "a cappella" groups, and speeches by the university president and a guest.
Immediately following the College Walk festivities is one of Columbia's older holiday traditions, the lighting of the Yule Log. The Christmas ceremony dates to a period prior to the American Revolutionary War, but lapsed before being revived by University President Nicholas Murray Butler in the early 20th century. A troop of students dressed as Continental Army soldiers carry the eponymous log from the sun-dial to the lounge of John Jay Hall, where it is lit amid the singing of seasonal carols. The Christmas ceremony is accompanied by a reading of "A Visit From St. Nicholas" by Clement Clarke Moore and "Yes, Virginia, There is a Santa Claus" by Francis Pharcellus Church.
The Varsity Show.
The Varsity Show is an annual musical written by and for students and was established in 1894, making it one of Columbia's oldest traditions. Past writers and directors have included Columbians Richard Rodgers and Oscar Hammerstein, Lorenz Hart, I.A.L. Diamond, and Herman Wouk. The show has one of the largest operating budgets of all university events.
Notable people.
Three United States Presidents, twenty-six foreign Heads of State, nine Justices of the Supreme Court of the United States (including three Chief Justices) and 43 Nobel Prize winners are alumni of Columbia. Alumni also have received more than 35 National Book Awards and 123 Pulitzer Prizes. Today, two United States Senators and 16 Chief Executives of Fortune 500 companies hold Columbia degrees, as do three of the 25 richest Americans and 20 living billionaires. Attendees of King's College, Columbia's predecessor, included five Founding Fathers.
Former U.S. Presidents Theodore Roosevelt and Franklin Delano Roosevelt attended the law school. Other more recent political figures educated at Columbia include U.S President Barack Obama, Associate Justice of the U.S. Supreme Court Ruth Bader Ginsburg, former U.S. Secretary of State Madeleine Albright, former chairman of the U.S. Federal Reserve Bank Alan Greenspan, U.S. Attorney General Eric Holder, and U.S. Solicitor General Donald Verrilli Jr.. Dwight D. Eisenhower served as the thirteenth president of Columbia University from 1948 to 1953. The university has also educated 26 foreign heads of state, including President of Georgia Mikheil Saakashvili, President of East Timor Jose Ramos Horta, President of Estonia Toomas Hendrik Ilves and other historical figures such as Wellington Koo, Radovan Karadžić, Gaston Eyskens, and T. V. Soong. The author of India's constitution Dr. B. R. Ambedkar was also an alumnus of Columbia. His bust is on display in the Lehman library.
Alumni of Columbia have occupied top positions in Wall Street and the rest of the business world. Notable members of the Astor family attended Columbia, while some recent business graduates include investor Warren Buffett, former CEO of PBS and NBC Larry Grossman, and chairman of Wal-Mart S. Robson Walton. CEO's of top Fortune 500 companies include James P. Gorman of Morgan Stanley, Robert J. Stevens of Lockheed Martin, Philippe Dauman of Viacom, Ursula Burns of Xerox, and Vikram Pandit of Citigroup.
In science and technology, Columbia alumni include: founder of IBM Herman Hollerith; inventor of FM radio Edwin Armstrong; Francis Mechner; integral in development of the nuclear submarine Hyman Rickover; founder of Google China Kai-Fu Lee; scientists Stephen Jay Gould, Robert Millikan, Helium–neon laser inventor Ali Javan and Mihajlo Pupin; chief-engineer of the New York City Subway, William Barclay Parsons; philosophers Irwin Edman and Robert Nozick; and economist Milton Friedman
Many Columbia alumni have gone on to renowned careers in the arts, such as the composers Richard Rodgers, Oscar Hammerstein II, Lorenz Hart, and Art Garfunkel. Four United States Poet Laureates received their degrees from Columbia. Columbia alumni have made an indelible mark in the field of American poetry and literature, with such people as Jack Kerouac and Allen Ginsberg, pioneers of the Beat Generation, and Langston Hughes, a seminal figure in the Harlem Renaissance, both having attended the university. Other notable writers who attended Columbia include authors Isaac Asimov, J.D. Salinger, Upton Sinclair, and the journalist Hunter S. Thompson, primarily known for his works in the American magazine Rolling Stone.
University alumni have also been very prominent in the film industry, with 28 different alumni and former students winning a combined 39 Academy Awards, second in the world only to NYU.
Some notable Columbia alumni that have gone on to work in film include directors Sidney Lumet ("12 Angry Men") and Kathryn Bigelow ("The Hurt Locker"), screenwriters Howard Koch ("Casablanca") and Joseph L. Mankiewicz ("All About Eve"), and actors James Cagney and Ed Harris.

</doc>
<doc id="6312" url="http://en.wikipedia.org/wiki?curid=6312" title="Cell wall">
Cell wall

The cell wall is a very tough, flexible and sometimes fairly rigid layer that surrounds some types of cells. It is located outside the cell membrane and provides these cells with structural support, protection an in addition is acting as a filtering mechanism. A major function of the cell wall is to act as a pressure vessel, preventing over-expansion when water enters the cell. Cell walls are found in plants, fungi and prokaryotic cells but not in mycoplasmas.
The material in the cell wall varies between species, and can also differ depending on cell type and developmental stage. In bacteria, peptidoglycan forms the cell wall. Archaean cell walls have various compositions, and may be formed of glycoprotein S-layers, pseudopeptidoglycan, or polysaccharides. Fungi possess cell walls made of the glucosamine polymer chitin, and algae typically possess walls made of glycoproteins and polysaccharides. Unusually, diatoms have a cell wall composed of biogenic silica. Often, other accessory molecules are found anchored to the cell wall.
Properties.
The cell wall serves a similar purpose in organisms that possess them. The wall gives cells rigidity and strength, offering protection against mechanical stress. In multicellular organisms, it permits the organism to build and hold its shape (morphogenesis). The cell wall also limits the entry of large molecules that may be toxic to the cell. It further permits the creation of a stable osmotic environment by preventing osmotic lysis and helping to retain water. The composition, properties, and form of the cell wall may change during the cell cycle and depend on growth conditions.
Rigidity of cell walls.
The rigidity of the cell walls is often overestimated. In most cells, the cell wall is flexible, meaning that it will bend rather than holding a fixed shape, but has considerable tensile strength. The apparent rigidity of primary plant tissues is enabled by cell walls, but not due to the walls' stiffness. Hydraulic turgor pressure creates this rigidity, along with the wall structure. The flexibility of the cell walls is seen when plants wilt, so that the stems and leaves begin to droop, or in seaweeds that bend in water currents. As John Howland states it:
The rigidity of the cell wall thus results in part from inflation of the cell contained. This inflation is a result of the passive uptake of water.
In plants, a secondary cell wall is a thicker additional layer of cellulose which increases wall rigidity. Additional layers may be formed containing lignin in xylem cell walls, or containing suberin in cork cell walls. These compounds are rigid and waterproof, making the secondary wall stiff. Both wood and bark cells of trees have secondary walls. Other parts of plants such as the leaf stalk may acquire similar reinforcement to resist the strain of physical forces.
Permeability.
The primary cell wall of most plant cells is semi-permeable and permits the passage of small molecules and small proteins, with size exclusion estimated to be 30-60 kDa. Key nutrients, especially water and carbon dioxide, are distributed throughout the plant from cell wall to cell wall in apoplastic flow. The pH is an important factor governing the transport of molecules through cell walls.
Cell wall evolution.
Cell walls evolved independently in many groups, even in the photosynthetic eukaryotes. In these lineages, the cell wall is involved in the evolution of the multicellularity, terrestrialization and vascularization.
Plant cell walls.
The walls of plant cells must have sufficient tensile strength to withstand internal osmotic pressures of several times atmospheric pressure that result from the difference in solute concentration between the cell interior and external water. Plant cell walls vary from 0.1 to several µm in thickness.
Layers.
Up to three strata or layers may be found in plant cell walls:
Composition.
In the primary (growing) plant cell wall, the major carbohydrates are cellulose, hemicellulose and pectin. The cellulose microfibrils are linked via hemicellulosic tethers to form the cellulose-hemicellulose network, which is embedded in the pectin matrix. The most common hemicellulose in the primary cell wall is xyloglucan. In grass cell walls, xyloglucan and pectin are reduced in abundance and partially replaced by glucuronarabinoxylan, another type of hemicellulose. Primary cell walls characteristically extend (grow) by a mechanism called acid growth, which involves turgor-driven movement of the strong cellulose microfibrils within the weaker hemicellulose/pectin matrix, catalyzed by expansin proteins. The outer part of the primary cell wall of the plant epidermis is usually impregnated with cutin and wax, forming a permeability barrier known as the plant cuticle.
Secondary cell walls contain a wide range of additional compounds that modify their mechanical properties and permeability. The major polymers that make up wood (largely secondary cell walls) include:
Additionally, structural proteins (1-5%) are found in most plant cell walls; they are classified as hydroxyproline-rich glycoproteins (HRGP), arabinogalactan proteins (AGP), glycine-rich proteins (GRPs), and proline-rich proteins (PRPs). Each class of glycoprotein is defined by a characteristic, highly repetitive protein sequence. Most are glycosylated, contain hydroxyproline (Hyp) and become cross-linked in the cell wall. These proteins are often concentrated in specialized cells and in cell corners. Cell walls of the epidermis and endodermis may also contain suberin or cutin, two polyester polymers that function as permeability barriers. The relative composition of carbohydrates, secondary compounds and protein varies between plants and between the cell type and age.
Plant cells walls also contain numerous enzymes, such as hydrolases, esterases, peroxidases, and transglycosylases, that cut, trim and cross-link wall polymers.
The walls of cork cells in the bark of trees are impregnated with suberin, and suberin also forms the permeability barrier in primary roots known as the Casparian strip. Secondary walls - especially in grasses - may also contain microscopic silica crystals, which may strengthen the wall and protect it from herbivores.
Cell walls in some plant tissues also function as storage depots for carbohydrates that can be broken down and resorbed to supply the metabolic and growth needs of the plant. For example, endosperm cell walls in the seeds of cereal grasses, nasturtium, and other species, are rich in glucans and other polysaccharides that are readily digested by enzymes during seed germination to form simple sugars that nourish the growing embryo. Cellulose microfibrils are not readily digested by plants, however.
Formation.
The middle lamella is laid down first, formed from the cell plate during cytokinesis, and the primary cell wall is then deposited inside the middle lamella. The actual structure of the cell wall is not clearly defined and several models exist - the covalently linked cross model, the tether model, the diffuse layer model and the stratified layer model. However, the primary cell wall, can be defined as composed of cellulose microfibrils aligned at all angles. Microfibrils are held together by hydrogen bonds to provide a high tensile strength. The cells are held together and share the gelatinous membrane called the "middle lamella", which contains magnesium and calcium pectates (salts of pectic acid). Cells interact though plasmodesma(ta), which are inter-connecting channels of cytoplasm that connect to the protoplasts of adjacent cells across the cell wall.
In some plants and cell types, after a maximum size or point in development has been reached, a "secondary wall" is constructed between the plasma membrane and primary wall. Unlike the primary wall, the microfibrils are aligned mostly in the same direction, and with each additional layer the orientation changes slightly. Cells with secondary cell walls are rigid. Cell to cell communication is possible through pits in the secondary cell wall that allow plasmodesma to connect cells through the secondary cell walls.
Algal cell walls.
Like plants, algae have cell walls. Algal cell walls contain either polysaccharides (such as cellulose (a glucan)) or a variety of glycoproteins (Volvocales) or both. The inclusion of additional polysaccharides in algal cells walls is used as a feature for algal taxonomy.
Other compounds that may accumulate in algal cell walls include sporopollenin and calcium ions.
The group of algae known as the diatoms synthesize their cell walls (also known as frustules or valves) from silicic acid (specifically orthosilicic acid, H4SiO4). The acid is polymerised intra-cellularly, then the wall is extruded to protect the cell. Significantly, relative to the organic cell walls produced by other groups, silica frustules require less energy to synthesize (approximately 8%), potentially a major saving on the overall cell energy budget and possibly an explanation for higher growth rates in diatoms.
In brown algae, phlorotannins may be a constituent of the cell walls.
Fungal cell walls.
There are several groups of organisms that may be called "fungi". Some of these groups have been transferred out of the Kingdom Fungi, in part because of fundamental biochemical differences in the composition of the cell wall. Most true fungi have a cell wall consisting largely of chitin and other polysaccharides. True fungi do not have cellulose in their cell walls.
True fungi.
In fungi, the cell wall is the outer-most layer, external to the plasma membrane. The fungal cell wall is a matrix of three main components:
Cell walls of water and slime molds.
The group Oomycetes, also known as water molds, are saprotrophic plant pathogens like fungi. Until recently they were widely believed to be fungi, but structural and molecular evidence has led to their reclassification as heterokonts, related to autotrophic brown algae and diatoms. Unlike fungi, oomycetes typically possess cell walls of cellulose and glucans rather than chitin, although some genera (such as "Achlya" and "Saprolegnia") do have chitin in their walls. The fraction of cellulose in the walls is no more than 4 to 20%, far less than the fraction of glucans. Oomycete cell walls also contain the amino acid hydroxyproline, which is not found in fungal cell walls.
The dictyostelids are another group formerly classified among the fungi. They are slime molds that feed as unicellular amoebae, but aggregate into a reproductive stalk and sporangium under certain conditions. Cells of the reproductive stalk, as well as the spores formed at the apex, possess a cellulose wall. The spore wall has been shown to possess three layers, the middle of which is composed primarily of cellulose, and the innermost is sensitive to cellulase and pronase.
Prokaryotic cell walls.
Bacterial cell walls.
Around the outside of the cell membrane is the bacterial cell wall. Bacterial cell walls are made of peptidoglycan (also called murein), which is made from polysaccharide chains cross-linked by unusual peptides containing D-amino acids. Bacterial cell walls are different from the cell walls of plants and fungi which are made of cellulose and chitin, respectively. The cell wall of bacteria is also distinct from that of Archaea, which do not contain peptidoglycan. The cell wall is essential to the survival of many bacteria, although L-form bacteria can be produced in the laboratory that lack a cell wall. The antibiotic penicillin is able to kill bacteria by preventing the cross-linking of peptidoglycan and this causes the cell wall to weaken and lyse. The lysozyme enzyme can also damage bacterial cell walls.
There are broadly speaking two different types of cell wall in bacteria, called Gram-positive and Gram-negative. The names originate from the reaction of cells to the Gram stain, a test long-employed for the classification of bacterial species.
Gram-positive bacteria possess a thick cell wall containing many layers of peptidoglycan and teichoic acids. In contrast, Gram-negative bacteria have a relatively thin cell wall consisting of a few layers of peptidoglycan surrounded by a second lipid membrane containing lipopolysaccharides and lipoproteins. Most bacteria have the Gram-negative cell wall and only the Firmicutes and Actinobacteria (previously known as the low G+C and high G+C Gram-positive bacteria, respectively) have the alternative Gram-positive arrangement. These differences in structure can produce differences in antibiotic susceptibility, for instance vancomycin can kill only Gram-positive bacteria and is ineffective against Gram-negative pathogens, such as "Haemophilus influenzae" or "Pseudomonas aeruginosa".
Archaeal cell walls.
Although not truly unique, the cell walls of Archaea are unusual. Whereas peptidoglycan is a standard component of all bacterial cell walls, all archaeal cell walls lack peptidoglycan, with the exception of one group of methanogens. In that group, the peptidoglycan is a modified form very different from the kind found in bacteria. There are four types of cell wall currently known among the Archaea.
One type of archaeal cell wall is that composed of pseudopeptidoglycan (also called pseudomurein). This type of wall is found in some methanogens, such as "Methanobacterium" and "Methanothermus". While the overall structure of archaeal "pseudo"peptidoglycan superficially resembles that of bacterial peptidoglycan, there are a number of significant chemical differences. Like the peptidoglycan found in bacterial cell walls, pseudopeptidoglycan consists of polymer chains of glycan cross-linked by short peptide connections. However, unlike peptidoglycan, the sugar N-acetylmuramic acid is replaced by N-acetyltalosaminuronic acid, and the two sugars are bonded with a "β",1-3 glycosidic linkage instead of "β",1-4. Additionally, the cross-linking peptides are L-amino acids rather than D-amino acids as they are in bacteria.
A second type of archaeal cell wall is found in "Methanosarcina" and "Halococcus". This type of cell wall is composed entirely of a thick layer of polysaccharides, which may be sulfated in the case of "Halococcus". Structure in this type of wall is complex and as yet is not fully investigated.
A third type of wall among the Archaea consists of glycoprotein, and occurs in the hyperthermophiles, "Halobacterium", and some methanogens. In "Halobacterium", the proteins in the wall have a high content of acidic amino acids, giving the wall an overall negative charge. The result is an unstable structure that is stabilized by the presence of large quantities of positive sodium ions that neutralize the charge. Consequently, "Halobacterium" thrives only under conditions with high salinity.
In other Archaea, such as "Methanomicrobium" and "Desulfurococcus", the wall may be composed only of surface-layer proteins, known as an "S-layer". S-layers are common in bacteria, where they serve as either the sole cell-wall component or an outer layer in conjunction with polysaccharides. Most Archaea are Gram-negative, though at least one Gram-positive member is known.
Other cell coverings.
Many protists and bacteria produce other cell surface structures apart from cell walls, external (extracellular matrix) or internal. Many algae have a sheath or envelope of mucilage outside the cell made of exopolysaccharides. Diatoms build a frustule from silica extracted from the surrounding water; radiolarians, foraminiferans, testate amoebae and silicoflagellates also produce a skeleton from minerals, called test in some groups. Many green algae, such as "Halimeda" and the Dasycladales, and some red algae, the Corallinales, encase their cells in a secreted skeleton of calcium carbonate. In each case, the wall is rigid and essentially inorganic. It is the non-living component of cell. Some golden algae, ciliates and choanoflagellates produces a shell-like protective outer covering called lorica. Some dinoflagellates have a theca of cellulose plates, and coccolithophoridss have coccoliths.
An extracellular matrix is also present in metazoans, and its composition varies between cells.

</doc>
<doc id="6313" url="http://en.wikipedia.org/wiki?curid=6313" title="Classical element">
Classical element

Many philosophies and worldviews have a set of classical elements believed to reflect the simplest essential parts and principles of which anything can consist or upon which the constitution and fundamental powers of everything are based. Most frequently, "classical elements" refer to ancient concepts which some science writers compare to the modern states of matter, relating earth to the solid state, water to liquid, air to gaseous and fire to plasma. Historians trace the evolution of modern theory pertaining to the chemical elements, as well as chemical compounds and mixtures of chemical substances to medieval, and Greek models. Many concepts once thought to be analogous, such as the Chinese Wu Xing, are now understood more figuratively.
Ancient.
In classical thought, the four elements earth (γῆ), water (ὕδωρ), air (ἀήρ), and fire (πῦρ) frequently occur; sometimes including a fifth element or "quintessence" (after "quint" meaning "fifth") called aether (αἰθήρ) in ancient Greece and "akasha" in India. The concept of the five elements formed a basis of analysis in both Hinduism and Buddhism. In Hinduism, particularly in an esoteric context, the four states-of-matter describe matter, and a fifth element describes that which was beyond the material world. Similar lists existed in ancient China and Japan. In Buddhism the four great elements, to which two others are sometimes added, are not viewed as substances, but as categories of sensory experience.
Cosmic elements in Babylonia.
In Babylonian mythology, the cosmogony called "Enûma Eliš", a text written between the 18th and 16th centuries BC, involves five gods that we might see as personified cosmic elements: sea, earth, sky, wind. In other Babylonian texts these phenomena are considered independent of their association with deities, though they are not treated as the component elements of the universe, as later in Empedocles.
Greece.
The ancient Greek belief in five basic elements, these being earth (γῆ), water (ὕδωρ), air (ἀήρ), fire (πῦρ) and aether (αἰθήρ), dates from pre-Socratic times and persisted throughout the Middle Ages and into the Renaissance, deeply influencing European thought and culture. These five elements are sometimes associated with the five platonic solids.
Plato characterizes the elements as being pre-Socratic in origin from a list created by the Sicilian philosopher Empedocles (ca. 450 BC). Empedocles called these the four "roots" (ῥιζὤματα, rhizōmata). Plato seems to have been the first to use the term "element (στοιχεῖον, "stoicheion")" in reference to air, fire, earth, and water. The ancient Greek word for element, "stoicheion" (from "stoicheo", "to line up") meant "smallest division (of a sun-dial), a syllable", as the composing unit of an alphabet it could denote a letter and the smallest unit from which a word is formed.
In his "On Generation and Corruption", Aristotle related each of the four elements to two of the four sensible qualities:
One classic diagram (above) has one square inscribed in the other, with the corners of one being the classical elements, and the corners of the other being the properties. The opposite corner is the opposite of these properties, "hot – cold" and "dry – wet".
Aristotle added a fifth element, aether, as the quintessence, reasoning that whereas fire, earth, air, and water were earthly and corruptible, since no changes had been perceived in the heavenly regions, the stars cannot be made out of any of the four elements but must be made of a different, unchangeable, heavenly substance.
The Neoplatonic philosopher, Proclus, rejected Aristotle's theory relating the elements to the sensible qualities hot, cold, wet, and dry. He maintained that each of the elements has three properties. Fire is sharp, subtle, and mobile while its opposite, earth, is blunt, dense, and immobile; they are joined by the intermediate elements, air and water, in the following fashion:
Medieval alchemy.
The elemental system used in Medieval alchemy was developed primarily by the Persian alchemist Jābir ibn Hayyān and rooted in the classical elements of Greek tradition. His system consisted of the four Aristotelian elements of air, earth, fire, and water in addition to two philosophical elements: sulphur, characterizing the principle of combustibility, "the stone which burns"; and mercury, characterizing the principle of metallic properties. They were seen by early alchemists as idealized expressions of irreducibile components of the universe and are of larger consideration within philosophical alchemy.
The three metallic principles—sulphur to flammability or combustion, mercury to volatility and stability, and salt to solidity—became the "tria prima" of the Swiss alchemist Paracelsus. He reasoned that Aristotle’s four element theory appeared in bodies as three principles. Paracelsus saw these principles as fundamental and justified them by recourse to the description of how wood burns in fire. Mercury included the cohesive principle, so that when it left in smoke the wood fell apart. Smoke described the volatility (the mercurial principle), the heat-giving flames described flammability (sulphur), and the remnant ash described solidity (salt).
Egypt.
A Greek text called the "Kore Kosmou" ("Virgin of the World") ascribed to Hermes Trismegistus (the name given by the Greeks to the Egyptian god Thoth), names the four elements fire, water, air, and earth. As described in this book:
And Isis answer made: Of living things, my son, some are made friends with "fire", and some with "water", some with "air", and some with "earth", and some with two or three of these, and some with all. And, on the contrary, again some are made enemies of fire, and some of water, some of earth, and some of air, and some of two of them, and some of three, and some of all. For instance, son, the locust and all flies flee fire; the eagle and the hawk and all high-flying birds flee water; fish, air and earth; the snake avoids the open air. Whereas snakes and all creeping things love earth; all swimming things love water; winged things, air, of which they are the citizens; while those that fly still higher love the fire and have the habitat near it. Not that some of the animals as well do not love fire; for instance salamanders, for they even have their homes in it. It is because one or another of the elements doth form their bodies' outer envelope. Each soul, accordingly, while it is in its body is weighted and constricted by these four.
According to Galen, these elements were used by Hippocrates in describing the human body with an association with the four humours: yellow bile (fire), black bile (earth), blood (air), and phlegm (water).
India.
Hinduism.
The system of five elements are found in Vedas, especially Ayurveda, the "pancha mahabhuta," or "five great elements", of Hinduism are "bhūmi" (earth), "ap" or "jala" (water), "tejas" or "agni" (fire), "marut" or "pavan" (air or wind), "vyom"; or "shunya" or "akash" (aether or void). They further suggest that all of creation, including the human body, is made up of these five essential elements and that upon death, the human body dissolves into these five elements of nature, thereby balancing the cycle of nature.
According to one of the principal texts of Hindu philosophy, the "Tattwa Kaumudi" authored by Vacaspati in the 9th century A.D., the Creator used akasha (aether), the most "subtle" element, to create the other four traditional elements; each element created is in turn used to create the next element, each less subtle than the last. The five elements are associated with the five senses, and act as the gross medium for the experience of sensations. The basest element, earth, created using all the other elements, can be perceived by all five senses – hearing, touch, sight, taste, and smell. The next higher element, water, has no odor but can be heard, felt, seen and tasted. Next comes fire, which can be heard, felt and seen. Air can be heard and felt. "Akasha" (aether) is the medium of sound but is inaccessible to all other senses.http://r.weavesilk.com/?v=4&id=jvpr5daxmn
Buddhism.
In the Pali literature, the "mahabhuta" ("great elements") or "catudhatu" ("four elements") are earth, water, fire and air. In early Buddhism, the four elements are a basis for understanding suffering and for liberating oneself from suffering. The earliest Buddhist texts explain that the four primary material elements are the sensory qualities solidity, fluidity, temperature, and mobility; their characterization as earth, water, fire, and air, respectively, is declared an abstractioninstead of concentrating on the fact of material existence, one observes how a physical thing is sensed, felt, perceived.
The Buddha's teaching regarding the four elements is to be understood as the base of all observation of real sensations rather than as a philosophy. The four properties are cohesion (water), solidity or inertia (earth), expansion or vibration (air) and heat or energy content (fire). He promulgated a categorization of mind and matter as composed of eight types of "kalapas" of which the four elements are primary and a secondary group of four are color, smell, taste, and nutriment which are derivative from the four primaries.
Thanissaro Bhikkhu (1997) renders an extract of Shakyamuni Buddha's from Pali into English thus:
Seven chakras.
In the philosophy of the seven chakras there are correspondences to the five elements as shared by both Hinduism and Buddhism as well as two other elements:
Indian medical literature is mentioned about Panch Mahābhūta.
Tibet.
In Bön or ancient Tibetan philosophy, the five elemental processes of earth, water, fire, air and space are the essential materials of all existent phenomena or aggregates. The elemental processes form the basis of the calendar, astrology, medicine, psychology and are the foundation of the spiritual traditions of shamanism, tantra and Dzogchen.
Tenzin Wangyal Rinpoche states that
The names of the elements are analogous to categorised experiential sensations of the natural world. The names are symbolic and key to their inherent qualities and/or modes of action by analogy. In Bön the elemental processes are fundamental metaphors for working with external, internal and secret energetic forces. All five elemental processes in their essential purity are inherent in the mindstream and link the trikaya and are aspects of primordial energy. As Herbert V. Günther states:
In the above block quote the trikaya is encoded as: dharmakaya "god"; sambhogakaya "temple" and nirmanakaya "house".
China.
The Chinese had a somewhat different series of elements, namely Fire, Earth, Metal (literally gold), Water and Wood, which were understood as different types of energy in a state of constant interaction and flux with one another, rather than the Western notion of different kinds of material.
Although it is usually translated as "element", the Chinese word "xing" literally means something like "changing states of being", "permutations" or "metamorphoses of being". In fact Sinologists cannot agree on any single translation. The Chinese elements were seen as ever changing and movingone translation of "wu xing" is simply "the five changes".
The Wu Xing are chiefly an ancient mnemonic device for systems with five stages; hence the preferred translation of "movements", "phases" or "steps" over "elements."
In the bagua, metal is associated with the divination figure 兌 "Duì" (☱, the lake or marsh: 澤/泽 "zé") and with 乾 "Qián" (☰, the sky or heavens: 天 "tiān"). Wood is associated with 巽 "Xùn" (☴, the wind: 風/风 "fēng") and with 震 "Zhèn" (☳, the arousing/thunder: 雷 "léi"). In view of the durability of meteoric iron, metal came to be associated with the aether, which is sometimes conflated with Stoic pneuma, as both terms originally referred to air (the former being higher, brighter, more fiery or celestial and the latter being merely warmer, and thus vital or biogenetic). In Taoism, "qi" functions similarly to pneuma in a prime matter (a basic principle of energetic transformation) that accounts for both biological and inanimate phenomena.
In Chinese philosophy the universe consists of heaven and earth. The five major planets are associated with and even named after the elements: Jupiter 木星 is Wood (木), Mars 火星 is Fire (火), Saturn 土星 is Earth (土), Venus 金星 is Metal (金), and Mercury 水星 is Water (水). Also, the Moon represents Yin (陰), and the Sun 太陽 represents Yang (陽). Yin, Yang, and the five elements are associated with themes in the I Ching, the oldest of Chinese classical texts which describes an ancient system of cosmology and philosophy. The five elements also play an important part in Chinese astrology and the Chinese form of geomancy known as Feng shui.
The doctrine of five phases describes two cycles of balance, a generating or creation (生, shēng) cycle and an overcoming or destruction (克/剋, kè) cycle of interactions between the phases.
"Generating"
"Overcoming"
There are also two cycles of imbalance, an overacting cycle (cheng) and an insulting cycle (wu).
Japan.
Japanese traditions use a set of elements called the ("godai", literally "five great"). These five are earth, water, fire, wind/air, and void. These came from Indian Vastu shastra philosophy and Buddhist beliefs; in addition, the classical Chinese elements (, "wu xing") are also prominent in Japanese culture, especially to the influential Neo-Confucianists during the Edo period.
Western astrology and tarot.
Western astrology uses the four classical elements in connection with astrological charts and horoscopes. The twelve signs of the zodiac are divided into the four elements: Fire signs are Aries, Leo and Sagittarius, Earth signs are Taurus, Virgo and Capricorn, Air signs are Gemini, Libra and Aquarius, and Water signs are Cancer, Scorpio, and Pisces.
In divinatory tarot, the suits of cups, swords, batons/wands, and discs/coins are said to correspond to water, air, fire, and earth respectively.
Modern.
The Aristotelian tradition and medieval Alchemy eventually gave rise to modern scientific theories and new taxonomies. By the time of Antoine Lavoisier, for example, a list of elements would no longer refer to classical elements. The classical elements correspond more closely to four of the states of matter: solid, liquid, gas and plasma.
Modern science recognizes classes of elementary particles which have no substructure (or rather, particles that are not made of other particles) and composite particles having substructure (particles made of other particles).

</doc>
<doc id="6314" url="http://en.wikipedia.org/wiki?curid=6314" title="Fire (classical element)">
Fire (classical element)

Fire has been an important part of all cultures and religions from pre-history to modern day and was vital to the development of civilization. It has been regarded in many different contexts throughout history, but especially as a metaphysical constant of the world.
Greek and Roman tradition.
Fire is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with the qualities of energy, assertiveness, and passion. In one Greek myth, Prometheus stole "fire" from the gods to protect the otherwise helpless humans, but was punished for this charity.
Fire was one of many "archai" proposed by the Pre-socratics, most of whom sought to reduce the cosmos, or its creation, by a single substance. Heraclitus considered "fire" to be the most fundamental of all elements. He believed fire gave rise to the other three elements: "All things are an interchange for fire, and fire for all things, just like goods for gold and gold for goods." He had a reputation for obscure philosophical principles and for speaking in riddles. He described how fire gave rise to the other elements as the: "upward-downward path", (), a "hidden harmony"  or series of transformations he called the "turnings of fire", (), first into "sea", and half that "sea" into "earth", and half that "earth" into rarefied "air". This is a concept that anticipates both the four classical elements of Empedocles and Aristotle's transmutation of the four elements into one another.
This world, which is the same for all, no one of gods or men has made. But it always was and will be: an ever-living fire, with measures of it kindling, and measures going out. 
Heraclitus regarded the soul as being a mixture of fire and water, with fire being the more noble part and water the ignoble aspect. He believed the goal of the soul is to be rid of water and become pure fire: the dry soul is the best and it is worldly pleasures that make the soul "moist". He was known as the "weeping philosopher" and died of hydropsy, a swelling due to abnormal accumulation of fluid beneath the skin.
However, Empedocles of Acragas , is best known for having selected all elements as his "archai" and by the time of Plato , the four Empedoclian elements were well established. In the "Timaeus", Plato's major cosmological dialogue, the Platonic solid he associated with fire was the tetrahedron which is formed from four triangles and contains the least volume with the greatest surface area. This also makes fire the element with the smallest number of sides, and Plato regarded it as appropriate for the heat of fire, which he felt is sharp and stabbing, (like one of the points of a tetrahedron).
Plato’s student Aristotle did not maintain his former teacher's geometric view of the elements, but rather preferred a somewhat more naturalistic explanation for the elements based on their traditional qualities. Fire the hot and dry element, like the other elements, was an abstract principle and not identical with the normal solids, liquids and combustion phenomena we experience:
 What we commonly call fire. It is not really fire, for fire is an excess of heat and a sort of ebullition; but in reality, of what we call air, the part surrounding the earth is moist and warm, because it contains both vapour and a dry exhalation from the earth.
According to Aristotle, the four elements rise or fall toward their natural place in concentric layers surrounding the center of the earth and form the terrestrial or sublunary spheres.
In ancient Greek medicine, each of the four humours became associated with an element. Yellow bile was the humor identified with fire, since both were hot and dry. Other things associated with fire and yellow bile in ancient and medieval medicine included the season of summer, since it increased the qualities of heat and aridity; the choleric temperament (of a person dominated by the yellow bile humour); the masculine; and the eastern point of the compass.
In alchemy the chemical element of sulfur was often associated with fire and its alchemical symbol and its symbol was an upward-pointing triangle. In alchemic tradition, metals are incubated by fire in the womb of the Earth and alchemists only accelerate their development.
Indian tradition.
Agni is a Hindu and Vedic deity. The word "agni" is Sanskrit for fire (noun), cognate with Latin "ignis" (the root of English "ignite"), Russian "огонь" (fire), pronounced "agon". Agni has three forms: fire, lightning and the sun.
Agni is one of the most important of the Vedic gods. He is the god of fire and the acceptor of sacrifices. The sacrifices made to Agni go to the deities because Agni is a messenger from and to the other gods. He is ever-young, because the fire is re-lit every day, yet he is also immortal. In Indian tradition Fire is also linked to Surya or the Sun and Mangala or Mars, and with the south-east direction.
Astrological personalities.
People born under the astrological signs of Aries, Leo and Sagittarius are thought to have dominant fire personalities. Fire personalities are believed to have good leading qualities and also tend to be enthusiastic, extroverted, rebellious, passionate, brave and valiant; however, they can also be hot-tempered, snappy, uncontrollable and angry.
Ceremonial magic.
Fire and the other Greek classical elements were incorporated into the Golden Dawn system. Philosophus (4=7) is the elemental grade attributed to fire; this grade is also attributed to the Qabalistic Sephirah Netzach and the planet Venus. The elemental weapon of fire is the Wand. Each of the elements has several associated spiritual beings. The archangel of fire is Michael, the angel is Aral, the ruler is Seraph, the king is Djin, and the fire elementals (following Paracelsus) are called salamanders. Fire is considered to be active; it is represented by the symbol for Leo and it is referred to the lower right point of the pentacle in the Supreme Invoking Ritual of the Pentacle. Many of these associations have since spread throughout the occult community.
Tarot.
Fire in Tarot symbolizes conversion or passion. Many references to fire in tarot are related to the usage of fire in the practice of alchemy, in which the application of fire is a prime method of conversion, and everything that touches fire is changed, often beyond recognition. The symbol of fire was a cue pointing towards transformation, the chemical variant being the symbol delta, which is also the classical symbol for fire. Conversion symbolized can be good, for example, refining raw crudities to gold, as seen in The Devil. Conversion can also be bad, as in The Tower, symbolizing a downfall due to anger. Fire is associated with the suit of rods/wands, and as such, represents passion from inspiration. As an element, fire has mixed symbolism because it represents energy, which can be helpful when controlled, but volatile if left unchecked.
Modern witchcraft.
Fire is one of the five elements that appear in most Wiccan traditions influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn.
Freemasonry and other traditions.
The element of fire shows up in mythological stories all across the world, often in stories related to the sun.
In East Asia fire is represented by the Vermilion Bird, known as 朱雀 ("Zhū Què") in Chinese, "Suzaku" in Japanese and Ju-jak (주작, Hanja:朱雀) in Korean. "Fire" is represented in the Aztec religion by a flint; to the Native Americans, a mouse; to the Hindu and Islamic faiths, a lightning bolt; to the Scythians, an axe, to the Greeks, an apple-bough; and in Christian iconography, lions and ravens.
In freemasonry, fire is present, for example, during the ceremony of winter solstice, a symbol also of renaissance and energy. Freemasonry takes the ancient symbolic meaning of fire and recognizes its double nature: creation, light, on the one hand, and destruction and purification, on the other.

</doc>
<doc id="6315" url="http://en.wikipedia.org/wiki?curid=6315" title="Air (classical element)">
Air (classical element)

Air is often seen as a universal power or pure substance. Its supposed fundamental importance to life can be seen in words such as "aspire", "inspire", "perspire" and "spirit", all derived from the Latin "spirare".
Greek and Roman tradition.
Air is one of the four classical elements in ancient Greek philosophy and science. According to Plato, it is associated with the octahedron; air is considered to be both hot and wet. The ancient Greeks used two words for air: "aer" meant the dim lower atmosphere, and "aether" meant the bright upper atmosphere above the clouds. Plato, for instance writes that "So it is with air: there is the brightest variety which we call "aether", the muddiest which we call mist and darkness, and other kinds for which we have no name..." Among the early Greek Pre-Socratic philosophers, Anaximenes (mid-6th century BCE) named air as the "arche". A similar belief was attributed by some ancient sources to Diogenes Apolloniates (late 5th century BCE), who also linked air with intelligence and soul ("psyche"), but other sources claim that his "arche" was a substance between air and fire. Aristophanes parodied such teachings in his play "The Clouds" by putting a prayer to air in the mouth of Socrates.
Air was one of many "archai" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495-c. 435 BCE) selected four "archai" for his four roots: Air, fire, water, and earth. Ancient and modern opinions differ as to whether he identified air by the divine name Hera, Aidoneus or even Zeus. Empedocles’ roots became the four classical elements of Greek philosophy. Plato (427-347 BCE) took over the four elements of Empedocles. In the "Timaeus", his major cosmological dialogue, the Platonic solid associated with air is the octahedron which is formed from eight equilateral triangles. This places air between fire and water which Plato regarded as appropriate because it is intermediate in its mobility, sharpness, and ability to penetrate. He also said of air that its minuscule components are so smooth that one can barely feel them.
Plato's student Aristotle (384-322 BCE) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the universe to form the sublunary sphere. According to Aristotle, air is both hot and wet and occupies a place between fire and water among the elemental spheres. Aristotle definitively separated air from aether. For him, aether was an unchanging, almost divine substance that was found only in the heavens, where it formed celestial spheres.
In ancient Greek medicine, each of the four humours became associated with an element. Blood was the humor identified with air, since both were hot and wet. Other things associated with air and blood in ancient and medieval medicine included the season of spring, since it increased the qualities of heat and moisture; the sanguine temperament (of a person dominated by the blood humour); hermaphrodite (combining the masculine quality of heat with the feminine quality of moisture); and the northern point of the compass.
The alchemical symbol for air is an upward-pointing triangle, bisected by a horizontal line.
Indian tradition.
In Hinduism, Vayu (Sanskrit वायु ), "also known as" Vāta वात, Pavana पवन (meaning the Purifier), or Prāna, is a primary deity, who is the father of Bhima and the spiritual father of Lord Hanuman. As the words for air (Vāyu) or wind (Pavana) it is one of the "Panchamahābhuta" the "five great elements" in Hinduism. The Sanskrit word 'Vāta' literally means "blown", 'Vāyu' "blower", and 'Prāna' "breathing" (viz. the breath of life, cf. the *an- in 'animate').
Chinese tradition.
Air is not one of the traditional five Chinese classical elements. Nevertheless, the ancient Chinese concept of "Qi" or "chi" is believed to be close to that of air. Qi (; spelled "qì" in Pinyin romanization and "ch'i4" in Wade-Giles) or ki (in Japanese romanization), is a fundamental concept of traditional Chinese culture. Qi is believed to be part of every living thing that exists, as a kind of "life force" or "spiritual energy". It is frequently translated as "energy flow", or literally as "air" or "breath". (For example, "tiānqì", literally "sky breath", is the ordinary Chinese word for "weather"). In Mandarin Chinese it is pronounced something like "chee" in English, but the tongue position is different. (See .) The concept of qi is often reified, however no scientific evidence supports its existence.
The element air also appears as a concept in the Buddhist religion which has an ancient history in China.
Some Western modern occultists equate the Chinese classical element of metal with "air", others with wood due to the elemental association of wind and wood in the bagua.
Astrological personalities.
People born under the astrological signs of Gemini, Libra and Aquarius are thought to have dominant air personalities. Air personalities tend to be kind, intellectual, communicative and social; however, they can also be selfish, superficial, vicious and insensitive to other people's emotions.
Ceremonial magic.
The Hermetic Order of the Golden Dawn, founded in 1888, incorporates air and the other Greek classical elements into its teachings. The elemental weapon of air is the dagger which must be painted yellow with magical names and sigils written upon it in violet. Each of the elements has several associated spiritual beings. The archangel of air is Raphael, the angel is Chassan, the ruler is Aral, the king is Paralda, and the air elementals (following Paracelsus) are called sylphs. Air is considerable and it is referred to the upper left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.
In the Golden Dawn and many other magical systems, each element is associated with one of the cardinal points and is placed under the care of guardian Watchtowers. The Watchtowers derive from the Enochian system of magic founded by Dee. In the Golden Dawn, they are represented by the Enochian elemental tablets. Air is associated with the east, which is guarded by the First Watchtower.
Modern witchcraft.
Air is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism.
Other traditions.
Enlil was the god of air in ancient Sumer. Shu was the ancient Egyptian god of air and the husband of Tefnut, goddess of moisture. He became an emblem of strength by virtue of his role in separating Nut from Geb. He played a primary role in the Coffin Texts, which were spells intended to help the deceased reach the realm of the afterlife safely. On the way to the sky, the spirit had to travel through the air as one spell indicates: "I have gone up in Shu, I have climbed on the sunbeams."
In East Asia, air is seen as the equivalent of wood. Air is represented in the Aztec religion by a snake to the Scythians, a yoke to the Hindus and for Greeks as a sword and in Christian iconography as mankind.

</doc>
<doc id="6316" url="http://en.wikipedia.org/wiki?curid=6316" title="Water (classical element)">
Water (classical element)

Water is one of the elements in ancient Greek philosophy, in the Asian Indian system "Panchamahabhuta", and in the Chinese cosmological and physiological system "Wu Xing". In contemporary esoteric traditions, it is commonly associated with the qualities of emotion and intuition.
Greek and Roman tradition.
Water was one of many "archai" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495-c. 435 BC) selected four archai for his four roots: air, fire, water and earth. Empedocles roots became the four classical elements of Greek philosophy. Plato (427-347 BC) took over the four elements of Empedocles. In the Timaeus, his major cosmological dialogue, the Platonic solid associated with water is the icosahedron which is formed from twenty equilateral triangles. This makes water the element with the greatest number of sides, which Plato regarded as appropriate because water flows out of one's hand when picked up, as if it is made of tiny little balls. 
Plato’s student Aristotle (384-322 BC) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the Universe to form the sublunary sphere. According to Aristotle, water is both cold and wet and occupies a place between air and earth among the elemental spheres.
In ancient Greek medicine, each of the four humours became associated with an element. Phlegm was the humor identified with water, since both were cold and wet. Other things associated with water and phlegm in ancient and medieval medicine included the season of Winter, since it increased the qualities of cold and moisture; the phlegmatic temperament, the feminine, the brain and the western point of the compass.
In alchemy, the chemical element of mercury was often associated with water and its alchemical symbol was a downward-pointing triangle.
Indian tradition.
Ap (') is the Vedic Sanskrit term for water, in Classical Sanskrit occurring only in the plural is not an element.v, ' (sometimes re-analysed as a thematic singular, '), whence Hindi '. The term is from PIE "hxap" water.
In Hindu philosophy, the term refers to 
water as an element, one of the "Panchamahabhuta," or "five great elements". In Hinduism, it is also the name of the deva, a personification of water, (one of the Vasus in most later Puranic lists). The element water is also associated with Chandra or the moon and Shukra, who represent feelings, intuition and imagination.
Astrological personalities.
People born under the astrological signs of Cancer, Scorpio and Pisces are thought to have dominant water personalities. Water personalities tend to be emotional, deep, nurturing, sympathetic, empathetic, imaginative and intuitive; however, they can also be cold, moody, sentimental, sensitive, escapistic, irrational and jealous.
Ceremonial magic.
Water and the other Greek classical elements were incorporated into the Golden Dawn system. The elemental weapon of water is the cup. Each of the elements has several associated spiritual beings. The archangel of water is Gabriel, the angel is Taliahad, the ruler is Tharsis, the king is Nichsa and the water elementals are called Ondines. It is referred to the upper right point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.
Modern witchcraft.
Water is one of the five elements that appear in most Wiccan traditions. Wicca in particular was influenced by the Golden Dawn system of magic and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn.

</doc>
<doc id="6317" url="http://en.wikipedia.org/wiki?curid=6317" title="Earth (classical element)">
Earth (classical element)

Earth is one of the classical elements, in some systems numbering four along with air, fire, and water.
European tradition.
Earth is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with qualities of heaviness, matter and the terrestrial world. Due to the hero cults, and chthonic underworld deities, the element of "earth" is also associated with the sensual aspects of both life and death in later occultism.
Empedocles of Acragas proposed four "archai" by which to understand the cosmos: "fire"," air", "water", and "earth". Plato believed the elements were geometric forms (the platonic solids) and he assigned the cube to the element of "earth" in his dialogue "Timaeus". Aristotle, (384–322 BCE), believed "earth" was the heaviest element, and his theory of "natural place" suggested that any "earth–laden" substances, would fall quickly, straight down, toward the center of the "cosmos".
In Classical Greek and Roman myth, various goddesses represented the Earth, seasons, crops and fertility, including Demeter and Persephone; Ceres; the Horae (goddesses of the seasons), and Proserpina; and Hades (Pluto) who ruled the souls of dead in the Underworld.
In ancient Greek medicine, each of the four humours became associated with an element. Black bile was the humor identified with earth, since both were cold and dry. Other things associated with earth and black bile in ancient and medieval medicine included the season of fall, since it increased the qualities of cold and aridity; the melancholic temperament (of a person dominated by the black bile humour); the feminine; and the southern point of the compass.
In alchemy, earth was believed to be primarily cold, and secondarily dry, (as per Aristotle). Beyond those classical attributes, the chemical substance salt, was associated with earth and its alchemical symbol was a downward-pointing triangle, bisected by a horizontal line.
Indian tradition.
Prithvi (Sanskrit: ', also ') is the Hindu "earth" and mother goddess. According to one such tradition, she is the personification of the Earth itself; according to another, its actual mother, being "Prithvi Tattwa", the essence of the element earth.
As "Prithvi Mata", or "Mother Earth", she contrasts with "Dyaus Pita", "father sky". In the Rigveda, "earth" and sky are frequently addressed as a duality, often indicated by the idea of two complementary "half-shells." In addition, the element Earth is associated with Budha or Mercury who represents communication, business, mathematics and other practical matters.
Astrological personalities.
People born under the astrological signs of Taurus, Virgo and Capricorn are thought to have dominant earth personalities. Earth personalities are characterized in this belief system as calm, practical, hard-working, brave, smart, wise, stable and patient; however, they can also be stubborn, possessive, nearsighted and harsh.
Ceremonial magic.
Earth and the other Greek classical elements were incorporated into the Golden Dawn system. Zelator is the elemental grade attributed to earth; this grade is also attributed to the Qabalistic sphere Malkuth. The elemental weapon of earth is the Pentacle. Each of the elements has several associated spiritual beings. The archangel of earth is Uriel, the angel is Phorlakh, the ruler is Kerub, the king is Ghob, and the earth elementals (following Paracelsus) are called gnomes. Earth is considered to be passive; it is represented by the symbol for Taurus, and it is referred to the lower left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.
It is sometimes represented by its Tattva or by a downward pointing triangle with a horizontal line through it.
Modern witchcraft.
Earth is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism which was in turn inspired by the Golden Dawn.
Other traditions.
In East Asia, metal is sometimes seen as the equivalent of "earth" and is represented by the White Tiger (Chinese constellation), known as 白虎 ("Bái Hǔ") in Chinese, "Byakko" in Japanese, "Bạch Hổ" in Vietnamese and "Baekho" (백호, Hanja:白虎) in Korean. "Earth" is represented in the Aztec religion by a house; to the Hindus, a lotus; to the Scythians, a plough; to the Greeks, a wheel; and in Christian iconography; bulls and birds.

</doc>
<doc id="6319" url="http://en.wikipedia.org/wiki?curid=6319" title="Blue Jam">
Blue Jam

Blue Jam was an ambient radio comedy programme created and directed by Chris Morris. It aired on BBC Radio 1 in the early hours of the morning from 1997 to 1999.
The programme gained cult status due to its unique mix of surreal monologue, music, synthesised voices, heavily edited broadcasts and recurring sketches. It featured the vocal talents of Kevin Eldon, Julia Davis, Mark Heap, David Cann and Amelia Bullmore. Morris himself delivered disturbing monologues, one of which was revamped and made into the BAFTA-winning short film, "My Wrongs #8245–8249 & 117".
Writers who contributed to the programme included Graham Linehan, Arthur Mathews, Peter Baynham, David Quantick, Jane Bussmann, Robert Katz and the cast.
Format and style.
Each episode opened (and closed) with a short spoken introduction (delivered by Morris) describing, in surreal, broken language, various bizarre feelings and situations, set to ambient music interspersed with short clips of other songs.
Radio stings.
Morris included a series of 'radio stings', bizarre sequences of sounds and prose as a parody of modern DJs' own soundbites and self-advertising pieces. Each one revolves around a contemporary DJ, such as Chris Moyles, Jo Whiley and Mark Goodier.
Broadcasts.
All episodes were originally broadcast on BBC Radio 1 between November 1997 to February 1999. Original broadcasts per series, one episode per week, with each having six episodes:
The first five episodes of series 1 of "Blue Jam" was repeated by BBC Radio 4 Extra between February and March 2014.
Derivative shows.
"Blue Jam" was later made for television and broadcast on Channel 4 as "Jam". It utilised unusual editing techniques to achieve an unnerving ambience in keeping with the radio show. Many of the sketches were lifted from the radio version, even to the extent of simply setting images to the radio soundtrack. A subsequent "re-mixed" airing, called "Jaaaaam" was even more extreme in its use of post-production gadgetry, often heavily distorting the footage.
In place of closing credits the show had the website address of jamcredits.com 
"Blue Jam" shares parallels with early editions of a US public radio show "Work in Progress" from the mid-1980s, that Joe Frank did on the NPR affiliate station, KCRW, in Santa Monica, California.
Blue Jam CD.
A CD of some of the best "Blue Jam" sketches was released on 23 October 2000 on Warp Records. Although the CD claims to have 22 tracks, the last one, "www.bishopslips.com," is a reference to the "Bishopslips" sketch. Most of the sketches on the CD were remade for "Jam".

</doc>
<doc id="6321" url="http://en.wikipedia.org/wiki?curid=6321" title="Channel 4">
Channel 4

Channel 4 is a British public-service television broadcaster which began transmission on 2 November 1982. Although largely commercially self-funded, it is ultimately publicly owned; originally a subsidiary of the Independent Broadcasting Authority (IBA), the station is now owned and operated by Channel Four Television Corporation, a public body established in 1990, coming into operation in 1993. With the conversion of the Wenvoe transmitter group in Wales to digital on 31 March 2010, Channel 4 became an entirely UK-wide TV channel for the first time.
The channel was established to provide a fourth television service to the United Kingdom in addition to the television licence-funded BBC's two services and the single commercial broadcasting network, ITV.
History.
Conception.
Before Channel 4 and S4C, Britain had three terrestrial television services: BBC1, BBC2, and ITV. The Broadcasting Act 1980 began the process of adding a fourth, and Channel 4, along with its Welsh counterpart, was formally created by an Act of Parliament in 1982. After some months of test broadcasts, it began scheduled transmissions on 2 November 1982.
The notion of a second commercial broadcaster in the United Kingdom had been around since the inception of ITV in 1954 and its subsequent launch in 1955; the idea of an 'ITV2' was long expected and pushed for. Indeed television sets sold throughout the 1970s and early 1980s had a spare channel called 'ITV/IBA 2'. Throughout ITV's history and until Channel 4 finally became a reality, a perennial dialogue existed between the GPO, the government, the ITV companies and other interested parties, concerning the form such an expansion of commercial broadcasting would take. It was most likely politics which had the biggest impact in leading to a delay of almost three decades before the second commercial channel became a reality. With what can crudely be summed up as a clash of ideologies between an expansion of ITV's commercial ethos and a public service approach more akin to the BBC, it was ultimately something of a compromise that eventually led to the formation of Channel 4 as launched in 1982.
One clear benefit of the 'late arrival' of the channel was that its frequency allocations at each transmitter had already been arranged in the early 1960s, when the launch of an ITV2 was highly anticipated. This led to very good coverage across most of the country and few problems of interference with other UK-based transmissions; a stark contrast to the problems associated with Channel 5's launch fourteen and a half years later.
Wales.
At the time the fourth service was being considered, a movement in Wales lobbied for the creation of dedicated service that would air Welsh-language programmes, then only catered for at 'off peak' times on BBC Wales and HTV. The campaign was taken so seriously by Gwynfor Evans, former president of Plaid Cymru, that he threatened the government with a hunger strike were it not to honour the plans.
The result was that Channel 4 as seen by the rest of the United Kingdom would be replaced in Wales by "Sianel Pedwar Cymru (S4C)" ("Channel Four Wales"). Operated by a specially created authority, S4C would air programmes in Welsh made by HTV, the BBC, or independent companies. Initially limited frequency space meant that Channel 4 could not be broadcast alongside S4C, though some Channel 4 programmes would be aired at less popular times on the Welsh variant, a practice that carried on up until the closure of S4C's analogue transmissions in 2010.
Since then, carriage on digital cable, satellite and digital terrestrial has introduced Channel 4 to Welsh homes where it is now universally available.
Launch and IBA control.
The first voice heard on Channel 4's opening day of Tuesday 2 November 1982 was that of continuity announcer Paul Coia, who intoned, "Good afternoon. It's a pleasure to be able to say to you: Welcome to Channel Four", before heading into a montage of clips from its programmes set to the station's signature tune, "Fourscore", written by Lord David Dundas, which would form the basis of the station's jingles for its first decade. The first programme to air on the channel was the teatime game show "Countdown", at 16:45 produced by Yorkshire Television; it is still running as of 2014. The first person to be seen on Channel 4 was Richard Whiteley with Ted Moult being the second. The first female on the channel, contrary to popular belief, was not Carol Vorderman and was a lexicographer only ever identified as Mary. Whiteley opened the show with the words "As the countdown to a brand new channel ends, a brand new countdown begins." On its first day, Channel 4 also broadcast controversial soap opera "Brookside", which ran for 21 years.
On its launch, Channel 4 committed itself to providing an alternative to the existing channels, an agenda in part set out by its remit which required the provision of programming to minority groups.
In step with its remit, the channel became well received both by minority groups and the arts and cultural worlds during this period, especially under Isaacs, where the channel gained a reputation for programmes on the contemporary arts. Channel 4 co-commissioned Robert Ashley's ground-breaking television opera "Perfect Lives", which it premiered over several episodes in 1984. The channel often did not receive mass audiences for much of this period, however, as might be expected for a station focusing on minority interest. Channel 4 for many years had a poorer quality signal compared to other channels.
Channel 4 also began the funding of independent films, such as the Merchant-Ivory docudrama "The Courtesans of Bombay", during this time.
In 1992, Channel 4 also faced its first libel case by Jani Allan, a South African journalist, who objected to her representation in the documentary "The Leader, His Driver and the Driver's Wife".
Channel Four Television Corporation.
After control of the station passed from the Channel Four Television Company to the Channel Four Television Corporation in 1993, a shift in broadcasting style took place. Instead of aiming for the fringes of society, it began to focus on the edges of the mainstream, and the centre of the mass market itself. It began to show many US programmes in peak viewing time, far more than it had previously done. It premièred such shows as "Friends" and "ER".
In the early 2000s, Channel 4 began broadcasting reality formats such as "Big Brother" and obtained the rights to broadcast mass appeal sporting events like cricket and horse racing. This new direction increased ratings and revenues.
In addition, the corporation launched a number of new television channels through its new 4Ventures off-shoot, including Film4, At the Races, E4 and More4.
Partially in reaction to its new 'populist' direction, the Communications Act 2003 directed the channel to demonstrate innovation, experimentation and creativity, appeal to the tastes and interests of a culturally diverse society and to include programmes of an educational nature which exhibit a distinctive character.
In 31 December 2004, Channel 4 launched a new look and new idents in which the logo is disguised as different objects and the 4 can be seen in an angle.
Under the leadership of Freeview founder Andy Duncan, 2005 saw a change of direction for Channel 4's digital channels. Channel 4 made E4 free-to-air on digital terrestrial television, and launched a new free-to-air digital channel called More4. By October, Channel 4 had joined the Freeview consortium. By July 2006, Film4 had also become a 'free to air' and restarted broadcasting on digital terrestrial.
Venturing into radio broadcasting, 2005 saw Channel 4 purchase 51 per cent of shares in the now defunct Oneword radio station with UBC Media holding on to the remaining shares. New programmes such as the weekly, half-hour "The Morning Report" news programme were among some of the new content Channel 4 provided for the station, with the name 4Radio being used. As of early 2009, however, Channel 4's future involvement in radio remained uncertain.
On 2 November 2007, the station celebrated its twenty-fifth birthday. It showed the first episode of "Countdown", an anniversary "Countdown" special, as well as a special edition of "The Big Fat Quiz" and using the original multicoloured 1982–1996 blocks logo on presentation and idents using the Fourscore jingle throughout the day.
In November 2009, Channel 4 launched a week of 3D television, broadcasting selected programmes each night using stereoscopic ColorCode technology. The accompanying 3D glasses were distributed through Sainsbury's supermarkets.
Future.
Channel 4 has raised concerns over how it might finance its public service obligations after digital switch-over. However, some certainty lies in the announcement in April 2006 that Channel 4's digital switch-over costs would be paid for by licence fee revenues.
On 28 March 2007, Channel 4 announced plans to launch a music channel "4Music" as a joint venture with British media company EMAP which would include carriage on the Freeview platform. On 15 August 2008, 4Music was launched across the UK. Recently, Channel 4 have announced interest in launching a high-definition version of Film4 on Freeview, to coincide with the launch of Channel 4 HD, however the fourth HD slot was given to Channel 5 instead. Channel 4 has since acquired a 50% stake in EMAP's TV business for a reported £28 million.
Public service remit.
Channel 4 was established with, and continues to hold, a remit of public service obligations which it must fulfil. The remit changes periodically, as dictated by various broadcasting and communications acts, and is regulated by the various authorities Channel 4 has been answerable to; originally the IBA, then the ITC and now Ofcom.
The preamble of the remit as per the Communications Act 2003 states that:
"The public service remit for Channel 4 is the provision of a broad range of high quality and diverse programming which, in particular:
The remit also involves an obligation to provide programming for schools, and a substantial amount of programming produced outside of Greater London.
Carriage.
Channel 4 was carried from its beginning on analogue terrestrial, which was practically the only means of television broadcast in the United Kingdom at the time. It continued to be broadcast through these means until the changeover to digital terrestrial television in the United Kingdom was complete. Since 1998, it has been universally available on digital terrestrial, and the Sky platform (initially encrypted, though encryption was dropped on 2008-04-14 and is now free of charge and available on the Freesat platform) as well as having been available from various times in various areas, on analogue and digital cable networks.
Due to its special status as a public service broadcaster with a specific remit, it is afforded free carriage on the terrestrial platforms, in contrast with other broadcasters such as ITV.
Channel 4 is also available outside the United Kingdom where it is widely available in Ireland, Switzerland, Belgium and the Netherlands. Here viewers receive the channel either on basic cable subscription services or premium services.
Channel 4 Ulster has been available in large parts of Ireland, especially border counties which have been able to receive terrestrial transmissions from Northern Ireland. Channel 4 Ulster has been carried on Irish cable networks since the station went on the air in 1982. 
S4C has been available as a terrestrial transmission from Wales in southern counties such as Cork, Waterford, Wexford and Wicklow.
From 4 December 2006 Channel 4 was officially available to Sky viewers in Ireland; some programmes, mainly imports, are not aired on this channel variant, due to Channel 4 not owning the relevant broadcast rights within the country.
Channel 4 allowed Internet users in the United Kingdom to watch Channel 4 live on the Internet. However some programmes (mostly international imports) were not shown and this service no longer exists. Channel 4 is also provided by Virgin Mobile's DAB mobile TV service which has the same restrictions as the Internet live stream had. Channel 4 is also carried by the Internet TV service TVCatchup and was previously carried by Zattoo until the operator removed the channel from its platform.
Channel 4 also makes some of its programming available "on demand" via cable and the Internet through 4oD.
Funding.
During the station's formative years, funding came from the ITV companies in return for their right to sell advertisements in their region on the fourth channel.
Nowadays it pays for itself in much the same way as most privately run commercial stations, i.e. through the sale of on-air advertising, programme sponsorship, and the sale of any programme content and merchandising rights it owns, such as overseas sales and video sales. For example, as of 2012 its total revenues were £925 million with 91% derived from sale of advertising. It also has the ability to subsidise the main network through any profits made on the corporation's other endeavours, which have in the past included subscription fees from stations such as E4 and Film4 (now no longer subscription services) and its 'video-on-demand' sales. In practice, however, these other activities are loss-making, and are subsidised by the main network. According to Channel 4's last published accounts, for 2005, the extent of this cross-subsidy was some £30 million.
The change in funding came about under the Broadcasting Act 1990 when the new corporation was afforded the ability to fund itself. Originally this arrangement left a 'safety net' guaranteed minimum income should the revenue fall too low, funded by large insurance payments made to the ITV companies. Such a subsidy was never required, however, and these premiums were phased out by government in 1998. After the link with ITV was cut, the cross-promotion which had existed between ITV and Channel 4 also ended.
In 2007 due to severe funding difficulties, the channel sought government help and was granted a payment of £14 million over a six-year period. The money would have come from the television licence fee and would have been the first time that money from the licence fee had been given to any broadcaster other than the BBC. The plan was scrapped by The Secretary of State for Culture, Media and Sport, Andy Burnham, ahead of "broader decisions about the future framework of public service broadcasting".
The broadcasting regulator Ofcom released their review in January 2009 in which they suggested that Channel 4 would preferably be funded by "partnerships, joint ventures or mergers".
Programming.
Channel 4 is a "publisher-broadcaster", meaning that it commissions or "buys" all of its programming from companies independent of itself, and was the first broadcaster in the United Kingdom to do so on any significant scale. This had the consequence of starting an industry of production companies that did not have to rely on owning an ITV licence to see their programmes air, though since Channel 4, external commissioning has become regular practise on the numerous stations that have launched since, as well as on the BBC and in ITV (where a quota of 25% minimum of total output has been imposed since the 1990 Broadcasting Act came into force). Ironically, having been the first British broadcaster to completely commission its programmes from third parties, Channel 4 was the last terrestrial broadcaster to outsource its transmission and playout operations (to Red Bee Media), after 25 years in-house.
The requirement to obtain all content externally is stipulated in its licence. Additionally, Channel 4 also began a trend of owning the copyright and distribution rights of the programmes it aired, in a manner that is similar to the major Hollywood studios' ownership of television programs that they did not directly produce. Thus, although Channel 4 does not produce programmes, many are seen as belonging to it.
Channel 4 also pioneered the concept of "stranded programming", where seasons of programmes following a common theme would be aired and promoted together. Some would be very specific, and run for a fixed period of time; the "4 Mation" season, for example, showed innovative animation. Other, less specific strands, were (and still are) run regularly, such as "T4", a strand of programming aimed at teenagers, on weekend mornings (and weekdays during school/college holidays); "Friday Night Comedy", a slot where the channel would pioneer its style of comedy commissions, "4Music" (now a separate channel) and "4Later", an eclectic collection of offbeat programmes transmitted to a cult audience in the early hours of the morning.
In its earlier years, "Red Triangle" was the name given to the airing of certain risqué art-house films due to the use of a red triangle DOG in the upper right of the screen, dubbed as being pornographic by many of Channel 4's critics, while general broadcasting of films on the station for many years came under the banner of "Film on Four" prior to the launch of the "FilmFour" brand and station in the late 1990s.
Its critically acclaimed news service, "Channel 4 News", is supplied by ITN while its long-standing investigative documentary, "Dispatches", causes perennial media attention.
Most watched programmes.
The following is a list of the ten most watched shows on Channel 4 since 2002, based on Live +7 data supplied by BARB.
Regions.
Channel 4 has, since its inception, broadcast identical programmes and continuity throughout the United Kingdom (excluding Wales where it did not operate on analogue transmitters). At launch this made it unique, as both the BBC and ITV had long established traditions of providing regional variations in their programming and announcements between transmitters in different areas of the country (although in the case of BBC2, variations have by and large tended to be limited to national idents as opposed to regional ones). In ITV's case, this was a consequence of its inherent federal structure (see ). Since the launch of subsequent British television channels, Channel 4 has become typical in its lack of variations of this nature.
A few exceptions exist to this rule for programming and continuity: Ireland has a dedicated variant broadcast on Sky Ireland which omits programmes for which broadcast rights are not held in Ireland. For example, the series "Glee" is not available on Channel 4 on Sky in Ireland.
Some of Channel 4's schools' programming (1980s/early '90s) were regionalised due to differences in curricula between different regions.
Part of Channel 4's remit covers the commissioning of programmes from outside London. Channel 4 has a dedicated director of nations and regions, Stuart Cosgrove, who is based in a regional office in Glasgow. As his job title suggests, it is his responsibility to foster relations with independent producers based in areas of the United Kingdom (including Wales) outside of London.
Advertising on Channel 4 does contain regular variation: prior to 1993, when ITV was responsible for selling Channel 4's advertising, each regional ITV company would provide the content of advertising breaks, covering the same transmitter area as themselves, and these breaks were often unique to that area. After Channel 4 became responsible for its own advertising, it continued to offer advertisers the ability to target particular audiences and divided its coverage area into six parts coining the term 'LEMNUS' standing for "London, The East [and South] of England, The Midlands, The North of England, Ulster and Scotland.
At present, Wales does not have its own advertising region, instead its viewers receive the southern region on digital platforms intentionally broadcast to the area, or the neighbouring region where terrestrial transmissions spill over into Wales. The Republic of Ireland shares its advertising region with Northern Ireland (referred to by Channel 4 as the 'Ulster Macro') with many advertisers selling products for Ireland here. E4 has an advertising variant for Ireland, although Northern Ireland receives the UK version of E4. The six regions are also carried on satellite, cable and Digital Terrestrial.
Channel 5 and ITV Breakfast use a similar model to Channel 4 for providing their own advertising regions, despite also having a single national output of programming.
Future possibility of regional news.
With ITV plc pushing for much looser requirements on the amount of regional news and other programming it is obliged to broadcast in its ITV regions, the idea of Channel 4 taking on a regional news commitment has been considered, with the corporation in talks with Ofcom and ITV over the matter. Channel 4 believe that a scaling-back of such operations on ITV's part would be detrimental to Channel 4's national news operation, which shares much of its resources with ITV through their shared news contractor ITN. At the same time, Channel 4 also believe that such an additional public service commitment would bode well in on-going negotiations with Ofcom in securing additional funding for its other public service commitments.
Channel 4 HD.
Previously, in the summer of 2006, Channel 4 ran a six-month closed trial of HDTV, as part of the wider Freeview HD experiment via the Crystal Palace transmitter to London and parts of the home counties, including the use of "Lost" and "Desperate Housewives" as part of the experiment, as US broadcasters such as ABC already have an HDTV back catalogue.
On 10 December 2007, Channel 4 launched a high definition television simulcast of Channel 4 on Sky's digital satellite platform, after Sky agreed to contribute toward the channel's satellite distribution costs. It was the first full-time high definition channel from a terrestrial UK broadcaster.
On 31 July 2009, Virgin Media added Channel 4 HD on channel 146 (now on channel 142) as a part of the M pack. On 25 March 2010 Channel 4 HD appeared on Freeview channel 52 with a placeholding caption, ahead of a commercial launch on 30 March 2010, coinciding with the commercial launch of Freeview HD. On 19 April 2011, Channel 4 HD was added to Freesat on channel 126. As a consequence, the channel moved from being free-to-view to free-to-air on satellite during March 2011. With the closure of S4C Clirlun in Wales on 1 December 2012, on Freeview, Channel 4 HD launched in Wales on 2 December 2012.
The channel carries the same schedule as Channel 4, broadcasting programmes in HD when available, acting as a simulcast. Therefore SD programming is broadcast upscaled to HD.
On 1 July 2014, Channel 4 +1 HD, a timeshift of Channel 4 HD, launched on Freeview channel 110.
4oD.
4oD is a video on demand service from Channel 4. Launched in November 2006, 4oD stands for "4 on Demand". The service offers a variety of programmes recently shown on Channel 4, E4, More4 or from their archives, though some programmes and movies are not available due to rights issues.
Teletext services.
4-Tel/FourText.
Channel 4 originally licensed an ancillary teletext service to provide schedules, programme information and features. The original service was called 4-Tel, and was produced by Intelfax, a company set up especially for the purpose. It was carried in the 400s on Oracle. In 1993, with Oracle losing its franchise to Teletext Ltd, 4-Tel found a new home in the 300s, and had its name shown in the header row. Intelfax continued to produce the service and in 2002 it was renamed FourText.
Teletext on 4.
In 2003, Channel 4 awarded Teletext Ltd a ten-year contract to run the channel's ancillary teletext service, named Teletext on 4. This has now ceased and Teletext is no longer available on Channel 4, ITV and Channel 5.

</doc>
<doc id="6322" url="http://en.wikipedia.org/wiki?curid=6322" title="Carolina parakeet">
Carolina parakeet

The Carolina parakeet ("Conuropsis carolinensis") or Carolina conure was a small green Neotropical parrot with a bright yellow head, reddish orange face and pale beak native to the eastern, midwest and plains states of the United States and was the only indigenous parrot within its range. It was found from southern New York and Wisconsin to Kentucky, Tennessee and the Gulf of Mexico, from the Atlantic seaboard to as far west as eastern Colorado. It lived in old-growth forests along rivers and in swamps. It was called "puzzi la née" ("head of yellow") or "pot pot chee" by the Seminole and "kelinky" in Chickasaw. Though formerly prevalent within its range, the bird had become rare by the middle of the 19th century. The last confirmed sighting in the wild was of the "ludovicianus" subspecies in 1910. The last known specimen perished in captivity at Cincinnati Zoo in 1918 and the species was declared extinct in 1939.
The earliest reference to these parrots was in 1583 in Florida reported by Sir George Peckham in "A True Report of the Late Discoveries of the Newfound Lands" of expeditions conducted by English explorer Sir Humphrey Gilbert who notes that explorers in North America "doe testifie that they have found in those countryes; ... parrots." They were first scientifically described in English naturalist Mark Catesby's two volume "Natural History of Carolina, Florida and the Bahama Islands" published in London in 1731 and 1743.
Carolina parakeets were probably poisonous—American naturalist and painter John J. Audubon noted that cats apparently died from eating them, and they are known to have eaten the toxic seeds of cockleburs.
Taxonomy.
"Carolinensis" is a species of the genus "Conuropsis", one of numerous genera of New World long-tailed parrots in tribe Arini, which also includes the Central and South American macaws. Tribe Arini together with the Amazonian parrots and a few miscellaneous genera make up subfamily Arinae of Neotropical parrots in family Psittacidae of true parrots.
The specific name "Psittacus carolinensis" was assigned by Swedish zoologist Carolus Linnaeus in the 10th edition of "Systema Naturae " published in 1758. The species was given its own genus "Conuropsis" by Italian zoologist and ornithologist Tommaso Salvadori in 1891 in his "Catalogue of the Birds in the British Museum", volume 20. The name is derived from the Greek-ified "conure" ("parrot of the genus "Conurus"" an obsolete name of genus "Aratinga") + "-opsis" ("likeness of") and Latinized "Carolina" (from Carolana, an English colonial province) + "-ensis" (of or "from a place"), therefore a bird "like a conure from Carolina".
There are two recognized subspecies. The Louisiana subspecies of the Carolina parakeet, "C. c. ludovicianus", was slightly different in color than the nominate subspecies, being more bluish-green and generally of a somewhat subdued coloration, and went extinct in much the same way, but at a somewhat earlier date (early 1910s). The Appalachian Mountains separated these birds from the eastern "C. c. carolinensis".
According to a study of mitochondrial DNA recovered from museum specimens, their closest living relatives include some of the South American "Aratinga" parakeets: the Nanday parakeet, the sun parakeet, and the golden-capped parakeet. The authors note the bright yellow and orange plumage and blue wing feathers found in "Conuropsis carolinensis" are traits shared by another species, the jenday parakeet ("A. jandaya"), that was not sampled in the study but is generally thought to be closely related. Carolinensis is in a sister clade to that of Spix's macaw. The Carolina parakeet colonized North America about 5.5 million years ago. This was well before North America and South America were joined together by the formation of the Panama land bridge about 3.5 mya. Since the Carolina parakeets' more distant relations are geographically closer to its own historic range whilst its closest relatives are more geographically distant to it, these data are consistent with the generally accepted hypothesis that Central and North America were colonized at different times by distinct lineages of parrots – parrots that originally invaded South America from Antarctica some time after the breakup of Gondwana, where Neotropical parrots originated approximately 50 mya.
A fossil parrot, designated "Conuropsis fratercula", was described based on a single humerus from the Miocene Sheep Creek Formation (possibly late Hemingfordian, c. 16 mya, possibly later) of Snake River, Nebraska. This was a smaller bird, three-quarters the size of the Carolina parakeet. "The present "species" is of peculiar interest as it represents the first known parrotlike bird to be described as a fossil from North America." (Wetmore 1926; italics added) However, it is not altogether certain that this species is correctly assigned to "Conuropsis", but some authors consider it a paleosubspecies of the Carolina parakeet.
Description.
The Carolina parakeet was a small green parrot very similar in size and coloration to the extant jenday and sun conures. The majority of the plumage was green with lighter green underparts, a bright yellow head and orange forehead and face extending to behind the eyes and upper cheeks (lores). The shoulders were yellow, continuing down the outer edge of the wings. The primary feathers were mostly green, but with yellow edges on the outer primaries. Thighs were green towards the top and yellow towards the feet. Male and female adults were identical in plumage, however males were slightly larger than females (sexually dimorphic). The legs and feet were light brown. They share the zygodactyl feet of the parrot family. The skin around the eyes was white and the beak was pale flesh colored. These birds weigh about 3.5 oz. are 13 in. long, and have wingspans of 21-23 in.
Young Carolina parakeets differed slightly in coloration from adults. The face and entire body was green, with paler underparts. They lacked yellow or orange plumage on the face, wings, and thighs. Hatchlings were covered in mouse-gray down, until about 39–40 days when green wings and tails appear. Fledglings had full adult plumage at around 1 year of age. ("Nature Serve, Conuropsis carolinensis", 2005; Fuller, 2001; Mauler, 2001; Rising, 2004; Snyder and Russell, 2002)
These birds were fairly long lived, at least in captivity - a pair was kept at the Cincinnati Zoo for over 35 years.
Distribution and habitat.
The Carolina parakeet had the northern-most range of any known parrot. It was found from southern New England and New York and Wisconsin to Kentucky, Tennessee and the Gulf of Mexico. Its also had a wide distribution west of the Mississippi River, as far west as eastern Colorado. Its range was described by early explorers thus: the 43rd parallel as the northern limit, the 26th as the most southern, the 73rd and 106th meridians as the eastern and western boundaries respectively, the range included all or portions of at least 28 states. Its habitats were old-growth wetland forests along rivers and in swamps especially in the Mississippi-Missouri drainage basin with large hollow trees including cypress and sycamore to use as roosting and nesting sites.
Only very rough estimates of the birds' former prevalence can be made: with an estimated range of 20,000 to 2.5 million km2, and population density of 0.5 to 2.0 parrots per km2, population estimates range from tens of thousands to a few million birds (though the densest populations occurred in Florida covering 170,000 km2, so there may have been hundreds of thousands of the birds in that state alone).
The species may have appeared as a very rare vagrant in places as far north as Southern Ontario. A few bones, including a pygostyle found at the Calvert Site in Southern Ontario, came from the Carolina parakeet. The possibility remains open that this specimen was taken to Southern Ontario for ceremonial purposes.
Behavior and diet.
The bird lived in huge, noisy flocks of as many as 200-300 birds. They built their nests in hollow trees, laying two to five (most accounts say two) 1.6 in round white eggs.
It mostly ate the seeds of forest trees and shrubs including those of cypress, hackberry, beech, sycamore, elm, pine, maple, oak, and other plants such as thistles and sandspurs ("Cechrus" species). It also ate fruits including apples, grapes and figs (often from orchards by the time of its decline). They were especially noted for their predilection for cockleburs ("Xanthium strumarium"), a plant which contains a toxic glucoside, and was an invasive pest in southern farms and fields.
Extinction.
There are no scientific studies or surveys of this bird by American naturalists; most information about it is from anecdotal accounts and museum specimens. Therefore details of its prevalence and decline are unverified or speculative.
There are extensive accounts of the pre-colonial and early colonial prevalence of this bird. The existence of flocks of gregarious, very colorful and raucous parrots could hardly have gone unnoted by European explorers, as parrots were virtually unknown in seafaring European nations in the 16th and 17th centuries. Later accounts in the latter half of the 19th century onward noted the birds' sparseness and absence.
The birds' range collapsed from east to west with settlement and clearing of the eastern and southern deciduous forests. John J. Audubon commented as early as 1832 on the decline of the birds. The bird was rarely reported outside Florida after 1860. The last reported sighting east of the Mississippi River (except Florida) was in 1878 in Kentucky. By the turn-of-the-century it was restricted to the swamps of central Florida. The last known wild specimen was killed in Okeechobee County, Florida, in 1904, and the last captive bird died at the Cincinnati Zoo on February 21, 1918. This was the male specimen, called "Incas", who died within a year of his mate, "Lady Jane". Additional reports of the bird were made in Okeechobee County, Florida, until the late 1920s, but these are not supported by specimens. It was not until 1939, however, that the American Ornithologists' Union declared that the Carolina parakeet had become extinct. The IUCN has listed the species as extinct since 1918.
In 1937, three parakeets resembling this species were sighted and filmed in the Okefenokee Swamp of Georgia. However, the American Ornithologists' Union analyzed the film and concluded that they had probably filmed feral parakeets.
About 720 skins and 16 skeletons are housed in museums around the world and analyzable DNA has been extracted from them.
Reasons for extinction.
The evidence is rather conclusive that extinction of the Carolina parakeet was by anthropogenic activity, through a variety of means. Chief among them is deforestation in the 18th and 19th centuries. Hunting played a significant role, both for their colorful feathers used to adorn women's hats and to reduce predation on southern crops. This was partially offset by recognition of their value in controlling invasive cockleburs. Minor roles were played by capture for the pet trade and, it was hypothesized, by the introduction for crop pollination of European honeybees that competed for nest sites.
A factor that exacerbated their decline to extinction was the unfortunate flocking behavior that led them to return to the vicinity of dead and dying birds (e.g., birds downed by hunting), enabling wholesale slaughter.
The final extinction of the species in the early years of the 20th century is somewhat of a mystery, as it happened so rapidly. Vigorous flocks with many juveniles and reproducing pairs were noted as late as 1896, and the birds were long-lived in captivity, but they had virtually disappeared by 1904. Sufficient nest sites remained intact, so deforestation was not the final cause. American ornithologist Noel F. Snyder speculates that the most likely cause seems to be that the birds succumbed to poultry disease, this in spite of the fact that no recent or historical records exist of New World parrot populations being afflicted by domestic poultry diseases. The modern poultry scourge Newcastle disease was not detected until 1926 in Indonesia, and only a subacute form of it was reported in the United States in 1938.

</doc>
<doc id="6324" url="http://en.wikipedia.org/wiki?curid=6324" title="Collective trauma">
Collective trauma

A collective trauma is a traumatic psychological effect shared by a group of people of any size, up to and including an entire society. Traumatic events witnessed by an entire society can stir up collective sentiment, often resulting in a shift in that society's culture and mass actions.
Well known collective traumas include: The Holocaust, The John F. Kennedy assassination in the United States, the Estonia disaster in Sweden, the September 11, 2001 attacks in the United States and various others.
Collective traumas have been shown to play a key role in group identity formation (see: Law of Common Fate). During World War II, a US submarine, the USS Puffer (SS-268), came under several hours of depth charge attack by a Japanese surface vessel until the ship became convinced the submarine had somehow escaped. Psychological studies later showed that crewmen transferred to the submarine after the event were never accepted as part of the team. Later, US naval policy was changed so that after events of such psychological trauma, the crew would be dispersed to new assignments.
Rehabilitation of survivors becomes extremely difficult when entire nation has experienced such severe traumas as war, genocide, torture, massacre, etc. Treatment is hardly effective when everybody is traumatized. Trauma remains chronic and would reproduce itself as long as social causes are not addressed and perpetrators continue to enjoy impunity. The whole society may suffer from an everlasting culture of pain. (1) 
During liberation war in Algeria, the Algerian Psychiatrist Frantz Omar Fanon found his practice of treatment of native Algerians ineffective due to the continuation of the horror of a colonial war. He emphasized about the social origin of traumas, joined the liberation movement and urged oppressed people to purge themselves of their degrading traumas through their collective liberation struggle. He made the following remarks in his letter of resignation, as the Head of the Psychiatry Department at the Blida-Joinville Hospital in Algeria:
"If psychiatry is the medical technique that aims to enable man no longer to be a stranger to his environment, I owe it to myself to affirm that the Arab, permanently an alien in his own country, lives in a state of absolute depersonalization.” (2)
Inculcation of horror and anxiety, through widespread torture, massacre, genocide and similar coercive measures has happened frequently in human history. There are plenty of examples in our modern history. Tyrants have always used their technique of “psychological artillery” in an attempt to cause havoc and confusion in the minds of people and hypnotize them with intimidation and cynicism. The result is a collective trauma that will pass through generations. There is no magic formula of rehabilitation. Collective trauma can be alleviated through cohesive and collective efforts such as recognition, remembrance, solidarity, communal therapy and massive cooperation. 
References.
1. Mossallanejad, E. (2005). Torture in the Age of Fear. Hamilton, Canada: Seraphim Editions
2. Frantz Fanon, Toward the African Revolution, New York, 1967. Reprint of Pour la revolution africaine. Paris, 1964, p. 53.

</doc>
<doc id="6325" url="http://en.wikipedia.org/wiki?curid=6325" title="Church (building)">
Church (building)

A church building, often simply called a church, is a building used for religious activities, particularly worship services. The term in its architectural sense is most often used by Christians to refer to their religious buildings but can be used by other religions. In traditional Christian architecture, the church is often arranged in the shape of a Christian cross. When viewed from plan view the longest part of a cross is represented by the aisle and the junction of the cross is located at the altar area. Towers or domes are often added with the intention of directing the eye of the viewer towards the heavens and inspiring church visitors. Modern church buildings have a variety of architectural styles and layouts; many buildings that were designed for other purposes have now been converted for church use; and, similarly, many original church buildings have been put to other uses. The earliest identified Christian church was founded between 233 and 256. During the 11th through 14th centuries, a wave of building of cathedrals and smaller parish churches occurred across Western Europe. A cathedral is a church, usually Roman Catholic, Anglican, Oriental Orthodox or Eastern Orthodox, housing the seat of a bishop. 
Etymology.
In Greek, the adjective "kyriak-ós/-ē/-ón" means "belonging, or pertaining, to a "Kýrios"" ("Lord"), and the usage was adopted by early Christians of the Eastern Mediterranean with regard to anything pertaining to the Lord Jesus Christ: hence "Kyriakós oíkos" ("house of the Lord", church), "Kyriakē" ("[the day] of the Lord", i.e. Sunday), or "Kyriakē proseukhē" (the "[Lord's prayer]").
In standard Greek usage, the older word "ecclesia" (ἐκκλησία, "ekklesía", literally "assembly", "congregation", or the place where such a gathering occurs) was retained to signify both a specific edifice of Christian worship (a "church"), and the overall community of the faithful (the "Church"). This usage was also retained in Latin and the languages derived from Latin (e.g. French "église", Italian "chiesa", Spanish "iglesia", Portuguese "igreja", etc.), as well as in the Celtic languages (Welsh "eglwys", Irish "eaglais", Breton "iliz", etc.).
In the Germanic and some Slavic languages, the word "kyriak-ós/-ē/-ón" was adopted instead and derivatives formed thereof. In Old English the sequence of derivation started as "cirice" (Ki-ri-keh), then "churche" (kerke), and eventually "church" in its current pronunciation. German "Kirche", Scottish "kirk", Russian "tserkov", etc., are all similarly derived.
History.
Antiquity.
The earliest identified Christian house church is the Dura-Europos church, founded between 233 and 256.
Medieval times.
During the 11th through 14th centuries, a wave of building of cathedrals and smaller parish churches occurred across Western Europe. In addition to being a place of worship, the cathedral or parish church was used by the community in other ways. It could serve as a meeting place for guilds or a hall for banquets. Mystery plays were sometimes performed in cathedrals, and cathedrals might also be used for fairs. The church could be used as a place to thresh and store grain.
Modern era.
Throughout the last few centuries, the types of churches have become much more widespread. Some have gospel choirs while other worship in total silence. The ornateness of churches varies widely depending on the religion of the deity being worshiped, or the praying culture of the community. Due to various cultural and social reasons, most churches have seen a decline in attendance in recent years.
Architecture.
A common architecture for churches is the shape of a cross (a long central rectangle, with side rectangles, and a rectangle in front for the altar space or sanctuary). These churches also often have a dome or other large vaulted space in the interior to represent or draw attention to the heavens. Other common shapes for churches include a circle, to represent eternity, or an octagon or similar star shape, to represent the church's bringing light to the world. Another common feature is the spire, a tall tower on the "west" end of the church or over the crossing.
Types.
Basilica.
The Latin word basilica (derived from Greek, "Basiliké Stoà", Royal "Stoa") was originally used to describe a Roman public building (as in Greece, mainly a tribunal), usually located in the forum of a Roman town.
After the Roman Empire became officially Christian, the term came by extension to refer to a large and important church that has been given special ceremonial rights by the Pope. Thus the word retains two senses today, one architectural and the other ecclesiastical.
Cathedral.
A cathedral is a church, usually Roman Catholic, Anglican, Oriental Orthodox or Eastern Orthodox, housing the seat of a bishop. The word cathedral takes its name from "cathedra", or Bishop's Throne (In Latin: "ecclesia cathedralis"). The term is sometimes (improperly) used to refer to any church of great size.
A church that has the function of cathedral is not necessarily a large building. It might be as small as Christ Church Cathedral in Oxford, England, Sacred Heart Cathedral in Raleigh, United States, or Chur Cathedral in Switzerland. However, frequently, the cathedral along with some of the abbey churches, was the largest building in any region.
Alternative buildings.
Old and disused church buildings can be seen as an interesting proposition for developers as the architecture and location often provide for attractive homes or city centre entertainment venues On the other hand, many newer Churches have decided to host meetings in public buildings such as schools, universities, cinemas or theatres.
There is another trend to convert old buildings for worship rather than face the construction costs and planning difficulties of a new build. Unusual venues in the UK include an old Tram power station, a former bus garage, an old cinema and bingo hall, a former Territorial Army Drill Hall, a former synagogue and a windmill.

</doc>
<doc id="6326" url="http://en.wikipedia.org/wiki?curid=6326" title="Childe's Tomb">
Childe's Tomb

Childe's Tomb is a granite cross on Dartmoor, Devon, England. Although not in its original form, it is more elaborate than most of the crosses on Dartmoor, being raised upon a constructed base, and it is known that a kistvaen is underneath.
A well-known legend attached to the site, first recorded in 1630 by Tristram Risdon, concerns a wealthy hunter, Childe, who became lost in a snow storm and supposedly died there despite disembowelling his horse and climbing into its body for protection. The legend relates that Childe left a note of some sort saying that whoever found and buried his body would inherit his lands at Plymstock. After a race between the monks of Tavistock Abbey and the men of Plymstock, the Abbey won.
The tomb was virtually destroyed in 1812 by a man who stole most of the stones to build a house nearby, but it was partly reconstructed in 1890.
Description.
Childe's Tomb is a reconstructed granite cross on the south-east edge of Foxtor Mires, about 500 metres north of Fox Tor on Dartmoor, Devon, England at . According to William Burt, in his notes to "Dartmoor, a Descriptive Poem" by N. T. Carrington (1826), the original tomb consisted of a pedestal of three steps, the lowest of which was built of four stones each six feet long and twelve inches square. The two upper steps were made of eight shorter but similarly shaped stones, and on top was an octagonal block about three feet high with a cross fixed upon it.
The tomb lies on the line of several cairns that marked the east-west route of the ancient Monks' Path between Buckfast Abbey and Tavistock Abbey and it was no doubt erected here as part of that route: it would have been particularly useful in this part of the moor with few landmarks where a traveller straying from the path could easily end up in Foxtor Mires. Tristram Risdon, writing in about 1630, said that Childe's Tomb was one of three remarkable things in the Forest of Dartmoor (the others being Crockern Tor and Wistman's Wood). Risdon also stated that the original tomb bore an inscription: "They fyrste that fyndes and bringes mee to my grave, The priorie of Plimstoke they shall have", but no sign of this has ever been found.
Today the cross, which is a replacement, is about 3 feet 4 inches (1 m) tall and 1 foot 8 inches (0.5 m) across at the crosspiece, and it has its base in a socket stone which rests on a pedestal of granite blocks that raises the total height of the cross to 7 ft (2.1 m). The original, now broken, socket stone for the cross lies nearby. The whole is surrounded by a circle of granite stones set on their edge which once surrounded the cairn—the rocks of which are now scattered around—that was originally built over a large kistvaen that still exists beneath the pedestal.
Destruction.
In the early 19th century there was much interest in enclosing and "improving" the open moorland on Dartmoor, encouraged by Sir Thomas Tyrwhitt's early successes at Tor Royal near Princetown. Enclosure was aided by the greatly enhanced access provided by the construction of the first turnpike roads over the moor: the road between Ashburton and Two Bridges opened in around 1800, for instance. In February 1809 one Thomas Windeatt, from Bridgetown, Totnes, took over the lease of a plot of land (a "newtake") of about 582 acres in the valley of the River Swincombe. In 1812 Windeatt started to build a farmhouse, Fox Tor Farm, on his land and his workmen robbed the nearby Childe's Tomb of most of its stones for the building and its doorsteps.
In 1902 William Crossing wrote that he had been told by an old moorman that some of the granite blocks from the tomb's pedestal had also been used to make a clapper bridge across a stream flowing into the River Swincombe near the farm. The moorman also said that they had lettering on their undersides. This encouraged Crossing to arrange to lift the clapper bridge, but no inscription was found. However he did locate nine out of the twelve stones that had made up the pedestal, as well as the broken socket stone for the cross.
Reconstruction.
Crossing rediscovered the original site of the tomb in 1882 and said that all that remained was a small mound and some half buried stones. He cleared out the kistvaen, reporting that it was 5 foot 6 inches (1.7 m) long by 2 foot 8 inches (86 cm) wide and that unlike most kistvaens found on the moor, the stones lining it had apparently been shaped by man, which led him to suggest that it was less old than most. Having located most of the stones of the original tomb, Crossing thought that it could be rebuilt in its original form with little effort, but it was not to be.
J. Brooking Rowe, writing in 1895, states that the tomb was re-erected in 1890 under the direction of Mr. E. Fearnley Tanner, who said that he was dissatisfied with the result because several stones were missing and it was difficult to recreate the original character of the monument. Tanner was the honourable secretary of the Dartmoor Preservation Association, and this reconstruction was one of the first acts of that organisation. The replacement base and cross were made in Holne in 1885.
Childe the Hunter.
According to legend, the cross was erected over the kistvaen (burial chamber) of Childe the Hunter, who was Ordulf, son of Ordgar, an Anglo-Saxon Earl of Devon in the 11th century. The name "Childe" is probably derived from the Old English word "cild" which was used as a title of honour.
Legend has it that Childe was in a party hunting on the moor when they were caught in some changeable weather. Childe became separated from the main party and was lost. In order to save himself from dying of exposure, he killed his horse, disembowelled it and crept inside the warm carcass for shelter. He nevertheless froze to death, but before he died, he wrote a note to the effect that whoever should find him and bury him in their church should inherit his Plymstock estate.
His body was found by the monks of Tavistock Abbey, who started to carry it back. However, they heard of a plot to ambush them by the people of Plymstock, at a bridge over the River Tavy. They took a detour and built a new bridge over the river, just outside of Tavistock. They were successful in burying the body in the grounds of the Abbey and inherited the Plymstock estate.
The first account of this story is to be found in Risdon's "Survey of Devon" which was completed in around 1632:
Finberg pointed out, however, that a document of 1651 refers to Tavistock's guildhall as "Guilehall", so "Guilebridge" is more likely to be "guild bridge", probably because it was built or maintained by one of the town guilds.
In popular culture.
Devon folk singer Seth Lakeman sang about Childe the Hunter on his 2006 album "Freedom Fields".

</doc>
<doc id="6328" url="http://en.wikipedia.org/wiki?curid=6328" title="Cognate">
Cognate

In linguistics, cognates are words that have a common etymological origin. This learned term derives from the Latin "cognatus" (blood relative).
For example, the English words "shirt" and "skirt" are doublets; the former derives from the Old English "sċyrte", while the latter is borrowed from Old Norse "skyrta", both of which derive from the Proto-Germanic "*skurtijǭ". Additional cognates of the same word in other Germanic languages include the German "Schürze" and Dutch "schort" (which both mean "apron").
Characteristics of cognate words.
Cognates do not need to have the same meaning, which may have changed as the languages developed separately. For example, consider English "starve" and Dutch "sterven" or German "sterben" ("to die"); these three words all derive from the same Proto-Germanic root, "*sterbaną" ("die"). English "dish" and German "Tisch" ("table"), with their flat surfaces, both come from Latin "discus", but it would be a mistake to identify their later meanings.
Across languages.
Examples of cognates in Indo-European languages are the words "night" (English), "nuit" (French), "Nacht" (German), "nacht" (Dutch), "nag" (Afrikaans), "nicht" (Scots), "natt" (Swedish, Norwegian), "nat" (Danish), "nátt" (Faroese), "nótt" (Icelandic), "noc" (Czech, Slovak, Polish), ночь, "noch" (Russian), ноќ, "noć" (Macedonian), нощ, "nosht" (Bulgarian), "ніч", "nich" (Ukrainian), "ноч", "noch"/"noč" (Belarusian), "noč" (Slovene), "noć" (Serbo-Croatian), νύξ, "nyx" (Ancient Greek, "νύχτα"/"nychta" in Modern Greek), "nox/nocte" (Latin), "nakt-" (Sanskrit), "natë" (Albanian), "noche" (Spanish), "nos" (Welsh), "nueche" (Asturian), "noite" (Portuguese and Galician), "notte" (Italian), "nit" (Catalan), "nuèch/nuèit" (Occitan), "noapte" (Romanian), "nakts" (Latvian), "naktis" (Lithuanian) and "Naach" (Colognian), all meaning "night" and derived from the Proto-Indo-European (PIE) , "night".
Another Indo-European example is "star" (English), "str-" (Sanskrit), "tara" (Hindustani), "étoile" (French), "ἀστήρ (astēr)" (Greek or "ἀστέρι"/"ἄστρο", "asteri"/"astro" in Modern Greek), "astro" (Italian), "aster" (Latin) "stea" (Romanian and Venetian), "stairno" (Gothic), "astl" (Armenian), "Stern" (German), "ster" (Dutch and Afrikaans), "Schtähn" (Colognian), "starn" (Scots), "stjerne" (Norwegian and Danish), "stjarna" (Icelandic), "stjärna" (Swedish), "stjørna" (Faroese), "setāre" (Persian), "stoorei" (Pashto), "seren" (Welsh), "steren" (Cornish), "estel" (Catalan), "estela" (Occitan) "estrella" and "astro" Spanish, "estrella" Asturian and Leonese, "estrela" (Portuguese and Galician) and "estêre" or "stêrk" (Kurdish), from the PIE , "star".
The Hebrew "shalom", the Arabic "salām" and the Amharic "selam" ("peace") are also cognates, derived from Proto-Semitic *šalām-.
Cognates may often be less easily recognised than the above examples and authorities sometimes differ in their interpretations of the evidence. The English word "milk" is clearly a cognate of German "Milch", Dutch "melk", Russian "молоко (moloko)" and Croatian "mlijeko". On the other hand, French "lait", Catalan "llet", Italian "latte", Romanian "lapte", and Spanish "leche" (all meaning "milk") are less obviously cognates of Ancient Greek "" "gálaktos" (genitive singular of "gála", "milk"), a relationship more evidently seen through the intermediate Latin "lac" "milk", as well as the English word "lactic" and other terms borrowed from Latin. At times, cognates may even be opposites. For instance, while the Hebrew word "chutzpah" means "impudence," its Classical Arabic cognate "ḥaṣāfah" means "sound judgment;" even more contradictorily, the English word "black" and Polish "biały", meaning white, both derive from the PIE , meaning, "to burn or shine."
A word may also enter another language, develop a new form or meaning there, and be re-borrowed into the original language; this is called a "Rückwanderer" (German for "one who wanders back"). For example, the Greek word "κίνημα" ("kinēma", "movement") became French "cinéma" (cf. American English "movie") and then later returned to Greece as "σινεμά" ("sinema", "the art of film", "movie theater"). Now in Greece "κίνημα" ("kinēma", "movement") and "σινεμά" ("sinema", "filmmaking, cinema") exist together as a doublet (see next section).
Within the same language.
Cognate doublets can exist within the same language, with meanings which may be anything from slightly to totally different. For example, English "ward" and "guard" (<PIE "*wer-", "to perceive, watch out for") are cognates, as are "shirt" (garment on top) and "skirt" (garment on bottom) (<PIE "*sker-", "to cut"). In some cases, such as "shirt" and "skirt", one of the cognate pairs has an ultimate source in another language related to English, while the other one is native, as happened with many loanwords from Old Norse borrowed during the Danelaw. Sometimes, both cognates come from other languages, often the same one but at different times. For example, the word "chief" (meaning the leader of any group) comes from the Middle French "chef" ("head"), and its modern pronunciation preserves the Middle French consonant sound; the word "chef" (the leader of the cooks) was borrowed from the same source centuries later, by which time the consonant had changed to a "sh"-sound in French. Such word sets can also be called etymological twins, and of course they may come in groups of higher numbers, as with, for example, the words "wain" (native), "waggon/wagon" (Dutch) and "vehicle" (Latin) in English.
An example of very different and non-obvious English-language cognates is "grammar" and "glamour".
False cognates.
False cognates are words that are commonly thought to be related (have a common origin) whereas linguistic examination reveals they are unrelated. Thus, for example, on the basis of superficial similarities one might suppose that the Latin verb "habere" and German "haben", both meaning 'to have', were cognates. However, an understanding of the way words in the two languages evolved from Proto-Indo-European (PIE) roots shows that they cannot be cognate (see for example Grimm's law). German "haben", like English "have", in fact comes from PIE "*kh₂pyé-" 'to grasp', and its real cognate in Latin is "capere", 'to seize, grasp, capture'. Latin "habēre", on the other hand, is from PIE "*gʰabʰ", 'to give, to receive', and hence cognate with English "give" and German "geben".
English "much" and Spanish "mucho" also look similar and even have a similar meaning yet are not cognates, with "much" < Proto-Germanic "*mikilaz" < PIE "*meǵ-", while "mucho" < Latin "multum" < PIE "*mel-".

</doc>
<doc id="6329" url="http://en.wikipedia.org/wiki?curid=6329" title="Chromatography">
Chromatography

Chromatography (; from Greek χρῶμα "chroma" "color" and γράφειν "graphein" "to write") is the collective term for a set of laboratory techniques for the separation of mixtures.
The mixture is dissolved in a fluid called the "mobile phase," which carries it through a structure holding another material called the "stationary phase." The various constituents of the mixture travel at different speeds, causing them to separate. The separation is based on differential partitioning between the mobile and stationary phases. Subtle differences in a compound's partition coefficient result in differential retention on the stationary phase and thus changing the separation.
Chromatography may be preparative or analytical. The purpose of preparative chromatography is to separate the components of a mixture for more advanced use (and is thus a form of purification). Analytical chromatography is done normally with smaller amounts of material and is for measuring the relative proportions of analytes in a mixture. The two are not mutually exclusive.
History.
Chromatography was first employed by the Russian scientist Mikhail Tsvet in 1900. He continued to work with chromatography in the first decade of the 20th century, primarily for the separation of plant pigments such as chlorophyll, carotenes, and xanthophylls. Since these components have different colors (green, orange, and yellow, respectively) they gave the technique its name. New types of chromatography developed during the 1930s and 1940s made the technique useful for many separation processes.
Chromatography technique developed substantially as a result of the work of Archer John Porter Martin and Richard Laurence Millington Synge during the 1940s and 1950s. They established the principles and basic techniques of partition chromatography, and their work encouraged the rapid development of several chromatographic methods: paper chromatography, gas chromatography, and what would become known as high performance liquid chromatography. Since then, the technology has advanced rapidly. Researchers found that the main principles of Tsvet's chromatography could be applied in many different ways, resulting in the different varieties of chromatography described below. Advances are continually improving the technical performance of chromatography, allowing the separation of increasingly similar molecules.
Chromatography terms.
Chromatography is based on the concept of partition coefficient. Any solute partitions between two immiscible solvents. When we make one solvent immobile (by adsorption on a solid support matrix) and another mobile it results in most common applications of chromatography. If matrix support is polar (e.g. paper, silica etc.) it is forward phase chromatography, and if it is non-polar (C-18) it is reverse phase.
Techniques by chromatographic bed shape.
Column chromatography.
Column chromatography is a separation technique in which the stationary bed is within a tube. The particles of the solid stationary phase or the support coated with a liquid stationary phase may fill the whole inside volume of the tube (packed column) or be concentrated on or along the inside tube wall leaving an open, unrestricted path for the mobile phase in the middle part of the tube (open tubular column). Differences in rates of movement through the medium are calculated to different retention times of the sample.
In 1978, W. Clark Still introduced a modified version of column chromatography called flash column chromatography (flash). The technique is very similar to the traditional column chromatography, except for that the solvent is driven through the column by applying positive pressure. This allowed most separations to be performed in less than 20 minutes, with improved separations compared to the old method. Modern flash chromatography systems are sold as pre-packed plastic cartridges, and the solvent is pumped through the cartridge. Systems may also be linked with detectors and fraction collectors providing automation. The introduction of gradient pumps resulted in quicker separations and less solvent usage.
In expanded bed adsorption, a fluidized bed is used, rather than a solid phase made by a packed bed. This allows omission of initial clearing steps such as centrifugation and filtration, for culture broths or slurries of broken cells.
Phosphocellulose chromatography utilizes the binding affinity of many DNA-binding proteins for phosphocellulose. The stronger a protein's interaction with DNA, the higher the salt concentration needed to elute that protein.
Planar chromatography.
Planar chromatography is a separation technique in which the stationary phase is present as or on a plane. The plane can be a paper, serving as such or impregnated by a substance as the stationary bed (paper chromatography) or a layer of solid particles spread on a support such as a glass plate (thin layer chromatography). Different compounds in the sample mixture travel different distances according to how strongly they interact with the stationary phase as compared to the mobile phase. The specific Retention factor (Rf) of each chemical can be used to aid in the identification of an unknown substance.
Paper chromatography.
Paper chromatography is a technique that involves placing a small dot or line of sample solution onto a strip of "chromatography paper". The paper is placed in a container with a shallow layer of solvent and sealed. As the solvent rises through the paper, it meets the sample mixture, which starts to travel up the paper with the solvent. This paper is made of cellulose, a polar substance, and the compounds within the mixture travel farther if they are non-polar. More polar substances bond with the cellulose paper more quickly, and therefore do not travel as far.
Thin layer chromatography.
Thin layer chromatography (TLC) is a widely employed laboratory technique and is similar to paper chromatography. However, instead of using a stationary phase of paper, it involves a stationary phase of a thin layer of adsorbent like silica gel, alumina, or cellulose on a flat, inert substrate. Compared to paper, it has the advantage of faster runs, better separations, and the choice between different adsorbents. For even better resolution and to allow for quantification, high-performance TLC can be used. An older popular use had been to differentiate chromosomes by observing distance in gel (separation of was a separate step).
Displacement chromatography.
The basic principle of displacement chromatography is:
A molecule with a high affinity for the chromatography matrix (the displacer) competes effectively for binding sites, and thus displace all molecules with lesser affinities.
There are distinct differences between displacement and elution chromatography. In elution mode, substances typically emerge from a column in narrow, Gaussian peaks. Wide separation of peaks, preferably to baseline, is desired for maximum purification. The speed at which any component of a mixture travels down the column in elution mode depends on many factors. But for two substances to travel at different speeds, and thereby be resolved, there must be substantial differences in some interaction between the biomolecules and the chromatography matrix. Operating parameters are adjusted to maximize the effect of this difference. In many cases, baseline separation of the peaks can be achieved only with gradient elution and low column loadings. Thus, two drawbacks to elution mode chromatography, especially at the preparative scale, are operational complexity, due to gradient solvent pumping, and low throughput, due to low column loadings. Displacement chromatography has advantages over elution chromatography in that components are resolved into consecutive zones of pure substances rather than “peaks”. Because the process takes advantage of the nonlinearity of the isotherms, a larger column feed can be separated on a given column with the purified components recovered at significantly higher concentrations.
Techniques by physical state of mobile phase.
Gas chromatography.
Gas chromatography (GC), also sometimes known as gas-liquid chromatography, (GLC), is a separation technique in which the mobile phase is a gas. Gas chromatographic separation is always carried out in a column, which is typically "packed" or "capillary". Packed columns are the routine work horses of gas chromatography, being cheaper and easier to use and often giving adequate performance. Capillary columns generally give far superior resolution and although more expensive are becoming widely used, especially for complex mixtures. Both types of column are made from non-adsorbent and chemically inert materials. Stainless steel and glass are the usual materials for packed columns and quartz or fused silica for capillary columns.
Gas chromatography is based on a partition equilibrium of analyte between a solid or viscous liquid stationary phase (often a liquid silicone-based material) and a mobile gas (most often helium). The stationary phase is adhered to the inside of a small-diameter (commonly 0.53 - 0.18mm inside diameter) glass or fused-silica tube (a capillary column) or a solid matrix inside a larger metal tube (a packed column). It is widely used in analytical chemistry; though the high temperatures used in GC make it unsuitable for high molecular weight biopolymers or proteins (heat denatures them), frequently encountered in biochemistry, it is well suited for use in the petrochemical, environmental monitoring and remediation, and industrial chemical fields. It is also used extensively in chemistry research.
Liquid chromatography.
Liquid chromatography (LC) is a separation technique in which the mobile phase is a liquid. It can be carried out either in a column or a plane. Present day liquid chromatography that generally utilizes very small packing particles and a relatively high pressure is referred to as high performance liquid chromatography (HPLC).
In HPLC the sample is forced by a liquid at high pressure (the mobile phase) through a column that is packed with a stationary phase composed of irregularly or spherically shaped particles, a porous monolithic layer, or a porous membrane. HPLC is historically divided into two different sub-classes based on the polarity of the mobile and stationary phases. Methods in which the stationary phase is more polar than the mobile phase (e.g., toluene as the mobile phase, silica as the stationary phase) are termed normal phase liquid chromatography (NPLC) and the opposite (e.g., water-methanol mixture as the mobile phase and C18 = octadecylsilyl as the stationary phase) is termed reversed phase liquid chromatography (RPLC).
Specific techniques under this broad heading are listed below.
Affinity chromatography.
Affinity chromatography is based on selective non-covalent interaction between an analyte and specific molecules. It is very specific, but not very robust. It is often used in biochemistry in the purification of proteins bound to tags. These fusion proteins are labeled with compounds such as His-tags, biotin or antigens, which bind to the stationary phase specifically. After purification, some of these tags are usually removed and the pure protein is obtained.
Affinity chromatography often utilizes a biomolecule's affinity for a metal (Zn, Cu, Fe, etc.). Columns are often manually prepared. Traditional affinity columns are used as a preparative step to flush out unwanted biomolecules.
However, HPLC techniques exist that do utilize affinity chromatogaphy properties. Immobilized Metal Affinity Chromatography (IMAC) is useful to separate aforementioned molecules based on the relative affinity for the metal (I.e. Dionex IMAC). Often these columns can be loaded with different metals to create a column with a targeted affinity.
Supercritical fluid chromatography.
Supercritical fluid chromatography is a separation technique in which the mobile phase is a fluid above and relatively close to its critical temperature and pressure.
Techniques by separation mechanism.
Ion exchange chromatography.
Ion exchange chromatography (usually referred to as ion chromatography) uses an ion exchange mechanism to separate analytes based on their respective charges. It is usually performed in columns but can also be useful in planar mode. Ion exchange chromatography uses a charged stationary phase to separate charged compounds including anions, cations, amino acids, peptides, and proteins. In conventional methods the stationary phase is an ion exchange resin that carries charged functional groups that interact with oppositely charged groups of the compound to retain. Ion exchange chromatography is commonly used to purify proteins using FPLC.
Size-exclusion chromatography.
Size-exclusion chromatography (SEC) is also known as gel permeation chromatography (GPC) or gel filtration chromatography and separates molecules according to their size (or more accurately according to their hydrodynamic diameter or hydrodynamic volume).
Smaller molecules are able to enter the pores of the media and, therefore, molecules are trapped and removed from the flow of the mobile phase. The average residence time in the pores depends upon the effective size of the analyte molecules. However, molecules that are larger than the average pore size of the packing are excluded and thus suffer essentially no retention; such species are the first to be eluted. It is generally a low-resolution chromatography technique and thus it is often reserved for the final, "polishing" step of a purification. It is also useful for determining the tertiary structure and quaternary structure of purified proteins, especially since it can be carried out under native solution conditions.
Expanded Bed Adsorption (EBA) Chromatographic Separation.
Expanded Bed Adsorption (EBA) Chromatographic Separation captures a target protein from a crude feed stream when it passes through a chromatography column system containing adsorbent beads. With this technique the crude feedstock can be treated directly in the chromatographic column, avoiding the traditional clarification and pre-treatment steps. EBA Chromatographic Separation is highly scalable, from laboratory-based 1 cm diameter columns to large production columns up to 2 meter in diameter. These columns can typically handle feed stock throughput of more than 1,000,000 liter per day with a production capacity of 1000 MT protein per year.
Special techniques.
Reversed-phase chromatography.
Reversed-phase chromatography (RPC) is any liquid chromatography procedure in which the mobile phase is significantly more polar than the stationary phase. It is so named because in normal-phase liquid chromatography, the mobile phase is significantly less polar than the stationary phase. Hydrophobic molecules in the mobile phase tend to adsorb to the relatively hydrophobic stationary phase. Hydrophilic molecules in the mobile phase will tend to elute first. Separating columns typically comprise a C8 or C18 carbon-chain bonded to a silica particle substrate.
Hydrophobic interactions between proteins and the chromatographic matrix can be exploited to purify the proteins. In hydrophobic interaction chromatography, the matrix material is lightly substituted with octyl or phenyl groups. At high salt concentrations, nonpolar groups on the surface on proteins "interact" with the hydrophobic groups; that is, both types of groups are excluded by the polar solvent (hydrophobic effects are augmented by increased ionic strength). The eluant is typically an aqueous buffer with decreasing salt concentrations, increasing concentrations of detergent (which disrupts hydrophobic interactions), or changes in pH.
Two-dimensional chromatography.
In some cases, the chemistry within a given column can be insufficient to separate some analytes. It is possible to direct a series of unresolved peaks onto a second column with different physico-chemical (Chemical classification) properties. Since the mechanism of retention on this new solid support is different from the first dimensional separation, it can be possible to separate compounds that are indistinguishable by one-dimensional chromatography.
The sample is spotted at one corner of a square plate,developed, air-dried, then rotated by 90° and usually redeveloped in a second solvent system.
Simulated moving-bed chromatography.
The simulated moving bed (SMB) technique is a variant of high performance liquid chromatography; it is used to separate particles and/or chemical compounds that would be difficult or impossible to resolve otherwise. This increased separation is brought about by a valve-and-column arrangement that is used to lengthen the stationary phase indefinitely.
In the moving bed technique of preparative chromatography the feed entry and the analyte recovery are simultaneous and continuous, but because of practical difficulties with a continuously moving bed, simulated moving bed technique was proposed. In the simulated moving bed technique instead of moving the bed, the sample inlet and the analyte exit positions are moved continuously, giving the impression of a moving bed.
True moving bed chromatography (TMBC) is only a theoretical concept. Its simulation, SMBC is achieved by the use of a multiplicity of columns in series and a complex valve arrangement, which provides for sample and solvent feed, and also analyte and waste takeoff at appropriate locations of any column, whereby it allows switching at regular intervals the sample entry in one direction, the solvent entry in the opposite direction, whilst changing the analyte and waste takeoff positions appropriately as well.
Pyrolysis gas chromatography.
Pyrolysis gas chromatography mass spectrometry is a method of chemical analysis in which the sample is heated to decomposition to produce smaller molecules that are separated by gas chromatography and detected using mass spectrometry.
Pyrolysis is the thermal decomposition of materials in an inert atmosphere or a vacuum. The sample is put into direct contact with a platinum wire, or placed in a quartz sample tube, and rapidly heated to 600–1000 °C. Depending on the application even higher temperatures are used. Three different heating techniques are used in actual pyrolyzers: Isothermal furnace, inductive heating (Curie Point filament), and resistive heating using platinum filaments. Large molecules cleave at their weakest points and produce smaller, more volatile fragments. These fragments can be separated by gas chromatography. Pyrolysis GC chromatograms are typically complex because a wide range of different decomposition products is formed. The data can either be used as fingerprint to prove material identity or the GC/MS data is used to identify individual fragments to obtain structural information. To increase the volatility of polar fragments, various methylating reagents can be added to a sample before pyrolysis.
Besides the usage of dedicated pyrolyzers, pyrolysis GC of solid and liquid samples can be performed directly inside Programmable Temperature Vaporizer (PTV) injectors that provide quick heating (up to 30 °C/s) and high maximum temperatures of 600–650 °C. This is sufficient for some pyrolysis applications. The main advantage is that no dedicated instrument has to be purchased and pyrolysis can be performed as part of routine GC analysis. In this case quartz GC inlet liners have to be used. Quantitative data can be acquired, and good results of derivatization inside the PTV injector are published as well.
Fast protein liquid chromatography.
Fast protein liquid chromatography (FPLC), is a form of liquid chromatography that is often used to analyze or purify mixtures of proteins. As in other forms of chromatography, separation is possible because the different components of a mixture have different affinities for two materials, a moving fluid (the "mobile phase") and a porous solid (the stationary phase). In FPLC the mobile phase is an aqueous solution, or "buffer". The buffer flow rate is controlled by a positive-displacement pump and is normally kept constant, while the composition of the buffer can be varied by drawing fluids in different proportions from two or more external reservoirs. The stationary phase is a resin composed of beads, usually of cross-linked agarose, packed into a cylindrical glass or plastic column. FPLC resins are available in a wide range of bead sizes and surface ligands depending on the application.
Countercurrent chromatography.
Countercurrent chromatography (CCC) is a type of liquid-liquid chromatography, where both the stationary and mobile phases are liquids. 
The operating principle of CCC equipment requires a column consisting of an open tube coiled around a bobbin. The bobbin is rotated in a double-axis gyratory motion (a cardioid), which causes a variable gravity (G) field to act on the column during each rotation. This motion causes the column to see one partitioning step per revolution and components of the sample separate in the column due to their partitioning coefficient between the two immiscible liquid phases used. There are many types of CCC available today. These include HSCCC (High Speed CCC) and HPCCC (High Performance CCC). HPCCC is the latest and best performing version of the instrumentation available currently.
Chiral chromatography.
Chiral chromatography involves the separation of stereoisomers. In the case of enantiomers, these have no chemical or physical differences apart from being three-dimensional mirror images. Conventional chromatography or other separation processes are incapable of separating them. To enable chiral separations to take place, either the mobile phase or the stationary phase must themselves be made chiral, giving differing affinities between the analytes. Chiral chromatography HPLC columns (with a chiral stationary phase) in both normal and reversed phase are commercially available.

</doc>
<doc id="6330" url="http://en.wikipedia.org/wiki?curid=6330" title="Clement Martyn Doke">
Clement Martyn Doke

Clement Martyn Doke (16 May 1893 in Bristol, United Kingdom – 24 February 1980 in East London, South Africa) was a South African linguist working mainly on African languages. Realizing that the grammatical structures of Bantu languages are quite different from those of European languages, he was one of the first African linguists of his time to abandon the Euro-centric approach to language description for a more locally grounded one. A most prolific writer, he published a string of grammars, several dictionaries, comparative work, and a history of Bantu linguistics.
Missionary in Lambaland.
The Doke family had been engaged in missionary activity for the Baptist Church for some generations. His father Reverend Joseph J. Doke left England and travelled to South Africa in 1882, where he met and married Agnes Biggs. They returned to England, where Clement was born as the third of four children. The family moved to New Zealand and eventually returned to South Africa in 1903, where they later on settled in Johannesburg.
At the age of 18, Clement received a bachelor's degree from Transvaal University College in Pretoria (now the University of Pretoria). He decided to devote his life to missionary activity. In 1913, he accompanied his father on a tour of north-western Rhodesia, to an area called Lambaland, now known as Ilamba. It is situated at the watershed of the Congo and Zambesi rivers, part of the district lay in Northern Rhodesia and part in the Belgian Congo State. The Cape-Cairo Railway threaded through its eastern portion; otherwise, travelling mostly had to be done on foot.
The Reverend William Arthur Phillips of the Nyasa Industrial Mission in Blantyre had established a Baptist mission there in 1905, serving an area of and 50,000 souls. The Dokes were supposed to investigate, whether the mission in Lambaland could be taken over by the Baptist Union of South Africa. It was on this trip that Doke's father contracted enteric fever and died soon afterwards (Gandhi attended the memorial service and addressed the congregation). Clement assumed his father's role.
The South African Baptists decided to take over Kafulafuta Mission, while its founder Reverend Phillips remained as superintendent. Clement Doke returned to Kafulafuta as missionary in 1914, followed by his sister Olive two years later.
The Lamba language.
At first, Clement Doke was frustrated by his inability to communicate with the Lamba. The only written material available at the time was a translation of Jonah and a collection of 47 hymns. Soon he mastered the language and published his first book "Ifintu Fyakwe Lesa" (The Things of God, a Primer of Scripture Knowledge) in 1917. He enrolled in Johannesburg as the extension of Transvaal University College for an MA degree. His thesis was published as "The Grammar of the Lamba language". The book is couched in traditional grammatical terms as Doke had not yet established his innovative method of analysis and description for the Bantu languages. His later "Textbook of Lamba Grammar" is far superior in this respect. 
Clement Doke was also interested in ethnology. In 1931 he compiled "The Lambas of Northern Rhodesia", which remains one of the outstanding ethnographic descriptions of the peoples of Central Africa. For Doke, literacy was part of the evangelisation since people had to able to read to appreciate the message of the Bible, but it was only after his retirement that he completed the translation of the Bible into Lamba. It was published under the title of "Amasiwi AwaLesa" (The Words of God) in 1959.
University of the Witwatersrand.
In 1919 Doke married Hilda Lehmann, who accompanied him back to Lambaland. They both contracted malaria during their work and she was forbidden to return to Lambaland. Clement Doke also realised that his field work couldn't continue much longer and left in 1921. He was recruited by the newly founded University of the Witwatersrand. In order to secure a qualification as a lecturer, the family moved to England, where he registered at the School of Oriental and African Studies. His major languages were Lamba and Luba, but as no suitable examiner was available, he eventually had to change his language to Zulu.
Doke took up his appointment in the new Department of Bantu Studies at the University of Witwatersrand in 1923. In 1925 he received his D. Litt. for his doctoral thesis "The Phonetics of the Zulu Language" and was promoted to Senior Lecturer. In 1931 he was appointed to the Chair of Bantu Studies and thus headed the Department of Bantu Studies. The Department acted as a catalyst for the admission of Africans to the University: as early as 1925 a limited number were admitted to the vacation course in African Studies. Doke supported the appointment of Benedict Wallet Vilakazi as member of the staff, as he believed a native speaker was essential for acquiring a language. This provoked a storm of criticism and controversy from the public. They both collaborated on the "Zulu-English Dictionary", first published in 1948. It is still one of the best examples of lexicography for any of the Bantu languages. 
At the request of the government of Southern Rhodesia, Doke investigated the range of dialect diversity among the languages of the country and made recommendations for "Unified Shona". This formed the basis for Standard Shona. He devised a unified orthography based on the Zezuru, Karanga and Manyika dialects. However, Doke's orthography was never fully accepted and the South African government introduced an alternative, leaving Shona with two competing orthographies between 1935 and 1955.
During his tenure Doke developed and promoted a method of linguistic analysis and description of the Bantu languages that was based upon the structure of these languages. The "Dokean model" continues to be one of the dominant models of linguistic description in Southern and Central Africa. His classification of the Bantu languages was for many years the dominant view of the interrelations among the African languages. He was also an early describer of Khoisan and Bantu click consonants, devising phonetic symbols for a number of them. 
Doke served the University of the Witwatersrand until his retirement in 1953. He was awarded the honorary degree of Doctor of letters by Rhodes University and the honorary degree of Doctor of Laws by the University of the Witwatersrand in 1972.
The former missionary always remained devoted to the Baptist Church. He was elected President of the South African Baptist Union in 1949 and spent a year visiting churches and mission stations. He used his presidential address in condemning the recently established apartheid policy: "I solemnly warn the Government that the spirit behind their apartheid legislation, and the way in which they are introducing discriminatory measures of all types today, will bring disaster upon this fair land of ours."

</doc>
<doc id="6331" url="http://en.wikipedia.org/wiki?curid=6331" title="Carl Meinhof">
Carl Meinhof

 
Carl Friedrich Michael Meinhof (July 23, 1857 – February 11, 1944) was a German linguist and one of the first linguists to study African languages.
Early years and career.
Meinhof was born in Barzwitz near Rügenwalde in the Province of Pomerania. He studied at the University of Tübingen and at the University of Greifswald. In 1905 he became professor at the School of Oriental Studies in Berlin. On 5 May 1933 he became a member of the Nazi Party.
Works.
His most notable work was developing comparative grammar studies of the Bantu languages, building on the pioneering work of Wilhelm Bleek. In his work, Meinhof looked at the common Bantu languages such as Swahili and Zulu to determine similarities and differences.
In his work, Meinhof looked at noun classes with all Bantu languages having at least 10 classes and with 22 classes of nouns existing throughout the Bantu languages, though his definition of noun class differs slightly from the accepted one, considering the plural form of a word as belonging to a different class from the singular form (thus leading, for example, to consider a language like French as having four classes instead of two). While no language has all 22 (later: 23) classes active, Venda has 20, Lozi has 18, and Ganda has 16 or 17 (depending on whether the locative class 23 "e-" is included). All Bantu languages have a noun class specifically for humans (sometimes including other animate beings).
Meinhof also examined other African languages, including groups classified at the time as Kordofanian, Bushman, Khoikhoi, and Hamitic.
Meinhof developed a comprehensive classification scheme for African languages. His classification was the standard one for many years (Greenberg 1955:3). It was superseded by those of Joseph Greenberg in 1955 and especially in 1963.
In 1902, Meinhof made recordings of East African music. These are among the first recordings made of traditional African music.
Controversial views.
In 1912, Carl Meinhof published "Die Sprachen Der Hamiten" (The Languages of the Hamites). He used the term Hamitic. Meinhof's system of classification of the Hamitic languages was based on a belief that "speakers of Hamitic became largely coterminous with cattle herding peoples with essentially Caucasian origins, intrinsically different from and superior to the 'Negroes of Africa'." However, in the case of the so-called Nilo-Hamitic languages (a concept he introduced), it was based on the typological feature of gender and a "fallacious theory of language mixture." Meinhof did this in spite of earlier work by scholars such as Lepsius and Johnston demonstrating that the languages which he would later dub "Nilo-Hamitic" were in fact Nilotic languages with numerous similarities in vocabulary with other Nilotic languages.
Family.
Carl Meinhof was the great-uncle (the brother of the grandfather) of Ulrike Meinhof, a founding member of the German Red Army Faction (RAF), a left-wing militant group, which operated in West Germany in the 1970s and 1980s.

</doc>
<doc id="6335" url="http://en.wikipedia.org/wiki?curid=6335" title="Cucurbitaceae">
Cucurbitaceae

The Cucurbitaceae are a plant family, sometimes called the gourd family, consisting of over a hundred genera, the most important of which are:
The plants in this family are grown around the tropics and in temperate areas, where those with edible fruits were among the earliest cultivated plants both in the Old and New World. The "Cucurbitaceae" family ranks among the highest of plant families for number and percentage of species used as human food.
The Cucurbitaceae consist of approximately 125 genera and 960 species, mainly in regions tropical and subtropical. All species are sensitive to frost. Most of the plants in this family are annual vines but there are also woody lianas, thorny shrubs, and trees ("Dendrosicyos"). Many species have large, yellow or white flowers. The stems are hairy and pentangular. Tendrils are present at 90° to the leaf petioles at nodes. Leaves are exstipulate alternate simple palmately lobed or palmately compound. The flowers are unisexual, with male and female flowers on different plants (dioecious) or on the same plant (monoecious). The female flowers have inferior ovaries. The fruit is often a kind of modified berry called a pepo.
Classification.
The about 125 existent genera in Cucurbitaceae include 960 species. The following is the classification as given by Charles Jeffrey in 1990. However, a 2011 study based on genetics does not support this taxonomy with two subfamilies and eight tribes, but rather delineates fifteen tribes, five of them new, consisting of 95 genera rather than Jeffrey's 121.
Subfamily Zanonioideae (small striate pollen grains)
Subfamily Cucurbitoideae (styles united into a single column)
Alphabetical list of genera:
"Abobra Acanthosicyos Actinostemma Alsomitra Ampelosycios Anacaona Apatzingania Apodanthera Bambekea Benincasa Biswarea Bolbostemma Brandegea Bryonia Calycophysum Cayaponia Cephalopentandra Ceratosanthes Chalema Cionosicyos Citrullus Coccinia Cogniauxia Corallocarpus Cremastopus Ctenolepis Cucumella Cucumeropsis Cucumis Cucurbita Cucurbitella Cyclanthera Dactyliandra Dendrosicyos Dicaelospermum Dieterlea Diplocyclos Doyerea Ecballium Echinocystis Echinopepon Edgaria Elateriopsis Eureiandra Fevillea Gerrardanthus Gomphogyne Gurania Guraniopsis Gymnopetalum Gynostemma Halosicyos Hanburia Helmontia Hemsleya Herpetospermum Hodgsonia Ibervillea Indofevillea Kedrostis Lagenaria Lemurosicyos Luffa Marah Melancium Melothria Melothrianthus Microsechium Momordica Muellerargia Mukia Myrmecosicyos Neoalsomitra Nothoalsomitra Odosicyos Oreosyce Parasicyos Penelopeia Peponium Peponopsis Polyclathra Posadaea Praecitrullus Pseudocyclanthera Pseudosicydium Psiguria Pteropepon Pterosicyos Raphidiocystis Ruthalicia Rytidostylis Schizocarpum Schizopepon Sechiopsis Sechium Selysia Seyrigia Sicana Sicydium Sicyos Sicyosperma Siolmatra Siraitia Solena Tecunumania Telfairia Thladiantha Trichosanthes Tricyclandra Trochomeria Trochomeriopsis Tumacoca Vaseyanthus Wilbrandia Xerosicyos Zanonia Zehneria Zombitsia Zygosicyos"
Ref: 3 September 2002

</doc>
<doc id="6336" url="http://en.wikipedia.org/wiki?curid=6336" title="Chorded keyboard">
Chorded keyboard

A keyset or chorded keyboard (also called a chorded keyset, "chord keyboard" or "chording keyboard") is a computer input device that allows the user to enter characters or commands formed by pressing several keys together, like playing a "chord" on a piano. The large number of combinations available from a small number of keys allows text or commands to be entered with one hand, leaving the other hand free. A secondary advantage is that it can be built into a device (such as a pocket-sized computer or a bicycle handlebar) that is too small to contain a normal-sized keyboard.
A chorded keyboard minus the board, typically designed to be used while held in the hand, is called a keyer. Douglas Engelbart introduced the chorded keyset as a computer interface in 1968 at what is often called "The Mother of All Demos".
Principles of operation.
Each key is mapped to a number and then can be mapped to a corresponding letter or command. By pressing two or more keys together the user can generate many combinations. In Engelbart's original mapping, he used five keys: 1,2,4,8,16. The keys were mapped as follows: a = 1, b = 2, c = 3, d = 4, and so on. If the user pressed keys 1 + 2 = 3 simultaneously the letter "c" appeared. Since Engelbart introduced the keyset, several different designs have been developed based on similar concepts.
As a crude example, each finger might control one key which corresponds to one bit in a byte, so that using seven keys and seven fingers, one could enter any character in the ASCII set—if the user could remember the binary codes. Due to the small number of keys required, chording is easily adapted from a desktop to mobile environment.
Practical devices generally use simpler chords for common characters ("e.g.," Baudot), or may have ways to make it easier to remember the chords ("e.g.," Microwriter), but the same principles apply. These portable devices first became popular with the wearable computer movement in the 1980s.
Douglas Engelbart filed two new patents for mobile chorded keyset devices and TipTap.mobi released a chording app for the iPhone with Douglas Engelbart in 2010.
Thad Starner from Georgia Institute of Technology and others published numerous studies showing that two handed chorded text entry was faster and yielded fewer errors than on a QWERTY keyboard. Currently stenotype machines hold the record for fastest word entry. Many stenotype users can reach 300 words per minute. However, stenographers typically train for three years before reaching professional levels of speed and accuracy.
History.
The earliest known chord keyboard was part of the "five-needle" telegraph operator station, designed by Wheatstone and Cooke in 1836, in which any two of the five needles could point left or right to indicate letters on a grid. It was designed to be used by untrained operators (who would determine which keys to press by looking at the grid), and was not used where trained telegraph operators were available.
The first widespread use of a chord keyboard was in the stenotype machine used by court reporters, which was invented in 1868 and is still in use. But the output of the stenotype is a phonetic code that has to be transcribed later (usually by the same operator who produced the original output), rather than arbitrary text.
In 1874, the five-bit Baudot telegraph code and a matching 5-key chord keyboard was designed to be used with the operator forming the codes manually. The code is optimized for speed and low wear: chords were chosen so that the most common characters used the simplest chords. But telegraph operators were already using typewriters with QWERTY keyboards to "copy" received messages, and at the time it made more sense to build a typewriter that could generate the codes automatically, rather than making them learn to use a new input device.
Some early keypunch machines used a keyboard with 12 labeled keys to punch the correct holes in paper cards. The numbers 0 through 9 were represented by one punch; 26 letters were represented by combinations of two punches, and symbols were represented by combinations of two or three punches.
Braille (a writing system for the blind) uses either 6 or 8 tactile 'points' from which all letters and numbers are formed. When Louis Braille invented it, it was produced with a needle holing successively all needed points in a cardboard sheet. In 1892, Frank Haven Hall, superintendent of the Illinois Institute for the Education of the Blind, created the Hall Braille Writer, which was like a typewriter with 6 keys, one for each dot in a braille cell. The Perkins Brailler, first manufactured in 1951, uses a 6-key chord keyboard (plus a spacebar) to produce braille output, and has been very successful as a mass market affordable product. Braille, like Baudot, uses a number symbol and a shift symbol, which may be repeated for shift lock, to fit numbers and upper case into the 31 codes that 6 bits offer.
After World War II, with the arrival of electronics for reading chords and looking in tables of "codes", the postal sorting offices started to research chordic solutions to be able to employ people other than trained and expensive typists. In 1954, an important concept was discovered: chordic production is easier to master when the production is done at the release of the keys instead of when they are pressed.
Researchers at IBM investigated chord keyboards for both typewriters and computer data entry as early as 1959, with the idea that it might be faster than touch-typing if some chords were used to enter whole words or parts of words. A 1975 design by IBM Fellow Nat Rochester had 14 keys that were dimpled on the edges as well as the top, so one finger could press two adjacent keys for additional combinations. Their results were inconclusive, but research continued until at least 1978.
Doug Engelbart began experimenting with keysets to use with the mouse in the mid 1960s. In a famous 1968 demonstration, Engelbart introduced a computer human interface that included the QWERTY keyboard, a three button mouse, and a five key keyset. Engelbart used the keyset with his left hand and the mouse with his right to type text and enter commands. To type a command Engelbart pressed one of the three buttons of the mouse.
Users in Engelbart's Augmentation Research Center at SRI became proficient with the mouse and keyset. In the 1970s the funding Engelbart's group received from the Advanced Research Projects Agency (ARPA) was cut and many key members of Engelbart's team went to work for Xerox PARC where they continued to experiment with the mouse and keyset. Keychord sets were used at Xerox PARC in the early 1980s, along with mice, GUIs, on the Xerox Star and Alto workstations. A one button version of the mouse was incorporated into the Apple Macintosh but Steve Jobs decided against incorporating the chorded keyset.
In the early 1980s, Philips Research labs at Redhill, Surrey did a brief study into small, cheap keyboards for entering text on a telephone. One solution used a grid of hexagonal keys with symbols inscribed into dimples in the keys that were either in the center of a key, across the boundary of two keys, or at the joining of three keys. Pressing down on one of the dimples would cause either one, two or three of the hexagonal buttons to be depressed at the same time, forming a chord that would be unique to that symbol. With this arrangement, a nine button keyboard with three rows of three hexagonal buttons could be fitted onto a telephone and could produce up to 33 different symbols. By choosing widely separated keys, one could employ one dimple as a 'shift' key to allow both letters and numbers to be produced. With eleven keys in a 3/4/4 arrangement, 43 symbols could be arranged allowing for lowercase text, numbers and a modest number of punctuation symbols to be represented along with a 'shift' function for accessing uppercase letters. While this had the advantage of being usable by untrained users via 'hunt and peck' typing and requiring one less key switch than a conventional 12 button keypad, it had the disadvantage that some symbols required three times as much force to depress them as others which made it hard to achieve any speed with the device. That solution is still alive and proposed by Fastap and Unitap among others, and a commercial phone has been produced and promoted in Canada during 2006.
Standards.
Historically, the baudot and braille keyboards were standardized to some extent, but they are unable to replicate the full character set of a modern keyboard. Braille comes closest, as it has been extended to eight bits.
The only proposed modern standard, GKOS (or Global Keyboard Open Standard) can support most characters and functions found on a computer keyboard but has had little commercial development. There is, however, a GKOS keyboard application available for iPhone since May 8, 2010, for Android since October 3, 2010 and for MeeGo Harmattan since October 27, 2011.
Open-source designs.
Three open-source keyer/keyset designs are available: The pickey a PS/2 device based on the PIC microcontroller, the spiffchorder a USB device based on the Atmel AVR family of microcontrollers, and the GKOS keypad driver for Linux as well as the Gkos library for the Atmel/Arduino open source board.
Plover is a free, open-source, cross-platform program intended to bring realtime stenographic technology not just to stenographers, but also to hobbyists using anything from professional Stenotype machines to low-cost NKRO gaming keyboards. It is available for GNU/Linux, MS Windows, and Apple Mac OS X.
Joy2chord is a chorded keyboard driver for GNU/Linux. With a configuration file, any joystick or gamepad can be turned into a chorded keyboard. This design philosophy was decided on to lower the cost of building devices, and in turn lower the entry barrier to becoming familiar with chorded keyboards. Macro keys, and multiple modes are also easily implemented with a user space driver.
Commercial devices.
One minimal chordic keyboard example is Edgar Matias' Half-Qwerty keyboard described in patent circa 1992 that produces the letters of the missing half when the user simultaneously presses the space bar along with the mirror key. INTERCHI '93 published a study by Matias, MacKenzie and Buxton showing that people who have already learned to touch-type can quickly recover 50 to 70% of their two-handed typing speed. The loss contributes to the speed discussion above. It is implemented on two popular mobile phones, each provided with software disambiguation, which allows users to avoid using the space-bar.
"Multiambic" keyers for use with wearable computers were invented in Canada in the 1970s. Multiambic keyers are similar to chording keyboards but without the board, in that the keys are grouped in a cluster for being handheld, rather than for sitting on a flat surface.
Chording keyboards are also used as portable but two handed input devices for the visually impaired (either combined with a refreshable braille display or vocal synthesis). Such keyboards use a minimum of seven keys, where each key corresponds to an individual braille point, except one key which is used as a spacebar. In some applications, the spacebar is used to produce additional chords which enable the user to issue editing commands, such as moving the cursor, or deleting words. Note that the number of points used in braille computing is not 6, but 8, as this allows the user, among other things, to distinguish between small and capital letters, as well as identify the position of the cursor. As a result, most newer chorded keyboards for braille input include at least nine keys.
Touch screen chordic keyboards are available to smartphone users as an optional way of entering text. As the number of keys is low the button areas can be made bigger and easier to hit on the small screen. The most common letters do not necessarily require chording as is the case with the GKOS keyboard optimised layouts (Android app) where the twelve most frequent characters only require single keys.
Historical.
The WriteHander, a 12-key chord keyboard from NewO Company, appeared in 1978 issues of ROM Magazine, an early microcomputer applications magazine.
Another early commercial model was the six-button Microwriter, designed by Cy Endfield and Chris Rainey, and first sold in 1980. Microwriting is the system of chord keying and is based on a set of mnemonics. It was designed only for right-handed use.
The BAT is a 7-key hand-sized device from Infogrip, and has been sold since 1985. It provides one key for each finger and three for the thumb. It is proposed for the hand which does not hold the mouse, in an exact continuation of Engelbart's vision.
Modern.
Modern examples of chorded keyboards include TipTapSpeech (using Engelbart's original mapping), the GKOS keyboard, the FrogPad, the In10did method, the EkaPad, TextFaster and HotTyper. Some of them are intended for tiny tablet computers and wireless mobile terminals, many of them are additionally available as apps on Apple's iOS devices. See also the on-screen virtual keyset at Teague Labs.
Chris Rainey, the co-inventor of Microwriter, re-introduced Microwriting for PC and Palm PDAs with a standalone miniature chording keyboard called CyKey which caters to both left and right-handed users, being 9-keys. CyKey (pronounced sai-ki) is named after the Microwriter chord system's co-inventor Cy Endfield, who died in 1995 but the name also reflects its intuitive nature.
The GKOS is a 6-key keyboard with a different signs and commands allocation of the 63 different chords in order to provide all PC keyboard functions and to make entering letters and numbers lighter by having to press fewer keys simultaneously. The 6 physical keys are intended to be on the back of the device and to be operated with the six free fingers of two hands holding the device. Another option is to have virtual GKOS keys positioned towards the sides of a touch sensitive screen. This so-called GKOS Thumbs has additional keys to enable all combos by only one keypress per hand. GKOS iPhone, Android phone/tablet and MeeGo Harmattan applications use this principle.
The EkaPad is a 12-key chorded keyboard operated with the four fingers of one hand. It is supported on the thumb. With the 9 main keys, (operated by the index, middle, and ring fingers), 2 prefix keys and one delete key, the EkaPad can produce all the inputs of a standard qwerty keyboard with one, two, and a few three finger chords. For some characters one or two prefix chords are required. 9 main keys (3×3 matrix) can produce a total of 511 chords. With each of the three fingers limited to its own row, 229 chords are possible with 3 fingers. EkaPad uses 66 of these accessible chords. One and two finger chords produce about 85% of American English; with an additional prefix chord about 97%. In addition, the EkaPad can store 100 text strings and 100 keyboard shortcuts. Like many other chorded keyboards, it can be used with one hand.
The FrogPad is a 20-key chorded keyboard about the size of a numeric keypad that can be used with one hand, and is optimized by character frequency. 85% of average keystrokes in English text can be typed without chording, and chords are limited to 2 fingers.
The IN10DID method (pronounced "intended") is a ten-key limited chord system that places one key under each finger in order to utilize all of them, however only two are needed for any operations (excluding the "F" keys, which require three key presses). Each key is essentially a shift key so that with ten keys, there are ten single strokes and ninety two-finger keystrokes. The alphabet is produced with a single press or by shifting with a thumb. Changing modes, such as number lock, can make other input provided with a single keystroke. This avoids complex chords while providing enough keystrokes for efficient typing and allows for some unique implementations such as typing with gloves. A video game controller called the X-SKIN, using this system, was expected to be commercially available by 2010 to help make MMORPGs popular on console systems and ease entry of common data such as a username and password, but announcement of its release was available on the in10did website as of 4 March 2012. The system can also be applied in a single hand configuration or as one key at a time if needed. Claimed advantages of the IN10DID method are the diversity of devices, limited motion and simple chords.
The Twiddler is a fully featured 16-key keyboard (plus mouse) designed to fit in the palm of one hand. It was originally introduced in the early 1990s by Handykey and is currently being produced by Tek Gear (Tek Gear acquired Handykey on April 30, 2008). It is popular among wearable computer researchers and hobbyists due to its ease of use, large community of users, and active support by the manufacturer. Every single and multi-key chord on the Twiddler can be customized by the end user. The Twiddler comes standard with an "A, B, C, D" chord set, with TabSpace and other chord sets available. Chords are not limited to single keystrokes - multiple keystrokes can be sent with a single chord press. An example of this is an email address or address block can be typed by pressing just one chord. The efficiency gained by using multi-character chords have novice Twiddler users typing at 47 WPM while experts can burst up to 130 WPM. 
ASETNIOP is a virtual keyboard based on chords that appeared in 2012. The alphabet uses the 8 keys of the home row as ASET and NIOP (the eight most common letters in the English language), plus 18 chorded combinations. The layout also makes a less-cluttered 10-button keypad for tablet computers, touchscreens, touchpads, and can be used in wired gloves.

</doc>
<doc id="6337" url="http://en.wikipedia.org/wiki?curid=6337" title="Carolyn Beug">
Carolyn Beug

Carolyn Ann Mayer-Beug (December 11, 1952 – September 11, 2001) was a filmmaker and video producer from Santa Monica, California. She died in the September 11 attacks.
Career.
In addition to her work as video producer, Beug also directed three music videos for country singer Dwight Yoakam: "Ain't That Lonely Yet", "A Thousand Miles from Nowhere" and "Fast as You." Beug co-directed the former two videos with Yoakam and was the sole director of the latter video. She won an award for the Van Halen music video of the song "Right Now", which she produced.
Personal life.
Beug lived in a Tudor-style home in the North 25th Street neighborhood. She hosted an annual backyard barbecue for the Santa Monica High School cross country and track team, which her daughters captained. Beug was a Latter Day Saint.
Death and legacy.
Beug was killed at the age of 48 in the crash of American Airlines Flight 11 in the September 11, 2001 attacks. At the time of her death, Carolyn Beug was working on a children's book about Noah's Ark which was to be told from Noah's wife's point of view. On the plane with her was her mother, Mary Alice Wahlstrom. Beug was survived by her twin eighteen-year-old daughters Lauren and Lindsey Mayer-Beug, her 13-year-old son, Nick, and her husband, John Beug, a senior vice president in charge of filmed production for Warner Brothers' record division. She was returning home from taking her daughters to college at the Rhode Island School of Design.
At the National 9/11 Memorial, Beug is memorialized at the North Pool, on Panel N-1.

</doc>
<doc id="6339" url="http://en.wikipedia.org/wiki?curid=6339" title="Cell biology">
Cell biology

Cell biology (formerly cytology, from the Greek "kytos", "contain") is a branch of biology that studies cells – their physiological properties, their structure, the organelles they contain, interactions with their environment, their life cycle, division, death and cell function. This is done both on a microscopic and molecular level. Cell biology research encompasses both the great diversity of single-celled organisms like bacteria and protozoa, as well as the many specialized cells in multicellular organisms such as humans, plants, and sponges.
Knowing the components of cells and how cells work is fundamental to all biological sciences. Appreciating the similarities and differences between cell types is particularly important to the fields of cell and molecular biology as well as to biomedical fields such as cancer research and developmental biology. These fundamental similarities and differences provide a unifying theme, sometimes allowing the principles learned from studying one cell type to be extrapolated and generalized to other cell types. Therefore, research in cell biology is closely related to genetics, biochemistry, molecular biology, immunology, and developmental biology.
Movement of proteins.
Each type of protein is usually sent to a particular part of the cell. An important part of cell biology is the investigation of molecular mechanisms by which proteins are moved to different places inside cells or secreted from cells.
Most proteins are synthesized by ribosomes in the rough endoplasmic reticulum (RER). Ribosomes contain the nucleic acid RNA, which assembles and joins amino acids to make proteins. They can be found alone or in groups within the cytoplasm as well as on the RER. This process is known as protein biosynthesis. Biosynthesis (also called biogenesis) is an enzyme-catalyzed process in cells of living organisms by which substrates are converted to more complex products (also simply known as protein translation). Some proteins, such as those to be incorporated in membranes (known as membrane proteins), are transported into the RER during synthesis. This process can be followed by transportation and processing in the Golgi apparatus. The Golgi apparatus is a large organelle that processes proteins and prepares them for use both inside and outside the cell. The Golgi apparatus is somewhat like a post office. It receives items (proteins from the ER), packages and labels them, and then sends them on to their destinations (to different parts of the cell or to the cell membrane for transport out of the cell). From the Golgi, membrane proteins can move to the plasma membrane, to other sub-cellular compartments, or they can be secreted from the cell. The endoplasmic reticulum (ER) and Golgi can be thought of as the "membrane protein synthesis compartment" and the "membrane protein processing compartment", respectively. There is a semi-constant flux of proteins through these compartments. ER and Golgi-resident proteins associate with other proteins but remain in their respective compartments. Other proteins "flow" through the ER and Golgi to the plasma membrane. Motor proteins transport membrane protein-containing vesicles along cytoskeletal tracks to distant parts of cells such as the axon terminals of neurons.
Some proteins that are made in the cytoplasm contain structural features that target them for transport into mitochondria or the cell nucleus. Some mitochondrial proteins are made inside mitochondria and are coded for by mitochondrial DNA. In plants, chloroplasts also make some cell proteins.
Extracellular and cell surface proteins destined to be degraded can move back into intracellular compartments upon being incorporated into endocytosed vesicles, some of which fuse with lysosomes where the proteins are broken down to their individual amino acids. The degradation of some membrane proteins begins while still at the cell surface when they are separated by secretases. Proteins that function in the cytoplasm are often degraded by proteasomes.
Techniques used to study cells.
Cells may be observed under the microscope, using several different techniques; these include optical microscopy, transmission electron microscopy, scanning electron microscopy, fluorescence microscopy, and confocal microscopy.
There are several different methods used in the study of cells:
Purification of cells and their parts
Purification may be performed using the following methods:

</doc>
<doc id="6340" url="http://en.wikipedia.org/wiki?curid=6340" title="Canadian English">
Canadian English

Canadian English (CanE, CE, en-CA) is the "standard" variety of English spoken in Canada. Canadian English is the sole first language, or "mother tongue", of approximately 18 million Canadians (57%), and one of two or more "mother tongues" for 450,000 Canadians (1%). The mother tongue of 7 million Canadians is French (22%), while another 6 million have a non-English, non-French mother tongue (21%). Approximately 20 million (65%) use English at home, while another 500,000 speakers are bilingual or trilingual in their homes. 61% of Canadians outside Quebec speak standard Canadian English as their mother tongue.
Standard Canadian English broadly encompasses the language variety as spoken by the majority of middle class Canadian anglophones. However, the complex colonial history, extreme regional isolation of many communities, and high level of non-English speaker immigration has left Canada with a diversity of regional variations and very distinct dialects, which are in some instances mutually unintelligible. Based on lexis and phonology, standard Canadian English is divided into eight dialect regions: British Columbia, the Prairies (Alberta, Saskatchewan, Manitoba,and northwestern Ontario), Southern Ontario, Greater Toronto, Eastern Ontario, Quebec (mostly Greater Montreal), the Maritimes (New Brunswick, Nova Scotia, Prince Edward Island), and Newfoundland and Labrador.
The term "Canadian English" first appears in a speech by the Reverend A. Constable Geikie in an address to the Canadian Institute in 1857. Geikie, a Scottish-born Canadian, reflected the Anglocentric attitude that would be prevalent in Canada for the next hundred years when he referred to the language as "a corrupt dialect", in comparison to what he considered the proper English spoken by immigrants from Britain.
Development of Standard Canadian English.
Modern standard Canadian English derives largely from variants of British English delivered over several centuries of colonisation in North America and through Canada's very close ties to British English as part of the British Empire and Commonwealth, to the present day. Recent studies have shown how it reflects an admixture of other languages, including those of the first nation's, Canadian French, Italian and Ukrainian and the English dialects of the United States. There had been some debate about the development of Canadian English, but these have been largely superseded by recent linguistic studies and data collection. The historic development of Canadian English is only recently the focus of scholarly study, while recent studies have shown the historically recent emergence of distinctly Canadian English features.
Spelling and dictionaries.
Canadian spelling of the English language combines British and American conventions.
Canadian spelling conventions can be partly explained by Canada's trade history. For instance, the British spelling of the word "cheque" probably relates to Canada's once-important ties to British financial institutions. Canada's automobile industry, on the other hand, has been dominated by American firms from its inception, explaining why Canadians use the American spelling of "tire" (hence, "Canadian Tire") and American terminology for the parts of automobiles (for example, "truck" instead of "lorry", "gasoline" instead of "petrol", "trunk" instead of "boot").
Canada's political history has also had an influence on Canadian spelling. Canada's first prime minister, John A. Macdonald, once directed the Governor General of Canada to issue an order-in-council directing that government papers be written in the British style.
A contemporary reference for formal Canadian spelling is the spelling used for Hansard transcripts of the Parliament of Canada (see "The Canadian Style" in Further reading below). Many Canadian editors, though, use the "Canadian Oxford Dictionary", often along with the chapter on spelling in "Editing Canadian English", and, where necessary (depending on context), one or more other references (see Further reading below.)
The first Canadian dictionaries of Canadian English were edited by Walter Spencer Avis and published by Gage Ltd. The "Beginner's Dictionary" (1962), the "Intermediate Dictionary" (1964) and, finally, the "Senior Dictionary" (1967) were milestones in Canadian English lexicography. Many secondary schools in Canada use these dictionaries. The dictionaries have regularly been updated since: the "Senior Dictionary" was renamed "Gage Canadian Dictionary" and exists in what may be called its 5th edition from 1997. Gage was acquired by Thomson Nelson around 2003. The latest editions were published in 2009 by HarperCollins.
In 1997, the "ITP Nelson Dictionary of the Canadian English Language" was another product but has not been updated since.
In 1998, Oxford University Press produced a Canadian English dictionary, after five years of lexicographical research, entitled "The Oxford Canadian Dictionary". A second edition, retitled "The Canadian Oxford Dictionary", was published in 2004. Just as in the older dictionaries, it includes uniquely Canadian words and words borrowed from other languages and surveyed spellings, such as whether "colour" or "color" was the more popular choice in common use. Paperback and concise versions (2005, 2006), with minor updates, are available.
The scholarly "Dictionary of Canadianisms on Historical Principles" ("DCHP") was first published in 1967 by Gage Ltd. It was a partner project of the "Senior Dictionary" (and appeared only a few weeks apart from it). The "DCHP" can be considered the "Canadian OED" because it documents the historical development of Canadian English words that can be classified as "Canadianisms". It therefore includes words such as "mukluk, Canuck, bluff", and "grow op" but does not list common core words such as "desk", "table", or "car". It is a specialist, scholarly dictionary but is not without interest to the general public. After more than 40 years, a second edition has been commenced at UBC in Vancouver in 2006.
Throughout part of the 20th century, some Canadian newspapers adopted American spellings (e.g., "color" as opposed to the British-based "colour"). The use of such spellings was the long-standing practice of the Canadian Press, perhaps since that news agency's inception, but visibly the norm prior to World War II. The practice of dropping the letter "u" in such words was also considered a labour-saving technique during the early days of printing in which movable type was set manually. Canadian newspapers also received much of their international content from American press agencies; therefore, it was much easier for editorial staff to leave the spellings from the wire services as provided.
More recently, Canadian newspapers have adopted the British spelling variants such as "-our" endings, notably with "The Globe and Mail" changing its spelling policy in October 1990. Other Canadian newspapers adopted similar changes later that decade, such as the Southam newspaper chain's conversion in September 1998. The "Toronto Star" adopted this new spelling policy in September 1997 after that publication's ombudsman discounted the issue earlier in the year. The "Star" had always avoided using recognized Canadian spelling, citing the "Gage Canadian Dictionary" in their defence. Controversy around this issue was frequent. When the "Gage Dictionary" finally adopted standard Canadian spelling, the "Star" followed suit.
With its unique blend of British and American orthographic styles, Canadian English has lead to particular words obtaining multiple accepted spelling denotations. As a result of the “Canadian compromise”, uniquely Canadian spellings have arose that combine elements of both British and American styles as is apparent with "maneuvre" that employs a British final -re yet utilizes the American -eu in place of the British -oeu which further emphasizes Canadian English's malleability. Eventually, the use of "maneuver" became more common than "manoeuvre", an indication that may reflect the perceived "Americanization" of Canadian English but it is simplistic to reduce such change to this notion because it ignores how American English is itself changing for reasons beyond intrinsic factors that may entail American English becoming more British among other things. While those of Nova Scotia, Ontario, and British Columbia tend to value the British style as being more "proper" than the American alternative as well as correspondingly preferring British style when uncertain of a particular spelling, those of Alberta, Manitoba, and Prince Edward Island are said to be inclined to follow the American form. It is interesting to note how Canadian English has and continues to be affected by the rise of computer technology with such implications as spell checkers potentially making Canadian English become more American as a consequence of spell checking aids for Canadian dialects often being inadequately adapted from American counterparts. Many editors of Canadian English insist upon the spelling of "programme" except where computer programs are concerned. This can be interpreted as perpetrating two divergent words with more specialized meanings than the parent word by virtue of segregating the original word's applicable use.
Phonemic incidence.
The pronunciation of certain words has both American and British influence; some pronunciations are more distinctively Canadian.
The intonation and pronunciation of some vowel sounds have similarities to the dialects of Scotland and to accents in Northern England such as Geordie, for example the raising to "about" to sound roughly like "aboot" or "aboat", is also heard in Scotland, the Tyneside, Chorley, and Bolton areas of England, Northern Ireland, and the Upper Midwest of the United States.
Homogeneity.
Almost since the onset of the study of Canadian English, the concept of linguistic homogeneity (i.e. contrary to regional variation, see below) has been an, at times even dominant, factor in the field (see for a comprehensive overview). However, while many linguists have held and still hold the homogeneity issue (put simply: "CE sounds the same from coast to coast"), it is clear that recent work has revealed regional variation based on national samples (e.g.,) that have been hitherto unavailable.
Regional variation.
Canada has very little dialect diversity compared to the United States. The provinces east of Ontario show the largest dialect diversity. Northern Canada is, according to William Labov, a dialect region in formation, and a homogeneous dialect has not yet formed. A very homogeneous dialect exists in Western and Central Canada, a situation that is similar to that of the Western United States. Labov identifies an inland region that concentrates all of the defining features of the dialect centred on the Prairies, with periphery areas with more variable patterns including the metropolitan areas of Vancouver and Toronto. This dialect forms a dialect continuum with the far Western United States; however, it is sharply differentiated from the Inland Northern United States. This is a result of the relatively recent phenomenon known as the Northern cities vowel shift; see below.
Western and Central Dialect.
As a variety of North American English, this variety is similar to most other forms of North American speech in being a rhotic accent, which is historically a significant marker in identifying different English varieties. However, in places with recent British migration, especially British Columbia, rhoticity is often less pronounced. 
Canadian raising.
Perhaps the most recognizable feature of Canadian English is Canadian raising. The diphthongs and are "raised" before voiceless consonants, namely , , , , and . In these environments, becomes . One of the few phonetic variables that divides Canadians regionally is the articulation of the raised allophone of : in Ontario, it tends to have a mid-central or even mid-front articulation, sometimes approaching , while in the West and Maritimes a more retracted sound is heard, closer to . Among some speakers in the Prairies and in Nova Scotia, the retraction is strong enough to cause some tokens of raised to merge with , so that "couch" and "coach" sound the same, and "about" sounds like "a boat". Canadian raising is found throughout western and central Canada, as well as in parts of the Atlantic Provinces. It is the strongest in southern Ontario, and is some what less pronounced in younger speakers in Vancouver B.C, a pattern which continues to be observed by linguistics across North America.
In most eastern regions "about" sounds like a-beh-oot , the prairies a-boat, and in southwestern BC nearest to (a non raised) a-bowt - especially among younger speakers. Speakers in Montreal whose first language was French often do not have the raising & enunciate it "a-bowt", even if there is no trace of a French accent anymore.
Many Canadians, especially in parts of the Atlantic provinces, do not possess Canadian raising. In the U.S., this feature can be found in areas near the border such as the Upper Midwest and parts of New England, although it is much less common than in Canada; raising of alone, however, is increasing in the U.S., and unlike raising of , is generally not noticed by people who do not have the raising.
Because of Canadian raising (C.R), many speakers are able to distinguish between words such as "writer" and "rider" – a feat otherwise impossible, because North American dialects turn intervocalic into an alveolar flap. Thus "writer" and "rider" are distinguished solely by their vowels, as the distinction between their consonants has been lost. Speakers who do not have C.R. cannot distinguish between these two words based on vowel sound alone.
The cot–caught merger and the Canadian Shift.
Almost all Canadians have the cot–caught merger, which also occurs in the Western US. Speakers do not distinguish (as in "caught") and (as in "cot"), which merge as either (more common in Western Canada) or (more common in Southern Ontario and in Atlantic Canada, where it might even be fronted). Speakers with this merger produce these vowels identically, and often fail to hear the difference when speakers who preserve the distinction (for example, speakers of General American and Inland Northern American English) pronounce these vowels. This merger has existed in Canada for several generations.
This merger creates a hole in the short vowel sub-system and triggers a sound change known as the Canadian Shift, which involves the front lax vowels . The of "bat" is lowered and retracted in the direction of (except in some environments, see below). Indeed, is further back in this variety than almost all other North American dialects; the retraction of was independently observed in Vancouver and is more advanced for Ontarians and women than for people from the Prairies or Atlantic Canada and men. Then, and may be lowered (in the direction of and ) and/or retracted; studies actually disagree on the trajectory of the shift. For example, Labov and others (2006) noted a backward and downward movement of in apparent time in all of Canada except the Atlantic Provinces, but no movement of was detected.
Therefore, in Canadian English, the short "a" and the short "o" are shifted in opposite directions to that of the Northern Cities shift, found across the border in the Inland Northern US, which is causing these two dialects to diverge: the Canadian short "a" is very similar in quality to the Inland Northern short "o"; for example, the production would be recognized as "map" in Canada, but "mop" in the Inland North.
The front vowel merger before /r/.
The Mary-marry-merry merger of front vowels [eɪ], [æ], [ɛ], respectively, before the intervocalic /r/, epitomizes this trend in North American speakers. In particular, scholars witness a trend in which Canadian English speakers merge front vowels TRAP (m[æ]rry) and FACE (M[eɪ]ry) towards the DRESS (m[ɛ]rry) front vowel, before intervocalic /r/. Thus, not only do "marry" and "Mary" themselves share the same-sounding vowel, transformed from [æ] and [eɪ] to [ɛ], but the pronunciation of "merry" (historically and presently with the DR[ɛ]SS front vowel) is now matched by "marry" and "Mary," all three of which have become exclusive homophones in Western-Central Canadian English speakers.
The front vowel merger before /r/ is the conventional trend in Canadian English speakers, with exceptions in Quebec and Newfoundland. Notably, while the merging of lexical sets DRESS to FACE, prevails in Canadian English, Boberg's MANCOVA study, conducted in 2008, demonstrates that the merging of TRAP to DRESS does not apply to English-speakers in Newfoundland, nor in urban Quebec (Montreal).
To Montreal Anglophones, "marry" and "merry" sound the same, sharing the [ɛ] front vowel before intervocalic /r/. Meanwhile, "Mary" retains its historical FACE ([eɪ]) front vowel, with differences ranging from 112 to 138 Hz from DRESS-vowel dominant "merry" and "marry". Comparatively, native English-speakers in rural (i.e. not Montreal) Quebec exhibited a mean difference of only 35 Hz in their respective pronunciations of [ær] and [ɛr]—results that echo the rest of Canadian speakers.
Moreover, this phonemic feature can also be observed on the coastal region of the mid-Atlantic United States; studies suggest that this resistance of conditioning the TRAP [æ] vowel to the DRESS [ɛ] and FACE [eɪ] vowels could be a British English retention. The resistance of the TRAP vowel merger before /r/ by Anglophones in Montreal, in which Quebec Anglophones predominantly reside, supports the British-English retention hypothesis.
It has been argued that the marry-merry merger has, in the past, been less general in Canada, with records of Ontario English speakers (1934, 1961) displaying "m[ɛr]ried", West Canadian English speakers (1976) maintaining distinct vowels in "marry" and "merry", and “some speakers” (1957) in Vancouver exhibiting the merger. Avis’ findings (1938) demonstrate a retention of distinct vowels in his generation, and a tendency towards TRAP-DRESS merging in the following generation.
Other features.
Most Canadians have two principal allophones of (raised to lower-mid position before voiceless consonants and low-central or low-back elsewhere) and three of (raised before voiceless consonants, fronted to or before nasals, and low-central elsewhere).
Unlike in many American English dialects, remains a low-front vowel in most environments in Canadian English. Raising along the front periphery of the vowel space is restricted to two environments – before nasal and voiced velar consonants – and varies regionally even in these. Ontario and Maritime Canadian English commonly show some raising before nasals, though not as extreme as in many American varieties. Much less raising is heard on the Prairies, and some ethnic groups in Montreal show no pre-nasal raising at all. On the other hand, some Prairie speech exhibits raising of before voiced velars ( and ), with an up-glide rather than an in-glide, so that "bag" sounds close to "vague".
The first element of (as in "start") tends to be raised. As with Canadian raising, the relative advancement of the raised nucleus is a regional indicator. A striking feature of Atlantic Canadian speech (the Maritimes and Newfoundland) is a nucleus that approaches the front region of the vowel space, accompanied by strong rhoticity, ranging from to . Western Canadian speech has a much more retracted articulation with a longer non-rhotic portion, approaching a mid-back quality, (though there is no tendency toward a merger with ). Articulation of in Ontario is in a position midway between the Atlantic and Western values.
Another change in progress in Canadian English, part of a continental trend affecting many North American varieties, is the fronting of , whereby the nucleus of moves forward to high-central or even high-front position, directly behind . There is a wide range of allophonic dispersion in the set of words containing (i.e., the GOOSE set), extending over most of the high region of the vowel space. Most advanced are tokens of in free position after coronals ("do", "too"); behind these are tokens in syllables closed with coronals ("boots", "food", "soon"), then tokens before non-coronals ("goof", "soup"); remaining in back position are tokens of before ("cool", "pool", "tool"). Unlike in some British speech, Canadian English does not show any fronting or unrounding of the glide of , and most Canadians show no parallel centralization of , which generally remains in back position, except in Cape Breton Island and Newfoundland.
Traditionally diphthongal vowels such as (as in "boat") and (as in "bait") have qualities much closer to monophthongs in some speakers especially in the Inland region.
Some older speakers still maintain a distinction between "whale" and "wail", and "do" and "dew".
Rhythm and intonation.
Another difference observed in General Canadian English (GenCan) in comparison to General American (GenAm) is a slight intonation difference. Canadians often possess a sing-songy cadence to their speech which isn't usually seen in most varieties of general american english which tends to be on average "flatter". The intonation difference may signify remnants of Scottish or Irish influence.
British Columbia.
British Columbia English has several words still in current use borrowed from the Chinook Jargon although the use of such vocabulary is observably decreasing. The most famous and widely used of these terms are "skookum" and "saltchuck". In the Yukon, "cheechako" is used for newcomers or greenhorns. A study shows that people from Vancouver exhibit more vowel retraction of before nasals than people from Toronto, and this retraction may become a regional marker of West Coast English.
Prairies (Manitoba, Saskatchewan and Alberta).
A strong Canadian raising exists in the prairie regions together with certain older usages such as "chesterfield" and "front room" also associated with the Maritimes. Aboriginal Canadians are a larger and more conspicuous population in prairie cities than elsewhere in the country and certain elements of aboriginal speech in English are sometimes to be heard. Similarly, the linguistic legacy, mostly intonation but also speech patterns and syntax, of the Scandinavian, Slavic and German settlers – who are far more numerous and historically important in the Prairies than in Ontario or the Maritimes – can be heard in the general milieu. Again, the large Métis population in Saskatchewan and Manitoba also carries with it certain linguistic traits inherited from French, Aboriginal and Celtic forebears.
Some terms are derived from immigrant groups or are just local inventions:
In farming communities with substantial Ukrainian, German or Mennonite populations, accents, sentence structure and vocabulary influenced by these languages is common. These communities are most common in the Saskatchewan Valley region of Saskatchewan and Red River Valley region of Manitoba.
Ontario.
Ottawa Valley.
The area to the north and west of Ottawa is heavily influenced by original Scottish, Irish, and German settlers, with many French loanwords. This is frequently referred to as the "Valley Accent".
Toronto.
Although only 1.5% of Torontonians speak French, a relatively low proportion of them (56.2%) are native speakers of English, according to the 2006 Census. As a result Toronto shows a more variable speech pattern.
Northern Ontario.
With a smaller, but more concentrated French population (notably in the cities of Timmins, North Bay and Sudbury) and sizable Aboriginal population, this area is somewhat unique as having elements from both the Western provinces and the rest of Ontario. Communities receive media from both directions, and residents travel frequently to both areas, prompting a blending of dialects. Sharp-eared locals can detect from word usage (soda versus pop, hoodie versus bunny hug) where one originated, "Down east" (east of Sault Ste. Marie and beyond the Great Lakes), or "Out West" (west of the Manitoba border).
Maritimes.
Many in the Maritime provinces – Nova Scotia, New Brunswick and Prince Edward Island – have an accent that sounds more like Scottish English and, in some places, Irish English than General American. Outside of major communities, dialects can vary markedly from community to community, as well as from province to province, reflecting ethnic origin as well as a past in which there were few roads and many communities, with some villages very isolated. Into the 1980s, residents of villages in northern Nova Scotia could identify themselves by dialects and accents distinctive to their village. The dialects of Prince Edward Island are often considered the most distinct grouping.
The phonology of Maritimer English has some unique features:
Newfoundland.
The varieties of English spoken in the province of Newfoundland and Labrador include several distinct English dialects. Newfoundland English differs in vowel pronunciation, morphology, syntax, and preservation of archaic adverbal-intensifiers. The dialect can vary markedly from community to community, as well as from region to region, reflecting ethnic origin as well as a past in which there were few roads and many communities, and fishing villages in particular remained very isolated. A few speakers have a transitional pin–pen merger.
Northern Canada.
First Nations and Inuit people from Northern Canada speak a version of Canadian English influenced by the phonology of their first languages. European Canadians in these regions are relatively recent arrivals, and have not produced a dialect that is distinct from southern Canadian English.
Vocabulary.
Where Canadian English shares vocabulary with other English dialects, it tends to share most with American English. Many terms are shared with Britain, but not with the majority of American speakers. In some cases British and the American terms coexist in Canadian English to various extents; a classic example is "holiday", often used interchangeably with "vacation", distinguishing the two between a trip elsewhere and general time off work respectively. In addition, the vocabulary of Canadian English also features words that are seldom (if ever) found elsewhere. A good resource for these and other words is the Dictionary of Canadianisms on Historical Principles (Avis and others. 1967), which is currently being revised at the University of British Columbia, Vancouver.
As a member of the Commonwealth of Nations, Canada shares many items of institutional terminology and professional designations with the countries of the former British Empire – for example, "constable", for a police officer of the lowest rank, and "chartered accountant".
Education.
The term "college", which refers to post-secondary education in general in the U.S., refers in Canada to either a post-secondary technical or vocational institution, or to one of the colleges that exist as federated schools within some Canadian universities. Most often, a "college" is a community college, not a university. It may also refer to a pre-university college in Quebec. In Canada, "college student" might denote someone obtaining a diploma in business management while "university student" is the term for someone earning a bachelor's degree. For that reason, "going to college" does not have the same meaning as "going to university", unless the speaker or context clarifies the specific level of post-secondary education that is meant.
Within the public school system the chief administrator of a school is generally "the principal", as in the United States, but the term is not used preceding his or her name, i.e. "Principal Smith". The assistant to the principal is not titled as "assistant principal", but rather as "vice-principal", although the former is not unknown. This usage is identical to that in Northern Ireland.
Canadian universities publish "calendars" or "schedules", not "catalogs" as in the U.S. Canadian students "write" or "take" exams (in the U.S., students generally "take" exams while teachers "write" them); they rarely "sit" them (standard British usage). Those who supervise students during an exam are sometimes called "invigilators" as in Britain, or sometimes "proctors" as in the U.S., but most often the general term "teaching assistant (TA)" is used; usage may depend on the region or even the individual institution.
Successive years of school are usually referred to as "grade one", "grade two", and so on. In Quebec, the speaker (if Francophone) and referring to grade school, will often say "first year" (grade 1), "second year" (grade 2) (a direct translation from the French), and so on; while Anglophones will say "grade one", "grade two". (Compare American "first grade, second grade" (sporadically found in Canada), and English/Welsh "Year 1, Year 2", Scottish/Nth. Irish "Primary 1, Primary 2" or "P1, P2", and Sth. Irish "First Class, Second Class" and so on.). In Nova Scotia only, the first year of school is called "grade primary".
In the U.S., the four years of high school are termed the freshman, sophomore, junior, and senior years (terms also used for college years); in Canada, the specific levels are used instead (i.e., "grade nine"), except in Quebec where the five years of high school are termed "secondary 1" (lowest/freshman) to "secondary 5" (highest/senior). Also in Quebec, high schools are often either "junior" (secondary 1 to secondary 3) institutions or "senior" (secondary 4 and 5), more similar to the U.S. As for higher education, only the term "freshman" (often reduced to "frosh") has some currency in Canada. The American usages "sophomore", "junior" and "senior" are not used in Canadian university terminology, or in speech. The specific high-school grades and university years are therefore stated and individualized; for example, "the grade 12s failed to graduate"; "John is in his second year at McMaster". The "first year", "third year" designation also applies to Canadian law school students, as opposed to the common American usage of "1L", "2L" and "3L."
Canadian students use the term "marks" (more common in England) or "grades" (more common in the U.S.) to refer to their results; usage is very mixed.
Units of measurement.
Unlike in the United States, use of metric units within a majority of industries (but not all) is standard in Canada, as a result of the national adoption of the Metric System during the mid-to-late 1970s; this has spawned some colloquial usages such as "klick" for kilometre (as also heard in the U.S. military). See metrication in Canada. Nonetheless, Imperial units are still used in many situations. For example, most English Canadians state their weight and height in pounds and feet/inches, respectively. Distances while playing golf are always marked and discussed in yards, though official scorecards may also show metres. Temperatures for cooking are often given in Fahrenheit, while the weather is given in Celsius. Directions in the Prairie provinces are sometimes given using miles, because the country roads generally follow the mile-based grid of the Dominion Land Survey. It is also common practice in the Prairies to measure distance, particularly on the highway, in travel time rather than the actual distance. Canadians measure property, both residential and commercial, in square feet exclusively. Fuel efficiency is frequently discussed in miles per gallon, less often the metric L/100 km. The letter paper size of 8.5 inches × 11 inches is used instead of the international and metric A4 size of 210 mm × 297 mm.
Transportation.
However, "expressway" may also refer to a limited-access road that has control of access but has at-grade junctions, railway crossings (for example, the Harbour Expressway in Thunder Bay.) Sometimes the term "parkway" is also used (for example, the Hanlon Parkway in Guelph). The terms "grid road" (Saskatchewan) and "mile road" (Manitoba) are used to refer to minor highways or rural roads, usually gravel, referring to the Dominion Land Survey grid upon which they were originally designed. In Quebec, freeways and expressways are sometimes called by the French term "autoroutes"; however, native English speakers use the term "highway".
In Alberta, the generic "trail" is often used to describe a freeway, expressway or major urban street (for example, Deerfoot Trail, Macleod Trail or Crowchild Trail in Calgary, St. Albert Trail in Edmonton). The Yellowhead Trail in Edmonton is an exception, where it is simply referred to as "the Yellowhead". The British term "motorway" is not used. The American terms "turnpike" and "tollway" for a toll road are not common. The term "throughway" or "thruway" was used for first tolled limited-access highways (for example, the Deas Island Throughway, now Highway 99, from Vancouver, to Blaine, Washington, or the Saint John Throughway (Highway 1) in Saint John, New Brunswick), but this term is not common anymore. In everyday speech, when a particular roadway is not being specified, the term "highway" is generally or exclusively used.
Law.
Lawyers in all parts of Canada, except Quebec, which has its own civil law system, are called "barristers and solicitors" because any lawyer licensed in any of the common law provinces and territories must pass bar exams for, and is permitted to engage in, both types of legal practice in contrast to other common-law jurisdictions such as England, Wales and Ireland where the two are traditionally separated (i.e., Canada has a fused legal profession). The words "lawyer" and "counsel" (not "counsellor") predominate in everyday contexts; the word "attorney" refers to any personal representative. Canadian lawyers generally do not refer to themselves as "attorneys", a term which is common in the United States.
The equivalent of an American "district attorney", meaning the barrister representing the state in criminal proceedings, is called a "crown attorney" (in Ontario), "crown counsel" (in British Columbia), "crown prosecutor" or "the crown", on account of Canada's status as a constitutional monarchy in which the Crown is the locus of state power.
The words "advocate" and "notary" – two distinct professions in Quebec civil law – are used to refer to that province's equivalent of barrister and solicitor, respectively. In Canada's common law provinces and territories, the word "notary" means strictly a notary public.
Within the Canadian legal community itself, the word "solicitor" is often used to refer to any Canadian lawyer in general (much like the way the word "attorney" is used in the United States to refer to any American lawyer in general). Despite the conceptual distinction between "barrister" and "solicitor", Canadian court documents would contain a phrase such as ""John Smith, "solicitor" for the Plaintiff"" even though "John Smith" may well himself be the barrister who argues the case in court. In a letter introducing him/herself to an opposing lawyer, a Canadian lawyer normally writes something like ""I am the "solicitor" for Mr. Tom Jones."
The word "litigator" is also used by lawyers to refer to a fellow lawyer who specialises in lawsuits even though the more traditional word "barrister" is still employed to denote the same specialization.
Judges of Canada's superior courts (which exist at the provincial and territorial levels) are traditionally addressed as "My Lord" or "My Lady"; however, there are some variances across certain jurisdictions, with some superior court judges preferring the titles "Mister Justice" or "Madam Justice" to "Lordship".
Masters are addressed as "Mr. Master" or simply "Sir".
Judges of provincial or inferior courts are traditionally referred to in person as "Your Honour". Judges of the Supreme Court of Canada and of the federal-level courts prefer the use of "Mister/Madam (Chief) Justice". Justices of The Peace are addressed as "Your Worship". "Your Honour" is also the correct form of address for a Lieutenant Governor.
A serious crime is called an indictable offence, while a less-serious crime is called a summary offence. The older words felony and misdemeanour, which are still used in the United States, are not used in Canada's current "Criminal Code" (R.S.C. 1985, c. C-46) or by today's Canadian legal system. As noted throughout the "Criminal Code", a person accused of a crime is called "the accused" and not "the defendant", a term used instead in civil lawsuits.
In Canada, "visible minority" refers to a non-aboriginal person or group visibly not one of the majority race in a given population. The term comes from the Canadian Employment Equity Act, which defines such people as "persons, other than Aboriginal people, who are non-Caucasian in race or non-white in colour." The term is used as a demographic category by Statistics Canada. The qualifier "visible" is used to distinguish such minorities from the "invisible" minorities determined by language (English vs. French) and certain distinctions in religion (Catholics vs. Protestants).
A county in British Columbia means only a regional jurisdiction of the courts and justice system and is not otherwise connected to governance as with counties in other provinces and in the United States. The rough equivalent to "county" as used elsewhere is a "Regional District".
Places.
Distinctive Canadianisms are:
Daily life.
Terms common in Canada, Britain and Ireland but less frequent or nonexistent in the United States are:
The following are more or less distinctively Canadian:
Apparel.
The following are common in Canada, but not in the United States or the United Kingdom.
Informal speech.
A "rubber" in the U.S. and Canada is slang for a condom; however, in Canada it is sometimes (rarely except for Newfoundland and South Western Ontario) another term for an eraser (as it is in Australia, the United Kingdom and Ireland).
The word "bum" can refer either to the buttocks (as in Britain), or, derogatorily, to a homeless person (as in the U.S.). However, the "buttocks" sense does not have the indecent character it retains in British use, as it and "butt" are commonly used as a polite or childish euphemism for ruder words such as "arse" (commonly used in Atlantic Canada and among older people in Ontario and to the west) or "ass", or "mitiss" (used in the Prairie Provinces, especially in northern and central Saskatchewan; probably originally a Cree loanword). Older Canadians may see "bum" as more polite than "butt", which before the 1980s was often considered rude.
Similarly the word "pissed" can refer either to being drunk (as in Britain), or being angry (as in the U.S.), though anger is more often said as "pissed off", while "piss drunk" or "pissed up" is said to describe inebriation (though "piss drunk" is sometimes also used in the U.S., especially in the northern states).
Canadian colloquialisms.
One of the most distinctive Canadian phrases is the spoken interrogation "eh" (, ), used widely in Central Canada but less frequently in the prairies and Atlantic Canada. The tag is commonly mocked by films such as "", and treated more warm-heartedly within Canada itself by television programmes such as "The Red Green Show" and "The Royal Canadian Air Farce" and TV performers Bob and Doug McKenzie. The only usage of "eh" exclusive to Canada, according to the "Canadian Oxford Dictionary", is for "ascertaining the comprehension, continued interest, agreement, etc., of the person or persons addressed" as in, "It's four kilometres away, eh, so I have to go by bike." In that case, "eh?" is used to confirm the attention of the listener and to invite a supportive noise such as "mm" or "oh" or "okay". This usage is also common in Queensland, Australia and New Zealand. Other uses of "eh" – for instance, in place of "huh?" or "what?" meaning "please repeat or say again" – are also found in parts of the British Isles and Australia.
In recent years it has been found that younger Canadians in the larger cities have been replacing "eh" with other words such as "right" at the end of sentences. It is not known if this trend will extend to rural areas, but such is normally the case.
The term "Canuck" simply means "Canadian" in its demonymic form, and, as a term used even by Canadians themselves, it is not considered derogatory. In the 19th century and early 20th century it tended to refer to French-Canadians, but Janey Canuck was used by Anglophone writer Emily Murphy in the 1920s and the "Johnny Canuck" comic book character of the 1940s. Throughout the 1970s, Canada's winning World Cup men's downhill ski team was called the "Crazy Canucks" for their fearlessness on the slopes. In the mid-1970s, Captain Canuck was a comic book superhero. It is also the name of the Vancouver Canucks, the National Hockey League team of Vancouver.
The term "hoser", popularized by Bob & Doug McKenzie, typically refers to an uncouth, beer-swilling male. Bob & Doug also popularized the use of "Beauty, eh", another western slang term which may be used in variety of ways. This describes something as being of interest, of note, signals approval or simply draws attention to it. 
A "Newf" or "Newfie" is someone from Newfoundland and Labrador; the term is sometimes considered derogatory. In Newfoundland, the term "Mainlander" refers to any Canadian (sometimes American, occasionally Labradorian) not from the island of Newfoundland. "Mainlander" is also occasionally used derogatorily.
In the Maritimes, a "Caper" or "Cape Bretoner" is someone from Cape Breton Island, a "Bluenoser" is someone with a thick, usually southern Nova Scotia accent or as a general term for a Nova Scotian (including Cape Bretoners, while an "Islander" is someone from Prince Edward Island (the same term is used in British Columbia for people from Vancouver Island, or the numerous islands along it). A "Haligonian" refers to someone from the city of Halifax.

</doc>
<doc id="6343" url="http://en.wikipedia.org/wiki?curid=6343" title="Czech language">
Czech language

Czech (; "čeština" ) is a West Slavic language spoken by over 10 million people. It is an official language in the Czech Republic, where most of its speakers reside, and claims minority language status in Slovakia. It is most closely related to Slovak—with which it is mutually intelligible— to other West Slavic languages like Polish, and then to other Slavic languages like Russian. Most of its vocabulary is based on roots shared with other Slavic and otherwise Indo-European languages, but many loanwords have been adopted in recent years, most of them associated with high culture.
Czech began life in its current branch as Old Czech before slowly dwindling in societal importance, being outclassed by German on its own land. In the mid-eighteenth century, however, the language underwent a revival, termed the Czech National Revival, in which Czech academics stressed the past accomplishments of their people and advocated for Czech to return as a written and esteemed language. The language has not changed much since this time, barring some minor morphological shifts and adoption of colloquial elements into formal varieties.
The language's phoneme inventory is of a moderate size: it includes five vowels—each of which is distinguished between short and long length—and twenty-five consonants, which are divided into "hard", "neutral", and "soft". Words may contain uncommon or complicated consonant clusters or be bereft of vowels altogether, and Czech contains a phoneme represented by the consonant "ř", which is believed not to exist elsewhere. However, Czech orthography is very simple and has been used by phonologists as a model.
As a member of the Slavic sub-family of Indo-European, Czech is a fusional language and highly inflected. Its nouns and adjectives undergo a complex system of declension that accounts for case, number, gender, animacy, and even whether words end in hard, neutral, or soft consonants. With somewhat less complexity, verbs are conjugated for tense, number, and gender, and also display aspect. Because of this inflection, Czech word order is very flexible, and words may be moved around freely to change emphasis or form questions.
Classification.
Czech is classified as a member of the West Slavic sub-branch of the Slavic branch of the expansive Indo-European family. This places it in the same branch as Polish, Kashubian, and Upper and Lower Sorbian, as well as Slovak. Slovak is by far its closest genetic neighbor, and the two languages are closer than any other pair of West Slavic languages, including Upper and Lower Sorbian, which share a name through association with the same ethnic group.
The West Slavic languages are all spoken in an area variously classified as part of Central or Eastern Europe. They are distinguished from East and South Slavic languages by features such as stress always being placed on the initial syllables of words, and from other members of the West Slavic family by features such as a more restricted distinction between "hard" and "soft" consonants, two classes of consonants explained further in "Phonology".
Mutual intelligibility.
Czech and Slovak has traditionally been considered mutually intelligible: speakers of the two languages can communicate with relative ease, more so than speakers of any other pair of languages within the West Slavic branch. However after the split of the Czechoslovakian state, intelligibility has declined for younger speakers. This is probably because Czech speakers now experience less exposure to Slovak, and vice versa.
Czech and Slovak have not undergone deliberate accentuation of minor linguistic differences in the name of nationalism, as has occurred with, for example, Bosnian, Serbian, and Croatian. However, most Slavic languages, Czech included, have been distanced in this way from Russian influences, due to widespread public resentment against the former Soviet Union, which occupied Czechoslovakia during the Cold War before this nation was divided into the current Czech Republic and Slovakia in 1993. Owing to the similarities between geographically close dialects of the two languages, Czech and Slovak form a dialect continuum, explained further in "Dialects".
In terms of phonetic differences, Czech is characterized by having a glottal stop before initial vowels, and Slovak by using long vowels less frequently than Czech. Slovak also has long forms of the consonants "r" and "l" for when they function as vowels. Overall, phonemic differences between the two languages are characterized as consistent, as typically happens between two dialects of the same language. As for the grammar, Czech has a vocative case, which Slovak does not. However, both languages have essentially the same syntax.
One study showed that the lexicons of Czech and Slovak differed by 80 percent, but this high percentage was found to stem mostly from differing orthographies and slight inconsistencies in morphological formation; Slovak morphology is more regular (e.g. "Praha" in the nominative case, when converted to the locative case, changes to "Praze" in Czech but "Prahe" in Slovak). In general, the lexicons are considered quite similar, with most differences lying in the everyday-life vocabulary and some scientific terminology. Slovak also contains somewhat more borrowings than Czech.
The similarities between Czech and Slovak led to the two sometimes being affectionately called a single language by scholars in the nineteenth century. These scholars referred to themselves as "Czechoslavs" ("Čechoslováci") and believed the two peoples were intrinsically connected in a way that excluded German Bohemians and, to a lesser extent, other Slavs and Hungarians. During the era of the unified First Czechoslovak Republic (1918–1938), "Czechoslovak" was designated as the Republic's single official language. However, the true situation was asymmetrical; both Czech and Slovak written standards were used. The official written standard of Slovak was modeled to some extent after literary Czech, and Czech was preferred for some official functions in the Slovak half of the Republic. The Czech influence on the Slovak language was protested against by Slovak scholars. When Slovakia broke off from Czechoslovakia in 1938 as the Slovak state, which then aligned with Nazi Germany in World War II, the Slovak literary language was deliberately distanced from Czech. When the Axis Powers lost the war and Czechoslovakia reformed, Slovak was able to develop somewhat on its own, but continued to be influenced by Czech. It was not until the Prague Spring of 1968 that Slovak gained full independence from and equality with Czech. Since this time, "Czechoslovak" has been used to refer to improvised pidgins of the two languages, which have arisen from mutual intelligibility decreasing.
History.
Origins: Proto-Czech and Old Czech.
Around the sixth century, a tribe of Slavs arrived in an area of Eastern Europe. According to legend, they were led by a hero named Čech, from whom the modern word "Czech" originates. These lands were shortly taken over by the Eurasian Avars, but the burgeoning ethnic group recaptured its old land from the Avars in the seventh century, led by a non-Czech named Samo. The ninth century brought with it the new state of Great Moravia, whose first ruler, Rastislav of Moravia, invited Byzantine ruler Michael III to send his missionaries over. These missionaries, Constantine and Methodius, converted the Czechs from traditional Slavic paganism to Orthodox Christianity and established an Orthodox church system. In addition, they brought the Latin alphabet for the West Slavs, who had had no writing system for their language before. Their language, later known as Proto-Czech, was only beginning to separate from the other West Slavic hatchlings, namely Proto-Slovak, Proto-Polish, and Proto-Sorbian. Among other features, Proto-Czech was marked by its ephemeral use of the voiced velar fricative consonant (/ɣ/) and consistently placing stress on the first syllables of words.
The Czechs' language had definitively separated from other Slavic tongues into what would later be called Old Czech by the thirteenth century, a classification that would extend through the sixteenth. Its use of cases differed from modern varieties. Old Czech did not yet have a vocative case or an animacy distinction, but declension paradigms for its six cases and three genders rapidly became more complicated – partly to differentiate homophones, although other causes are not known. Overall, Old Czech declension patterns resembled those of its Balto-Slavic cousin Lithuanian.
While Old Czech had a basic alphabet from which a general set of orthographical correspondences was drawn, it did not have a standard orthography. In addition, the language was liberal with sound clusters that no longer exist. It allowed "ě" (/jɛ/) after soft consonants, which has since shifted mostly to "e" (/ɛ/), and it allowed complex consonant clusters to be pronounced all at once rather than syllabically. A phonological phenomenon known as Havlik's law, which had begun during Proto-Slavic and took place in various forms in other Slavic languages, completed in Old Czech: counting backwards from the end of a clause, every odd-numbered yer was vocalized to a full vowel, while the other yers disappeared.
Bohemia, as the Czech civilization was known by then, rose in power over the centuries, as did its language in regional importance. This growth was expedited in the fourteenth century by Charles IV, Holy Roman Emperor, who founded Charles University in Prague in 1348. At this university flourished early literature in the Czech language: a Bible translation, hymns, and hagiography. Old Czech texts were produced outside the university as well, including poetry and cookbooks. Later in the fourteenth century, Jan Hus contributed significantly to the standardization of Czech orthography, advocated for widespread literacy among Czech commoners—particularly in religious contexts—and made early efforts at modeling written Czech after spoken varieties.
Overall, Czech continued to evolve and gain regional importance for hundreds of years, being used as a literary language in the Slovak lands since the early fifteenth century. A new Bible translation called the Kralice Bible appeared; it was published late in the sixteenth century, around the time of the King James and Luther versions, but was more linguistically conservative than either of them. The Kralice Bible's publication spawned widespread nationalistic feelings, and in 1615 the government of Bohemia declared that only Czech-speaking residents would be allowed to become full citizens or inherit goods or land. This bold move—along with the Czech upper classes converting from the Habsburg Empire's Catholicism to Protestantism—angered the Habsburgs and caused the Czechs to tumble into the Thirty Years' War, where they were summarily defeated at the Battle of White Mountain. Among other consequences such as the Czechs being made serfs, Bohemia's printing industry and linguistic and political rights were dismembered, so the Czech language now had no official regulation or governmental support. German quickly gained dominance in Bohemia.
Revival: Modern Czech.
The general consensus among linguists is that the modern standard form of the Czech language came into being in the eighteenth century. By this point, Czech had developed a literary tradition, after which the language has not changed much; journals from around this time have been described as possessing no meaningful differences from modern standard Czech, and Czechs nowadays can understand them with little difficulty. Among the changes conceded are the overall morphological shift of "í" into "ej" and "é" into "í" to take its place, though "é" survives for some uses, and the merging of "í" and the former "ejí". Sometime before the eighteenth century, the Czech language abandoned a distinction between phonemic /l/ and /ʎ/ (which survives in Slovak).
The Czech people gained a widespread sense of nationalistic pride during the mid-eighteenth century, inspired by the ideals of the European Age of Enlightenment a half-century earlier. Czech historians began to take pride in their people's accomplishments from the fifteenth through seventeenth centuries and, as a result, rebel against the Counter-Reformation in the Bohemian lands, which had regarded the Czech language and other non-Latin tongues with scorn. These scholars took to philology and studied sixteenth-century Czech texts, advocating for Czech to return as a language of high culture. This period has been termed the Czech National Revival or Renascence.
In 1809, during the National Revival, linguist and historian Josef Dobrovský released a German-language grammar of old Czech titled "Ausfürliches Lehrgebäude der böhmischen Sprache" ("Comprehensive Doctrine of the Bohemian Language"). Dobrovský had intended his book to be merely descriptive, as he did not think Czech had a realistic chance of returning as a widespread language. However, Josef Jungmann and other revivalists latched onto Dobrovský's work and advocated for a conservative standard of Czech to make a comeback. Other changes consciously made during this time included spelling reforms (notably, "í" being used in place of the former "j" and "j" in place of "g"), the use of "t" rather than "ti" to end infinitive verbs, and the de-capitalization of nouns (this capitalization had been borrowed from German). In general, these reforms to Czech distanced the language from Slovak. The modern academic community is divided on whether these conservative revivalists were motivated more by their nationalist ideology or because contemporary spoken Czech was unsuitable for formal and widespread usage.
Later on, however, allegiance to historical patterns was relaxed, and standard Czech took on a number of adoptions from Common Czech, a widespread informal register, that have been decried as "decay" or even "agony", such as leaving certain proper nouns undeclined. This has resulted in a relatively high level of homogeneity among all varieties of the Czech language.
Geographic distribution.
In 2005 and 2007, Czech was spoken by about 10 million residents of the Czech Republic. A Eurobarometer survey conducted between January and March 2012 found that 98% of Czech citizens had their nation's official language as their mother tongue – the third highest in the European Union, behind Malta and Hungary.
Through being the official language of the Czech Republic, a member of the European Union (EU) since 2004, Czech is one of the EU's official languages. The 2012 Eurobarometer survey found that Czech was the most spoken foreign language in Slovakia. Economist Jonathan van Parys collected data on knowledge of various languages across European nations to celebrate the 2012 European Day of Languages, and the five countries with the highest prevalence of Czech knowledge were as follows.
Czech speakers in Slovakia cluster mainly in its urban areas. Czech is recognized as a minority language in Slovakia; thus, citizens of this country who speak only Czech are allowed to interact with the government in their language to the extent that Slovak speakers are in theirs.
United States.
Immigration of Czechs from Europe to the United States occurred mainly between 1848 and 1914, and they brought their language with them. However, it is rarely taught in schools, instead being mainly offered at Czech heritage centers. Large communities of Czech Americans live in the states of Nebraska, Texas, and Wisconsin. In the 2000 United States Census, Czech was reported as the most common language spoken at home besides English in Valley, Butler, and Saunders Counties, Nebraska, and Republic County, Kansas. However, Spanish is by far the most common language spoken at home besides English, and when Spanish too was removed, Czech was the most common in over a dozen more counties of Nebraska, Kansas, Texas, North Dakota, and Minnesota. As of 2009, 70,500 Americans spoke Czech as their primary language; this placed it 49th among all languages, behind Turkish and ahead of Swedish.
Dialects.
The Czech language comprises a few regional dialects in addition to a general spoken standard and a closely related written standard. Czechs especially in rural areas have mostly spoken in their dialects; some are less than proficient in other dialects or in standard Czech. Beginning roughly with the second half of the twentieth century, however, dialect use among Czechs began to weaken. By the early 1990s, dialect use had become stigmatized and associated with the shrinking lower class; when represented in literature or other media, it was usually used for comedic effect rather than to sincerely represent its associated populace. Increasing availability of travel and media to populations speaking divergent dialects has encouraged them to shift to—or adopt alongside their own dialect—standard Czech. Moreover, while Czech has seen a high amount of scholarly interest for a Slavic language, this interest has focused mostly on modern standard Czech and ancient texts rather than on dialects of any time period. While standard Czech is still the norm for politicians, businesspeople, and other Czechs in formal situations, Common Czech is gaining hold in mass-media broadcasts and journalism.
The division of Czech into dialects is not consistent. One fairly high estimate made in 2003 comes from the Czech Statistical Office; it counts the following dialects.
The main colloquial dialect of the language, spoken especially near Prague but also elsewhere throughout the country, is known as Common Czech ("obecná čeština"). This term is, first and foremost, an academic distinction. Most Czechs either do not know the compound term "obecná čeština" or associate it with all vernacular or incorrect forms of Czech combined. Compared to standard Czech, Common Czech is characterized by generally simplified inflection patterns and some differences in sound distribution.
The general dialect of Moravia and Silesia is known widely as Moravian ("moravština"). During the Czech people's time in the Austro-Hungarian Empire, "Bohemian-Moravian-Slovak" was distinguished as a language aspiring citizens could register under, alongside German, Polish, and a few others. Among Czech dialects, only Moravian is distinguished in nationwide surveys by the Czech Statistical Office. As of 2011, 62,908 Czech citizens had Moravian as their only mother tongue, while 45,561 more were natively diglossal between Moravian and standard Czech.
Beginning in the sixteenth century, some varieties of Czech have resembled the Slovak language; in particular, southeastern Moravian dialects are sometimes considered to be dialects of Slovak rather than Czech. These dialects form a continuum between the Czech and Slovak languages and still use the same declension patterns for nouns and pronouns and the same verb conjugations as Slovak.
In a 1964 textbook on Czech dialectology, Prof. Břetislav Koudela used the following sentence to highlight phonetic differences between dialects.
Phonology.
Czech contains ten basic vowel phonemes and a further three only found in loanwords. They are /a/, /ɛ/, /ɪ/, /o/, and /u/, their long counterparts /aː/, /ɛː/, /iː/, /oː/ and /uː/, and three diphthongs, /ou̯/, /au̯/ and /ɛu̯/. The latter two diphthongs and the long /oː/ are only found in loanwords. Vowels are never reduced to schwa sounds when unstressed. Each word usually has primary stress on its first syllable; one exception is enclitics, minor monosyllabic words that receive no stress. In all words of more than two syllables, every odd-numbered syllable receives secondary stress. In all cases, stress is unrelated to vowel length; the possibility of stressed short vowels and unstressed long vowels can be confusing to learners of Czech whose native language combines the two features, such as English.
Voiced consonants with unvoiced counterparts are unvoiced at the end of a word or when followed by unvoiced consonants. As an unrelated feature, the body of Czech consonants is divided into "hard", "neutral", and "soft" consonants:
This distinction is not based on phonetic values of the sounds, but is used to describe the declension patterns of nouns which is based on the category of consonant that the word ends in. In orthography, hard consonants may not be followed by "i" or "í", nor soft ones by "y" or "ý", except in loanwords such as "kilogram" and in a few exceptions in declined nouns such as "tác" having the plural form "tácy". Neutral consonants may take either character. Hard consonants are sometimes referred to as "strong" and soft ones as "weak".
The phoneme represented by the letter "ř" (capital "Ř") is believed to be unique to Czech. It represents the raised alveolar non-sonorant trill (IPA: []), a sound somewhere between Czech's "r" and "ž" (example: ). Notably, it appears in the name "Dvořák".
The consonants /r/ and /l/ can be syllabic, meaning they act as syllable nuclei in place of a vowel. This can be difficult for outsiders to pronounce; there exists a Czech tongue twister that goes: "strč prst skrz krk" (stick [your] finger down [your] throat).
Consonants
Vowels
Vocabulary.
The vocabulary of Czech comes mostly from Slavic, Baltic, and other Indo-European roots. Generally, most verbs and prepositions are of Balto-Slavic origin, while pronouns and some verbs and prepositions are of wider Indo-European origin. Some loanwords from other languages have been reanalyzed through folk etymologies to resemble native Czech words, e.g. "hřbitov" (graveyard), "listina" (list).
Most loanwords in Czech come from one of two time periods. Initially, they arrived, mostly from German, Greek, and Latin, before the nationalist re-invigoration of Czech as a literary language. In recent times, as the Czech people have come in contact with more of the world, loanwords from a wider variety of languages have arrived: principally English and French, but also the likes of Hebrew, Arabic, and Persian. Lasting Russian loanwords have also been adopted, mainly concerning animal names and naval terms.
Older German loanwords tend to be seen as crude or even vulgar, while more recent adoptions from other tongues are often associated with high culture. Moreover, adoptions from Greek and Latin roots began to be rejected in the nineteenth century in favor of words based on older Czech words and common Slavic roots. For example, while the Polish word for "music" is "muzyka" and the Russian word "музыка" ("muzyka"), Czech uses "hudba".
Some Czech words have been adopted as loanwords into English and other languages, e.g. "robot" (from "robota" [labor]), and "polka" (from "polka" [Polish woman]).
Grammar.
Typical of Indo-European languages, Czech grammar is fusional: its nouns, verbs, and adjectives are inflected by phonological processes to modify their meanings and grammatical functions, and the use of easily separable affixes characteristic of agglutinative languages is limited. In Slavic languages inflection is particularly complex and pervasive, inflecting for many categories such as case, gender, and number of nouns and tense, aspect, mood and person, and number and gender of the grammatical subject in verbs.
Other parts of speech include adjectives, adverbs, numbers, question words, prepositions, conjunctions, and interjections. The rest stand on their own, but adverbs are mostly formed by taking the final "ý" or "í" of an adjective and replacing it with "e", "ě", or "o". Negative statements are formed simply by adding the affix "ne-" to the verb of the clause, with one exception: "je" (he is, she is, it is) becomes "není".
Sentence and clause structure.
Because the Czech language uses case marking to convey the grammatical functions of words in a sentence, rather than relying on word order as English does, Czech word order is quite flexible. Czech is also a pro-drop language, which describes the fact that in Czech an intransitive sentence can consist of only a verb; information about the pronominal category of the grammatical subject is encoded in the verb. There are however strict rules for the placement of words considered enclitica, primarily auxiliary verbs and pronouns, which must always fall in the second syntactic slot of a sentence, after the first stress bearing unit. The first slot must be filled with a subject, and object, a main form of a verb or an adverb or conjunction (though not the light conjunctions "a" "and", "i" "and even" or "ale" "but")
Czech syntax is primarily described as having the basic constituent order, Subject Verb Object in pragmatically neutral sentences. But in practice constituent order is highly flexible; sometimes all possible permutations of the main constituents of a clause are acceptable and used for pragmatic effects such as topicalization and focus. Although the language has a periphrastic passive construction like English, in colloquial usage word order changes is also frequently used to produce the passive meaning. For example changing the meaning from ‘Peter killed
Paul’ to ‘Paul was killed by Peter’ one may simply invert the order of subject and object: "Petr zabil Pavla" "Peter killed Paul", "Paul, Peter killed" "Pavla zabil Petr" which is possible because "Pavla" is marked with the accusative case, specifying that he is the grammatical object ( in this case the victim) of the verb.
Typically, any word at the end of a clause is to be emphasized, unless an upward intonation indicates that the sentence is a question. One example follows.
However, in parts of Bohemia such as Prague, questions such as "Jí pes bagetu?" that do not have a distinctive question word (such as "co" [what] or "kdo" [who]) are instead given intonation that slowly escalates from low to high, then quickly drops to low on the last word or phrase.
In Czech word order, adjectives precede nouns. Relative clauses are introduced by relativizers such as the adjective "který", which is analogous to the English relative pronouns "which", "that", "who", and "whom". As with other adjectives, it is declined into the appropriate case (see "Declension") to match its associated noun, as well as into the appropriate person and number. Relative clauses follow the noun they modify. The following is a glossed example.
English: I want to visit the university that John attends.
Declension.
In Czech, nouns and adjectives are declined into one of seven grammatical cases. Nouns are inflected to indicate the noun's use in the sentence. Czech has accusative grammatical alignment and marks nouns that function as grammatical subjects with nominative case, and grammatical objects with accusative case. The genitive case is used to mark possessors, as well as some kinds of movement. The remaining cases are the instrumental, the locative, the vocative and dative cases each used to describe different kinds of semantic relations such as movement or position, and secondary objects (dative) and obliques arguments such as instruments (instrumental case). Adjectives agree in case with the noun they are describing. When Czech children are formally learning their language's declension patterns, the cases are referred to by numbers, as follows. 
However, some grammars of Czech order the cases differently to group the nominative and accusative together, as well as the dative and locative, as these declension patterns are often identical. An added benefit of this order is to accommodate learners with experience in other inflected languages like Latin or Russian. This order is: nominative, accusative, genitive, dative, locative, instrumental, vocative.
Different prepositions require the nouns they modify to take different cases. The cases assigned by each preposition is largely predictable based on the physical or metaphorical direction or location conveyed by each preposition. For example, "od" (from, away from) and "z" (out of, off of) assign the genitive case. Complicating the system is that some prepositions may take any of multiple cases and change their meaning depending on the case. For example, "na" means "onto" or "for" when used with the accusative case, but "on" with the locative.
Examples of declension patterns (using prepositions) for a few nouns with adjectives follow. Only one plural example is given, as declension patterns for plurals are similar across genders. A full explanation of the system is much more complicated and is given at "Czech declension".
A glossed example of a sentence using multiple cases:
English: I carried the box into the house with my friend.
Gender and animacy.
Czech distinguishes three genders—masculine, feminine, and neuter—and masculine is further divided into animate and inanimate. With few exceptions, feminine nouns in the nominative case end with "-a", "-e", or "-ost"; neuter nouns with "-o", "-e", or "-í"; and masculine nouns with a consonant. Adjectives agree in gender with the nouns they modify and—for masculine nouns in the accusative/genitive singular and the nominative plural—also agree in animacy. The main effect of gender in Czech is the differences in noun and adjective declension, but there are other effects. For example, past-tense verbs take similar endings based on gender: e.g. "dělal" (he did/made); "dělala" (she did/made); "dělalo" (it did/made).
Number.
Nouns are also inflected for number, distinguishing between singular and plural. Typical for a Slavic language, Czech cardinal numbers one through four allow the nouns and adjectives they modify to take any case, but numbers over five place these nouns and adjectives in the genitive case. The Czech koruna is a handy example of this feature; it is shown here as the subject of a hypothetical sentence, and thus declined as genitive for numbers five and up.
Words for numbers decline for case and, for numbers one and two, also for gender. Numbers one through five are shown below as examples; they have some of the most exceptions among the numbers. The number one has declension patterns identical to those of the demonstrative pronoun, "to".
While Czech's main grammatical numbers are singular and plural, vestiges of a dual number remain. Most notably, some nouns referring to parts of the body that come in pairs have a dual form, e.g. "ruka" (hand) – "ruce", "noha" (leg) – "nohy", "oko" (eye) – "oči", "ucho" (ear) – "uši". Oddly, while two of these nouns are neuter in their singular forms, all dual nouns are treated as feminine. Czech has no standard declension scheme for dual nouns; their gender is relevant for their associated adjectives and verbs.
Verb conjugation.
Czech verb conjugation is generally less complex than noun and adjective declension because it codes for fewer categories. Verbs agree with their subjects in person (first, second, and third) and number (singular and plural) and are also conjugated for tense (past, present, and future). For example, the conjugated verb "mluvíme" (we speak) is in the present tense and the first-person plural; it is distinguished from other conjugations of the infinitive "mluvit" by its ending, "me".
Aspect.
As is typical in Slavic languages, Czech marks its verbs for one of two grammatical aspect categories: perfective and imperfective. Most verbs come in inflected aspectual pairs (e.g. "koupit" [perfective] – "kupovat" [imperfective]). The meaning is identical or similar in each case, but differs in that perfective verbs are seen as completed and imperfective verbs as ongoing. However, this does not mean that the perfective aspect is equal to the past tense and the imperfective aspect the present. In fact, any Czech verb of either aspect can be conjugated into any of the language's three tenses. More accurately, aspect describes the state of the action at the time specified by tense.
The verbs of most aspectual pairs differ in one of two ways: by prefixes or by suffixes. In prefix pairs, the perfective verb has an added prefix, e.g. imperfective "psát" (to write, to be writing) vs. perfective "napsat" (to write down, to finish writing). The most common prefixes are "na-", "o-", "po-", "s-", "u-", "vy-", "z-", and "za-". In suffix pairs, a different infinitive ending is added to the perfective stem, e.g. perfective "koupit", "prodat" (to buy, to sell) have the imperfective forms "kupovat", "prodávat". Imperfective verbs can undergo further morphology to make other imperfective verbs known as iterative and frequentative forms, which denote repeated actions. For example, the verb "jít" (to go) has the iterative form "chodit", denoting a repeated action, and the frequentative form "chodívat", denoting a regular action.
Some verbs only exist in one aspect. Many verbs concerning continual states of being, e.g. "být" (to be), "chtít" (to want), "moct" (to be able to), "ležet" (to lie down, to be lying down) have no perfective form. Conversely, many verbs that represent immediate states of change, e.g. "otěhotnět" (to become pregnant), "nadchnout se" (to become enthusiastic), have no imperfective.
Tense and mood.
The language's use of the present and future tenses is comparable to that of English, for the most part. However, Czech simply utilizes the past tense to represent what in English is the present perfect and past perfect. This means that "Ona běžela" could correspond to "She ran", "She has run", or "She had run".
In some contexts, Czech's perfective present (not to be confused with the "present perfect" of English) carries an implication of future action. In others, it connotes a habitual action. As a result, Czech contains a proper future tense that is used to minimize ambiguity. The future tense does not involve conjugation of the verb that represents an action to be undertaken in the future; instead, the future form of "být", as shown in the table at left, is placed before the infinitive of this verb (e.g. "budu jíst" – I will eat).
However, this conjugation is never followed by "být" itself, so future-oriented expressions involving nouns, adjectives, or prepositions rather than verbs simply omit "být". For example, the expression "I will be happy" is translated as "Budu šťáštný", not "Budu být šťáštný".
The infinitive form ends in "t" (archaically, "ti"), and it is used as the form found in dictionaries as well as for auxiliary verbs (e.g. "Můžu tě slyšet" – I can hear you), including the future. Czech includes three mood categories: indicative, imperative, and conditional. The imperative mood adds specific endings for each of three person/number categories: "-Ø/-i/-ej" for the second-person singular, "-te/-ete/-ejte" for the second-person plural, and "-me/-eme/-ejme" for the first-person plural. Czech also includes a conditional mood, which is formed by placing special particles after the past-tense verb. This mood indicates possible events, namely "I would" and "I wish".
Classes.
Czech verbs come in several classes, affecting their declension patterns. The future tense of "být" would be classified as a typical "Class I" verb because of its endings. Although a full explanation of the system is much more complicated, a basic sample of the present tense of each class—as well as some common irregular verbs—follows in the tables below.
Orthography.
Czech has one of the most phonetic and regular orthographies of all European languages: its thirty-one graphemes represent thirty sounds (in most dialects, "i" and "y" denote the same sound), and it contains only one digraph, "ch", which follows "h" in alphabetical order. As a result, some of its characters have been used by phonologists to denote corresponding sounds in other languages. However, the characters "q", "w", and "x" appear only in foreign words. The háček (ˇ) is used with certain letters to form new characters: "š", "ž", and "č", as well as "ň", "ě", "ř", "ť", and "ď", which are uncommon outside Czech. The latter two are sometimes written with a comma above (ʼ) as an evolution of the háček that accommodates the letters' height. The character "ó" exists only in loanwords and onomatopoeia.
Unlike most European languages, Czech distinguishes vowel length: long vowels are indicated by an acute accent or, in one case, a ring, while short vowels are left unadorned. Long vowels, as well as the letter "ě", are not normally considered separate letters, and Czech alphabetical order does not afford them their own spots. The long "u" is usually written "ú" at the start of a word (e.g. "úroda") or morpheme (e.g. "neúrodný") and "ů" elsewhere. The two exceptions to this rule are in loanwords (e.g. "skútr") or onomatopoeia (e.g. "bú").
In general, Czech typographical features not tied to phonetics resemble those of most European languages using the Latin alphabet, including English. Proper nouns, honorifics, and the initial letters of direct quotations are capitalized, and punctuation is typical for the most part. One unusual feature is the way thousands are marked off in numbers written with Arabic numerals: the millions place and all higher places receive commas, the thousands place receives a period, and the ones place (preceding decimals) receives a mid-height period, similar to a bullet point. For example, the number written "20,671,634.09" in English would be "20,671.634·09" in Czech. Another unusual feature is that in proper noun phrases of more than one word, only the first word is capitalized, e.g. "Pražský hrad" (Prague Castle). This rule does not apply to personal or geographic names.
Sample text.
Czech: "Všichni lidé se rodí svobodní a sobě rovní co do důstojnosti a práv. Jsou nadáni rozumem a svědomím a mají spolu jednat v duchu bratrství."
English: "All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood."

</doc>
<doc id="6344" url="http://en.wikipedia.org/wiki?curid=6344" title="Capsid">
Capsid

A capsid is the protein shell of a virus. It consists of several oligomeric structural subunits made of protein called protomers. The observable 3-dimensional morphological subunits, which may or may not correspond to individual proteins, are called capsomeres. The capsid encloses the genetic material of the virus.
Capsids are broadly classified according to their structure. The majority of viruses have capsids with either helical or icosahedral structure. Some viruses, such as bacteriophages, have developed more complicated structures due to constraints of elasticity and electrostatics. The icosahedral shape, which has 20 equilateral triangular faces, approximates a sphere, while the helical shape is cylindrical. The capsid faces may consist of one or more proteins. For example, the foot-and-mouth disease virus capsid has faces consisting of three proteins named VP1–3.
Some viruses are "enveloped", meaning that the capsid is coated with a lipid membrane known as the "viral envelope". The envelope is acquired by the capsid from an intracellular membrane in the virus' host; examples include the inner nuclear membrane, the golgi membrane, and the cell's outer membrane.
Once the virus has infected the cell, it will start replicating itself, using the mechanisms of the infected host cell. During this process, new capsid subunits are synthesized according to the genetic material of the virus, using the protein biosynthesis mechanism of the cell. During the assembly process, a portal subunit is assembled at one vertex of the capsid. Through this portal, viral DNA or RNA is transported into the capsid.
Structural analyses of major capsid protein (MCP) architectures have been used to categorise viruses into families. For example, the bacteriophage PRD1, Paramecium bursaria Chlorella algal virus, and mammalian adenovirus have been placed in the same family.
Specific shapes.
Icosahedral.
Although the icosahedral structure is extremely common among viruses, size differences and slight variations exist between virions. Given an asymmetric subunit on a triangular face of a regular icosahedron, with three subunits per face 60 such subunits can be placed in an equivalent manner. Most virions, because of their size, have more than 60 subunits. These variations have been classified on the basis of the quasi-equivalence principle proposed by Donald Caspar and Aaron Klug.
An icosahedral structure can be regarded as being constructed from 12 pentamers. The number of pentamers is fixed but the number of hexamers can vary. These shells can be constructed from pentamers and hexamers by minimizing the number T (triangulation number) of nonequivalent locations that subunits occupy, with the T-number adopting the particular integer values 1, 3, 4, 7, 12, 13...(T = h2 + k2 + hk, with h, k equal to nonnegative integers). These shells always contain 12 pentamers plus 10 (T-1) hexamers. Although this classification can be applied to the majority of known viruses exceptions are known including the retroviruses where point mutations disrupt the symmetry.
Prolate.
This is an icosahedron elongated along the fivefold axis and is a common arrangement of the heads of bacteriophages. Such a structure is composed of a cylinder with a cap at either end. The cylinder is composed of 10 triangles. The Q number, which can be any positive integer, specifies the number of triangles, composed of asymmetric subunits, that make up the 10 triangles of the cylinder. The caps are classified by the T number.
Helical.
Many rod-shaped and filamentous plant viruses have capsids with helical symmetry. The helical structure can be described as a set of n 1-D molecular helices related by an n-fold axial symmetry. The helical transformation are classified into two categories: one-dimensional and two-dimensional helical systems. Creating an entire helical structure relies on a set of translational and rotational matrices which are coded in the protein data bank. Helical symmetry is given by the formula P=μ x ρ, where μ is the number of structural units per turn of the helix, ρ is the axial rise per unit and P is the pitch of the helix. The structure is said to be open due to the characteristic that any volume can be enclosed by varying the length of the helix. The most understood helical virus is the tobacco mosaic virus.The virus is a single molecule of (+) strand RNA. Each coat protein on the interior of the helix bind three nucleotides of the RNA genome. Influenza A viruses differ by comprising multiple ribonucleoproteins, the viral NP protein organizes the RNA into a helical structure. The size is also different the tobacco mosaic virus has a 16.33 protein subunits per helical turn, while the influenza A virus has a 28 amino acid tail loop.
Triangulation number.
Icosahedral virus capsids are typically assigned a triangulation number (T-number) to describe the relation between the number of pentagons and hexagons "i.e." their quasi-symmetry in the capsid shell. The T-number idea was originally developed to explain the quasi-symmetry by Caspar and Klug in 1962.
For example, a purely dodecahedral virus has a T-number of 1 (usually written, T=1) and a truncated icosahedron is assigned T=3. The T-number is calculated by (1) applying a grid to the surface of the virus with coordinates "h" and "k", (2) counting the number of steps between successive pentagons on the virus surface, (3) applying the formula:
where formula_3 and "h" and "k" are the distances between the successive pentagons on the virus surface for each axis (see figure on right). The larger the T-number the more hexagons are present relative to the pentagons.
For the hexagonal system, the polyhedra have 20"T" vertices, 30"T" edges, 10"T"+2 faces (12 pentagons and 10("T"-1) hexagons). For the dual triangular, the vertex and face counts are flipped.
T-numbers can be represented in different ways, for example T=1 can only be represented as an icosahedron or a dodecahedron and, depending on the type of quasi-symmetry, T= 3 can be presented as a truncated dodecahedron, an icosidodecahedron, or a truncated icosahedron and their respective duals a triakis icosahedron, a rhombic triacontahedron, or a pentakis dodecahedron.
Functions.
The functions of the virion are to protect the genome, deliver the genome and interact with the host. The virion must assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents. These include forms of natural radiation, extremes of pH or temperature and proteolytic and nucleolytic enzymes. Delivery of the genome is also important by specific binding to external receptors of the host cell, transmission of specific signals that induce uncoating of the genome, and induction of fusion with host cell membranes.
Chemical properties.
The viral particle must be metastable so that interactions can be reversed readily when entering and uncoating a new host cell. If it attains the minimum free energy state conformation will be irreversible associated with attachment and entry. Each subunit of the capsid has identical bonding contacts with its neighbors, and the two binding contacts are usually noncovalent. The non-covalent bonding holds the structural unit together. The reversible formation of non-covalent bonds between properly folded subunits leads to error-free assembly and minimizes free energy.

</doc>
<doc id="6346" url="http://en.wikipedia.org/wiki?curid=6346" title="Chloramphenicol">
Chloramphenicol

Chloramphenicol (INN) is an antibiotic useful for the treatment of a number of bacterial infections. It is a bacteriostatic; it became available in 1949. It is considered a prototypical broad-spectrum antibiotic, alongside the tetracyclines, and as it is both cheap and easy to manufacture, it is frequently an antibiotic of choice in the developing world.
Chloramphenicol, also known as chlornitromycin, is effective against a wide variety of Gram-positive and Gram-negative bacteria, including most anaerobic organisms. Due to resistance and safety concerns, it is no longer a first-line agent for any infection in developed nations, with the notable exception of topical treatment of bacterial conjunctivitis. Nevertheless, the global problem of advancing bacterial resistance to newer drugs has led to renewed interest in its use. In low-income countries, chloramphenicol is still widely used because it is inexpensive and readily available.
The most serious adverse effect associated with chloramphenicol treatment is bone marrow toxicity, which may occur in two distinct forms: bone marrow suppression, which is a direct toxic effect of the drug and is usually reversible, and aplastic anemia, which is idiosyncratic (rare, unpredictable, and unrelated to dose) and generally fatal.
Use of intravenous chloramphenicol has also been associated with gray baby syndrome, a phenomenon resulting from newborn infants' inability to metabolize chloramphenicol in the body. Other less serious reactions include fever, rashes, headache, and confusion. Prescription use is usually associated with monitoring of a patient's complete blood count. The drug should be discontinued upon appearance of reticulocytopenia, leukopenia, thrombocytopenia, anemia, or any other abnormal blood study findings attributable to chloramphenicol.
It is on the World Health Organization's List of Essential Medicines, a list of the most important medications needed in a basic health system.
Medical uses.
The original indication of chloramphenicol was in the treatment of typhoid, but the now almost universal presence of multiple drug-resistant "Salmonella typhi" has meant it is seldom used for this indication except when the organism is known to be sensitive. Chloramphenicol may be used as a second-line agent in the treatment of tetracycline-resistant cholera.
Because of its excellent blood-brain barrier penetration (far superior to any of the cephalosporins), chloramphenicol remains the first-choice treatment for staphylococcal brain abscesses. It is also useful in the treatment of brain abscesses due to mixed organisms or when the causative organism is not known.
Chloramphenicol is active against the three main bacterial causes of meningitis: "Neisseria meningitidis", "Streptococcus pneumoniae", and "Haemophilus influenzae". In the West, chloramphenicol remains the drug of choice in the treatment of meningitis in patients with severe penicillin or cephalosporin allergy and general practitioners are recommended to carry intravenous chloramphenicol in their bag. In low-income countries, the WHO recommend oily chloramphenicol as first-line to treat meningitis.
Chloramphenicol has been used in the U.S. in the initial empirical treatment of children with fever and a petechial rash, when the differential diagnosis includes both "Neisseria meningitidis" septicaemia and Rocky Mountain spotted fever, pending the results of diagnostic investigations.
Chloramphenicol is also effective against "Enterococcus faecium", which has led to its being considered for treatment of vancomycin-resistant enterococcus.
Although unpublished, recent research suggests chloramphenicol could also be applied to frogs to prevent their widespread destruction from fungal infections. It has recently been discovered to be a life-saving cure for chytridiomycosis in amphibians. Chytridiomycosis is a fungal disease, blamed for the extinction of one-third of the 120 frog species lost since 1980.
Spectrum of activity.
Chloramphenicol has a broad spectrum of activity and has been effective in treating ocular infections caused by a number of bacteria including "Staphylococcus aureus, Streptococcus pneumoniae", and "Escherichia coli". It is not effective against "Pseudomonas aeruginosa". The following susceptibility data represent the minimum inhibitory concentration for a few medically significant organisms.
Each of these concentrations is dependent upon the bacterial strain being targeted. Some strains of "E. coli", for example, show spontaneous emergence of chloramphenicol resistance.
Adverse effects.
Aplastic anemia.
The most serious side effect of chloramphenicol treatment is aplastic anaemia. This effect is rare and is generally fatal. No treatment is available and no way exists to predict who may or may not get this side effect. The effect usually occurs weeks or months after treatment has been stopped, and a genetic predisposition may be involved. It is not known whether monitoring the blood counts of patients can prevent the development of aplastic anaemia, but patients are recommended to have a baseline blood count with a repeat blood count every few days while on treatment. Chloramphenicol should be discontinued if the complete blood count drops below 2.5 x 10 cells/l. The highest risk is with oral chloramphenicol (affecting 1 in 24,000–40,000) and the lowest risk occurs with eye drops (affecting less than one in 224,716 prescriptions).
Thiamphenicol, a related compound with a similar spectrum of activity, is available in Italy and China for human use, and has never been associated with aplastic anaemia . Thiamphenicol is available in the U.S. and Europe as a veterinary antibiotic, but is not approved for use in humans.
Bone marrow suppression.
Chloramphenicol may cause bone marrow suppression during treatment; this is a direct toxic effect of the drug on human mitochondria. This effect manifests first as a fall in hemoglobin levels, which occurs quite predictably once a cumulative dose of 20 g has been given. The anaemia is fully reversible once the drug is stopped and does not predict future development of aplastic anaemia. Studies in mice have suggested existing marrow damage may compound any marrow damage resulting from the toxic effects of chloramphenicol.
Leukemia.
Leukemia, a cancer of the blood or bone marrow, is characterized by an abnormal increase of immature white blood cells. The risk of childhood leukemia is increased, as demonstrated in a Chinese case-controlled study, and the risk increases with length of treatment.
Gray baby syndrome.
Intravenous chloramphenicol use has been associated with the so-called gray baby syndrome.
This phenomenon occurs in newborn infants because they do not yet have fully functional liver enzymes (i.e. UDP-glucuronyl transferase), so chloramphenicol remains unmetabolized in the body.
This causes several adverse effects, including hypotension and cyanosis. The condition can be prevented by using the drug at the recommended doses, and monitoring blood levels.
Hypersensitivity reactions.
Fever, macular and vesicular rashes, angioedema, urticaria, and anaphylaxis may occur. Herxheimer’s reactions have occurred during therapy for typhoid fever.
Neurotoxic reactions.
Headache, mild depression, mental confusion, and delirium have been described in patients receiving chloramphenicol. Optic and peripheral neuritis have been reported, usually following long-term therapy. If this occurs, the drug should be promptly withdrawn.
Pharmacokinetics.
Chloramphenicol is extremely lipid soluble; it remains relatively unbound to protein and is a small molecule. It has a large apparent volume of distribution and penetrates effectively into all tissues of the body, including the brain. Distribution is not uniform, with highest concentrations found in the liver and kidney, with lowest in the brain and cerebrospinal fluid. The concentration achieved in brain and cerebrospinal fluid is around 30 to 50%, even when the meninges are not inflamed; this increases to as high as 89% when the meninges are inflamed.
Chloramphenicol increases the absorption of iron.
Use in special populations.
Chloramphenicol is metabolized by the liver to chloramphenicol glucuronate (which is inactive). In liver impairment, the dose of chloramphenicol must therefore be reduced. No standard dose reduction exists for chloramphenicol in liver impairment, and the dose should be adjusted according to measured plasma concentrations.
The majority of the chloramphenicol dose is excreted by the kidneys as the inactive metabolite, chloramphenicol glucuronate. Only a tiny fraction of the chloramphenicol is excreted by the kidneys unchanged. Plasma levels should be monitored in patients with renal impairment, but this is not mandatory. Chloramphenicol succinate ester (an intravenous prodrug form) is readily excreted unchanged by the kidneys, more so than chloramphenicol base, and this is the major reason why levels of chloramphenicol in the blood are much lower when given intravenously than orally.
Chloramphenicol passes into breast milk, so should therefore be avoided during breast feeding, if possible.
Dose monitoring.
Plasma levels of chloramphenicol must be monitored in neonates and patients with abnormal liver function. Plasma levels should be monitored in all children under the age of four, the elderly, and patients with renal failure.
Because efficacy and toxicity of chloramphenicol are associated with a maximum serum concentration, peak levels (one hour after the intravenous dose is given) should be 10-20 mcg/ml with toxicity >40 mcg/ml; trough levels (taken immediately before a dose) should be 5-10 mcg/ml.
Drug interactions.
Administration of chloramphenicol concomitantly with bone marrow depressant drugs is contraindicated, although concerns over aplastic anaemia associated with ocular chloramphenicol have largely been discounted.
Chloramphenicol is a potent inhibitor of the cytochrome P450 isoforms CYP2C19 and CYP3A4 in the liver. Inhibition of CYP2C19 causes decreased metabolism and therefore increased levels of, for example, antidepressants, antiepileptics, proton pump inhibitors, and anticoagulants if they are given concomitantly. Inhibition of CYP3A4 causes increased levels of, for example, calcium channel blockers, immunosuppressants, chemotherapeutic drugs, benzodiazepines, azole antifungals, tricyclic antidepressants, macrolide antibiotics, SSRIs, statins, cardiac antiarrhythmics, antivirals, anticoagulants, and PDE5 inhibitors.
Drug antagonistic.
Bacteriostatic Chloramphenicol is antagonistic with bactericidal Cephalosporin and should be avoided in the treatment of infections.
Mechanism of action.
Chloramphenicol is a bacteriostatic by inhibiting protein synthesis. It prevents protein chain elongation by inhibiting the peptidyl transferase activity of the bacterial ribosome. It specifically binds to A2451 and A2452 residues in the 23S rRNA of the 50S ribosomal subunit, preventing peptide bond formation. While chloramphenicol and the macrolide class of antibiotics both interact with ribosomes, chloramphenicol is not a macrolide. It directly interferes with substrate binding, whereas macrolides sterically block the progression of the growing peptide. 
Resistance.
Three mechanisms of resistance to chloramphenicol are known: reduced membrane permeability, mutation of the 50S ribosomal subunit, and elaboration of chloramphenicol acetyltransferase. It is easy to select for reduced membrane permeability to chloramphenicol "in vitro" by serial passage of bacteria, and this is the most common mechanism of low-level chloramphenicol resistance. High-level resistance is conferred by the "cat"-gene; this gene codes for an enzyme called chloramphenicol acetyltransferase, which inactivates chloramphenicol by covalently linking one or two acetyl groups, derived from acetyl-S-coenzyme A, to the hydroxyl groups on the chloramphenicol molecule. The acetylation prevents chloramphenicol from binding to the ribosome. Resistance-conferring mutations of the 50S ribosomal subunit are rare.
Chloramphenicol resistance may be carried on a plasmid that also codes for resistance to other drugs. One example is the ACCoT plasmid (A=ampicillin, C=chloramphenicol, Co=co-trimoxazole, T=tetracycline), which mediates multiple-drug resistance in typhoid (also called R factors).
Currently, some "Enterococcus faecium" and" Pseudomonas aeruginosa" strains are resistant to chloramphenicol. Some "Veillonella" spp. and "Staphylococcus capitis" strains have also developed resistance to chloramphenicol to varying degrees.
History.
Chloramphenicol was originally derived from the bacterium "Streptomyces venezuelae", isolated by David Gottlieb, and introduced into clinical practice in 1949, under the trade name Chloromycetin. It was the first antibiotic to be manufactured synthetically on a large scale.
The topical formulation of chloramphenicol was commonly used as eye drops as first-line treatment of conjunctivitis. The first fatality from eye drops was reported in 1955.
In 2007, the accumulation of reports associating aplastic anemia and blood dyscrasia with chloramphenicol eye drops lead to the classification of “probable” according to World Health Organization criteria, based on the known published case reports and the spontaneous reports submitted to the National Registry of Drug-Induced Ocular Side Effects.
Formulations.
Chloramphenicol is available as 250-mg capsules or as a liquid (125 mg/5 ml). In some countries, it is sold as chloramphenicol palmitate ester (CPE). CPE is inactive, and is hydrolysed to active chloramphenicol in the small intestine. No difference in bioavailability is noted between chloramphenicol and CPE.
Manufacture of oral chloramphenicol in the U.S. stopped in 1991, because the vast majority of chloramphenicol-associated cases of aplastic anaemia are associated with the oral preparation. No oral formulation of chloramphenicol is now available in the U.S.
In molecular biology, chloramphenicol is prepared as 25–50 mg/ml stock in ethanol.
Intravenous.
The intravenous (IV) preparation of chloramphenicol is the succinate ester, because pure chloramphenicol does not dissolve in water. This creates a problem: Chloramphenicol succinate ester is an inactive prodrug and must first be hydrolysed to chloramphenicol; however, the hydrolysis process is often incomplete, and 30% of the dose is lost and removed in the urine. Serum concentrations of IV chloramphenicol are only 70% of those achieved when chloramphenicol is given orally. For this reason, the dose needs to be increased to 75 mg/kg/day when administered IV to achieve levels equivalent to the oral dose.
Oily.
Oily chloramphenicol (or chloramphenicol oil suspension) is a long-acting preparation of chloramphenicol first introduced by Roussel in 1954; marketed as Tifomycine, it was originally used as a treatment for typhoid. Roussel stopped production of oily chloramphenicol in 1995; the International Dispensary Association has manufactured it since 1998, first in Malta and then in India from December 2004.
Oily chloramphenicol is recommended by the World Health Organization as the first-line treatment of meningitis in low-income countries, and appears on the WHO essential drugs list. It was first used to treat meningitis in 1975 and numerous studies since have demonstrated its efficacy. It is the cheapest treatment available for meningitis (US$5 per treatment course, compared to US$30 for ampicillin and US$15 for five days of ceftriaxone). It has the great advantage of requiring only a single injection, whereas ceftriaxone is traditionally given daily for five days. This recommendation may yet change, now that a single dose of ceftriaxone (cost US$3) has been shown to be equivalent to one dose of oily chloramphenicol.
Eye drops.
Chloramphenicol is still widely used in topical preparations (ointments and eye drops) for the treatment of bacterial conjunctivitis. Isolated case reports of aplastic anaemia following use of chloramphenicol eyedrops exist, but the risk is estimated to be less than one in 224,716 prescriptions. In Mexico, this is the treatment used prophylactically in newborns.

</doc>
<doc id="6347" url="http://en.wikipedia.org/wiki?curid=6347" title="Cut-up technique">
Cut-up technique

The cut-up technique is an aleatory literary technique in which a text is cut up and rearranged to create a new text.
The concept can be traced to at least the Dadaists of the 1920s, but was popularized in the late 1950s and early 1960s by writer William S. Burroughs, and has since been used in a wide variety of contexts.
Technique.
The cut-up and the closely associated fold-in are the two main techniques:
History in literature.
A precedent of the technique occurred during a Dadaist rally in the 1920s in which Tristan Tzara offered to create a poem on the spot by pulling words at random from a hat. Collage, which was popularized roughly contemporaneously with the Surrealist movement, sometimes incorporated texts such as newspapers or brochures. Prior to this event, the technique had been published in an issue of 391 in the poem by Tzara, "dada manifesto on feeble love and bitter love" under the sub-title, "" 
Burroughs cited T. S. Eliot's poem, "The Waste Land" (1922) and John Dos Passos' U.S.A. trilogy, which incorporated newspaper clippings, as early examples of the cut ups he popularized.
Gil J. Wolman developed cut-up techniques as part of his lettrist practice in the early 1950s.
Also in the 1950s, painter and writer Brion Gysin more fully developed the cut-up method after accidentally re-discovering it. He had placed layers of newspapers as a mat to protect a tabletop from being scratched while he cut papers with a razor blade. Upon cutting through the newspapers, Gysin noticed that the sliced layers offered interesting juxtapositions of text and image. He began deliberately cutting newspaper articles into sections, which he randomly rearranged. The book "Minutes to Go" resulted from his initial cut-up experiment: unedited and unchanged cut-ups which emerged as coherent and meaningful prose. South African poet Sinclair Beiles also used this technique and co-authored "Minutes To Go".
Gysin introduced Burroughs to the technique at the Beat Hotel. The pair later applied the technique to printed media and audio recordings in an effort to decode the material's implicit content, hypothesizing that such a technique could be used to discover the true meaning of a given text. Burroughs also suggested cut-ups may be effective as a form of divination saying, "When you cut into the present the future leaks out." Burroughs also further developed the "fold-in" technique. In 1977, Burroughs and Gysin published "The Third Mind", a collection of cut-up writings and essays on the form. Jeff Nuttall's publication "My Own Mag" was another important outlet for the then-radical technique.
In an interview, Alan Burns noted that for "Europe After The Rain" (1965) and subsequent novels he used a version of cut-ups: "I did not actually use scissors, but I folded pages, read across columns, and so on, discovering for myself many of the techniques Burroughs and Gysin describe".
Argentine writer Julio Cortázar often used cut ups in his 1963 novel "Hopscotch".
In 1969, poets Howard W. Bergerson and J. A. Lindon developed a cut-up technique known as vocabularyclept poetry, in which a poem is formed by taking all the words of an existing poem and rearranging them, often preserving the metre and stanza lengths.
Musical influence.
From the early 1970s, David Bowie has used cut-ups to create some of his lyrics. This technique influenced Kurt Cobain's songwriting. Thom Yorke applied a similar method in Radiohead's "Kid A" (2000) album, writing single lines, putting them into a hat, and drawing them out at random while the band rehearsed the songs.
Burroughs taught the cut-up technique to musician Genesis P-Orridge in 1971 as a method for "altering reality". H/er explanation was that everything is recorded, and if it is recorded, then it can be edited (P-Orridge, 2003).
Stephen Mallinder of Cabaret Voltaire reported to "Inpress" magazine's Andrez Bergen that "I do think the manipulation of sound in our early days - the physical act of cutting up tapes, creating tape loops and all that - has a strong reference to Burroughs and Gysin..."

</doc>
<doc id="6352" url="http://en.wikipedia.org/wiki?curid=6352" title="Cretinism">
Cretinism

Cretinism is a condition of severely stunted physical and mental growth due to untreated congenital deficiency of thyroid hormones (congenital hypothyroidism) usually due to maternal hypothyroidism.
Etymology.
The term "cretin" was once used to describe a person affected by cretinism, but, as with words such as "spastic", and "lunatic", it is now considered derogatory and inappropriate. "Cretin" became a medical term in the 18th century, from an Occitan and an Alpine French expression, prevalent in a region where persons with such a condition were especially common (see below); it saw wide medical use in the 19th and early 20th centuries, and was actually a "tick box" category on Victorian-era census forms in the UK. The term spread more widely in popular English as a markedly derogatory term for a person who behaves stupidly. Because of its pejorative connotations in popular speech, health-care workers have mostly abandoned "cretin".
The etymology of "cretin" is uncertain. Several hypotheses exist. The most common derivation provided in English dictionaries is from the Alpine French dialect pronunciation of the word "Chrétien" ("(a) Christian"), which was a greeting there. According to the "Oxford English Dictionary", the translation of the French term into "human creature" implies that the label "Christian" is a reminder of the humanity of the afflicted, in contrast to brute beasts. Other sources suggest that "Christian" describes the person's "Christ-like" inability to sin, stemming, in such cases, from an incapacity to distinguish right from wrong.
Other speculative etymologies have been offered:
Sporadic cretinism due to congenital hypothyroidism.
Congenital hypothyroidism can be endemic, genetic, or sporadic. If untreated, it results in mild to severe impairment of both physical and mental growth and development.
Poor length growth is apparent as early as the first year of life. Adult stature without treatment ranges from 1 to 1.6 metres (3'4 to 5'3), depending on severity, sex and other genetic factors. In adults, Cretinism results in mental deterioration, swelling of the skin, loss of water and hair. 
Bone maturation and puberty are severely delayed. Ovulation is impeded and infertility is common.
Neurological impairment may be mild, with reduced muscle tone and coordination, or so severe that the person cannot stand or walk. Cognitive impairment may also range from mild to so severe that the person is nonverbal and dependent on others for basic care. Thought and reflexes are slower.
Other signs may include thickened skin, enlarged tongue, or a protruding abdomen.
Sporadic and genetic cretinism results from abnormal development or function of the foetal thyroid gland. This type of cretinism has been almost completely eliminated in developed countries by early diagnosis by newborn screening schemes followed by lifelong treatment with thyroxine (T4).
Thyroxine must be dosed as tablets only, even to newborns, as the liquid oral suspensions and compounded forms cannot be depended on for reliable dosing. In the case of dosing infants, the T4 tablets are generally crushed and mixed with breast milk, formula milk or water. If the medication is mixed with formulas containing iron or soya products, larger doses may be required, as these substances may alter the absorption of thyroid hormone from the gut. Frequent monitoring (every 2–3 weeks during the first months of life) is recommended to ensure that infants with congenital hypothyroidism remain within the high end of normal range, or euthyroid.
Epidemiology.
Around the world, the most common cause of congenital hypothyroidism is iodine deficiency. Cretinism is therefore most probably due to a diet deficient in iodine. It has affected many people worldwide and continues to be a major public health problem in many countries. Iodine is an essential trace element, necessary primarily for the synthesis of thyroid hormones. Iodine deficiency is the most common preventable cause of brain damage worldwide. Although iodine is found in many foods, it is not universally present in all soils in adequate amounts. Most iodine, in iodide form, is in the oceans where the iodide ions oxidize to elemental iodine, which then enters the atmosphere and falls to earth as rain, introducing iodine to soils. Earth deficient in iodine is most common inland and in mountainous areas and areas of frequent flooding, but can also occur in coastal regions owing to past glaciation, and leaching by snow, water and heavy rainfall, which removes iodine from the soil. Plants and animals grown in iodine deficient soils are correspondingly deficient. Populations living in those areas without outside food sources are most at risk of iodine deficiency diseases.
Iodine deficiency results in the impairments in varying degrees of physical and mental development. It also causes gradual enlargement of the thyroid gland, referred to as a goitre. It is being combated in many countries by public health campaigns of iodine administration.
History.
Endemic cretinism was especially common in areas of southern Europe around the Alps and was described by ancient Roman writers, and often depicted by medieval artists. The earliest Alpine mountain climbers sometimes came upon whole villages of cretins. Alpine cretinism was described from a medical perspective by several travellers and physicians in the late 18th and early 19th centuries. At that time the cause was not known and it was often attributed to "stagnant air" in mountain valleys or "bad water". The proportion of people affected varied markedly throughout southern Europe and even within very small areas it might be common in one valley and not another. The number of severely affected persons was always a minority, and most persons were only affected to the extent of having a goitre and some degree of reduced cognition and growth. The majority of such cases were still socially functional in their pastoral villages.
More mildly affected areas of Europe and North America in the 19th century were referred to as "goitre belts". The degree of iodine deficiency was milder and manifested primarily as thyroid enlargement rather than severe mental and physical impairment. In Switzerland, for example, where soil does not contain a large amount of iodine, cases of cretinism were very abundant and even considered genetically caused. As the variety of food sources dramatically increased in Europe and North America and the populations became less completely dependent on locally grown food, the prevalence of endemic goitre diminished.
The early 20th century saw the discovery of the relationships of sporadic cretinism with congenital hypothyroidism, and of endemic cretinism with hypothyroidism due to iodine deficiency. Both have been largely eliminated in the developed world.

</doc>
<doc id="6353" url="http://en.wikipedia.org/wiki?curid=6353" title="Cretin">
Cretin

Cretin may refer to:

</doc>
<doc id="6354" url="http://en.wikipedia.org/wiki?curid=6354" title="Council of Trent">
Council of Trent

The Council of Trent (), held between 1545 and 1563 in Trento (Trent) and Bologna, northern Italy, was one of the Roman Catholic Church's most important ecumenical councils. Prompted by the Protestant Reformation, it has been described as the embodiment of the Counter-Reformation. Four hundred years later, when Pope John XXIII initiated preparations for the Second Vatican Council (Vatican II), he affirmed the decrees it had issued: "What was, still is."
As well as decrees, the Council issued condemnations of what it defined to be heresies committed by Protestantism and, in response to them, key statements and clarifications of the Church's doctrine and teachings. These addressed a wide range of subjects, including scripture, the Biblical canon, sacred tradition, original sin, justification, salvation, the sacraments, the Mass and the veneration of saints. The Council met for twenty-five sessions between 13 December 1545 and 4 December 1563, all in Trento (then the capital of the Prince-Bishopric of Trent in the Holy Roman Empire), apart from the ninth to eleventh sessions held in Bologna during 1547. Pope Paul III, who convoked the Council, presided over these and the first eight sessions (1545–47), while the twelfth to sixteenth sessions (1551–52) were overseen by Pope Julius III and the seventeenth to twenty-fifth sessions (1559–63) by Pope Pius IV.
The consequences of the Council were also significant as regards the Church's liturgy and practices. During its deliberations, the Council made the Vulgate the official example of the Biblical canon and commissioned the creation of a standard version, although this was not achieved until the 1590s. In 1565, however, a year or so after the Council finished its work, Pius IV issued the Tridentine Creed (after "Tridentum", Trento's Latin name) and his successor Pius V then issued the Roman Catechism and revisions of the Breviary and Missal in, respectively, 1566, 1568 and 1570. These, in turn, led to the establishment of the Tridentine Mass, which remained the Church's primary form of the Mass for the next four hundred years.
More than three hundred and fifty years passed until the next ecumenical council, the First Vatican Council (Vatican I), was convened.
Background.
Obstacles and events before the Council.
On 15 March 1517, the Fifth Council of the Lateran closed its activities with a number of reform proposals (on the selection of bishops, taxation, censorship and preaching) but not on the major problems that confronted the Church in Germany and other parts of Europe. A few months later, on 31 October 1517, Martin Luther issued his 95 Theses in Wittenberg.
A general, free council in Germany.
Luther's position on ecumenical councils shifted over time, but in 1520 he appealed to the German princes to oppose the papal Church, if necessary with a council in Germany, open and free of the Papacy. After the Pope condemned in "Exsurge Domine" fifty-two of Luther's theses as heresy, German opinion considered a council the best method to reconcile existing differences. German Catholics, diminished in number, hoped for a council to clarify matters.
It took a generation for the council to materialise, partly because of papal reluctance, given that a Lutheran demand was the exclusion of the papacy from the Council, and partly because of ongoing political rivalries between France and Germany and the Turkish dangers in the Mediterranean. Under Pope Clement VII (1523–34), troops of the Catholic Holy Roman Emperor Charles V sacked Papal Rome in 1527, "raping, killing, burning, stealing, the like had not been seen since the Vandals". Saint Peter's Basilica and the Sistine Chapel were used for horses. This, together with the Pontiff's ambivalence between France and Germany, led to his hesitation. Charles V strongly favoured a council, but needed the support of King Francis I of France, who attacked him militarily. Francis I generally opposed a general council due to partial support of the Protestant cause within France, and in 1533 he further complicated matters when suggesting a general council to include both Catholic and Protestant rulers of Europe that would devise a compromise between the two theological systems. This proposal met the opposition of the Pope for it gave recognition to Protestants and also elevated the secular Princes of Europe above the clergy on church matters. Faced with a Turkish attack, Charles held the support of the Protestant German rulers, all of whom delayed the opening of the Council of Trent.
Occasion, sessions, and attendance.
In reply to the Papal bull "Exsurge Domine" of Pope Leo X (1520), Martin Luther burned the document and appealed for a general council. In 1522 German diets joined in the appeal, with Charles V seconding and pressing for a council as a means of reunifying the Church and settling the Reformation controversies. Pope Clement VII (1523–34) was vehemently against the idea of a council, agreeing with Francis I of France. After Pope Pius II, in his bull "Execrabilis" (1460) and his reply to the University of Cologne (1463), set aside the theory of the supremacy of general councils laid down by the Council of Constance.
Pope Paul III (1534–49), seeing that the Protestant Reformation was no longer confined to a few preachers, but had won over various princes, particularly in Germany, to its ideas, desired a council. Yet when he proposed the idea to his cardinals, it was almost unanimously opposed. Nonetheless, he sent nuncios throughout Europe to propose the idea. Paul III issued a decree for a general council to be held in Mantua, Italy, to begin on 23 May 1537. Martin Luther wrote the Smalcald Articles in preparation for the general council. The Smalcald Articles were designed to sharply define where the Lutherans could and could not compromise.The council was ordered by the Emperor and Pope Paul III to convene in Mantua on 23 May 1537. It failed to convene after another war broke out between France and Charles V, resulting in a non-attendance of French prelates. Protestants, just defeated by Charles V, refused to attend as well. Financial difficulties in Mantua led the Pope in the autumn of 1537 to move the council to Vicenza, where participation was poor. The Council was postponed indefinitely on 21 May 1539. Pope Paul III then initiated several internal Church reforms while Emperor Charles V convened a meeting with Protestants in Regensburg, seat of the German diet, to reconcile differences. Unity failed between Catholic and Protestant representatives "because of different concepts of "Church" and "justification"".
However, the council was delayed until 1545 and, as it happened, convened right before Luther's death. Unable, however, to resist the urging of Charles V, the pope, after proposing Mantua as the place of meeting, convened the council at Trento (at that time a free city of the Holy Roman Empire under a prince-bishop), on 13 December 1545; the Pope's decision to transfer it to Bologna in March, 1547 on the pretext of avoiding a plague failed to take effect and the Council was indefinitely prorogued on 17 September 1549. None of the three popes reigning over the duration of the council ever attended, which had been a condition of Charles V. Papal legates were appointed to represent the Papacy.
Reopened at Trento on 1 May 1551 by convocation of Pope Julius III (1550–5), it was broken up by the sudden victory of Maurice, Elector of Saxony over the Emperor Charles V and his march into surrounding state of Tirol on 28 April 1552. There was no hope of reassembling the council while the very anti-Protestant Paul IV was Pope. The council was reconvened by Pope Pius IV (1559–65) for the last time, meeting from 18 January 1562, and continued until its final adjournment on 4 December 1563. It closed with a series of ritual acclamations honouring the reigning Pope, the Popes who had convoked the Council, the emperor and the kings who had supported it, the papal legates, the cardinals, the ambassadors present, and the bishops, followed by acclamations of acceptance of the faith of the Council and its decrees, and of anathema for all heretics.
The history of the council is thus divided into three distinct periods: 1545–49, 1551–52 and 1562–63. During the second period, the Protestants present asked for renewed discussion on points already defined and for bishops to be released from their oaths of allegiance to the Pope. When the last period began, all hope of conciliating the Protestants was gone and the Jesuits had become a strong force.
The number of attending members in the three periods varied considerably. The council was small to begin with, opening with only about 30 bishops. It increased toward the close, but never reached the number of the First Council of Nicaea (which had 318 members) nor of the First Vatican Council (which numbered 744). The decrees were signed in 1563 by 255 members, the highest attendance of the whole council, including four papal legates, two cardinals, three patriarchs, twenty-five archbishops, and 168 bishops, two-thirds of whom were Italians. The Italian and Spanish prelates were vastly preponderant in power and numbers. At the passage of the most important decrees, not more than sixty prelates were present. 
The French monarchy boycotted the entire council until the last minute; a delegation led by Charles de Guise, Cardinal of Lorraine finally arrived in November 1562. The first outbreak of the French Wars of Religion had been earlier in the year, and the French had experience of a significant and powerful Protestant minority, iconoclasm and tensions leading to violence in a way the Italians and Iberians did not. Among other influences, the last minute inclusion of a decree on sacred images was a French initiative, and the text, never discussed on the floor of the council or referred to council theologians, was based on a French draft.
Objectives and overall results.
The main objectives of the council were twofold, although there were other issues that were also discussed:
The doctrinal decisions of the council are divided into decrees ("decreta"), which contain the positive statement of the conciliar dogmas, and into short canons ("canones"), which condemn the dissenting Protestant views with the concluding "anathema sit" ("let him be anathema").
Canons and decrees.
The doctrinal acts are as follows: after reaffirming the Niceno-Constantinopolitan Creed (third session), the decree was passed (fourth session) confirming that the deuterocanonical books were on a par with the other books of the canon (against Luther's placement of these books in the Apocrypha of his edition) and coordinating church tradition with the Scriptures as a rule of faith. The Vulgate translation was affirmed to be authoritative for the text of Scripture.
Justification (sixth session) was declared to be offered upon the basis of human cooperation with divine grace as opposed to the Protestant doctrine of passive reception of grace. Understanding the Protestant "faith alone" doctrine to be one of simple human confidence in divine mercy, the Council rejected the "vain confidence" of the Protestants, stating that no one can know who has received the grace of God. Furthermore the Council affirmed against Protestant doctrine that the grace of God can be forfeited through mortal sin.
The greatest weight in the Council's decrees is given to the sacraments. The seven sacraments were reaffirmed and the Eucharist pronounced to be a true propitiatory sacrifice as well as a sacrament, in which the bread and wine were consecrated into the Eucharist (thirteenth and twenty-second sessions). The term transubstantiation was used by the Council, but the specific Aristotelian explanation given by Scholasticism was not cited as dogmatic. Instead, the decree states that Christ is "really, truly, substantially present" in the consecrated forms. The sacrifice of the Mass was to be offered for dead and living alike and in giving to the apostles the command "do this in remembrance of me," Christ conferred upon them a sacerdotal power. The practice of withholding the cup from the laity was confirmed (twenty-first session) as one which the Church Fathers had commanded for good and sufficient reasons; yet in certain cases the Pope was made the supreme arbiter as to whether the rule should be strictly maintained. On the language of the Mass, "contrary to what is often said", the council condemned the belief that only vernacular languages should be used, but did not insist on the use of Latin. 
Ordination (twenty-third session) was defined to imprint an indelible character on the soul. The priesthood of the New Testament takes the place of the Levitical priesthood. To the performance of its functions, the consent of the people is not necessary.
In the decrees on marriage (twenty-fourth session) the excellence of the celibate state was reaffirmed, concubinage condemned and the validity of marriage made dependent upon the wedding taking place before a priest and two witnesses, although the lack of a requirement for parental consent ended a debate that had proceeded from the 12th century. In the case of a divorce, the right of the innocent party to marry again was denied so long as the other party was alive, even if the other party had committed adultery. However the council "refused ... to assert the necessity of usefulness of clerical celibacy. 
In the twenty-fifth and last session, the doctrines of purgatory, the invocation of saints and the veneration of relics were reaffirmed, as was also the efficacy of indulgences as dispensed by the Church according to the power given her, but with some cautionary recommendations, and a ban on the sale of indulgences. Short and rather inexplicit passages concerning religious images, were to have great impact on the development of Roman Catholic art. Much more than the Second Council of Nicaea (787) the Council fathers of Trent stressed the pedagogical purpose of Christian images.
The council appointed, in 1562 (eighteenth session), a commission to prepare a list of forbidden books ("Index Librorum Prohibitorum"), but it later left the matter to the Pope. The preparation of a catechism and the revision of the Breviary and Missal were also left to the pope. The catechism embodied the council's far-reaching results, including reforms and definitions of the sacraments, the Scriptures, church dogma, and duties of the clergy.
On adjourning, the Council asked the supreme pontiff to ratify all its decrees and definitions. This petition was complied with by Pope Pius IV, on 26 January 1564, in the papal bull, "Benedictus Deus", which enjoins strict obedience upon all Roman Catholics and forbids, under pain of excommunication, all unauthorised interpretation, reserving this to the Pope alone and threatens the disobedient with "the indignation of Almighty God and of his blessed apostles, Peter and Paul." Pope Pius appointed a commission of cardinals to assist him in interpreting and enforcing the decrees.
The "Index librorum prohibitorum" was announced in 1564 and the following books were issued with the papal imprimatur: the Profession of the Tridentine Faith and the Tridentine Catechism (1566), the Breviary (1568), the Missal (1570) and the Vulgate (1590 and then 1592).
The decrees of the council were acknowledged in Italy, Portugal, Poland and by the Catholic princes of Germany at the Diet of Augsburg in 1566. Philip II of Spain accepted them for Spain, the Netherlands and Sicily inasmuch as they did not infringe the royal prerogative. In France they were officially recognised by the king only in their doctrinal parts. The disciplinary sections received official recognition at provincial synods and were enforced by the bishops. No attempt was made to introduce it into England. Pius IV sent the decrees to Mary, Queen of Scots, with a letter dated 13 June 1564, requesting her to publish them in Scotland, but she dared not do it in the face of John Knox and the Reformation.
These decrees were later supplemented by the First Vatican Council of 1870.
Publication of documents.
The most comprehensive history is still Hubert Jedin's "The History of the Council of Trent (Geschichte des Konzils von Trient)" with about 2500 pages in four volumes: "The History of the Council of Trent: The fight for a Council" (Vol I, 1951); "The History of the Council of Trent: The first Sessions in Trent (1545–1547)" (Vol II, 1957); "The History of the Council of Trent: Sessions in Bologna 1547–1548 and Trento 1551–1552" (Vol III, 1970, 1998); "The History of the Council of Trent: Third Period and Conclusion" (Vol IV, 1976).
The canons and decrees of the council have been published very often and in many languages (for a large list consult "British Museum Catalogue", under "Trent, Council of"). The first issue was by Paulus Manutius (Rome, 1564). The best Latin editions are by J. Le Plat (Antwerp, 1779) and by F. Schulte and A. L. Richter (Leipzig, 1853). Other good editions are in vol. vii. of the "Acta et decreta conciliorum recentiorum. Collectio Lacensis" (7 vols., Freiburg, 1870–90), reissued as independent volume (1892); "Concilium Tridentinum: Diariorum, actorum, epastularum, ... collectio", ed. S. Merkle (4 vols., Freiburg, 1901 sqq.; only vols. i.–iv. have as yet appeared); not to overlook Mansi, "Concilia", xxxv. 345 sqq. Note also Mirbt, "Quellen", 2d ed, pp. 202–255. The best English edition is by James Waterworth (London, 1848; "With Essays on the External and Internal History of the Council").
The original acts and debates of the council, as prepared by its general secretary, Bishop Angelo Massarelli, in six large folio volumes, are deposited in the Vatican Library and remained there unpublished for more than 300 years and were brought to light, though only in part, by Augustin Theiner, priest of the oratory (d. 1874), in "Acta genuina sancti et oecumenici Concilii Tridentini nunc primum integre edita" (2 vols., Leipzig, 1874).
Most of the official documents and private reports, however, which bear upon the council, were made known in the 16th century and since. The most complete collection of them is that of J. Le Plat, "Monumentorum ad historicam Concilii Tridentini collectio" (7 vols., Leuven, 1781–87). New materials(Vienna, 1872); by JJI von Döllinger "(Ungedruckte Berichte und Tagebücher zur Geschichte des Concilii von Trient)" (2 parts, Nördlingen, 1876); and A. von Druffel, "Monumenta Tridentina" (Munich, 1884–97).

</doc>
<doc id="6355" url="http://en.wikipedia.org/wiki?curid=6355" title="Chloroplast">
Chloroplast

Chloroplasts are organelles, specialized subunits, in plant and algal cells. Their main role is to conduct photosynthesis, where the photosynthetic pigment chlorophyll captures the energy from sunlight, and stores it in the energy storage molecules ATP and NADPH while freeing oxygen from water. They then use the ATP and NADPH to make organic molecules from carbon dioxide in a process known as the Calvin cycle. Chloroplasts carry out a number of other functions, including fatty acid synthesis, much amino acid synthesis, and the immune response in plants.
A chloroplast is one of three types of plastids, characterized by its high concentration of chlorophyll. (The other two types, the leucoplast and the chromoplast, contain little chlorophyll and do not carry out photosynthesis.)
Chloroplasts are highly dynamic—they circulate and are moved around within plant cells, and occasionally pinch in two to reproduce. Their behavior is strongly influenced by environmental factors like light color and intensity. Chloroplasts, like mitochondria, contain their own DNA, which is thought to be inherited from their ancestor—a photosynthetic cyanobacterium that was engulfed by an early eukaryotic cell. Chloroplasts cannot be made by the plant cell, and must be inherited by each daughter cell during cell division.
With one exception (a member of the genus "Paulinella"), all chloroplasts can probably be traced back to a single endosymbiotic event (the cyanobacterium being engulfed by the eukaryote). Despite this, chloroplasts can be found in an extremely wide set of organisms, some not even directly related to each other—a consequence of many secondary and even tertiary endosymbiotic events.
The word "chloroplast" (χλωροπλάστης) is derived from the Greek words "chloros" (χλωρός), which means green, and "plastes" (πλάστης), which means "the one who forms".
Chloroplast lineages and evolution.
Chloroplasts are one of many types of organelles in the plant cell. They are considered to have originated from cyanobacteria through endosymbiosis—when a eukaryotic cell engulfed a photosynthesizing cyanobacterium which remained and became a permanent resident in the cell. Mitochondria are thought to have come from a similar event, where an ærobic prokaryote was engulfed. This origin of chloroplasts was first suggested by Russian biologist Konstantin Mereschkowski in 1905 after Andreas Schimper observed that chloroplasts closely resemble cyanobacteria in 1883. Chloroplasts are only found in plants and algae.
Cyanobacterial ancestor.
Cyanobacteria are considered the ancestors of chloroplasts. They are sometimes called blue-green algae even though they are prokaryotes. They are a diverse phylum of bacteria capable of carrying out photosynthesis, and are gram-negative, meaning they have two cell membranes. They also contain a peptidoglycan cell wall, which is thicker than in other gram-negative bacteria, and which is located between their two cell membranes. Like chloroplasts, they have thylakoids inside of them. On the thylakoid membranes are photosynthetic pigments, including chlorophyll "a". Phycobilins are also common cyanobacterial pigments, usually organized into hemispherical phycobilisomes attached to the outside of the thylakoid membranes (phycobilins are not shared with all chloroplasts though).
Primary endosymbiosis.
Primary endosymbiosis<br>A eukaryote with mitochondria engulfed a cyanobacterium in an event of serial primary endosymbiosis, creating a lineage of cells with both organelles. It is important to note that the cyanobacterial endosymbiont already had a double membrane—the phagosomal vacuole-derived membrane was lost.
<div style="float: right; clear: right; width: 480px; height: 30px; " />
<div style="float: right; clear: right; width: 550px; height: 200px; " />
<div style="float: right; clear: right; width: 500px; height: 50px; " />
Somewhere around a billion years ago, a free-living cyanobacterium entered an early eukaryotic cell, either as food or an internal parasite, and managed to escape the phagocytic vacuole it was contained in. The two innermost lipid-bilayer membranes that surround all chloroplasts correspond to the outer and inner membranes of the ancestral cyanobacterium's gram negative cell wall, and not the phagosomal membrane from the host, which was probably lost.
The new cellular resident quickly became an advantage, providing food for the eukaryotic host, which allowed it to live within it. Over time, the cyanobacterium was assimilated, and many of its genes were lost or transferred to the nucleus of the host. Some of its proteins were then synthesized in the cytoplasm of the host cell, and imported back into the chloroplast.
This event is called "endosymbiosis", or "cell living inside another cell". The cell living inside the other cell is called the "endosymbiont"; the endosymbiont is found inside the "host cell".
Chloroplasts are believed to have arisen after mitochondria, since all eukaryotes contain mitochondria, but not all have chloroplasts. This is called "serial endosymbiosis"—an early eukaryote engulfing the mitochondrion ancestor, and some descendants of it then engulfing the chloroplast ancestor, creating a cell with both chloroplasts and mitochondria.
Whether or not chloroplasts came from a single endosymbiotic event, or many independent engulfments across various eukaryotic lineages has been long debated, but it is now generally held that all organisms with chloroplasts either share a single ancestor or obtained their chloroplast from organisms that share a common ancestor that took in a cyanobacterium 600–1600 million years ago.
These chloroplasts, which can be traced back directly to a cyanobacterial ancestor are known as "primary plastids" ("plastid" in this context means the almost the same thing as chloroplast). All primary chloroplasts belong to one of three chloroplast lineages—the glaucophyte chloroplast lineage, the rhodophyte, or red algal chloroplast lineage, or the chloroplastidan, or green chloroplast lineage. The second two are the largest, and the green chloroplast lineage is the one that contains the land plants.
Glaucophyta.
The alga "Cyanophora", a glaucophyte, is thought to be one of the first organisms to contain a chloroplast. The glaucophyte chloroplast group is the smallest of the three primary chloroplast lineages, being found in only thirteen species, and is thought to be the one that branched off the earliest. Glaucophytes have chloroplasts which retain a peptidoglycan wall between their double membranes, like their cyanobacterial parent. For this reason, glaucophyte chloroplasts are also known as "muroplasts". Glaucophyte chloroplasts also contain concentric unstacked thylakoids which surround a carboxysome, an icosahedral structure that glaucophyte chloroplasts and cyanobacteria keep their carbon fixation enzyme rubisco in. The starch they synthesize collects outside the chloroplast. Like cyanobacteria, glaucophyte chloroplast thylakoids are studded with light collecting structures called phycobilisomes. For these reasons, glaucophyte chloroplasts are considered a primitive intermediate between cyanobacteria and the more evolved chloroplasts in red algae and plants.
Rhodophyceæ (red algae).
The rhodophyte, or red algal chloroplast group is another large and diverse chloroplast lineage. Rhodophyte chloroplasts are also called "rhodoplasts", literally "red chloroplasts".
Rhodoplasts have a double membrane with an intermembrane space and phycobilin pigments organized into phycobilisomes on the thylakoid membranes, preventing their thylakoids from stacking. Some contain pyrenoids. Rhodoplasts have chlorophyll "a" and phycobilins for photosynthetic pigments; the phycobilin phycoerytherin is responsible for giving many red algae their distinctive red color. However, since they also contain the blue-green chlorophyll "a" and other pigments, many are reddish to purple from the combination. The red phycoerytherin pigment is an adaptation to help red algae catch more sunlight in deep water—as such, some red algae that live in shallow water have less phycoerytherin in their rhodoplasts, and can appear more greenish. Rhodoplasts synthesize a form of starch called floridean, which collects into granules outside the rhodoplast, in the cytoplasm of the red alga.
Chloroplastida (green algae and plants).
The chloroplastidan chloroplasts, or green chloroplasts, are another large, highly diverse primary chloroplast lineage. Their host organisms are commonly known as the green algae and land plants. They differ from glaucophyte and red algal chloroplasts in that they have lost their phycobilisomes, and contain chlorophyll "b" instead. Most green chloroplasts are (obviously) green, though some aren't, like some forms of "Hæmatococcus pluvialis", due to accessory pigments that override the chlorophylls' green colors. Chloroplastidan chloroplasts have lost the peptidoglycan wall between their double membrane, and have replaced it with an intermembrane space. Some plants seem to have kept the genes for the synthesis of the peptidoglycan layer, though they've been repurposed for use in chloroplast division instead.
Most of the chloroplasts depicted in this article are green chloroplasts.
Green algae and plants keep their starch "inside" their chloroplasts, and in plants and some algae, the chloroplast thylakoids are arranged in grana stacks. Some green algal chloroplasts contain a structure called a pyrenoid, which is functionally similar to the glaucophyte carboxysome in that it is where rubisco and CO are concentrated in the chloroplast.
Helicosproidia.
The helicosproidia are nonphotosynthetic parasitic green algae that are thought to contain a vestigial chloroplast. Genes from a chloroplast and nuclear genes indicating the presence of a chloroplast have been found in helicosporoidia. even if nobody's seen the chloroplast itself.
Secondary and tertiary endosymbiosis.
Many other organisms obtained chloroplasts from the primary chloroplast lineages through secondary endosymbiosis—engulfing a red or green alga that contained a chloroplast. These chloroplasts are known as secondary plastids.
While primary chloroplasts have a double membrane from their cyanobacterial ancestor, secondary chloroplasts have additional membranes outside of the original two, as a result of the secondary endosymbiotic event, when a nonphotosynthetic eukaryote engulfed a chloroplast-containing alga but failed to digest it—much like the cyanobacterium at the beginning of this story. The engulfed alga was broken down, leaving only its chloroplast, and sometimes its cell membrane and nucleus, forming a chloroplast with three to four membranes—the two cyanobacterial membranes, sometimes the eaten alga's cell membrane, and the phagosomal vacuole from the host's cell membrane.
The genes in the phagocytosed eukaryote's nucleus are often transferred to the secondary host's nucleus.
Cryptomonads and chlorarachniophytes retain the phagocytosed eukaryote's nucleus, an object called a nucleomorph, located between the second and third membranes of the chloroplast.
All secondary chloroplasts come from green and red algae—no secondary chloroplasts from glaucophytes have been observed, probably because glaucophytes are relatively rare in nature, making them less likely to have been taken up by another eukaryote.
Green algal derived chloroplasts.
Green algae have been taken up by the euglenids, chlorarachniophytes, a lineage of dinoflagellates, and possibly the ancestor of the chromalveolates in three or four separate engulfments. Many green algal derived chloroplasts contain pyrenoids, but unlike chloroplasts in their green algal ancestors, starch collects in granules outside the chloroplast.
Euglenophytes.
Euglenophytes are a group of common flagellated protists that contain chloroplasts derived from a green alga. Euglenophyte chloroplasts have three membranes—it is thought that the membrane of the primary endosymbiont was lost, leaving the cyanobacterial membranes, and the secondary host's phagosomal membrane. Euglenophyte chloroplasts have a pyrenoid and thylakoids stacked in groups of three. Starch is stored in the form of paramylon, which is contained in membrane-bound granules in the cytoplasm of the euglenophyte.
Chlorarachniophytes.
Chlorarachniophytes are a rare group of organisms that also contain chloroplasts derived from green algae, though their story is more complicated than that of the euglenophytes. The ancestor of chlorarachniophytes is thought to have been a chromalveolate, a eukaryote with a "red" algal derived chloroplast. It is then thought to have lost its first red algal chloroplast, and later engulfed a green alga, giving it its second, green algal derived chloroplast.
Chlorarachniophyte chloroplasts are bounded by four membranes, except near the cell membrane, where the chloroplast membranes fuse into a double membrane. Their thylakoids are arranged in loose stacks of three. Chlorarachniophytes have a form of starch called chrysolaminarin, which they store in the cytoplasm, often collected around the chloroplast pyrenoid, which bulges into the cytoplasm.
Chlorarachniophyte chloroplasts are notable because the green alga they are derived from has not been completely broken down—its nucleus still persists as a nucleomorph found between the second and third chloroplast membranes—the periplastid space, which corresponds to the green alga's cytoplasm.
Early chromalveolates.
Recent research has suggested that the ancestor of the chromalveolates acquired a green algal prasinophyte endosymbiont. The green algal derived chloroplast was lost and replaced with a red algal derived chloroplast, but not before contributing some of its genes to the early chromalveolate's nucleus. The presence of both green algal and red algal genes in chromalveolates probably helps them thrive under fluctuating light conditions.
Red algal derived chloroplasts (chromalveolate chloroplasts).
Like green algae, red algae have also been taken up in secondary endosymbiosis, though it is thought that all red algal derived chloroplasts are descended from a single red alga that was engulfed by an early chromalveolate, giving rise to the chromalveolates, some of which, like the ciliates, subsequently lost the chloroplast. This is still debated though.
Pyrenoids and stacked thylakoids are common in chromalveolate chloroplasts, and the outermost membrane of many are continuous with the rough endoplasmic reticulum and studded with ribosomes. They have lost their phycobilisomes and exchanged them for chlorophyll "c", which isn't found in primary red algal chloroplasts themselves.
Cryptophytes.
Cryptophytes, or cryptomonads are a group of algae that contain a red-algal derived chloroplast. Cryptophyte chloroplasts contain a nucleomorph that superficially resembles that of the chlorarachniophytes. Cryptophyte chloroplasts have four membranes, the outermost of which is continuous with the rough endoplasmic reticulum. They synthesize ordinary starch, which is stored in granules found in the periplastid space—outside the original double membrane, in the place that corresponds to the red alga's cytoplasm. Inside cryptophyte chloroplasts is a pyrenoid and thylakoids in stacks of two.
Their chloroplasts do not have phycobilisomes, but they do have phycobilin pigments which they keep in their thylakoid space, rather than anchored on the outside of their thylakoid membranes.
Haptophytes.
Haptophytes are similar and closely related to cryptophytes, and are thought to be the first chromalveolates to branch off. Their chloroplasts lack a nucleomorph, their thylakoids are in stacks of three, and they synthesize chrysolaminarin sugar, which they store completely outside of the chloroplast, in the cytoplasm of the haptophyte.
Heterokontophytes (stramenopiles).
The heterokontophytes, also known as the stramenopiles, are a very large and diverse group of algae that also contain red algal derived chloroplasts. Heterokonts include the diatoms and the brown algae, golden algae, and yellow-green algae.
Heterokont chloroplasts are very similar to haptophyte chloroplasts, containing a pyrenoid, triplet thylakoids, and with some exceptions, having an epiplastid membrane connected to the endoplasmic reticulum. Like haptophytes, heterokontophytes store sugar in chrysolaminarin granules in the cytoplasm. Heterokontophyte chloroplasts contain chlorophyll "a" and with a few exceptions chlorophyll "c", but also have carotenoids which give them their many colors.
Apicomplexans.
Apicomplexans are another group of chromalveolates. Like the helicosproidia, they're parasitic, and have a nonphotosynthetic chloroplast. They were once thought to be related to the helicosproidia, but it is now known that the helicosproida are green algae rather than chromalveolates. The apicomplexans include "Plasmodium", the malaria parasite. Many apicomplexans keep a vestigial red algal derived chloroplast called an apicoplast, which they inherited from their ancestors. Other apicomplexans like "Cryptosporidium" have lost the chloroplast completely. Apicomplexans store their energy in amylopectin starch granules that are located in their cytoplasm, even though they are nonphotosynthetic.
Apicoplasts have lost all photosynthetic function, and contain no photosynthetic pigments or true thylakoids. They are bounded by four membranes, but the membranes are not connected to the endoplasmic reticulum. The fact that apicomplexans still keep their nonphotosynthetic chloroplast around demonstrates how the chloroplast carries out important functions other than photosynthesis. Plant chloroplasts provide plant cells with many important things besides sugar, and apicoplasts are no different—they synthesize fatty acids, isopentenyl pyrophosphate, iron-sulfur clusters, and carry out part of the heme pathway. This makes the apicoplast an attractive target for drugs to cure apicomplexan-related diseases. The most important apicoplast function is isopentenyl pyrophosphate synthesis—in fact, apicomplexans die when something interferes with this apicoplast function, and when apicomplexans are grown in an isopentenyl pyrophosphate-rich medium, they dump the organelle.
Dinophytes.
The dinoflagellates are yet another very large and diverse group of protists, around half of which are (at least partially) photosynthetic.
Most dinophyte chloroplasts are secondary red algal derived chloroplasts, like other chromalveolate chloroplasts. Many other dinophytes have lost the chloroplast (becoming the nonphotosynthetic kind of dinoflagellate), or replaced it though "tertiary" endosymbiosis—the engulfment of another chromalveolate containing a red algal derived chloroplast. Others replaced their original chloroplast with a green algal derived one.
Most dinophyte chloroplasts contain at least the photosynthetic pigments chlorophyll "a", chlorophyll "c2", "beta"-carotene, and at least one dinophyte-unique xanthophyll (peridinin, dinoxanthin, or diadinoxanthin), giving many a golden-brown color. All dinophytes store starch in their cytoplasm, and most have chloroplasts with thylakoids arranged in stacks of three.
Peridinin-containing dinophyte chloroplast.
The most common dinophyte chloroplast is the peridinin-type chloroplast, characterized by the carotenoid pigment peridinin in their chloroplasts, along with chlorophyll "a" and chlorophyll "c"2. Peridinin is not found in any other group of chloroplasts. The peridinin chloroplast is bounded by three membranes (occasionally two), having lost the red algal endosymbiont's original cell membrane. The outermost membrane is not connected to the endoplasmic reticulum. They contain a pyrenoid, and have triplet-stacked thylakoids. Starch is found outside the chloroplast An important feature of these chloroplasts is that their chloroplast DNA is highly reduced and fragmented into many small circles. Most of the genome has migrated to the nucleus, and only critical photosynthesis-related genes remain in the chloroplast.
The peridinin chloroplast is thought to be the dinophytes' "original" chloroplast, which has been lost, reduced, replaced, or has company in several other dinophyte lineages.
Fucoxanthin-containing dinophyte chloroplasts (haptophyte endosymbionts).
The fucoxanthin dinophyte lineages (including "Karlodinium" and "Karenia") lost their original red algal derived chloroplast, and replaced it with a new chloroplast derived from a haptophyte endosymbiont. "Karlodinium" and "Karenia" probably took up different heterokontophytes. Because the haptophyte chloroplast has four membranes, tertiary endosymbiosis would be expected to create a six membraned chloroplast, adding the haptophyte's cell membrane and the dinophyte's phagosomal vacuole. However, the haptophyte was heavily reduced, stripped of a few membranes and its nucleus, leaving only its chloroplast (with its original double membrane), and possibly one or two additional membranes around it.
Fucoxanthin-containing chloroplasts are characterized by having the pigment fucoxanthin (actually 19′-hexanoyloxy-fucoxanthin and/or 19′-butanoyloxy-fucoxanthin) and no peridinin. Fucoxanthin is also found in haptophyte chloroplasts, providing evidence of ancestry.
Cryptophyte derived dinophyte chloroplast.
Members of the genus "Dinophysis" have a phycobilin-containing chloroplast taken from a cryptophyte. However, the cryptophyte is not an endosymbiont—only the chloroplast seems to have been taken, and the chloroplast has been stripped of its nucleomorph and outermost two membranes, leaving just a two-membraned chloroplast. Cryptophyte chloroplasts require their nucleomorph to maintain themselves, and "Dinophysis" species grown in cell culture alone cannot survive, so it is possible (but not confirmed) that the "Dinophysis" chloroplast is a kleptoplast—if so, "Dinophysis" chloroplasts wear out and "Dinophysis" species must continually engulf cryptophytes to obtain new chloroplasts to replace the old ones.
Diatom derived dinophyte chloroplasts.
Some dinophytes, like "Kryptoperidinium" and "Durinskia" have a diatom (heterokontophyte) derived chloroplast. These chloroplasts are bounded by up to "five" membranes, (depending on whether you count the entire diatom endosymbiont as the chloroplast, or just the red algal derived chloroplast inside it). The diatom endosymbiont has been reduced relatively little—it still retains its original mitochondria, and has endoplasmic reticulum, ribosomes, a nucleus, and of course, red algal derived chloroplasts—practically a complete cell, all inside the host's endoplasmic reticulum lumen. However the diatom endosymbiont can't store its own food—its starch is found in granules in the dinophyte host's cytoplasm instead. The diatom endosymbiont's nucleus is present, but it probably can't be called a nucleomorph because it shows no sign of genome reduction, and might have even been "expanded". Diatoms have been engulfed by dinoflagellates at least three times.
The diatom endosymbiont is bounded by a single membrane, inside it are chloroplasts with four membranes. Like the diatom endosymbiont's diatom ancestor, the chloroplasts have triplet thylakoids and pyrenoids.
In some of these genera, the diatom endosymbiont's chloroplasts aren't the only chloroplasts in the dinophyte. The original three-membraned peridinin chloroplast is still around, converted to an eyespot.
Prasinophyte (green algal) derived dinophyte chloroplast.
"Lepidodinium viride" and its close relatives are dinophytes that lost their original peridinin chloroplast and replaced it with a green algal derived chloroplast (more specifically, a prasinophyte). "Lepidodinium" is the only dinophyte that has a chloroplast that's not from the rhodoplast lineage. The chloroplast is surrounded by two membranes and has no nucleomorph—all the nucleomorph genes have been transferred to the dinophyte nucleus. The endosymbiotic event that led to this chloroplast was serial secondary endosymbiosis rather than tertiary endosymbiosis—the endosymbiont was a green alga containing a primary chloroplast (making a secondary chloroplast).
Chromatophores.
While most chloroplasts originate from that first set of endosymbiotic events, "Paulinella chromatophora" is an exception, which has acquired a photosynthetic cyanobacterial endosymbiont more recently. It is not clear whether that symbiont is closely related to the ancestral chloroplast of other eukaryotes. Being in the early stages of endosymbiosis, "Paulinella chromatophora" can offer some insights into how chloroplasts evolved. "Paulinella" cells contain one or two sausage shaped blue-green photosynthesizing structures called chromatophores, descended from the cyanobacterium "Synechococcus". Chromatophores cannot survive outside their host. Chromatophore DNA is about a million base pairs long, containing around 850 protein encoding genes—far less than the three million base pair "Synechococcus" genome, but much larger than the approximately 150,000 base pair genome of the more assimilated chloroplast. Chromatophores have transferred much less of their DNA to the nucleus of their host. About 0.3–0.8% of the nuclear DNA in "Paulinella" is from the chromatophore, compared with 11–14% from the chloroplast in plants.
Kleptoplastidy.
In some groups of mixotrophic protists, like some dinoflagellates, chloroplasts are separated from a captured alga or diatom and used temporarily. These klepto chloroplasts may only have a lifetime of a few days and are then replaced.
Chloroplast DNA.
Chloroplasts have their own DNA, often abbreviated as ctDNA, or cpDNA. It is also known as the plastome. Its existence was first proved in 1962, and first sequenced in 1986—when two Japanese research teams sequenced the chloroplast DNA of liverwort and tobacco. Since then, hundreds of chloroplast DNAs from various species have been sequenced, but they're mostly those of land plants and green algae—glaucophytes, red algae, and other algal groups are extremely underrepresented, potentially introducing some bias in views of "typical" chloroplast DNA structure and content.
Molecular structure.
With few exceptions, most chloroplasts have their entire chloroplast genome combined into a single large ring, typically 120,000–170,000 base pairs long. They can have a contour length of around 30–60 micrometers, and have a mass of about 80–130 million daltons.
While usually thought of as a circular molecule, there is some evidence that chloroplast DNA molecules more often take on a linear shape.
Inverted repeats.
Many chloroplast DNAs contain two "inverted repeats", which separate a long single copy section (LSC) from a short single copy section (SSC).
While a given pair of inverted repeats are rarely completely identical, they are always very similar to each other, apparently resulting from concerted evolution.
The inverted repeats vary wildly in length, ranging from 4,000 to 25,000 base pairs long each and containing as few as four or as many as over 150 genes. Inverted repeats in plants tend to be at the upper end of this range, each being 20,000–25,000 base pairs long.
The inverted repeat regions are highly conserved among land plants, and accumulate few mutations. Similar inverted repeats exist in the genomes of cyanobacteria and the other two chloroplast lineages (glaucophyta and rhodophyceæ), suggesting that they predate the chloroplast, though some chloroplast DNAs have since lost or flipped the inverted repeats (making them direct repeats). It is possible that the inverted repeats help stabilize the rest of the chloroplast genome, as chloroplast DNAs which have lost some of the inverted repeat segments tend to get rearranged more.
Nucleoids.
New chloroplasts may contain up to 100 copies of their DNA, though the number of chloroplast DNA copies decreases to about 15–20 as the chloroplasts age. They are usually packed into nucleoids which can contain several identical chloroplast DNA rings. Many nucleoids can be found in each chloroplast.
In primitive red algae, the chloroplast DNA nucleoids are clustered in the center of the chloroplast, while in green plants and green algae, the nucleoids are dispersed throughout the stroma.
Though chloroplast DNA is not associated with true histones, in red algae, similar proteins that tightly pack each chloroplast DNA ring into a nucleoid have been found.
Gene content and protein synthesis.
The chloroplast genome most commonly includes around 100 genes which code for a variety of things, mostly to do with the protein pipeline and photosynthesis. As in prokaryotes, genes in chloroplast DNA are organized into operons. Interestingly though, unlike prokaryotic DNA molecules, chloroplast DNA molecules contain introns (plant mitochondrial DNAs do too, but not human mtDNAs).
Among land plants, the contents of the chloroplast genome are fairly similar.
Chloroplast genome reduction and gene transfer.
Over time, many parts of the chloroplast genome were transferred to the nuclear genome of the host, a process called "endosymbiotic gene transfer".
As a result, the chloroplast genome is heavily reduced compared to that of free-living cyanobacteria. Chloroplasts may contain 60–100 genes whereas cyanobacteria often have more than 1500 genes in their genome.
Endosymbiotic gene transfer is how we know about the lost chloroplasts in many chromalveolate lineages. Even if a chloroplast is eventually lost, the genes it donated to the former host's nucleus persist, providing evidence for the lost chloroplast's existence. For example, while diatoms (a heterokontophyte) now have a red algal derived chloroplast, the presence of many green algal genes in the diatom nucleus provide evidence that the diatom ancestor (probably the ancestor of all chromalveolates too) had a green algal derived chloroplast at some point, which was subsequently replaced by the red chloroplast.
In land plants, some 11–14% of the DNA in their nuclei can be traced back to the chloroplast, up to 18% in "Arabidopsis", corresponding to about 4,500 protein-coding genes. There have been a few recent transfers of genes from the chloroplast DNA to the nuclear genome in land plants.
Of the approximately three-thousand proteins found in chloroplasts, some 95% of them are encoded by nuclear genes. Many of the chloroplast's protein complexes consist of subunits from both the chloroplast genome and the host's nuclear genome. As a result, protein synthesis must be coordinated between the chloroplast and the nucleus. The chloroplast is mostly under nuclear control, though chloroplasts can also give out signals regulating gene expression in the nucleus, called "retrograde signaling".
Protein synthesis.
Protein synthesis within chloroplasts relies on two RNA polymerases. One is coded by the chloroplast DNA, the other is of nuclear origin. The two RNA polymerases may recognize and bind to different kinds of promoters within the chloroplast genome. The ribosomes in chloroplasts are similar to bacterial ribosomes.
Protein targeting and import.
Because so many chloroplast genes have been moved to the nucleus, many proteins that would originally have been translated in the chloroplast are now synthesized in the cytoplasm of the plant cell. These proteins must be directed back to the chloroplast, and imported through at least two chloroplast membranes.
Curiously, around half of the protein products of transferred genes aren't even targeted back to the chloroplast. Many became exaptations, taking on new functions like participating in cell division, protein routing, and even disease resistance. A few chloroplast genes found new homes in the mitochondrial genome—most became nonfunctional pseudogenes, though a few tRNA genes still work in the mitochondrion. Some transferred chloroplast DNA protein products get directed to the secretory pathway (though it should be noted that many secondary plastids are bounded by an outermost membrane derived from the host's cell membrane, and therefore topologically outside of the cell, because to reach the chloroplast from the cytosol, you have to cross the cell membrane, just like if you were headed for the extracellular space. In those cases, chloroplast-targeted proteins do initially travel along the secretory pathway).
Because the cell acquiring a chloroplast already had mitochondria (and peroxisomes, and a cell membrane for secretion), the new chloroplast host had to develop a unique protein targeting system to avoid having chloroplast proteins being sent to the wrong organelle, and the wrong proteins being sent to the chloroplast.
In most, but not all cases, nuclear-encoded chloroplast proteins are translated with a "cleavable transit peptide" that's added to the N-terminus of the protein precursor. Sometimes the transit sequence is found on the C-terminus of the protein, or within the functional part of the protein.
Transport proteins and membrane translocons.
After a chloroplast polypeptide is synthesized on a ribosome in the cytosol, an enzyme specific to chloroplast proteins phosphorylates, or adds a phosphate group to many (but not all) of them in their transit sequences.
Phosphorylation helps many proteins bind the polypeptide, keeping it from folding prematurely. This is important because it prevents chloroplast proteins from assuming their active form and carrying out their chloroplast functions in the wrong place—the cytosol. At the same time, they have to keep just enough shape so that they can be recognized by the chloroplast. These proteins also help the polypeptide get imported into the chloroplast.
From here, chloroplast proteins bound for the stroma must pass through two protein complexes—the TOC complex, or translocon on the outer chloroplast membrane", and the TIC translocon, or translocon on the inner chloroplast membrane translocon". Chloroplast polypeptide chains probably often travel through the two complexes at the same time, but the TIC complex can also retrieve preproteins lost in the intermembrane space.
Structure.
In land plants, chloroplasts are generally lens-shaped, 5–8 μm in diameter and 1–3 μm thick. Greater diversity in chloroplast shapes exists among the algae, which often contain a single chloroplast that can be shaped like a net (e.g., "Oedogonium"), a cup (e.g., "Chlamydomonas"), a ribbon-like spiral around the edges of the cell (e.g., "Spirogyra"), or slightly twisted bands at the cell edges (e.g., "Sirogonium"). Some algae have two chloroplasts in each cell; they are star-shaped in "Zygnema", or may follow the shape of half the cell in order Desmidiales. In some algae, the chloroplast takes up most of the cell, with pockets for the nucleus and other organelles (for example some species of "Chlorella" have a cup-shaped chloroplast that occupies much of the cell).
All chloroplasts have at least three membrane systems—the outer chloroplast membrane, the inner chloroplast membrane, and the thylakoid system. Chloroplasts that are the product of secondary endosymbiosis may have additional membranes surrounding these three. Inside the outer and inner chloroplast membranes is the chloroplast stroma, a semi-gel-like fluid that makes up much of a chloroplast's volume, and in which the thylakoid system floats.
There are some common misconceptions about the outer and inner chloroplast membranes. The fact that chloroplasts are surrounded by a double membrane is often cited as evidence that they are the descendants of endosymbiotic cyanobacteria. This is often interpreted as meaning the outer chloroplast membrane is the product of the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium—which is not true—both chloroplast membranes are homologous to the cyanobacterium's original double membranes.
The chloroplast double membrane is also often compared to the mitochondrial double membrane. This is not a valid comparison—the inner mitochondria membrane is used to run proton pumps and carry out oxidative phosphorylation across to generate ATP energy. The only chloroplast structure that can considered analogous to it is the internal thylakoid system. Even so, in terms of "in-out", the direction of chloroplast H ion flow is in the opposite direction compared to oxidative phosphorylation in mitochondria. In addition, in terms of function, the inner chloroplast membrane, which regulates metabolite passage and synthesizes some materials, has no counterpart in the mitochondrion.
Outer chloroplast membrane.
The outer chloroplast membrane is a semi-porous membrane that small molecules and ions can easily diffuse across. However, it is not permeable to larger proteins, so chloroplast polypeptides being synthesized in the cell cytoplasm must be transported across the outer chloroplast membrane by the TOC complex, or "translocon on the outer chloroplast" membrane.
The chloroplast membranes sometimes protrude out into the cytoplasm, forming a stromule, or stroma-containing tubule. Stromules are very rare in chloroplasts, and are much more common in other plastids like chromoplasts and amyloplasts in petals and roots, respectively. They may exist to increase the chloroplast's surface area for cross-membrane transport, because they are often branched and tangled with the endoplasmic reticulum. They were once thought to connect chloroplasts allowing them to exchange proteins, however recent research strongly refutes this idea. Observed stromules are probably just oddly shaped chloroplasts with constricted regions or dividing chloroplasts.
Intermembrane space and peptidoglycan wall.
Usually, a thin intermembrane space about 10–20 nanometers thick exists between the outer and inner chloroplast membranes.
Glaucophyte algal chloroplasts have a peptidoglycan layer between the chloroplast membranes. It corresponds to the peptidoglycan cell wall of their cyanobacterial ancestors, which is located between their two cell membranes. These chloroplasts are called muroplasts (from Latin "mura", meaning "wall"). Other chloroplasts have lost the cyanobacterial wall, leaving an intermembrane space between the two chloroplast envelope membranes.
Inner chloroplast membrane.
The inner chloroplast membrane borders the stroma and regulates passage of materials in and out of the chloroplast. After passing through the TOC complex in the outer chloroplast membrane, polypeptides must pass through the TIC complex "(translocon on the inner chloroplast membrane)" which is located in the inner chloroplast membrane.
In addition to regulating the passage of materials, the inner chloroplast membrane is where fatty acids, lipids, and carotenoids are synthesized.
Peripheral reticulum.
Some chloroplasts contain a structure called the chloroplast peripheral reticulum. It is often found in the chloroplasts of plants, though it has also been found in some angiosperms, and even some gymnosperms. The chloroplast peripheral reticulum consists of a maze of membranous tubes and vesicles continuous with the inner chloroplast membrane that extends into the internal stromal fluid of the chloroplast. Its purpose is thought to be to increase the chloroplast's surface area for cross-membrane transport between its stroma and the cell cytoplasm. The small vesicles sometimes observed may serve as transport vesicles to shuttle stuff between the thylakoids and intermembrane space.
Stroma.
The protein-rich, alkaline, aqueous fluid within the inner chloroplast membrane and outside of the thylakoid space is called the stroma, which corresponds to the cytosol of the original cyanobacterium. Nucleoids of chloroplast DNA, chloroplast ribosomes, the thylakoid system with plastoglobuli, starch granules, and many proteins can be found floating around in it. The Calvin cycle, which fixes CO into sugar takes place in the stroma.
Chloroplast ribosomes.
Chloroplasts have their own ribosomes, which they use to synthesize a small fraction of their proteins. Chloroplast ribosomes are about two-thirds the size of cytoplasmic ribosomes (around 17 nm vs 25 nm). They take mRNAs transcribed from the chloroplast DNA and translate them into protein. While similar to bacterial ribosomes, chloroplast translation is more complex than in bacteria, so chloroplast ribosomes include some chloroplast-unique features.
Plastoglobuli.
Plastoglobuli (singular "plastoglobulus", sometimes spelled "plastoglobule(s)"), are spherical bubbles of lipids and proteins about 45–60 nanometers across. They are surrounded by a lipid monolayer. Plastoglobuli are found in all chloroplasts, but become more common when the chloroplast is under oxidative stress, or when it ages and transitions into a gerontoplast. Plastoglobuli also exhibit a greater size variation under these conditions. They are also common in etioplasts, but decrease in number as the etioplasts mature into chloroplasts.
Plastoglubuli contain both structural proteins and enzymes involved in lipid synthesis and metabolism. They contain many types of lipids including plastoquinone, vitamin E, carotenoids and chlorophylls.
Plastoglobuli were once thought to be free-floating in the stroma, but it is now thought that they are permanently attached either to a thylakoid or to another plastoglobulus attached to a thylakoid, a configuration that allows a plastoglobulus to exchange its contents with the thylakoid network. In normal green chloroplasts, the vast majority of plastoglobuli occur singularly, attached directly to their parent thylakoid. In old or stressed chloroplasts, plastoglobuli tend to occur in linked groups or chains, still always anchored to a thylakoid.
Plastoglobuli form when a bubble appears between the layers of the lipid bilayer of the thylakoid membrane, or bud from existing plastoglubuli—though they never detach and float off into the stroma. Practically all plastoglobuli form on or near the highly curved edges of the thylakoid disks or sheets. They are also more common on stromal thylakoids than on granal ones.
Starch granules.
Starch granules are very common in chloroplasts, typically taking up 15% of the organelle's volume, though in some other plastids like amyloplasts, they can be big enough to distort the shape of the organelle. Starch granules are simply accumulations of starch in the stroma, and are not bounded by a membrane.
Starch granules appear and grow throughout the day, as the chloroplast synthesizes sugars, and are consumed at night to fuel respiration and continue sugar export into the phloem, though in mature chloroplasts, it is rare for a starch granule to be completely consumed or for a new granule to accumulate.
Starch granules vary in composition and location across different chloroplast lineages. In red algae, starch granules are found in the cytoplasm rather than in the chloroplast. In plants, mesophyll chloroplasts, which do not synthesize sugars, lack starch granules.
Rubisco.
The chloroplast stroma contains many proteins, though the most common and important is Rubisco, which is probably also the most abundant protein on the planet. Rubisco is the enzyme that fixes CO into sugar molecules. In plants, rubisco is abundant in all chloroplasts, though in plants, it is confined to the bundle sheath chloroplasts, where the Calvin cycle is carried out in plants.
Pyrenoids.
The chloroplasts of some hornworts and algae contain structures called pyrenoids. They are not found in higher plants. Pyrenoids are roughly spherical and highly refractive bodies which are a site of starch accumulation in plants that contain them. They consist of a matrix opaque to electrons, surrounded by two hemispherical starch plates. The starch is accumulated as the pyrenoids mature. In algae with carbon concentrating mechanisms, the enzyme rubisco is found in the pyrenoids. Starch can also accumulate around the pyrenoids when CO2 is scarce. Pyrenoids can divide to form new pyrenoids, or be produced "de novo".
Thylakoid system.
Suspended within the chloroplast stroma is the thylakoid system, a highly dynamic collection of membranous sacks called thylakoids where chlorophyll is found and the light reactions of photosynthesis happen.
In most vascular plant chloroplasts, the thylakoids are arranged in stacks called grana, though in certain plant chloroplasts and some algal chloroplasts, the thylakoids are free floating.
Granal structure.
Using a light microscope, it is just barely possible to see tiny green granules—which were named grana. With electron microscopy, it became possible to see the thylakoid system in more detail, revealing it to consist of stacks of flat thylakoids which made up the grana, and long interconnecting stromal thylakoids which linked different grana.
In the transmission electron microscope, thylakoid membranes appear as alternating light-and-dark bands, 8.5 nanometers thick.
For a long time, the three-dimensional structure of the thylakoid system has been unknown or disputed. One model has the granum as a stack of thylakoids linked by helical stromal thylakoids; the other has the granum as a single folded thylakoid connected in a "hub and spoke" way to other grana by stromal thylakoids. While the thylakoid system is still commonly depicted according to the folded thylakoid model, it was determined in 2011 that the stacked and helical thylakoids model is correct.
In the helical thylakoid model, grana consist of a stack of flattened circular granal thylakoids that resemble pancakes. Each granum can contain anywhere from two to a hundred thylakoids, though grana with 10–20 thylakoids are most common. Wrapped around the grana are helicoid stromal thylakoids, also known as frets or lamellar thylakoids. The helices ascend at an angle of 20–25°, connecting to each granal thylakoid at a bridge-like slit junction. The helicoids may extend as large sheets that link multiple grana, or narrow to tube-like bridges between grana. While different parts of the thylakoid system contain different membrane proteins, the thylakoid membranes are continuous and the thylakoid space they enclose form a single continuous labyrinth.
Thylakoids.
Thylakoids (sometimes spelled "thylakoïds"), are small interconnected sacks which contain the membranes that the light reactions of photosynthesis take place on. The word "thylakoid" comes from the Greek word "thylakos" which means "sack".
Embedded in the thylakoid membranes are important protein complexes which carry out the light reactions of photosynthesis. Photosystem II and photosystem I contain light-harvesting complexes with chlorophyll and carotenoids that absorb light energy and use it to energize electrons. Molecules in the thylakoid membrane use the energized electrons to pump hydrogen ions into the thylakoid space, decreasing the pH and turning it acidic. ATP synthase is a large protein complex that harnesses the concentration gradient of the hydrogen ions in the thylakoid space to generate ATP energy as the hydrogen ions flow back out into the stroma—much like a dam turbine.
There are two types of thylakoids—granal thylakoids, which are arranged in grana, and stromal thylakoids, which are in contact with the stroma. Granal thylakoids are pancake-shaped circular disks about 300–600 nanometers in diameter. Stromal thylakoids are helicoid sheets that spiral around grana. The flat tops and bottoms of granal thylakoids contain only the relatively flat photosystem II protein complex. This allows them to stack tightly, forming grana with many layers of tightly appressed membrane, called granal membrane, increasing stability and surface area for light capture.
In contrast, photosystem I and ATP synthase are large protein complexes which jut out into the stroma. They can't fit in the appressed granal membranes, and so are found in the stromal thylakoid membrane—the edges of the granal thylakoid disks and the stromal thylakoids. These large protein complexes may act as spacers between the sheets of stromal thylakoids.
The number of thylakoids and the total thylakoid area of a chloroplast is influenced by light exposure. Shaded chloroplasts contain larger and more grana with more thylakoid membrane area than chloroplasts exposed to bright light, which have smaller and fewer grana and less thylakoid area. Thylakoid extent can change within minutes of light exposure or removal.
Pigments and chloroplast colors.
Inside the photosystems embedded in chloroplast thylakoid membranes are various photosynthetic pigments, which absorb and transfer light energy. The types of pigments found are different in various groups of chloroplasts, and are responsible for a wide variety of chloroplast colorations.
 box-shadow: 1px 1px 3px rgba(0,0,0,0.2);">
Paper chroma-tography of some spinach leaf extract shows the various pigments present in their chloroplasts.
Xanthophylls
Chlorophyll "a"
Chlorophyll "b"
Chlorophylls.
Chlorophyll "a" is found in all chloroplasts, as well as their cyanobacterial ancestors. Chlorophyll "a" is a blue-green pigment partially responsible for giving most cyanobacteria and chloroplasts their color. Other forms of chlorophyll exist, such as the accessory pigments chlorophyll "b", chlorophyll "c", chlorophyll "d", and chlorophyll "f".
Chlorophyll "b" is an olive green pigment found only in the chloroplasts of plants, green algae, any secondary chloroplasts obtained through the secondary endosymbiosis of a green alga, and a few cyanobacteria. It is the chlorophylls "a" and "b" together that make most plant and green algal chloroplasts green.
Chlorophyll "c" is mainly found in secondary endosymbiotic chloroplasts that originated from a red alga, although it is not found in chloroplasts of red algae themselves. Chlorophyll "c" is also found in some green algae and cyanobacteria.
Chlorophylls "d" and "f" are pigments found only in some cyanobacteria.
Carotenoids.
In addition to chlorophylls, another group of yellow–orange pigments called carotenoids are also found in the photosystems. There are about thirty photosynthetic carotenoids. They help transfer and dissipate excess energy, and their bright colors sometimes override the chlorophyll green, like during the fall, when the leaves of some land plants change color. β-carotene is a bright red-orange carotenoid found in nearly all chloroplasts, like chlorophyll "a". Xanthophylls, especially the orange-red zeaxanthin, are also common. Many other forms of carotenoids exist that are only found in certain groups of chloroplasts.
Phycobilins.
Phycobilins are a third group of pigments found in cyanobacteria, and glaucophyte, red algal, and cryptophyte chloroplasts. Phycobilins come in all colors, though phycoerytherin is one of the pigments that makes many red algae red. Phycobilins often organize into relatively large protein complexes about 40 nanometers across called phycobilisomes. Like photosystem I and ATP synthase, phycobilisomes jut into the stroma, preventing thylakoid stacking in red algal chloroplasts. Cryptophyte chloroplasts and some cyanobacteria don't have their phycobilin pigments organized into phycobilisomes, and keep them in their thylakoid space instead.
Specialized chloroplasts in plants.
To fix carbon dioxide into sugar molecules in the process of photosynthesis, chloroplasts use an enzyme called rubisco. Rubisco has a problem—it has trouble distinguishing between carbon dioxide and oxygen, so at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors. This has the end result of ATP energy being wasted and being released, all with no sugar being produced. This is a big problem, since O is produced by the initial light reactions of photosynthesis, causing issues down the line in the Calvin cycle which uses rubisco.
plants evolved a way to solve this—by spatially separating the light reactions and the Calvin cycle. The light reactions, which store light energy in ATP and NADPH, are done in the mesophyll cells of a leaf. The Calvin cycle, which uses the stored energy to make sugar using rubisco, is done in the bundle sheath cells, a layer of cells surrounding a vein in a leaf.
As a result, chloroplasts in mesophyll cells and bundle sheath cells are specialized for each stage of photosynthesis. In mesophyll cells, chloroplasts are specialized for the light reactions, so they lack rubisco, and have normal grana and thylakoids, which they use to make ATP and NADPH, as well as oxygen. They store in a four-carbon compound, which is why the process is called " photosynthesis". The four-carbon compound is then transported to the bundle sheath chloroplasts, where it drops off and returns to the mesophyll. Bundle sheath chloroplasts do not carry out the light reactions, preventing oxygen from building up in them and disrupting rubisco activity. Because of this, they lack thylakoids organized into grana stacks—though bundle sheath chloroplasts still have free-floating thylakoids in the stroma where they still carry out cyclic electron flow, a light-driven method of synthesizing ATP to power the Calvin cycle without generating oxygen. They lack photosystem II, and only have photosystem I—the only protein complex needed for cyclic electron flow. Because the job of bundle sheath chloroplasts is to carry out the Calvin cycle and make sugar, they often contain large starch grains.
Both types of chloroplast contain large amounts of chloroplast peripheral reticulum, which they use to get more surface area to transport stuff in and out of them. Mesophyll chloroplasts have a little more peripheral reticulum than bundle sheath chloroplasts.
Location.
Distribution in a plant.
Not all cells in a multicellular plant contain chloroplasts. All green parts of a plant contain chloroplasts—the chloroplasts, or more specifically, the chlorophyll in them are what make the photosynthetic parts of a plant green. The plant cells which contain chloroplasts are usually parenchyma cells, though chloroplasts can also be found in collenchyma tissue. A plant cell which contains chloroplasts is known as a chlorenchyma cell. A typical chlorenchyma cell of a land plant contains about 10 to 100 chloroplasts.
In some plants such as cacti, chloroplasts are found in the stems, though in most plants, chloroplasts are concentrated in the leaves. One square millimeter of leaf tissue can contain half a million chloroplasts. Within a leaf, chloroplasts are mainly found in the mesophyll layers of a leaf, and the guard cells of stomata. Palisade mesophyll cells can contain 30–70 chloroplasts per cell, while stomatal guard cells contain only around 8–15 per cell, as well as much less chlorophyll. Chloroplasts can also be found in the bundle sheath cells of a leaf, especially in C plants, which carry out the Calvin cycle in their bundle sheath cells. They are often absent from the epidermis of a leaf.
Cellular location.
Chloroplast movement.
The chloroplasts of plant and algal cells can orient themselves to best suit the available light. In low-light conditions, they will spread out in a sheet—maximizing the surface area to absorb light. Under intense light, they will seek shelter by aligning in vertical columns along the plant cell's cell wall or turning sideways so that light strikes them edge-on. This reduces exposure and protects them from photooxidative damage. This ability to distribute chloroplasts so that they can take shelter behind each other or spread out may be the reason why land plants evolved to have many small chloroplasts instead of a few big ones.
Chloroplast movement is considered one of the most closely regulated stimulus-response systems that can be found in plants. Mitochondria have also been observed to follow chloroplasts as they move.
In higher plants, chloroplast movement is run by phototropins, blue light photoreceptors also responsible for plant phototropism. In some algae, mosses, ferns, and flowering plants, chloroplast movement is influenced by red light in addition to blue light, though very long red wavelengths inhibit movement rather than speeding it up. Blue light generally causes chloroplasts to seek shelter, while red light draws them out to maximize light absorption.
Studies of "Vallisneria gigantea", an aquatic flowering plant, have shown that chloroplasts can get moving within five minutes of light exposure, though they don't initially show any net directionality. They may move along microfilament tracks, and the fact that the microfilament mesh changes shape to form a honeycomb structure surrounding the chloroplasts after they have moved suggests that microfilaments may help to anchor chloroplasts in place.
Function and chemistry.
Guard cell chloroplasts.
Unlike most epidermal cells, the guard cells of plant stomata contain relatively well developed chloroplasts. However, exactly what they do is controversial.
Plant innate immunity.
Plants lack specialized immune cells—all plant cells participate in the plant immune response. Chloroplasts, along with the nucleus, cell membrane, and endoplasmic reticulum, are key players in pathogen defense. Due to its role in a plant cell's immune response, pathogens frequently target the chloroplast.
Plants have two main immune responses—the hypersensitive response, in which infected cells seal themselves off and undergo programmed cell death, and systemic acquired resistance, where infected cells release signals warning the rest of the plant of a pathogen's presence.
Chloroplasts stimulate both responses by purposely damaging their photosynthetic system, producing reactive oxygen species. High levels of reactive oxygen species will cause the hypersensitive response. The reactive oxygen species also directly kill any pathogens within the cell. Lower levels of reactive oxygen species initiate systemic acquired resistance, triggering defense-molecule production in the rest of the plant.
In some plants, chloroplasts are known to move closer to the infection site and the nucleus during an infection.
Chloroplasts can serve as cellular sensors. After detecting stress in a cell, which might be due to a pathogen, chloroplasts begin producing molecules like salicylic acid, jasmonic acid, nitric oxide and reactive oxygen species which can serve as defense-signals. As cellular signals, reactive oxygen species are unstable molecules, so they probably don't leave the chloroplast, but instead pass on their signal to an unknown second messenger molecule. All these molecules initiate retrograde signaling—signals from the chloroplast that regulate gene expression in the nucleus.
In addition to defense signaling, chloroplasts, with the help of the peroxisomes, help synthesize an important defense molecule, jasmonate. Chloroplasts synthesize all the fatty acids in a plant cell—linoleic acid, a fatty acid, is a precursor to jasmonate.
Photosynthesis.
One of the main functions of the chloroplast is its role in photosynthesis, the process by which light is transformed into chemical energy, to subsequently produce food in the form of sugars. Water (H2O) and carbon dioxide (CO2) are used in photosynthesis, and sugar and oxygen (O2) is made, using light energy. Photosynthesis is divided into two stages—the light reactions, where water is split to produce oxygen, and the dark reactions, or Calvin cycle, which builds sugar molecules from carbon dioxide. The two phases are linked by the energy carriers adenosine triphosphate (ATP) and nicotinamide adenine dinucleotide phosphate (NADP+).
Light reactions.
The light reactions take place on the thylakoid membranes. They take light energy and store it in NADPH, a form of NADP+, and ATP to fuel the dark reactions.
Energy carriers.
ATP is the phosphorylated version of adenosine diphosphate (ADP), which stores energy in a cell and powers most cellular activities. ATP is the energized form, while ADP is the (partially) depleted form. NADP+ is an electron carrier which ferries high energy electrons. In the light reactions, it gets reduced, meaning it picks up electrons, becoming NADPH.
Photophosphorylation.
Like mitochondria, chloroplasts use the potential energy stored in an H+, or hydrogen ion gradient to generate ATP energy. The two photosystems capture light energy to energize electrons taken from water, and release them down an electron transport chain. The molecules between the photosystems harness the electrons' energy to pump hydrogen ions into the thylakoid space, creating a concentration gradient, with more hydrogen ions (up to a thousand times as many) inside the thylakoid system than in the stroma. The hydrogen ions in the thylakoid space then diffuse back down their concentration gradient, flowing back out into the stroma through ATP synthase. ATP synthase uses the energy from the flowing hydrogen ions to phosphorylate adenosine diphosphate into adenosine triphosphate, or ATP. Because chloroplast ATP synthase projects out into the stroma, the ATP is synthesized there, in position to be used in the dark reactions.
NADP+ reduction.
Electrons are often removed from the electron transport chains to charge NADP+ with electrons, reducing it to NADPH. Like ATP synthase, ferredoxin-NADP+ reductase, the enzyme that reduces NADP+, releases the NADPH it makes into the stroma, right where it is needed for the dark reactions.
Because NADP+ reduction removes electrons from the electron transport chains, they must be replaced—the job of photosystem II, which splits water molecules (H2O) to obtain the electrons from its hydrogen atoms.
Cyclic photophosphorylation.
While photosystem II photolyzes water to obtain and energize new electrons, photosystem I simply reenergizes depleted electrons at the end of an electron transport chain. Normally, the reenergized electrons are taken by NADP+, though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP. This is termed cyclic photophosphorylation because the electrons are recycled. Cyclic photophosphorylation is common in plants, which need more ATP than NADPH.
Dark reactions.
The Calvin cycle, also known as the dark reactions, is a series of biochemical reactions that fixes CO2 into G3P sugar molecules and uses the energy and electrons from the ATP and NADPH made in the light reactions. The Calvin cycle takes place in the stroma of the chloroplast.
While named "the dark reactions", in most plants, they take place in the light, since the dark reactions are dependent on the products of the light reactions.
Carbon fixation and G3P synthesis.
The Calvin cycle starts by using the enzyme Rubisco to fix CO2 into five-carbon Ribulose bisphosphate (RuBP) molecules. The result is unstable six-carbon molecules that immediately break down into three-carbon molecules called 3-phosphoglyceric acid, or 3-PGA.
The ATP and NADPH made in the light reactions is used to convert the 3-PGA into glyceraldehyde-3-phosphate, or G3P sugar molecules. Most of the G3P molecules are recycled back into RuBP using energy from more ATP, but one out of every six produced leaves the cycle—the end product of the dark reactions.
Sugars and starches.
Glyceraldehyde-3-phosphate can double up to form larger sugar molecules like glucose and fructose. These molecules are processed, and from them, the still larger sucrose, a disaccharide commonly known as table sugar, is made, though this process takes place outside of the chloroplast, in the cytoplasm.
Alternatively, glucose monomers in the chloroplast can be linked together to make starch, which accumulates into the starch grains found in the chloroplast.
Under conditions such as high atmospheric CO2 concentrations, these starch grains may grow very large, distorting the grana and thylakoids. The starch granules displace the thylakoids, but leave them intact.
Waterlogged roots can also cause starch buildup in the chloroplasts, possibly due to less sucrose being exported out of the chloroplast (or more accurately, the plant cell). This depletes a plant's free phosphate supply, which indirectly stimulates chloroplast starch synthesis.
While linked to low photosynthesis rates, the starch grains themselves may not necessarily interfere significantly with the efficiency of photosynthesis, and might simply be a side effect of another photosynthesis-depressing factor.
Photorespiration.
Photorespiration can occur when the oxygen concentration is too high. Rubisco cannot distinguish between oxygen and carbon dioxide very well, so it can accidentally add O2 instead of CO2 to RuBP. This process reduces the efficiency of photosynthesis—it consumes ATP and oxygen, releases CO2, and produces no sugar. It can waste up to half the carbon fixed by the Calvin cycle. Several mechanisms have evolved in different lineages that raise the carbon dioxide concentration relative to oxygen within the chloroplast, increasing the efficiency of photosynthesis. These mechanisms are called carbon dioxide concentrating mechanisms, or CCMs. These include Crassulacean acid metabolism, carbon fixation, and pyrenoids. Chloroplasts in plants are notable as they exhibit a distinct chloroplast dimorphism.
pH.
Because of the H+ gradient across the thylakoid membrane, the interior of the thylakoid is acidic, with a pH around 4, while the stroma is slightly basic, with a pH of around 8.
The optimal stroma pH for the Calvin cycle is 8.1, with the reaction nearly stopping when the pH falls below 7.3.
CO2 in water can form carbonic acid, which can disturb the pH of isolated chloroplasts, interfering with photosynthesis, even though CO2 is used in photosynthesis. However, chloroplasts in living plant cells are not affected by this as much.
Chloroplasts can pump K+ and H+ ions in and out of themselves using a poorly understood light-driven transport system.
In the presence of light, the pH of the thylakoid lumen can drop up to 1.5 pH units, while the pH of the stroma can rise by nearly one pH unit.
Amino acid synthesis.
Chloroplasts alone make almost all of a plant cell's amino acids in their stroma except the sulfur-containing ones like cysteine and methionine. Cysteine is made in the chloroplast (the proplastid too) but it is also synthesized in the cytosol and mitochondria, probably because it has trouble crossing membranes to get to where it is needed. The chloroplast is known to make the precursors to methionine but it is unclear whether the organelle carries out the last leg of the pathway or if it happens in the cytosol.
Other nitrogen compounds.
Chloroplasts make all of a cell's purines and pyrimidines—the nitrogenous bases found in DNA and RNA. They also convert nitrite (NO2–) into ammonia (NH3) which supplies the plant with nitrogen to make its amino acids and nucleotides.
Other chemical products.
Chloroplasts are the site of complex lipid metabolism.
Differentiation, replication, and inheritance.
Chloroplasts are a special type of a plant cell organelle called a plastid, though the two terms are sometimes used interchangeably. There are many other types of plastids, which carry out various functions. All chloroplasts in a plant are descended from undifferentiated proplastids found in the zygote, or fertilized egg. Proplastids are commonly found in an adult plant's apical meristems. Chloroplasts do not normally develop from proplastids in root tip meristems—instead, the formation of starch-storing amyloplasts is more common.
In shoots, proplastids from shoot apical meristems can gradually develop into chloroplasts in photosynthetic leaf tissues as the leaf matures, if exposed to the required light. This process involves invaginations of the inner plastid membrane, forming sheets of membrane that project into the internal stroma. These membrane sheets then fold to form thylakoids and grana.
If angiosperm shoots are not exposed to the required light for chloroplast formation, proplastids may develop into an etioplast stage before becoming chloroplasts. An etioplast is a plastid that lacks chlorophyll, and has inner membrane invaginations that form a lattice of tubes in their stroma, called a prolamellar body. While etioplasts lack chlorophyll, they have a yellow chlorophyll precursor stocked. Within a few minutes of light exposure, the prolamellar body begins to reorganize into stacks of thylakoids, and chlorophyll starts to be produced. This process, where the etioplast becomes a chloroplast, takes several hours. Gymnosperms do not require light to form chloroplasts.
Light, however, does not guarantee that a proplastid will develop into a chloroplast. Whether a proplastid develops into a chloroplast some other kind of plastid is mostly controlled by the nucleus and is largely influenced by the kind of cell it resides in.
Plastid interconversion.
Plastid differentiation is not permanent, in fact many interconversions are possible. Chloroplasts may be converted to chromoplasts, which are pigment-filled plastids responsible for the bright colors you see in flowers and ripe fruit. Starch storing amyloplasts can also be converted to chromoplasts, and it is possible for proplastids to develop straight into chromoplasts. Chromoplasts and amyloplasts can also become chloroplasts, like what happens when you illuminate a carrot or a potato. If a plant is injured, or something else causes a plant cell to revert to a meristematic state, chloroplasts and other plastids can turn back into proplastids. Chloroplast, amyloplast, chromoplast, proplast, etc., are not absolute states—intermediate forms are common.
Chloroplast division.
Most chloroplasts in a photosynthetic cell do not develop directly from proplastids or etioplasts. In fact, a typical shoot meristematic plant cell contains only 7–20 proplastids. These proplastids differentiate into chloroplasts, which divide to create the 30–70 chloroplasts found in a mature photosynthetic plant cell. If the cell divides, chloroplast division provides the additional chloroplasts to partition between the two daughter cells.
In single-celled algae, chloroplast division is the only way new chloroplasts are formed. There is no proplastid differentiation—when an algal cell divides, its chloroplast divides along with it, and each daughter cell receives a mature chloroplast.
Almost all chloroplasts in a cell divide, rather than a small group of rapidly dividing chloroplasts. Chloroplasts have no definite S-phase—their DNA replication is not synchronized or limited to that of their host cells.
Much of what we know about chloroplast division comes from studying organisms like "Arabidopsis" and the red alga "Cyanidioschyzon merolæ".
The division process starts when the proteins FtsZ1 and FtsZ2 assemble into filaments, and with the help of a protein ARC6, form a structure called a Z-ring within the chloroplast's stroma. The Min system manages the placement of the Z-ring, ensuring that the chloroplast is cleaved more or less evenly. The protein MinD prevents FtsZ from linking up and forming filaments. Another protein ARC3 may also be involved, but it is not very well understood. These proteins are active at the poles of the chloroplast, preventing Z-ring formation there, but near the center of the chloroplast, MinE inhibits them, allowing the Z-ring to form.
Next, the two plastid-dividing rings, or PD rings form. The inner plastid-dividing ring is located in the inner side of the chloroplast's inner membrane, and is formed first. The outer plastid-dividing ring is found wrapped around the outer chloroplast membrane. It consists of filaments about 5 nanometers across, arranged in rows 6.4 nanometers apart, and shrinks to squeeze the chloroplast. This is when chloroplast constriction begins. In a few species like "Cyanidioschyzon merolæ", chloroplasts have a third plastid-dividing ring located in the chloroplast's intermembrane space.
Late into the constriction phase, dynamin proteins assemble around the outer plastid-dividing ring, helping provide force to squeeze the chloroplast. Meanwhile, the Z-ring and the inner plastid-dividing ring break down. During this stage, the many chloroplast DNA plasmids floating around in the stroma are partitioned and distributed to the two forming daughter chloroplasts.
Later, the dynamins migrate under the outer plastid dividing ring, into direct contact with the chloroplast's outer membrane, to cleave the chloroplast in two daughter chloroplasts.
A remnant of the outer plastid dividing ring remains floating between the two daughter chloroplasts, and a remnant of the dynamin ring remains attached to one of the daughter chloroplasts.
Of the five or six rings involved in chloroplast division, only the outer plastid-dividing ring is present for the entire constriction and division phase—while the Z-ring forms first, constriction does not begin until the outer plastid-dividing ring forms.
Regulation.
In species of algae which contain a single chloroplast, regulation of chloroplast division is extremely important to ensure that each daughter cell receives a chloroplast—chloroplasts can't be made from scratch. In organisms like plants, whose cells contain multiple chloroplasts, coordination is looser and less important. It is likely that chloroplast and cell division are somewhat synchronized, though the mechanisms for it are mostly unknown.
Light has been shown to be a requirement for chloroplast division. Chloroplasts can grow and progress through some of the constriction stages under poor quality green light, but are slow to complete division—they require exposure to bright white light to complete division. Spinach leaves grown under green light have been observed to contain many large dumbbell-shaped chloroplasts. Exposure to white light can stimulate these chloroplasts to divide and reduce the population of dumbbell-shaped chloroplasts.
Chloroplast inheritance.
Like mitochondria, chloroplasts are usually inherited from a single parent. Biparental chloroplast inheritance—where plastid genes are inherited from both parent plants—occurs in very low levels in some flowering plants.
Many mechanisms prevent biparental chloroplast DNA inheritance including selective destruction of chloroplasts or their genes within the gamete or zygote, and chloroplasts from one parent being excluded from the embryo. Parental chloroplasts can be sorted so that only one type is present in each offspring.
Gymnosperms, such as pine trees, mostly pass on chloroplasts paternally, while flowering plants often inherit chloroplasts maternally. Flowering plants were once thought to only inherit chloroplasts maternally. However, there are now many documented cases of angiosperms inheriting chloroplasts paternally.
Angiosperms which pass on chloroplasts maternally have many ways to prevent paternal inheritance. Most of them produce sperm cells which do not contain any plastids. There are many other documented mechanisms that prevent paternal inheritance in these flowering plants, such as different rates of chloroplast replication within the embryo.
Among angiosperms, paternal chloroplast inheritance is observed more often in hybrids than in offspring from parents of the same species. This suggests that incompatible hybrid genes might interfere with the mechanisms that prevent paternal inheritance.
Transplastomic plants.
Recently, chloroplasts have caught attention by developers of genetically modified crops. Since in most flowering plants, chloroplasts are not inherited from the male parent, transgenes in these plastids cannot be disseminated by pollen. This makes plastid transformation a valuable tool for the creation and cultivation of genetically modified plants that are biologically contained, thus posing significantly lower environmental risks. This biological containment strategy is therefore suitable for establishing the coexistence of conventional and organic agriculture. While the reliability of this mechanism has not yet been studied for all relevant crop species, recent results in tobacco plants are promising, showing a failed containment rate of transplastomic plants at 3 in 1,000,000.

</doc>
<doc id="6357" url="http://en.wikipedia.org/wiki?curid=6357" title="Camp David">
Camp David

Camp David is the country retreat of the President of the United States. It is located in wooded hills about 62 miles (100 km) north-northwest of Washington, D.C., in Catoctin Mountain Park near Thurmont, Maryland. It is officially known as Naval Support Facility Thurmont and is technically a military installation; staffing is primarily provided by the U.S. Navy and the U.S. Marine Corps.
First known as Hi-Catoctin, Camp David was originally built as a camp for federal government agents and their families by the WPA. Construction started in 1935, and was completed in 1938. In 1942, it was converted to a presidential retreat by Franklin D. Roosevelt and renamed "Shangri-La" (for the fictional Himalayan paradise). Camp David received its present name from Dwight D. Eisenhower, in honor of his father and grandson, both named David. Camp David is not open to the general public. Catoctin Mountain Park does not indicate the location of Camp David on its official park maps due to privacy and security concerns.
Presidential use.
Every president since Franklin D. Roosevelt has made use of Camp David.
Security issues.
On July 2, 2011, an F-15 intercepted a small two-seat passenger plane flying near Camp David, when President Obama was in residence. The civilian aircraft, which was out of radio communication, was intercepted approximately from the presidential retreat. The F-15 escorted the aircraft out of the area and it landed in nearby Hagerstown, Maryland, without incident. The civilian plane's occupants were flying between two Maryland towns and were released without charge.
On July 10, 2011, an F-15 intercepted another small two-seat passenger plane flying near Camp David when President Barack Obama was again in residence; the total number of interceptions over this July 9 weekend was three planes.

</doc>
<doc id="6359" url="http://en.wikipedia.org/wiki?curid=6359" title="Crux">
Crux

Crux , located in the deep southern sky, is the smallest yet one of the most distinctive of the 88 modern constellations. Its name is Latin for cross, and it is dominated by a cross-shaped asterism that is commonly known as the Southern Cross. Although visible to the Ancient Greeks, it was seen as part of the constellation Centaurus, and not defined or accurately mapped till the 16th century.
Known as Acrux, blue-white Alpha Crucis is the constellation's brightest star and the bottom star of the cross. Nearly as bright are Beta and Gamma, while Delta and Epsilon make up the asterism. Many of the constellation's brighter stars are members of the Scorpius–Centaurus Association, a loose group of hot blue-white stars that appear to share a common origin and motion across the Milky Way. Two star systems have been found to have planets. The constellation also contains four Cepheid variables visible to the naked eye under optimum conditions. Crux also contains the Jewel Box, a bright open cluster, and the Coalsack Nebula, the most prominent dark nebula in the sky.
History.
Crux was visible to the Ancient Greeks; Ptolemy regarded it as part of the constellation Centaurus. It was entirely visible as far north as Britain in the fourth millennium BC. However, the precession of the equinoxes gradually lowered its stars below the European horizon, and they were eventually forgotten by the inhabitants of northern latitudes. By AD 400, most of the constellation never rose above the horizon for Athenians.
The 15th-century Venetian navigator Alvise Cadamosto made note of what was probably the Southern Cross on exiting the Gambia River in 1455, calling it the "carro dell'ostro" ("southern chariot"). However, Cadamosto's constellation had too many stars and was tilted incorrectly. Historians generally credit João Faras - astronomer and physician of King Manuel I of Portugal who accompanied Pedro Álvares Cabral in the discovery of Brazil in 1500 - for being the first European to depict it correctly. Faras sketched and described the constellation (calling it "Las Guardas") in a letter written on the beaches of Brazil on May 1, 1500, to the Portuguese monarch.
Another early modern description clearly describing Crux as a separate constellation is attributed to Andreas Corsali, an Italian navigator who from 1515 to 1517 sailed to China and the East Indies in an expedition sponsored by King Manuel I. In 1516, Corsali wrote a letter to the monarch describing his observations of the southern sky, which included a small map showing 19 stars and the two Magellanic Clouds in a geocentric orientation, along with a vivid textual description of the Southern Cross.
Émerie Mollineux has also been cited as the first uranographer to distinguish Crux; his illustration dates to 1592. Later adopters of the constellation included Jakob Bartsch in 1624 and Augustin Royer in 1679. Royer is sometimes wrongly cited as initially distinguishing Crux. Explorer Amerigo Vespucci depicted Crux as an almond, called "Mandorla".
Crux was first shown as a separate constellation on the celestial globes of Petrus Plancius and Jodocus Hondius in 1598 and 1600. Its stars were first catalogued separately from Centaurus by Frederick de Houtman in 1603.
Characteristics.
Crux is bordered by the constellations Centaurus (which surrounds it on three sides) on the east, north and west, and Musca to the south. Covering 68 square degrees and 0.165% of the night sky, it is the smallest of the 88 constellations. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'Cru'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of four segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between −55.68° and −64.70°. The whole constellation is visible to observers south of latitude 25°N.
In tropical regions Crux can be seen in the sky from April to June. Crux is exactly opposite to Cassiopeia on the celestial sphere, and therefore it cannot appear in the sky with the latter at the same time. For locations south of 34°S, Crux is circumpolar and thus always visible in the night sky.
Crux is sometimes confused with the nearby False Cross by stargazers. Crux is somewhat kite-shaped, and it has a fifth star (ε Crucis). The False Cross is diamond-shaped, somewhat dimmer on average, does not have a fifth star and lacks the two prominent nearby "Pointer Stars."
Visibility.
Crux is easily visible from the southern hemisphere at practically any time of year. It is also visible near the horizon from tropical latitudes of the northern hemisphere for a few hours every night during the northern winter and spring. For instance, it is visible from Cancun or any other place at latitude 25° N or less at around 10 pm at the end of April. There are 5 main stars.
Use in navigation.
In the Southern Hemisphere, the Southern Cross is frequently used for navigation in much the same way that the Pole Star is used in the Northern Hemisphere. Alpha and Gamma (known as Acrux and Gacrux respectively) are commonly used to mark south. Tracing a line from Gacrux to Acrux leads to a point close to the Southern Celestial Pole. Alternatively, if a line is constructed perpendicularly between Alpha Centauri and Beta Centauri, the point where the above-mentioned line and this line intersect marks the Southern Celestial Pole. The two stars of Alpha and Beta Centauri are often referred to as the "Southern Pointers" or just "The Pointers", allowing people to easily find the asterism of the Southern Cross or the constellation of Crux. Very few bright stars of importance lie between Crux and the pole itself, although the constellation Musca is fairly easily recognised immediately beneath Crux.
A technique used in the field is to clench one's right fist and to view the cross, aligning the first knuckle with the axis of the cross. The tip of the thumb will indicate south.
Argentine Gauchos are well known for using it for night orientation in the vast Pampas and Patagonic regions. It is also of cultural significance, as it is referenced in several songs and literature, including the Martin Fierro. The Argentinian singer Charly Garcia says that he is from the southern cross in the song "No voy en tren".
Notable features.
Stars.
The four main stars that form the asterism are Alpha, Beta, Gamma, and Delta Crucis. Alpha Crucis, called Acrux, is a triple star 321 light-years from Earth. Blue-tinged and magnitude 0.8 to the unaided eye, it has two close components of magnitude 1.3 and 1.8, as well as a wide component of magnitude 5. The two close components are divisible in a small amateur telescope and the wide component is divisible in a pair of binoculars. Beta Crucis, called Mimosa, is a blue-hued giant of magnitude 1.3, 353 light-years from Earth. It is a Beta Cephei-type Cepheid variable with a variation of less than 0.1 magnitudes. Gamma Crucis, called Gacrux, is a double star. The primary is a red-hued giant star of magnitude 1.6, 88 light-years from Earth. The secondary is of magnitude 6.5, 264 light-years from Earth. Delta Crucis is a blue-white hued star of magnitude 2.8, 364 light-years from Earth. It is the dimmest of the Southern Cross stars. Like Beta it is a Beta Cepheid.
There are several dimmer stars within the borders of Crux. Epsilon Crucis is an orange-hued giant star of magnitude 3.6, 228 light-years from Earth. Iota Crucis is a binary star 125 light-years from Earth. The primary is an orange-hued giant of magnitude 4.6 and the secondary is of magnitude 9.5. Mu Crucis is a double star where the unrelated components are about 370 light-years from Earth. The primary is a blue-white hued star of magnitude 4.0 and the secondary is a blue-white hued star of magnitude 5.1. Mu Crucis is divisible in small amateur telescopes or large binoculars.
15 of the 23 brightest stars are blue-white B-type stars. Of the five main cross stars, Delta Crucis and probably Acrux and Mimosa are co-moving B-type members of the Scorpius–Centaurus Association, the nearest OB association to the Sun. They are among the highest-mass stellar members of the Lower Centaurus-Crux subgroup of the association, with ages of roughly 10 to 20 million years. Other members include the blue-white stars Zeta, Lambda, Mu1 and Mu2.
Lambda Crucis and Theta2 Crucis are also Beta Cepheid stars.
Crux boasts four Cepheid variables that reach naked eye visibility. BG Crucis ranges from magnitude 5.34 to 5.58 over 3.3428 days, T Crucis ranges from 6.32 to 6.83 over 6.73331 days, S Crucis ranges from 6.22 to 6.92 over 4.68997 days, and R Crucis ranges from 6.4 to 7.23 over 5.82575 days. BH Crucis, also known as Welch's Red Variable, is a Mira variable that ranges from magnitude 6.6 to 9.8 over 530 days. Discovered in October 1969, it has become redder and brighter (mean magnitude changing from 8.047 to 7.762) and its period lengthened by 25% in the first thirty years since its discovery.
The star HD 106906 has been found to have a planet—HD 106906 b—that has a larger orbit than any other exoplanet discovered to date.
Deep-sky objects.
The Coalsack Nebula is the most prominent dark nebula in the skies, easily visible to the naked eye as a prominent dark patch in the southern Milky Way. It is large, five degrees by seven degrees, and is 600 light-years from Earth. Not all of the nebula is in the borders of Crux; some of it is technically in Musca and Centaurus.
The open cluster NGC 4755, better known as the Jewel Box or Kappa Crucis Cluster, has an overall magnitude of 4.2—to the naked eye it appears to be a fuzzy star—and is about 7600 light-years from Earth. The cluster was given its name by John Herschel. About seven million years old, an age that makes it one of the youngest open clusters in the Milky Way, it appears to have the shape of a letter A. The Jewel Box Clusters is a Shapley class g and Trumpler class I 3 r cluster; it is a very rich, centrally-concentrated cluster detached from the surrounding star field. It has more than 100 stars that range significantly in brightness. The brightest stars are mostly blue supergiants, though the cluster contains a few bright red supergiants. Kappa Crucis is a true member of the cluster that bears its name, and is one of the brighter stars at magnitude 5.9.
Cultural significance.
The most prominent feature of Crux is the distinctive asterism known as the Southern Cross. It has great significance in the cultures of the southern hemisphere, particularly of Australia, whose citizens colloquially refer to themselves as sons and daughters of the Southern Cross.
Flags and symbols.
Beginning in the colonial age, Crux became used as a national symbol by several southern nations. The brightest stars of Crux appear on the flags of Australia, Brazil, New Zealand, Papua New Guinea and Samoa. They also appear on the flags of the Australian state of Victoria, the Australian Capital Territory, the Northern Territory, as well as the flag of Magallanes Region of Chile, the flag of Londrina (Brazil) and several Argentine provincial flags and emblems (for example, "Tierra del Fuego" and "Santa Cruz"). The flag of the Mercosur trading zone displays the four brightest stars. Crux also appears on the Brazilian coat of arms.
In Australia, the Southern Cross played a crucial role as symbol of the Eureka Stockade. In the Eureka Oath from Peter Lalor's famous speech in 1854 under the Eureka Flag he proclaimed "We swear by the Southern Cross to stand truly by each other and fight to defend our rights and liberties." Of the Australian national flag, the Australian poet Banjo Paterson wrote in 1893: The English flag may flutter and wave,<br> where the world wide oceans toss,<br>but the flag the Australian dies to save,<br>is the flag of the Southern Cross."
The Southern Cross was written into the lyrics of "Advance Australia Fair" in 1901: "Beneath our radiant Southern Cross"; the song was adopted as the Australian National Anthem in 1984. The victory song of the Australian national cricket team is entitled "Under the Southern Cross I Stand".
The Southern Cross was included in the lyrics of the Brazilian National Anthem (1909): "A imagem do Cruzeiro resplandece" ("the image of the Cross shines"). The five stars are also in the logo of the Brazilian football team Cruzeiro Esporte Clube and the Brazilian coat of arms; it is mentioned in the Brazilian national anthem, and even featured as the name of the currency (the "cruzeiro" from 1942 to 1986 and again from 1990 to 1994. The constellation is displayed in all coins of the current series of the Brazilian real.
In O Sweet Saint Martin's Land, the lyrics for the Southern Cross are "Thy Southern Cross the night".
A stylized version of Crux appears on the Australian Eureka Flag. The constellation was also used on the dark blue, shield-like patch worn by personnel of the U.S. Army's Americal Division, which was organized in the Southern Hemisphere, on the island of New Caledonia, and also the blue diamond of the U.S. 1st Marine Division, which fought on the Southern Hemisphere islands of Guadalcanal and New Britain.
In non-Western astronomy.
In Australian Aboriginal astronomy, Crux and the Coalsack mark the head of the 'Emu in the Sky' in several Aboriginal cultures, while Crux itself is said to be a possum sitting in a tree and a representation of the sky deity Mirrabooka. Two Pacific constellations also included Gamma Centauri. Torres Strait Islanders in modern-day Australia saw Gamma Centauri as the handle and the four stars as the trident of Tagai's Fishing Spear. The Aranda people of central Australia saw the four Cross stars as the talon of an eagle and Gamma Centauri as its leg.
In ancient Hindu astrology, the modern Crux is referred to as "Trishanku".
Various peoples in the East Indies and Brazil viewed the four main stars as the body of a ray. In both Indonesia and Malaysia, it is known as "Bintang Pari" and "Buruj Pari" respectively ("ray stars")
The Javanese people of Indonesia called this constellation "Gubug pèncèng" ("raking hut") or "lumbung" ("the granary"), because the shape of the constellation was like a raking hut.
The Māori name for the Southern Cross is "Te Punga" ("the anchor"). It is thought of as the anchor of Tama-rereti's "waka" (the Milky Way), while the Pointers are its rope. In Tonga it is known as "Toloa" ("duck"); it is depicted as a duck flying south, with one of his wings (δ Crucis) wounded because "Ongo tangata" ("two men", α and β Centauri) threw a stone at it. The Coalsack is known as "Humu" (the "triggerfish"), because of its shape. In Samoa the constellation is called "Sumu" ("triggerfish") because of its rhomboid shape, while α and β Centauri are called "Luatagata" (Two Men), just as they are in Tonga. The peoples of the Solomon Islands saw several figures in the Southern Cross. These included a knee protector and a net used to catch Palolo worms. Neighboring peoples in the Marshall Islands saw these stars as a fish.
In Mapudungun, the language of Patagonian Mapuches, the name of the Southern Cross is "Melipal", which means "four stars". In Quechua, the language of the Inca civilization, Crux is known as "Chakana", which means literally "stair" ("chaka", bridge, link; "hanan", high, above), but carries a deep symbolism within Quechua mysticism. Acrux and Mimosa make up one foot of the Great Rhea, a constellation encompassing Centaurus and Circinus along with the two bright stars. The Great Rhea was a constellation of the Bororo people of Brazil. The Mocoví people of Argentina also saw a rhea including the stars of Crux. Their rhea is attacked by two dogs, represented by bright stars in Centaurus and Circinus. The dogs' heads are marked by Alpha and Beta Centauri. The rhea's body is marked by the four main stars of Crux, while its head is Gamma Centauri and its feet are the bright stars of Musca. The Bakairi people of Brazil had a sprawling constellation representing a bird snare. It included the bright stars of Crux, the southern part of Centaurus, Circinus, at least one star in Lupus, the bright stars of Musca, Beta and Delta Chamaeleonis, Volans, and Mensa. The Kalapalo people of Mato Grosso state in Brazil saw the stars of Crux as "Aganagi" angry bees having emerged from the Coalsack, which they saw as the beehive.
Among Tuaregs, the four most visible stars of Crux are considered "iggaren", i.e. four "Maerua crassifolia" trees. The Tswana people of Botswana saw the constellation as "Dithutlwa", two giraffes - Acrux and Mimosa forming a male, and Gacrux and Delta Crucis forming the female.
In popular culture.
The Argentine Air Force acrobatic display team is called "Cruz del Sur", the Spanish for "Southern Cross".
In the "Victory At Sea" suite, Richard Rodgers wrote "Beneath The Southern Cross" to depict the battleships in convoy and the loneliness of the sailors in the Southern Pacific during World War II. This tango melody is also "No Other Love Have I" in the musical "Me and Juliet" and a popular hit for Perry Como during the 1950s.
Cruzeiro Esporte Clube (Crux/Southern Cross Sports Club) is a first class football (soccer) club in Brazil.
Melbourne's Southern Cross Hotel was built and named in 1962 and was one of the city's foremost hotels during the decade. The hotel was demolished in 2005 and replaced by the similarly named office building known as Southern Cross Tower. There is a town in the Western Australian wheatbelt approx 300 km east of Perth called Southern Cross. Melbourne's Spencer Street Station was rebuilt and renamed "Southern Cross Station" in 2006.
The 1974 Australian America's Cup Challenger was named "Southern Cross" KA 4 representing the Royal Perth Yacht Club and was defeated 4-0 sailing off Newport Rhode Island by "Courageous" US26 sailing for the New York Yacht Club. Southern Cross became the trial horse for the 1977 Australian Challenger "Australia" KA 5 representing the Sun City Yacht Club that was defeated 4-0 sailing off Newport Rhode Island by Courageous US26 sailing for the New York Yacht Club.
The Commonwealth Bank of Australia uses a stylized image of the Southern Cross as a corporate logo.
"Southern Cross" is also a 1982 song by the classic rock group Crosby, Stills and Nash, written by Rick Curtis, Michael Curtis, and Stephen Stills. This song was also covered by Jimmy Buffett and is commonly played at his concerts.
After identifying a need for a church for Afrikaans speakers living in the Netherlands, a church was established in Leusden and is known as Suiderkruis Kerk. (Southern Cross Church) There is a town called Suiderkruis (Southern Cross) in the Western Cape province of South Africa. The opening lines of South African composer Koos du Plessis' Christmas carol, 'Somerkersfees' (Summer Christmas) are:
"" claims that the Sun can be in the "vicinity" of Crux: this is seen through the northern hemisphere of the earth.
In the 2006 video game , Crux plays a major role in the story of the game and is the name of the player's radio operator.
The 1981 Black Sabbath album "Mob Rules" features the song "The Sign of the Southern Cross", whose lyrics were written by then member and vocalist Ronnie James Dio.
Namesakes.
USS Crux (AK-115) was a United States Navy Crater class cargo ship named after the constellation.

</doc>
<doc id="6360" url="http://en.wikipedia.org/wiki?curid=6360" title="Cepheus">
Cepheus

Cepheus (Ancient Greek: Κηφεύς "Kepheús") may refer to:

</doc>
<doc id="6361" url="http://en.wikipedia.org/wiki?curid=6361" title="Cassiopeia">
Cassiopeia

Cassiopeia () can refer to:

</doc>
<doc id="6362" url="http://en.wikipedia.org/wiki?curid=6362" title="Cetus">
Cetus

Cetus is a constellation. Its name refers to Cetus, a sea monster in Greek mythology, although it is often called 'the whale' today. Cetus is located in the region of the sky that contains other water-related constellations such as Aquarius, Pisces, and Eridanus.
Notable features.
Ecliptic.
Although Cetus is not generally considered part of the zodiac, the ecliptic passes less than a quarter of a degree from its constellation boundary, and thus the moon, planets, and even part of the sun may be in Cetus for brief periods of time. This is all the more true of asteroids, since their orbits usually have a greater inclination to the ecliptic than the moon and planets. For example, the asteroid 4 Vesta was discovered in this constellation in 1807.
Stars.
The most notable star in Cetus is Mira ("the Wonderful"), designated Omicron Ceti, the first variable star to be discovered and the prototype of its class. Over a period of 332 days it reaches a maximum apparent magnitude of 3 - visible to the naked eye - and dips to a minimum magnitude of 10, invisible to the unaided eye. Its seeming appearance and disappearance gave it its common name, which means "the amazing one". Mira pulsates with a minimum size of 400 solar diameters and a maximum size of 500 solar diameters. 420 light-years from Earth, it was discovered by David Fabricius in 1596.
There are several other bright stars in Cetus. α Ceti, traditionally called Menkar ("the nose"), is a red-hued giant star of magnitude 2.5, 220 light-years from Earth. It is a wide double star; the secondary is 93 Ceti, a blue-white hued star of magnitude 5.6, 440 light-years away. β Ceti, also called Deneb Kaitos and Diphda, is the brightest star in Cetus. It is an orange-hued giant star of magnitude 2.0, 96 light-years from Earth. The traditional name "Deneb Kaitos" means "the whale's tail". γ Ceti, Kaffaljidhma ("head of the whale") is a very close double star. The primary is a yellow-hued star of magnitude 3.5, 82 light-years from Earth, and the secondary is a blue-hued star of magnitude 6.6. Tau Ceti, or Durre Menthor, is noted for being the nearest Sun-like star at a distance of 11.9 light-years. It is a yellow-hued main-sequence star of magnitude 3.5.
AA Ceti is a triple star system; the brightest member has a magnitude of 6.2. The primary and secondary are separated by 8.4 arcseconds at an angle of 304 degrees. The tertiary is not visible in telescopes. AA Ceti is an eclipsing variable star; the tertiary star passes in front of the primary and causes the system's apparent magnitude to decrease by 0.5 magnitudes. UV Ceti is an unusual binary variable star. 8.7 light-years from Earth, the system consists of two red dwarfs. both of magnitude 13. One of the stars is a flare star, which are prone to sudden, random outbursts that last several minutes; these increase the pair's apparent brightness significantly - as high as magnitude 7.
Deep-sky objects.
Cetus lies far from the galactic plane, so that many distant galaxies are visible, unobscured by dust from the Milky Way. Of these, the brightest is Messier 77 (NGC 1068), a 9th magnitude spiral galaxy near Delta Ceti. It appears face-on and has a clearly visible nucleus of magnitude 10. About 50 million light-years from Earth, M77 is also a Seyfert galaxy and thus a bright object in the radio spectrum. Recently, the galactic cluster JKCS 041 was confirmed to be the most distant cluster of galaxies yet discovered.
NGC 246 (Caldwell 56), also called the Cetus Ring, is a planetary nebula with a magnitude of 8.0, 1600 light-years from Earth. Among some amateur astronomers, NGC 246 has garnered the nickname "Pac-Man Nebula" because of the arrangement of its central stars and the surrounding star field.
History and mythology.
Cetus may have originally been associated with a whale, which would have had mythic status amongst Mesopotamian cultures. It is often now called the Whale, though it is most strongly associated with Cetus the sea-monster, who was slain by Perseus as he saved the princess Andromeda from Poseidon's wrath. Cetus is located in a region of the sky called "The Sea" because many water-associated constellations are placed there, including Eridanus, Pisces, Piscis Austrinus, Capricornus, and Aquarius.
Cetus has been depicted many ways throughout its history. In the 17th century, Cetus was depicted as a "dragon fish" by Johann Bayer. Both Willem Blaeu and Andreas Cellarius depicted Cetus as a whale-like creature in the same century. However, Cetus has also been variously depicted with animal heads attached to a piscine body.
In global astronomy.
In Chinese astronomy, the stars of Cetus are found among two areas: the Black Tortoise of the North (北方玄武, "Běi Fāng Xuán Wǔ") and the White Tiger of the West (西方白虎, "Xī Fāng Bái Hǔ").
The Brazilian Tukano and Kobeua people used the stars of Cetus to create a jaguar, representing the god of hurricanes and other violent storms. Lambda, Mu, Xi, Nu, Gamma, and Alpha Ceti represented its head; Omicron, Zeta, and Chi Ceti represented its body; Eta Eri, Tau Cet, and Upsilon Cet marked its legs and feet; and Theta, Eta, and Beta Ceti delineated its tail.
In Hawaii, the constellation was called "Na Kuhi", and Mira (Omicron Ceti) may have been called "Kane".
Namesakes.
USS Cetus (AK-77) was a United States Navy Crater class cargo ship named after the constellation.

</doc>
<doc id="6363" url="http://en.wikipedia.org/wiki?curid=6363" title="Carina (constellation)">
Carina (constellation)

Carina is a constellation in the southern sky. Its name is Latin for the keel of a ship, and it was formerly part of the larger constellation of Argo Navis (the ship "Argo") until that constellation was divided into three pieces, the other two being Puppis (the poop deck), and Vela (the sails of the ship).
History and mythology.
Carina was once a part of Argo Navis, the great ship of Jason and the Argonauts who searched for the Golden Fleece. The constellation of Argo was introduced in ancient Greece. However, Nicolas Louis de Lacaille divided Argo into three component constellations in 1763, including Carina, the Keel.
Despite the division, Lacaille kept Argo's Bayer designations. Therefore Carina has the α, β and ε, Vela has γ and δ, Puppis has ζ, and so on.
Notable features.
Stars.
Carina contains Canopus, a white-hued supergiant that is the second brightest star in the night sky at magnitude −0.72, 313 light-years from Earth. Alpha Carinae, as Canopus is formally designated, is a variable star that varies by approximately 0.1 magnitudes. Its traditional name comes from the mythological Canopus, who was a navigator for Menelaus, king of Sparta.
There are several other stars above magnitude 3 in Carina. Beta Carinae, traditionally called Miaplacidus, is a blue-white hued star of magnitude 1.7, 111 light-years from Earth. Epsilon Carinae is an orange-hued giant star similarly bright to Miaplacidus at magnitude 1.9; it is 630 light-years from Earth. Another fairly bright star is the blue-white hued Theta Carinae; it is a magnitude 2.7 star 440 light-years from Earth. Theta Carinae is also the most prominent member of the cluster IC 2602. Iota Carinae is a white-hued supergiant star of magnitude 2.2, 690 light-years from Earth.
Eta Carinae is the most prominent variable star in Carina; it weighs in at approximately 100 solar masses and is 4 million times as bright as the Sun. It was first discovered to be unusual in 1677, when its magnitude suddenly rose to 4, attracting the attention of Edmond Halley. Eta Carinae is inside NGC 3372, commonly called the Carina Nebula. It had a long outburst in 1827, when it brightened to magnitude 1, only fading to magnitude 1.5 in 1828. Its most prominent outburst made Eta Carinae the equal of Sirius; it brightened to magnitude −1.5 in 1843. However, since 1843, Eta Carinae has remained relatively placid, having a magnitude between 6.5 and 7.9. However, in 1998, it brightened again, though only to magnitude 5.0, a far less drastic outburst. Eta Carinae is a binary star, with a companion that has a period of 5.5 years; the two stars are surrounded by the Homunculus Nebula, which is composed of gas that was ejected in 1843.
There are several less prominent variable stars in Carina. l Carinae is a Cepheid variable noted for its brightness; it is the brightest Cepheid that is variable to the unaided eye. It is a yellow-hued supergiant star with a minimum magnitude of 4.2 and a maximum magnitude of 3.3; it has a period of 35.5 days.
Two bright Mira variable stars are in Carina: R Carinae and S Carinae; both stars are red giants. R Carinae has a minimum magnitude of 10.0 and a maximum magnitude of 4.0. Its period is 309 days and it is 416 light-years from Earth. S Carinae is similar, with a minimum magnitude of 10.0 and a maximum magnitude of 5.0. However, S Carinae has a shorter period – 150 days, though it is much more distant at 1300 light-years from Earth.
Carina is home to several double stars and binary stars. Upsilon Carinae is a binary star with two blue-white hued giant components, 1600 light-years from Earth. The primary is of magnitude 3.0 and the secondary is of magnitude 6.0; the two components are distinguishable in a small amateur telescope.
Two asterisms are prominent in Carina. One is known as the 'Diamond Cross', which is larger than the Southern Cross (but fainter), and, from the perspective of the southern hemisphere viewer, upside down, the long axes of the two crosses being close to parallel. Another asterism in the constellation is the False Cross, often mistaken for the Southern Cross, which is an asterism in Crux. The False Cross consists of two stars in Carina, Iota Carinae and Epsilon Carinae, and two stars in Vela, Kappa Velorum and Delta Velorum.
Deep-sky objects.
Carina is known for its namesake nebula, NGC 3372, discovered by French astronomer Nicolas Louis de Lacaille in 1751, which contains several nebulae. The Carina Nebula overall is a colossal emission nebula approximately 8,000 light-years away and 300 light-years wide that possesses vast star-forming regions; it has an overall magnitude of 8.0. It also has a massive apparent diameter, more than 2 degrees. Its central region is called the Keyhole Nebula, named in 1847 by John Herschel. The Keyhole is about seven light-years wide and is mostly made up of ionized hydrogen, with two major star-forming regions. The Homunculus Nebula is a planetary nebula visible to the naked eye that is being ejected by the erratic luminous blue variable star Eta Carinae, the most massive visible star known. Eta Carinae is so massive that it has reached the theoretical upper limit for the mass of a star and is therefore unstable. It is known for its outbursts; in 1840 it briefly became one of the brightest stars in the sky due to a particularly massive outburst, which largely created the Homunculus Nebula. Because of this instability and history of outbursts, Eta Carinae is considered a prime supernova candidate for the next several hundred thousand years because it has reached the end of its estimated million-year life span.
Since the Milky Way runs through Carina, there are a large number of open clusters in the constellation, embedded in rich star fields. NGC 2516 is an open cluster that is both quite large–approximately half a degree square–and bright, visible to the unaided eye. It is located 1100 light-years from Earth and has approximately 80 stars, the brightest of which is a red giant star of magnitude 5.2. NGC 3114 is another open cluster approximately of the same size, though it is more distant at 3000 light-years from Earth. It is more loose and dim than NGC 2516, as its brightest stars are only 6th magnitude. The most prominent open cluster in Carina is IC 2602, also called the "Southern Pleiades". It contains Theta Carinae, along with several other stars visible to the unaided eye, in total, the cluster possesses approximately 60 stars. The Southern Pleiades is particularly large for an open cluster, with a diameter of approximately one degree. Like IC 2602, NGC 3532 is visible to the unaided eye and is of comparable size. It possesses approximately 150 stars that are arranged in an unusual shape, approximating an ellipse with a dark central area. Several prominent orange giants are among the cluster's bright stars, of the 7th magnitude. Superimposed on the cluster is Chi Carinae, a yellow-white hued star of magnitude 3.9, far more distant than NGC 3532.
Carina also contains the naked-eye globular cluster NGC 2808. Epsilon Carinae and Upsilon Carinae are double stars visible in small telescopes.
One noted galaxy cluster is 1E 0657-56, the Bullet Cluster. At a distance of 4 billion light years (redshift 0.296), this galaxy cluster is named for the shock wave seen in the intracluster medium, which resembles the shock wave of a supersonic bullet. The bow shock visible is thought to be due to the smaller galaxy cluster moving through the intracluster medium at a relative speed of 3000–4000 kilometers per second to the larger cluster. Because this gravitational interaction has been ongoing for hundreds of millions of years, the smaller cluster is being destroyed and will eventually merge with the larger cluster.
Meteors.
Carina contains the radiant of the Eta Carinids meteor shower, which peaks around January 21 each year.
Equivalents.
From China (especially northern China), the stars of Carina can barely be seen. The star Canopus (the south polar star in Chinese astronomy) was located by Chinese astronomers in the The Vermillion Bird of the South (南方朱雀, "Nán Fāng Zhū Què"). The rest of the stars were first classified by Xu Guanggi during the Ming Dynasty, based on the knowledge acquired from western star charts, and placed among The Southern Asterisms (近南極星區, "Jìnnánjíxīngōu").
Polynesian peoples had no name for the constellation in particular, though they had many names for Canopus. 
The Maori name "Ariki" ("High-born"), . and the Hawaiian "Ke Alii-o-kona-i-ka-lewa", "The Chief of the southern expanse". both attest to the star’s prominence in the southern sky, while the Maori "Atutahi", "First-light" or "Single-light", and the Tuamotu "Te Tau-rari" and "Marere-te-tavahi", "He-who-stands-alone". refer to the star’s solitary nature.
It was also called "Kapae-poto", ("Short horizon"), because it rarely sets from the vantage point of New Zealand; and "Kauanga" ("Solitary"), when it was the last star visible before sunrise.
Namesakes.
 was a United States Navy Crater class cargo ship named after the constellation.

</doc>
<doc id="6364" url="http://en.wikipedia.org/wiki?curid=6364" title="Camelopardalis">
Camelopardalis

Camelopardalis or the Giraffe constellation is a large, faint grouping of stars in the northern sky. The constellation was introduced in 1612 (or 1613) by Petrus Plancius. Some older astronomy books give an alternative spelling of the name, Camelopardus.
Etymology.
First attested in English in 1785, the word "camelopardalis" comes from Latin, and it is the romanisation of the Greek "καμηλοπάρδαλις" meaning "giraffe", from "κάμηλος" ("kamēlos"), "camel" + "πάρδαλις" ("pardalis"), "leopard", due to its having a long neck like a camel and spots like a leopard.
Notable features.
Stars.
Although Camelopardalis is the 18th largest constellation, it is not a particularly bright constellation, as the brightest stars are only of fourth magnitude. In fact, it only contains four stars above magnitude 5.0.
Other variable stars are U Camelopardalis, VZ Camelopardalis, and Mira variables T Camelopardalis, X Camelopardalis, and R Camelopardalis. RU Camelopardalis is one of the brighter Type II Cepheids visible in the night sky.
In 2011 a supernova was discovered in the constellation.
Deep-sky objects.
Camelopardalis is in the part of the celestial sphere facing away from the galactic plane. Accordingly, many distant galaxies are visible within its borders. NGC 2403 is a galaxy in the M81 group of galaxies, located approximately 12 million light-years from Earth with a redshift of 0.00043. It is classified as being between an elliptical and a spiral galaxy because it has faint arms and a large central bulge. NGC 2403 was first discovered by the 18th century astronomer William Herschel, who was working in England at the time. It has an integrated magnitude of 8.0 and is approximately 0.25° long.
NGC 1502 is a magnitude 6.9 open cluster about 3,000 light years from Earth. It has about 45 bright members, and features a double star of magnitude 7.0 at its center. NGC 1502 is also associated with Kemble's Cascade, a simple but beautiful asterism appearing in the sky as a chain of stars 2.5° long that is parallel to the Milky Way and is pointed towards Cassiopeia. NGC 1501 is a planetary nebula located roughly 1.4° south of NGC 1502.
NGC 2655 is a small galaxy. IC 342 is one of the brightest two galaxies in the IC 342/Maffei Group of galaxies. The dwarf irregular galaxy NGC 1569 is a magnitude 11.9 starburst galaxy, about 11 million light years away.
MS0735.6+7421 is a galaxy cluster with a redshift of 0.216, located 2.6 billion light-years from Earth. It is unique for its intracluster medium, which emits x-rays at a very high rate. This galaxy cluster features two cavities 600,000 light-years in diameter, caused by its central supermassive black hole, which emits jets of matter. MS0735.6+7421 is one of the largest and most distant examples of this phenomenon.
Tombaugh 5 is a fairly dim open cluster in Camelopardalis. It has an overall magnitude of 8.4 and is located 5,800 light-years from Earth. It is a Shapley class c and Trumpler class III 1 r cluster, meaning that it is irregularly shaped and appears loose. Though it is detached from the star field, it is not concentrated at its center at all. It has more than 100 stars which do not vary widely in brightness, mostly being of the 15th and 16th magnitude.
NGC 2146 is an 11th magnitude barred spiral starburst galaxy conspicuously warped by interaction with a neighbour.
MACS0647-JD, one of the possible candidates for the farthest known galaxies in the universe (z= 10.7), is also in Camelopardalis.
Meteor showers.
The annual May meteor shower Camelopardalids from comet 209P/LINEAR have a radiant in Camelopardalis.
Space exploration.
The space probe "Voyager 1" is moving in the direction of this constellation, though it will not be nearing any of the stars in this constellation for many thousands of years, by which time its power source will be long dead.
History.
Camelopardalis was created by Petrus Plancius in 1613 to represent the animal Rebecca rode to marry Isaac in the Bible. One year later, Jakob Bartsch featured it in his atlas. Johannes Hevelius gave it the official name of "Camelopardus" or "Camelopardalis" because he saw the constellation's many faint stars as the spots of a giraffe.
Visualizations.
H. A. Rey has suggested an alternative way to connect the stars of Camelopardalis into a giraffe figure.
 <br clear=left>The giraffe's body consists of the quadrangle of stars α Cam, β Cam, BE Cam, and γ Cam: α Cam and β Cam being of the fourth magnitude. The stars HD 42818 (HR 2209) and M Cam form the head of the giraffe, and the stars M Cam and α Cam form the giraffe's long neck. Stars β Cam and 7 Cam form the giraffe's front leg, and variable stars BE Cam and CS Cam form the giraffe's hind leg.
Equivalents.
In Chinese astronomy, the stars of Camelopardalis are located within a group of circumpolar stars called the Purple Forbidden Enclosure (紫微垣 "Zǐ Wēi Yuán").

</doc>
<doc id="6365" url="http://en.wikipedia.org/wiki?curid=6365" title="Convention of Kanagawa">
Convention of Kanagawa

On March 31, 1854, the or was concluded between Commodore Matthew C. Perry of the United States Navy and the Tokugawa shogunate.
Treaty of Peace and Amity (1854).
The treaty opened the Japanese ports of Shimoda and Hakodate to United States trade and guaranteed the safety of shipwrecked US sailors; however, the treaty did not create a basis for establishing a permanent residence in these locations. The treaty did establish a foundation for the Americans to maintain a permanent consul in Shimoda. The arrival of the fleet would trigger the end of Japan's 200 year policy of seclusion (Sakoku).
Perry initially refused to deal with local Japanese officials and demanded to speak only with representatives of the Japanese head of state. At the time, Shogun Tokugawa Ieyoshi was the de facto ruler of Japan; for the Emperor to interact in any way with foreigners was out of the question. Perry concluded the treaty with representatives of the Shogun, led by plenipotentiary and the text was reluctantly endorsed subsequently by Emperor Komei.
The treaty was ratified on 21 February 1855.
Later treaties.
The Kanagawa treaty was followed by the United States-Japan Treaty of Kanagawa, the "Harris Treaty" of 1858, which allowed the establishment of foreign concessions, extraterritoriality for foreigners, and minimal import taxes for foreign goods. The Japanese chafed under the "unequal treaty system" which characterized Asian and western relations during this period.
The Kanagawa treaty became a significant causative factor leading to serious internal conflicts within Japan — an upheaval which was only resolved in 1867 with the end of the Tokugawa shogunate and the beginning of the Meiji Restoration.
Similar treaties were subsequently negotiated by the United Kingdom (Anglo-Japanese Friendship Treaty, October 1854), the Russians (Treaty of Shimoda, 7 February 1855), and the French (Treaty of Amity and Commerce between France and Japan, 9 October 1858).
Kanagawa Treaty House.
The Convention was negotiated and then it signed in a purpose-built house in Yokohama, Japan.

</doc>
<doc id="6366" url="http://en.wikipedia.org/wiki?curid=6366" title="Canis Major">
Canis Major

Canis Major is a constellation in the southern celestial hemisphere. In the second century, it was included in Ptolemy's 48 constellations, and is counted among the 88 modern constellations. Its name is Latin for "greater dog" in contrast to Canis Minor, the "lesser dog"; both figures are commonly represented as following the constellation of Orion the hunter. The Milky Way passes through Canis Major and several open clusters lie within its borders.
Canis Major contains Sirius, the brightest star in the night sky, known as the 'dog star'. It is bright because of its proximity to our Solar System. In contrast, the other bright stars of the constellation are stars of great distance and high luminosity. At magnitude 1.5, Epsilon Canis Majoris (Adhara) is the second brightest star of the constellation and one of the brightest sources of ultraviolet radiation in the night sky. Next in brightness are the yellow-white supergiant Delta (Wezen) at 1.8, the blue-white giant Beta (Mirzam) at 2.0, blue-white supergiants Eta (Aludra) at 2.4 and Omicron1 at 3.0, and white spectroscopic binary Zeta (Furud), also at 3.0. The red hypergiant VY Canis Majoris is one of the largest stars known, while the neutron star RX J0720.4-3125 has a radius of a mere 5 km.
History and mythology.
In western astronomy.
In ancient Mesopotamia, Sirius, named KAK.SI.DI by the Babylonians, was seen as an arrow aiming towards Orion, while the southern stars of Canis Major and a part of Puppis were viewed as a bow, named BAN in the "Three Stars Each" tablets, dating to around 1100 BC. In the later compendium of Babylonian astronomy and astrology titled "MUL.APIN", the arrow, Sirius, was also linked with the warrior Ninurta, and the bow with Ishtar, daughter of Enlil. Ninurta was linked to the later deity Marduk, who was said to have slain the ocean goddess Tiamat with a great bow, and worshipped as the principal deity in Babylon. The Ancient Greeks replaced the bow and arrow depiction with that of a dog.
In Greek Mythology, Canis Major represented the dog Laelaps, a gift from Zeus to Europa; or sometimes the hound of Procris, Diana's nymph; or the one given by Aurora to Cephalus, so famed for its speed that Zeus elevated it to the sky. It was also considered to represent one of Orion's hunting dogs, pursuing Lepus the Hare or helping Orion fight Taurus the Bull; and is referred to in this way by Aratos, Homer and Hesiod. The ancient Greeks refer only to one dog, but by Roman times, Canis Minor appears as Orion's second dog. Alternative names include Canis Sequens and Canis Alter. Canis Syrius was the name used in the 1521 "Alfonsine Tables".
The Roman myth refers to Canis Major as "Custos Europae", the dog guarding Europa but failing to prevent her abduction by Jupiter in the form of a bull; and as "Janitor Lethaeus", "the watchdog". In medieval Arab astronomy, the constellation became "Al Kalb al Akbar", "the Greater Dog", transcribed as "Alcheleb Alachbar" by 17th century writer Edmund Chilmead. Islamic scholar Abū Rayḥān al-Bīrūnī referred to Orion as "Al Kalb al Jabbār", "the Dog of the Giant". Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called "Merzem", includes the stars of Canis Major and Canis Minor and is the herald of two weeks of hot weather.
In non-western astronomy.
In Chinese astronomy, the modern constellation of Canis Major lies in The Vermillion Bird of the South (南方朱雀, "Nán Fāng Zhū Què"), where the stars were classified in several separate asterisms of stars. The Military Market ("Jūnshì" 軍市) was a circular pattern of stars containing Nu3, Beta, Xi1 and Xi2, and some stars from Lepus. The Wild Cockerel ("Yějī" 野雞) was at the centre of the Military Market, although it is uncertain which stars depicted what. Schlegel reported that the stars Omicron and Pi Canis Majoris might have been them, while Beta or Nu2 have also been proposed. Sirius was "Tiānláng" (天狼), the Celestial Wolf, denoting invasion and plunder. Southeast of the Wolf was the asterism "Húshǐ" (弧矢), the celestial Bow and Arrow, which was interpreted as containing Delta, Epsilon, Eta and Kappa Canis Majoris and Delta Velorum. Alternatively, the arrow was depicted by Omicron2 and Eta and aiming at Sirius (the Wolf), while the bow comprised Kappa, Epsilon, Sigma, Delta and 164 Canis Majoris, and Pi and Omicron Puppis.
Both the Maori people and the people of the Tuamotus recognized the figure of Canis Major as a distinct entity, though it was sometimes absorbed into other constellations. "Te Huinga-o-Rehua", also called "Te Putahi-nui-o-Rehua" and "Te Kahui-Takurua", ("The Assembly of Rehua" or "The Assembly of Sirius") was a Maori constellation that included both Canis Minor and Canis Major, along with some surrounding stars. Related was "Taumata-o-Rehua", also called "Pukawanui", the Mirror of Rehua, formed from an undefined group of stars in Canis Major. They called Sirius "Rehua" and "Takarua", corresponding to two of the names for the constellation, though "Rehua" was a name applied to other stars in various Maori groups and other Polynesian cosmologies. The Tuamotu people called Canis Major "Muihanga-hetika-o-Takurua", "the abiding assemblage of Takurua".
The Tharumba people of the Shoalhaven River saw three stars of Canis Major as "Wunbula" (Bat) and his two wives "Murrumbool" (Mrs Brown Snake) and "Moodtha" (Mrs Black Snake); bored of following their husband around, the women try to bury him while he is hunting a wombat down its hole. He spears them and all three are placed in the sky as the constellation "Munowra". To the Boorong people of Victoria, Sigma Canis Majoris was "Unurgunite", and its flanking stars Delta and Epsilon were his two wives. The moon, "Mityan" "native cat" sought to lure the further wife (Epsilon) away, but Unurgunite assaulted him and he has been wandering the sky ever since.
Characteristics.
Canis Major is a constellation in the southern hemisphere's summer (or northern hemisphere's winter) sky, bordered by Monoceros (which lies between it and Canis Minor) to the north, Puppis to the east and southeast, Columba to the southwest, and Lepus to the west. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'CMa'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a quadrilateral; in the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between −11.03° and −33.25°. Covering 380 square degrees or 0.921% of the sky, it ranks 43rd of the 88 currently-recognized constellations in size.
Notable features.
Stars.
Canis Major is a prominent constellation because of its many bright stars. These include Sirius (Alpha Canis Majoris), the brightest star in the night sky, as well as three other stars above magnitude 2.0. Furthermore, two other stars are thought to have previously outshone all others in the night sky—Adhara (Epsilon Canis Majoris) shone at -3.99 around 4.7 million years ago, and Mirzam (Beta Canis Majoris) peaked at −3.65 around 4.42 million years ago, and another—NR Canis Majoris—will be brightest at magnitude −0.88 in about 2.87 million years' time.
The German cartographer Johann Bayer used the Greek letters Alpha through Omicron to label the most prominent stars in the constellation, including three adjacent stars as Nu and two further pairs as Xi and Omicron, while subsequent observers designated further stars in the southern parts of the constellation that were hard to discern from Central Europe. Bayer's countryman Johann Elert Bode later added Sigma, Tau and Omega; the French astronomer Nicolas Louis de Lacaille added lettered stars a to k (though none are in use today). John Flamsteed numbered 31 stars, with 3 Canis Majoris being placed by Lacaille into Columba as Delta Columbae (Flamsteed had not recognised Columba as a distinct constellation). He also labelled two stars—his 10 and 13 Canis Majoris—as Kappa1 and Kappa2 respectively, but subsequent cartographers such as Francis Baily and John Bevis dropped the fainter former star, leaving Kappa2 as the sole Kappa. Flamsteed's listing of Nu1, Nu2, Nu3, Xi1, Xi2, Omicron1 and Omicron2 have all remained in use.
At apparent magnitude −1.46, Sirius is one of the closest stars to Earth at a distance of 8.6 light-years. Its name comes from the Greek word for "scorching" or "searing". Sirius is also a binary star; its companion Sirius B is a white dwarf with a magnitude of 8.4—10,000 times fainter than Sirius A to observers on Earth. The two orbit each other every 50 years. Their closest approach last occurred in 1993 and they will be at their greatest separation between 2020 and 2025. Sirius was the basis for the ancient Egyptian calendar. The star marked the Great Dog's mouth on Bayer's star atlas.
Flanking Sirius are Beta and Gamma Canis Majoris. Also called Mirzam or Murzim, Beta is a blue-white Beta Cephei variable star of magnitude 2.0, which varies by a few hundredths of a magnitude over a period of six hours. Mirzam is 500 light-years from Earth, and its traditional name means "the announcer", referring to its position as the "announcer" of Sirius, as it rises a few minutes before Sirius does. Gamma, also known as Muliphein, is a fainter star of magnitude 4.12, in reality a blue-white bright giant of spectral type B8IIe located 441 light-years from earth. Iota Canis Majoris, lying between Sirius and Gamma, is another star that has been classified as a Beta Cephei variable, varying from magnitude 4.36 to 4.40 over a period of 1.92 hours. However it is a remote blue-white supergiant star of spectral type B3Ib, around 46,000 times as luminous as the sun and, at 2500 light-years distant, 300 times further away than Sirius.
Epsilon, Omicron2, Delta and Eta Canis Majoris were called "Al Adzari" "the virgins" in medieval Arabic tradition. Marking the dog's right thigh on Bayer's atlas is Epsilon Canis Majoris, also known as Adhara. At magnitude 1.5, it is the second-brightest star in Canis Major and the 23rd-brightest star in the sky. It is a blue-white supergiant of spectral type B2Iab, around 404 light-years from Earth. This star is one of the brightest known extreme ultraviolet sources in the sky. It is a binary star; the secondary is of magnitude 7.4. Its traditional name means "the virgins", having been transferred from the group of stars to Epsilon alone. Nearby is Delta Canis Majoris, also called Wezen. It is a yellow-white supergiant of spectral type F8Iab and magnitude 1.84, around 1605 light-years from Earth. With a traditional name meaning "the weight", Wezen is 17 times as massive and 50,000 times as luminous as the Sun. If located in the centre of the Solar System, it would extend out to Earth as its diameter is 200 times that of the Sun. Only around 10 million years old, Wezen has stopped fusing hydrogen in its core. Its outer envelope is beginning to expand and cool, and in the next 100,000 years it will become a red supergiant as its core fuses heavier and heavier elements. Once it has a core of iron, it will collapse and explode as a supernova. Nestled between Adhara and Wezen lies Sigma Canis Majoris, known as Unurgunite to the Boorong and Wotjobaluk people, a red supergiant of spectral type K7Ib that varies irregularly between magnitudes 3.43 and 3.51.
Also called Aludra, Eta Canis Majoris is a blue-white supergiant of spectral type B5Ia with a luminosity 176,000 times and diameter around 80 times that of the Sun. Classified as an Alpha Cygni type variable star, Aludra varies in brightness from magnitude 2.38 to 2.48 over a period of 4.7 days. It is located 1120 light-years away. To the west of Adhara lies 3.0-magnitude Zeta Canis Majoris or Furud, around 362 light-years distant from Earth. It is a spectroscopic binary, whose components orbit each other every 1.85 years, the combined spectrum indicating a main star of spectral type B2.5V.
Between these stars and Sirius lie Omicron1, Omicron2, and Pi Canis Majoris. Omicron2 is a massive supergiant star about 21 times as massive as the Sun. Only 7 million years old, it has exhausted the supply of hydrogen at its core and is now processing helium. It has an Alpha Cygni variable that undergoes periodic non-radial pulsations, which cause its brightness to cycle from magnitude 2.93 to 3.08 over a 24.44-day interval. Omicron1 is an orange K-type supergiant of spectral type K2.5Iab that is an irregular variable star, varying between apparent magnitudes 3.78 and 3.99. Around 18 times as massive as the Sun, it shines with 65,000 times its luminosity.
North of Sirius lie Theta and Mu Canis Majoris, Theta being the most northerly star with a Bayer designation in the constellation. Around 8 billion years old, it is an orange giant of spectral type K4III that is around as massive as the Sun but has expanded to 30 times the Sun's diameter. Mu is a multiple star system located around 1244 light-years distant, its components discernible in a small telescope as a 5.3-magnitude yellow-hued and 7.1-magnitude bluish star. The brighter star is a giant of spectral type K2III, while the companion is a main sequence star of spectral type B9.5V. Nu Canis Majoris is a yellow-hued giant star of magnitude 5.7, 278 light-years away; it is at the threshold of naked-eye visibility. It has a companion of magnitude 8.1.
At the southern limits of the constellation lie Kappa and Lambda Canis Majoris. Although of similar spectra and nearby each other as viewed from Earth, they are unrelated. Kappa is a Gamma Cassiopeiae variable of spectral type B2Vne, which brightened by 50% between 1963 and 1978, from magnitude 3.96 or so to 3.52. It is around 659 light-years distant. Lambda is a blue-white B-type main sequence dwarf with an apparent magnitude of 4.48 located around 423 light-years from Earth. It is 3.7 times as wide as and 5.5 times as massive as the Sun, and shines with 940 times its luminosity.
Canis Major is also home to many variable stars. EZ Canis Majoris is a Wolf-Rayet star of spectral type WN4 that varies between magnitudes 6.71 and 6.95 over a period of 3.766 days; the cause of its variability is unknown but thought to be related to its stellar wind and rotation. VY Canis Majoris is one of the largest stars known, a remote red supergiant located around 3800 light-years away from Earth. Estimates of its size, mass and luminosity have varied, with figures of 600 to 3000 times the radius, and 60,000 to 500,000 times the luminosity of the Sun. It was observed in 2011 using interferometry with the Very Large Telescope, yielding a radius of 1420 ± 120 solar radii, surface temperature of around 3490 K (and hence spectral type M4Ia) and a luminosity 270,000 times that of the Sun. Its current mass has been revised at 9–25 solar masses, having shed material from an initial 15–35 solar masses. W Canis Majoris is a type of red giant known as a carbon star—a semiregular variable, it ranges between magnitudes 6.27 and 7.09 over a period of 160 days. A cool star, it has a surface temperature of around 2900 K and a radius 234 times that of the Sun, its distance estimated at 1444–1450 light-years from Earth. At the other extreme in size is RX J0720.4-3125, a neutron star with a radius of around 5 km. Exceedingly faint, it has an apparent magnitude of 26.6. Its spectrum and temperature appear to be mysteriously changing over several years. The nature of the changes are unclear, but it is possible they were caused by an event such as the star's absorption of an accretion disc.
Tau Canis Majoris is a Beta Lyrae-type eclipsing multiple star system that varies from magnitude 4.32 to 4.37 over 1.28 days. Its four main component stars are hot O-type stars, with a combined mass 80 times that of the Sun and shining with 500,000 times its luminosity, but little is known of their individual properties. A fifth component, a magnitude 10 star, lies 13,000 AU distant. The system is only 5 million years old. UW Canis Majoris is another Beta Lyrae-type star 3000 light-years from Earth; it is an eclipsing binary that ranges in magnitude from a minimum of 5.3 to a maximum of 4.8. It has a period of 4.4 days; its components are two massive hot blue stars, one a blue supergiant of spectral type O7.5-8 Iab, while its companion is a slightly cooler, less evolved and less luminous supergiant of spectral type O9.7Ib. The stars are 200,000 and 63,000 times as luminous as the Sun. However the fainter star is the more massive at 19 solar masses to the primary's 16. R Canis Majoris is another eclipsing binary that varies from magnitude 5.7 to 6.34 over 1.13 days, with a third star orbiting these two every 93 years. The shortness of the orbital period and the low ratio between the two main components make this an unusual Algol-type system.
Seven star systems have been found to have planets. Nu2 Canis Majoris is an ageing orange giant of spectral type K1III of apparent magnitude 3.91 located around 64 light-years distant. Around 1.5 times as massive and 11 times as luminous as the Sun, it is orbited over a period of 763 days by a planet 2.6 times as massive as Jupiter. HD 47536 is likewise an ageing orange giant found to have a planetary system—echoing the fate of our own Solar System in a few billion years as the Sun ages and becomes a giant. Conversely, HD 45364 is a star 107 light-years distant that is a little smaller and cooler than the Sun, of spectral type G8V, which has two planets discovered in 2008. With orbital periods of 228 and 342 days, the planets have a 3:2 orbital resonance, which helps stabilise the system. HD 47186 is another sunlike star with two planets; the inner—HD 47186 b—takes four days to complete an orbit and has been classified as a Hot Neptune, while the outer—HD 47186 c—has an eccentric 3.7-year period orbit and has a similar mass to Saturn. HD 43197 is a sunlike star around 183 light-years distant that has a Jupiter-size planet with an eccentric orbit.
Z Canis Majoris is a star system a mere 300,000 years old composed of two pre-main-sequence stars—a FU Orionis star and a Herbig Ae/Be star, which has brightened episodically by two magnitudes to magnitude 8 in 1987, 2000, 2004 and 2008. The more massive Herbig Ae/Be star is enveloped in an irregular roughly spherical cocoon of dust that has an inner diameter of 20 and outer diameter of 50 AU. The cocoon has a hole in it through which light shines that covers an angle of 5 to 10 degrees of its circumference. Both stars are surrounded by a large envelope of in-falling material left over from the original cloud that formed the system. Both stars are emitting jets of material, that of the Herbig Ae/Be star being much larger—11.7 light-years (3.6 parsecs) long. Meanwhile, FS Canis Majoris is another star with infra-red emissions indicating a compact shell of dust, however it appears to be a main-sequence star that has absorbed material from a companion. These stars are thought to be significant contributors to interstellar dust.
Deep-sky objects.
The band of the Milky Way goes through Canis Major, with only patchy obscurement by interstellar dust clouds. It is bright in the northeastern corner of the constellation, as well as in a triangular area between Adhara, Wezen and Aludra, with many stars visible in binoculars. Canis Major boasts several open clusters. The only Messier object is M41 (NGC 2287), an open cluster with a combined visual magnitude of 4.5, around 2300 light-years from Earth. Located 4 degrees south of Sirius, it contains contrasting blue, yellow and orange stars and covers an area the apparent size of the full Moon—in reality around 25 light-years in diameter. Its most luminous stars have already evolved into giants. The brightest is a 6.3-magnitude star of spectral type K3. Located in the field is 12 Canis Majoris, though this star is only 670 light-years distant. NGC 2360, known as Caroline's Cluster after its discoverer Caroline Herschel, is an open cluster located 3.5 degrees west of Muliphein and has a combined apparent magnitude of 7.2. Around 15 light-years in diameter, it is located 3700 light-years away from Earth, and has been dated to around 2.2 billion years old. NGC 2362 is a small, compact open cluster, 5200 light-years from Earth. It contains about 60 stars, of which Tau Canis Majoris is the brightest member. Located around 3 degrees northeast of Wezen, it covers an area around 12 light-years in diameter, though the stars appear huddled around Tau when seen through binoculars. It is a very young open cluster as its member stars are only a few million years old. Lying 2 degrees southwest of NGC 2362 is NGC 2354 a fainter open cluster of magnitude 6.5, with around 15 member stars visible with binoculars. Located around 30' northeast of NGC 2360, NGC 2359 (Thor's Helmet or the Duck Nebula) is a relatively bright emission nebula in Canis Major, with an approximate magnitude of 10, which is 10,000 light-years from Earth. The nebula is shaped by HD 56925, an unstable Wolf-Rayet star embedded within it.
In 2003, an overdensity of stars in the region was announced to be the Canis Major Dwarf, the closest satellite galaxy to Earth. However, there remains debate over whether it represents a disrupted dwarf galaxy or in fact a variation in the thin and thick disk and spiral arm populations of the Milky Way. Investigation of the area yielded only ten RR Lyrae variables—consistent with the Milky Way's halo and thick disk populations rather than a separate dwarf spheroidal galaxy. On the other hand, a globular cluster in Puppis, NGC 2298—which appears to be part of the Canis Major dwarf system—is extremely metal-poor, suggesting it did not arise from the Milky Way's thick disk, and instead is of extragalactic origin.
NGC 2207 and IC 2163 are a pair of face-on interacting spiral galaxies located 125 million light-years from Earth. About 40 million years ago, the two galaxies had a close encounter and are now moving farther apart; nevertheless, the smaller IC 2163 will eventually be incorporated into NGC 2207. As the interaction continues, gas and dust will be perturbed, sparking extensive star formation in both galaxies. Supernovae have been observed in NGC 2207 in 1975 (type Ia SN 1975a), 1999 (the type Ib SN 1999ec), 2003 (type 1b supernova SN 2003H), and 2013 (type II supernova SN 2013ai). Located 16 million light-years distant, ESO 489-056 is an irregular dwarf- and Low-surface-brightness galaxy that has one of the lowest metallicities known.

</doc>
<doc id="6367" url="http://en.wikipedia.org/wiki?curid=6367" title="Canis Minor">
Canis Minor

Canis Minor is a small constellation in the northern celestial hemisphere. In the second century, it was included as an asterism, or pattern, of two stars in Ptolemy's 48 constellations, and it is counted among the 88 modern constellations. Its name is Latin for "lesser dog", in contrast to Canis Major, the "greater dog"; both figures are commonly represented as following the constellation of Orion the hunter.
Canis Minor contains only two stars brighter than the fourth magnitude, Procyon (Alpha Canis Minoris), with a magnitude of 0.34, and Gomeisa (Beta Canis Minoris), with a magnitude of 2.9. The constellation's dimmer stars were noted by Johann Bayer, who named eight stars including Alpha and Beta, and John Flamsteed, who numbered fourteen. Procyon is the seventh-brightest star in the night sky, as well as one of the closest. A yellow-white main sequence star, it has a white dwarf companion. Gomeisa is a blue-white main sequence star. Luyten's Star is a ninth-magnitude red dwarf and the Solar System's next closest stellar neighbour in the constellation after Procyon. The fourth-magnitude HD 66141, which has evolved into an orange giant towards the end of its life cycle, was discovered to have a planet in 2012. There are two faint deep sky objects within the constellation's borders. The 11 Canis-Minorids are a meteor shower that can be seen in early December.
History and mythology.
Though strongly associated with the Classical Greek uranographic tradition, Canis Minor originates from ancient Mesopotamia. Procyon and Gomeisa were called "MASH.TAB.BA" or "twins" in the "Three Stars Each" tablets, dating to around 1100 BC. In the later "MUL.APIN", this name was also applied to the pairs of Pi3 and Pi4 Orionis and Zeta and Xi Orionis. The meaning of "MASH.TAB.BA" evolved as well, becoming the twin deities Lulal and Latarak, who are on the opposite side of the sky from "Papsukal", the True Shepherd of Heaven in Babylonian mythology. Canis Minor was also given the name "DAR.LUGAL", which translates to "the star which stands behind it", in the "MUL.APIN"; the constellation represents a rooster. This name may have also referred to the constellation Lepus. "DAR.LUGAL" was also denoted "DAR.MUŠEN" and "DAR.LUGAL.MUŠEN" in Babylonia. Canis Minor was then called "tarlugallu" in Akkadian astronomy.
Canis Minor was one of the original 48 constellations formulated by Ptolemy in his second-century Almagest, in which it was defined as a specific pattern (asterism) of stars; Ptolemy identified only two stars and hence no depiction was possible. The Ancient Greeks called the constellation προκυων/"Procyon", "coming before the dog", transliterated into Latin as "Antecanis", "Praecanis", or variations thereof, by Cicero and others. Roman writers also appended the descriptors "parvus", "minor" or "minusculus" ("small" or "lesser", for its faintness), "septentrionalis" ("northerly", for its position in relation to Canis Major), "primus" (rising "first") or "sinister" (rising to the "left") to its name "Canis". 
In Greek mythology, Canis Minor was sometimes connected with the Teumessian Fox, a beast turned into stone with its hunter, Laelaps, by Zeus, who placed them in heaven as Canis Major (Laelaps) and Canis Minor (Teumessian Fox). Eratosthenes accompanied the Little Dog with Orion, while Hyginus linked the constellation with Maera, a dog owned by Icarius of Athens. On discovering the latter's death, the dog and Icarius' daughter Erigone took their lives and all three were placed in the sky—Erigone as Virgo and Icarius as Boötes. As a reward for his faithfulness, the dog was placed along the "banks" of the Milky Way, which the ancients believed to be a heavenly river, where he would never suffer from thirst.
The medieval Arabic astronomers maintained the depiction of Canis Minor ("al-Kalb al-Asghar" in Arabic) as a dog; in his Book of the Fixed Stars, Abd al-Rahman al-Sufi included a diagram of the constellation with a canine figure superimposed. There was one slight difference between the Ptolemaic vision of Canis Minor and the Arabic; al-Sufi claims Mirzam, now assigned to Orion, as part of both Canis Minor—the collar of the dog—and its modern home. The Arabic names for both Procyon and Gomeisa alluded to their proximity and resemblance to Sirius, though they were not direct translations of the Greek; Procyon was called "ash-Shi'ra ash-Shamiya", the "Syrian Sirius" and Gomeisa was called "ash-Shira al-Ghamisa", the Sirius with bleary eyes. Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called "Merzem", includes the stars of Canis Minor and Canis Major and is the herald of two weeks of hot weather.
The ancient Egyptians thought of this constellation as Anubis, the jackal god.
Alternative names have been proposed: Johann Bayer in the early 17th century termed the constellation "Fovea" "The Pit", and "Morus" "Sycamine Tree". Seventeenth-century German poet and author Philippus Caesius linked it to the dog of Tobias from the Apocrypha. Richard A. Proctor gave the constellation the name "Felis" "the Cat" in 1870 (contrasting with Canis Major, which he had abbreviated to "Canis" "the Dog"), explaining that he sought to shorten the constellation names to make them more manageable on celestial charts. Occasionally, Canis Minor is confused with Canis Major and given the name "Canis Orionis" ("Orion's Dog").
In non-Western astronomy.
In Chinese astronomy, the stars corresponding to Canis Minor lie in the The Vermilion Bird of the South (南方朱雀, "Nán Fāng Zhū Què"). Procyon, Gomeisa and Eta Canis Minoris form an asterism known as Nánhé, the Southern River. With its counterpart, the Northern River Beihe (Castor and Pollux), Nánhé was also associated with a gate or sentry. Along with Zeta and 8 Cancri, 6 Canis Minoris and 11 Canis Minoris formed the asterism "Shuiwei", which literally means "water level". Combined with additional stars in Gemini, Shuiwei represented an official who managed floodwaters or a marker of the water level. Neighboring Korea recognized four stars in Canis Minor as part of a different constellation, "the position of the water". This constellation was located in the Red Bird, the southern portion of the sky.
Polynesian peoples often did not recognize Canis Minor as a constellation, but they saw Procyon as significant and often named it; in the Tuamotu Archipelago it was known as "Hiro", meaning "twist as a thread of coconut fiber", and "Kopu-nui-o-Hiro" ("great paunch of Hiro"), which was either a name for the modern figure of Canis Minor or an alternative name for Procyon. Other names included "Vena" (after a goddess), on Mangaia and "Puanga-hori" (false "Puanga", the name for Rigel), in New Zealand. In the Society Islands, Procyon was called "Ana-tahua-vahine-o-toa-te-manava", literally "Aster the priestess of brave heart", figuratively the "pillar for elocution". The Wardaman people of the Northern Territory in Australia gave Procyon and Gomeisa the names "Magum" and "Gurumana", describing them as humans who were transformed into gum trees in the dreamtime. Although their skin had turned to bark, they were able to speak with a human voice by rustling their leaves.
The Aztec calendar was related to their cosmology. The stars of Canis Minor were incorporated along with some stars of Orion and Gemini into an asterism associated with the day called "Water".
Characteristics.
Lying directly south of Gemini's bright stars Castor and Pollux, Canis Minor is a small constellation bordered by Monoceros to the south, Gemini to the north, Cancer to the northeast, and Hydra to the east. It does not border Canis Major; Monoceros is in between the two. Covering 183 square degrees, Canis Minor ranks seventy-first of the 88 constellations in size. It appears prominently in the southern sky during the Northern Hemisphere's winter. The constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of 14 sides. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between and . Most visible in the evening sky from January to March, Canis Minor is most prominent at 10 PM during mid-February. It is then seen earlier in the evening until July, when it is only visible after sunset before setting itself, and rising in the morning sky before dawn. The constellation's three-letter abbreviation, as adopted by the International Astronomical Union in 1922, is "CMi".
Notable features.
Stars.
Canis Minor contains only two stars brighter than fourth magnitude. At magnitude 0.34, Procyon, or Alpha Canis Minoris, is the seventh-brightest star in the night sky, as well as one of the closest. Its name means "before the dog" or "preceding the dog" in Greek, as it rises an hour before the "Dog Star", Sirius, of Canis Major. It is a binary star system, consisting of a yellow-white main sequence star of spectral type F5 IV-V, named Procyon A, and a faint white dwarf companion of spectral type DA, named Procyon B. Procyon B, which orbits the more massive star every 41 years, is of magnitude 10.7. Procyon A is 1.4 times the Sun's mass, while its smaller companion is 0.6 times as massive as the Sun. The system is from Earth, the shortest distance to a northern-hemisphere star of the first magnitude. Gomeisa, or Beta Canis Minoris, with a magnitude of 2.89, is the second-brightest star in Canis Minor. Lying from the Solar System, it is a blue-white main sequence star of spectral class B8 Ve. Although fainter to Earth observers, it is much brighter than Procyon, and is 250 times as luminous and three times as massive as the Sun. Although its variations are slight, Gomeisa is classified as a shell star (Gamma Cassiopeiae variable), with a maximum magnitude of 2.84 and a minimum magnitude of 2.92. It is surrounded by a disk of gas which it heats and causes to emit radiation. 
Johann Bayer used the Greek letters Alpha to Eta to label the most prominent eight stars in the constellation, designating two stars as Delta (named Delta1 and Delta2). John Flamsteed numbered fourteen stars, discerning a third star he named Delta3; his star 12 Canis Minoris was not found subsequently. In Bayer's 1603 work "Uranometria", Procyon is located on the dog's belly, and Gomeisa on its neck. Gamma, Epsilon and Eta Canis Minoris lie nearby, marking the dog's neck, crown and chest respectively. Although it has an apparent magnitude of 4.34, Gamma Canis Minoris is an orange K-type giant of spectral class K3-III C, which lies away. Its colour is obvious when seen through binoculars. It is a multiple system, consisting of the spectroscopic binary Gamma A and three optical companions, Gamma B, magnitude 13; Gamma C, magnitude 12; and Gamma D, magnitude 10. The two components of Gamma A orbit each other every 389.2 days, with an eccentric orbit that takes their separation between 2.3 and 1.4 astronomical units (AU). Epsilon Canis Minoris is a yellow bright giant of spectral class G6.5IIb of magnitude of 4.99. It lies from Earth, with 13 times the diameter and 750 times the luminosity of the Sun. Eta Canis Minoris is a giant of spectral class F0III of magnitude 5.24, which has a yellowish hue when viewed through binoculars as well as a faint companion of magnitude 11.1. Located 4 arcseconds from the primary, the companion star is actually around 440 AU from the main star and takes around 5000 years to orbit it.
Near Procyon, three stars share the name Delta Canis Minoris. Delta1 is a yellow-white F-type giant of magnitude 5.25 located around from Earth. About 360 times as luminous and 3.75 times as massive as the Sun, it is expanding and cooling as it ages, having spent much of its life as a main sequence star of spectrum B6V. Also known as 8 Canis Minoris, Delta2 is an F-type main-sequence star of spectral type F2V and magnitude 5.59 which is distant. The last of the trio, Delta3 (also known as 9 Canis Minoris), is a white main sequence star of spectral type A0Vnn and magnitude 5.83 which is distant. These stars mark the paws of the Lesser Dog's left hind leg, while magnitude 5.13 Zeta marks the right. A blue-white bright giant of spectral type B8II, Zeta lies around away from the Solar System.
Lying approximately 264 light-years (81 parsecs) away with an apparent magnitude of 4.39, HD 66141 is 6.8 billion years old and has evolved into an orange giant of spectral type K2III with a diameter around 22 times that of the Sun, and weighing 1.1 solar masses. It is 174 times as luminous as the Sun, with an absolute magnitude of −0.15. HD 66141 was mistakenly named 13 Puppis, as its celestial coordinates were recorded incorrectly when catalogued and hence mistakenly thought to be in the constellation of Puppis; Bode gave it the name Lambda Canis Minoris, which is now obsolete. The orange giant is orbited by a planet, HD 66141b, which was detected in 2012 by measuring the star's radial velocity. The planet has a mass around 6 times that of Jupiter and a period of 480 days.
A red giant of spectral type M4III, BC Canis Minoris lies around distant from the Solar System. It is a semiregular variable star that varies between a maximum magnitude of 6.14 and minimum magnitude of 6.42. Periods of 27.7, 143.3 and 208.3 days have been recorded in its pulsations. AZ, AD and BI Canis Minoris are Delta Scuti variables—short period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. AZ is of spectral type F0III, and ranges between magnitudes 6.44 and 6.51 over a period of 2.3 hours. AD has a spectral type of F2III, and has a maximum magnitude of 9.21 and minimum of 9.51, with a period of approximately 2.95 hours. BI is of spectral type F2 with an apparent magnitude varying around 9.19 and a period of approximately 2.91 hours.
At least three red giants are Mira variables in Canis Minor. S Canis Minoris, of spectral type M7e, is the brightest, ranging from magnitude 6.6 to 13.2 over a period of 332.94 days. V Canis Minoris ranges from magnitude 7.4 to 15.1 over a period of 366.1 days. Similar in magnitude is R Canis Minoris, which has a maximum of 7.3, but a significantly brighter minimum of 11.6. An S-type star, it has a period of 337.8 days.
YZ Canis Minoris is a red dwarf of spectral type M4.5V and magnitude 11.2, roughly three times the size of Jupiter and from Earth. It is a flare star, emitting unpredictable outbursts of energy for mere minutes, which might be much more powerful analogues of solar flares. Luyten's Star (GJ 273) is a red dwarf star of spectral type M3.5V and close neighbour of the Solar System. Its visual magnitude of 9.9 renders it too faint to be seen with the naked eye, even though it is only away. Fainter still is PSS 544-7, an eighteenth-magnitude red dwarf around 20 percent the mass of the Sun, located from Earth. First noticed in 1991, it is thought to be a cannonball star, shot out of a star cluster and now moving rapidly through space directly away from the galactic disc.
The WZ Sagittae-type dwarf nova DY CMi (also known as VSX J074727.6+065050) flared up to magnitude 11.4 over January and February 2008 before dropping eight magnitudes to around 19.5 over approximately 80 days. It is a remote binary star system where a white dwarf and low mass star orbit each other close enough for the former star to draw material off the latter and form an accretion disc. This material builds up until it erupts dramatically.
Deep-sky objects.
The Milky Way passes through much of Canis Minor, yet it has few deep-sky objects. William Herschel recorded four objects in his 1786 work "Catalogue of Nebulae and Clusters of Stars", including two he mistakenly believed were star clusters. NGC 2459 is a group of five thirteenth- and fourteenth-magnitude stars that appear to lie close together in the sky but are not related. A similar situation has occurred with NGC 2394, also in Canis Minor. This is a collection of fifteen unrelated stars of ninth-magnitude and fainter. 
Herschel also observed three faint galaxies, two of which are interacting with each other. NGC 2508 is a lenticular galaxy of thirteenth-magnitude, estimated at 205 million light-years (63 million parsecs) distance with a diameter of 80 thousand light-years (25 thousand parsecs). Named as a single object by Herschel, NGC 2402 is actually a pair of near-adjacent galaxies that appear to be interacting with each other. Only of fourteenth- and fifteenth-magnitudes respectively, the elliptical and spiral galaxy are thought to be approximately 245 million light-years distant, and each measure 55,000 light-years in diameter.
Canis Minorids.
The 11 Canis-Minorids, also called the Beta Canis Minorids, are a meteor shower that arise near the fifth-magnitude star 11 Canis Minoris and were discovered in 1964 by Keith Hindley, who investigated their trajectory and proposed a common origin with the comet D/1917 F1 Mellish. However, this conclusion has been refuted subsequently as the number of orbits analysed was low and their trajectories too disparate to confirm a link. They last from 4 to 15 December, peaking over 10 and 11 December.
References.
Sources

</doc>
<doc id="6371" url="http://en.wikipedia.org/wiki?curid=6371" title="Centaurus">
Centaurus

Centaurus is a bright constellation in the southern sky. One of the largest constellations, Centaurus was included among the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains one of the 88 modern constellations. In Greek mythology, Centaurus represents a centaur; a creature that is half human, half horse (another constellation named after a centaur is one from the zodiac: Sagittarius). Notable stars include Alpha Centauri, the nearest star system to our own Solar System, its neighbour in the sky Beta Centauri, and V766 Centauri, one of the largest stars yet discovered. The constellation also contains Omega Centauri, the brightest globular cluster as visible from Earth and one of the largest known.
Notable features.
Stars.
Centaurus contains several very bright stars because of its position in the Milky Way; in addition, its alpha and beta stars are used to find the constellation Crux. The constellation has 281 stars above magnitude 6.5, meaning that they are visible to the unaided eye, the most of any constellation. Alpha Centauri, the closest star to the Sun, has a high proper motion; it will be a mere half-degree from Beta Centauri in approximately 4000 years.
Alpha Centauri is a triple star system that contains Proxima Centauri, the nearest star to the Sun. Traditionally called Rigil Kentaurus or Toliman, meaning "foot of the centaur", the system has an overall magnitude of -0.28 and is 4.4 light-years from Earth. The primary and secondary are both yellow-hued stars; the primary, is of magnitude -0.01 and the secondary is of magnitude 1.35. Proxima, the tertiary star, is a red dwarf of magnitude 11.0; it is almost 2 degrees away from the primary and secondary and has a period of approximately one million years. Also a flare star, Proxima has minutes-long outbursts where it brightens by over a magnitude. The primary and secondary have a period of 80 years and will be closest to each other as seen from Earth in 2037 and 2038.
In addition to Alpha Centauri (the 3rd brightest star in the sky), a second first magnitude star, Beta Centauri, is part of Centaurus. Also called Hadar and Agena, Beta Centauri is a double star; the primary is a blue-hued giant star of magnitude 0.6, 525 light-years from Earth. The secondary is of magnitude 4.0 and has a very small separation. A bright binary star in Centaurus is Gamma Centauri, which appears to the naked eye at magnitude 2.2. The primary and secondary are both blue-white hued stars of magnitude 2.9; their period is 85 years.
Centaurus also has many dimmer double stars and binary stars. 3 Centauri is a double star with a blue-white hued primary of magnitude 4.6 and a secondary of magnitude 6.1. The primary is 298 light-years from Earth.
Centaurus is home to many variable stars. R Centauri is a Mira variable star with a minimum magnitude of 11.8 and a maximum magnitude of 5.3; it is 2100 light-years from Earth and has a period of 18 months. V810 Centauri is a semiregular variable.
BPM 37093 is a white dwarf star whose carbon atoms are thought to have formed a crystalline structure. Since diamond also consists of carbon arranged in a crystalline lattice (though of a different configuration), scientists have nicknamed this star "Lucy" after the Beatles song "Lucy in the Sky with Diamonds."
Deep-sky objects.
ω Centauri (NGC 5139), despite being listed as the constellation's "omega" star, is in fact a naked-eye globular cluster, located at a distance of 17,000 light-years with a diameter of 150 light-years. It is the largest and brightest globular cluster in the Milky Way, at ten times the size of the next-largest cluster, it has a magnitude of 3.7. It is also the most luminous globular cluster in the Milky Way, at over one million solar luminosities. Omega Centauri is classified as a Shapley class VIII cluster, which means that its center is loosely concentrated. It is also the only globular cluster to be designated with a Bayer letter; the globular cluster 47 Tucanae is the only one designated with a Flamsteed number. It contains several million stars, most of which are yellow dwarf stars, but also possesses red giants and blue-white stars; the stars have an average age of 12 billion years. This has prompted suspicion that Omega Centauri was the core of a dwarf galaxy that had been absorbed by the Milky Way. Omega Centauri was determined to be nonstellar in 1677 by the English astronomer Edmond Halley, though it was visible as a star to the ancients. Its status as a globular cluster was determined by James Dunlop in 1827. To the unaided eye, Omega Centauri appears fuzzy and is obviously non-circular; it is approximately half a degree in diameter, the same size as the full Moon.
Centaurus is also home to open clusters. NGC 3766 is an open cluster 6300 light-years from Earth that is visible to the unaided eye. It contains approximately 100 stars, the brightest of which are 7th magnitude. NGC 5460 is another naked-eye open cluster, 2500 light-years from Earth, that has an overall magnitude of 6 and contains approximately 40 stars.
There is one bright planetary nebula in Centaurus, NGC 3918, also known as the Blue Planetary. It has an overall magnitude of 8.0 and a central star of magnitude 11.0; it is 2600 light-years from Earth. The Blue Planetary was discovered by John Herschel and named for its color's similarity to Uranus, though the nebula is three times larger than the planet.
Centaurus is rich in galaxies as well. NGC 4622 is a face-on spiral galaxy located 200 million light-years from Earth (redshift 0.0146). Its spiral arms wind in both directions, which makes it nearly impossible for astronomers to determine the rotation of the galaxy. Astronomers theorize that a collision with a smaller companion galaxy near the core of the main galaxy could have led to the unusual spiral structure. NGC 5253, a peculiar irregular galaxy, is located near the border with Hydra and M83, with which it likely had a close gravitational interaction 1-2 billion years ago. This may have sparked the galaxy's high rate of star formation, which continues today and contributes to its high surface brightness. NGC 5253 includes a large nebula and at least 12 large star clusters. In the eyepiece, it is a small galaxy of magnitude 10 with dimensions of 5 arcminutes by 2 arcminutes and a bright nucleus. NGC 4945 is a spiral galaxy seen edge-on from Earth, 13 million light-years away. It is visible with any amateur telescope, as well as binoculars under good conditions; it has been described as "shaped like a candle flame", being long and thin (16' by 3'). In the eyepiece of a large telescope, its southeastern dust lane becomes visible. Another galaxy is NGC 5102, found by star-hopping from Iota Centauri. In the eyepiece, it appears as an elliptical object 9 arcminutes by 2.5 arcminutes tilted on a southwest-northeast axis.
One of the closest active galaxies to Earth is the Centaurus A galaxy, NGC 5128, at a distance of 11 million light-years (redshift 0.00183). It has a supermassive black hole at its core, which expels massive jets of matter that emit radio waves due to synchrotron radiation. Astronomers posit that its dust lanes, not common in elliptical galaxies, are due to a previous merger with another galaxy, probably a spiral galaxy. NGC 5128 appears in the optical spectrum as a fairly large elliptical galaxy with a prominent dust lane. Its overall magnitude is 7.0, and it has been seen under perfect conditions with the naked eye, making it one of the most distant objects visible to the unaided observer. In equatorial and southern latitudes, it is easily found by star hopping from Omega Centauri. In small telescopes, the dust lane is not visible; it begins to appear with about 4 inches of aperture under good conditions. In large amateur instruments, above about 12 inches in aperture, the dust lane's west-northwest to east-southeast direction is easily discerned. Another dim dust lane on the east side of the 12 arcminute by 15 arcminute galaxy is also visible. ESO 270-17, also called the Fourcade-Figueroa Object, is a low-surface brightness object believed to be the remnants of a galaxy; it does not have a core and is very difficult to observe with an amateur telescope. It measures 7 arcminutes by 1 arcminute. It likely originated as a spiral galaxy and underwent a catastrophic gravitational interaction with Centaurus A around 500 million years ago, stopping its rotation and destroying its structure.
NGC 4650A is a polar-ring galaxy located at a distance of 136 million light years from Earth (redshift 0.01). It has a central core made of older stars that resembles an elliptical galaxy, and an outer ring of young stars that orbits around the core. The plane of the outer ring is distorted, which suggests that NGC 4650A is the result of a galaxy collision about a billion years ago. This galaxy has also been cited in studies of dark matter, because the stars in the outer ring orbit too quickly for their collective mass. This suggests that the galaxy is surrounded by a dark matter halo, which provides the necessary mass.
One of the closest galaxy clusters to Earth is the Centaurus Cluster, located at a distance of 160 million light-years (redshift 0.0114). It has a cooler, denser central region of gas and a hotter, more diffuse outer region. The intracluster medium in the Centaurus Cluster has a high concentration of metals (elements heavier than helium) due to a large number of supernovae. This cluster also possesses a plume of gas whose origin is unknown.
History.
While Centaurus now has a high southern latitude, at the dawn of civilization it was an equatorial constellation. Precession has been slowly shifting it southward for millennia, and it is now close to its maximal southern declination. Thousands of years from now Centaurus will, once again, be at lower latitudes and be visible worldwide.
The figure of Centaurus can be traced back to a Babylonian constellation known as the Bison-man (MUL.GUD.ALIM). This being was depicted in two major forms: firstly, as a 4-legged bison with a human head, and secondly, as a being with a man's head and torso attached to the rear legs and tail of a bull or bison. It has been closely associated with the Sun god Utu-Shamash from very early times.
The Greeks depicted the constellation as a centaur and gave it its current name. It was mentioned by Eudoxus in the 4th century BCE and Aratus in the 3rd century BCE. In the 2nd century AD, Claudius Ptolemy catalogued 37 stars in Centaurus. Large as it is now, in earlier times it was even larger, as the constellation Lupus was treated as an asterism within Centaurus, portrayed in illustrations as an unspecified animal either in the centaur's grasp or impaled on its spear. The Southern Cross, which is now regarded as a separate constellation, was treated by the ancients as a mere asterism formed of the stars composing the centaur's legs. Additionally, what is now the minor constellation Circinus was treated as undefined stars under the centaur's front hooves.
According to the Roman poet Ovid ("Fasti" v.379), the constellation honors the centaur Chiron, who was tutor to many of the earlier Greek heroes including Heracles (Hercules), Theseus, and Jason, the leader of the Argonauts. However, most authorities consider Sagittarius to be the civilized Chiron, while Centaurus represents a more uncouth member of the species. The legend associated with Chiron says that he was accidentally poisoned with an arrow shot by Hercules, and was subsequently placed in the heavens.
Equivalents.
In Chinese astronomy, the stars of Centaurus are found in three areas: the Azure Dragon of the East (東方青龍, "Dōng Fāng Qīng Lóng"), the Vermillion Bird of the South (南方朱雀, "Nán Fāng Zhū Què"), and the Southern Asterisms (近南極星區, "Jìnnánjíxīngōu"). Not all of the stars of Centaurus can be seen from China, and the unseen stars were classified among the Southern Asterisms by Xu Guangqi, based on his study of western star charts. However, most of the brightest stars of Centaurus, including α Cen, θ Cen, ε Cen and η Cen, can be seen in the Chinese sky.
Some Polynesian peoples considered the stars of Centaurus to be a constellation as well. On Pukapuka, Centaurus had two names: "Na Mata-o-te-tokolua" and "Na Lua-mata-o-Wua-ma-Velo". In Tonga, the constellation was called by four different names: "O-nga-tangata", "Tautanga-ufi", "Mamangi-Halahu", and "Mau-kuo-mau". Alpha and Beta Centauri were not named specifically by the people of Pukapuka or Tonga, but they were named by the people of Hawaii and the Tuamotus. In Hawaii, the name for Alpha Centauri was either "Melemele" or "Ka Maile-hope" and the name for Beta Centauri was either "Polapola" or "Ka Maile-mua". In the Tuamotu islands, Alpha was called "Na Kuhi" and Beta was called "Tere".
Namesakes.
Two United States navy ships, USS Centaurus (AKA-17) and USS Centaurus (AK-264), are named after the constellation.
The Centaurus is a Mega Mall and commercial/residential complex in Islamabad, Pakistan. Construction started in 2005 and the three 41-storey towers, the tallest structures in Islamabad, were completed by late 2012. The shopping mall was officially opened on February 17, 2013. The Centaurus originally included a 7 star hotel, construction of which is yet to begin.

</doc>
<doc id="6416" url="http://en.wikipedia.org/wiki?curid=6416" title="Impact crater">
Impact crater

An impact crater is an approximately circular depression in the surface of a planet, moon or other solid body in the Solar System, formed by the hypervelocity impact of a smaller body with the surface. In contrast to volcanic craters, which result from explosion or internal collapse, impact craters typically have raised rims and floors that are lower in elevation than the surrounding terrain. Impact craters range from small, simple, bowl-shaped depressions to large, complex, multi-ringed impact basins. Meteor Crater is perhaps the best-known example of a small impact crater on the Earth.
Impact craters are the dominant geographic features on many solid Solar System objects including the Moon, Mercury, Callisto, Ganymede and most small moons and asteroids. On other planets and moons that experience more active surface geological processes, such as Earth, Venus, Mars, Europa, Io and Titan, visible impact craters are less common because they become eroded, buried or transformed by tectonics over time. Where such processes have destroyed most of the original crater topography, the terms impact structure or astrobleme are more commonly used. In early literature, before the significance of impact cratering was widely recognised, the terms cryptoexplosion or cryptovolcanic structure were often used to describe what are now recognised as impact-related features on Earth.
The cratering records of very old surfaces, such as Mercury, the Moon, and the southern highlands of Mars, record a period of intense early bombardment in the inner Solar System around 3.9 billion years ago. Since that time, the rate of crater production on Earth has been considerably lower, but it is appreciable nonetheless; Earth experiences from one to three impacts large enough to produce a 20 km diameter crater about once every million years on average. This indicates that there should be far more relatively young craters on the planet than have been discovered so far. The cratering rate in the inner solar system fluctuates as a consequence of collisions in the asteroid belt that create a family of fragments that are often sent cascading into the inner solar system. Formed in a collision 160 million years ago, the Baptistina family of asteroids is thought to have caused a large spike in the impact rate, perhaps causing the Chicxulub impact that may have triggered the extinction of the dinosaurs 66 million years ago. Note that the rate of impact cratering in the outer Solar System could be different from the inner Solar System.
Although the Earth’s active surface processes quickly destroy the impact record, about 170 terrestrial impact craters have been identified. These range in diameter from a few tens of meters up to about 300 km, and they range in age from recent times (e.g. the Sikhote-Alin craters in Russia whose creation were witnessed in 1947) to more than two billion years, though most are less than 500 million years old because geological processes tend to obliterate older craters. They are also selectively found in the stable interior regions of continents. Few undersea craters have been discovered because of the difficulty of surveying the sea floor, the rapid rate of change of the ocean bottom, and the subduction of the ocean floor into the Earth's interior by processes of plate tectonics.
Impact craters are not to be confused with landforms that in some cases appear similar, including calderas and ring dikes.
History.
Daniel Barringer (1860–1929) was one of the first to identify an impact crater, Meteor Crater in Arizona; to crater specialists the site is referred to as Barringer Crater in his honor. Initially Barringer's ideas were not widely accepted, and even when the origin of Meteor Crater was finally acknowledged, the wider implications for impact cratering as a significant geological process on Earth were not.
In the 1920s, the American geologist Walter H. Bucher studied a number of sites now recognized as impact craters in the USA. He concluded they had been created by some great explosive event, but believed that this force was probably volcanic in origin. However, in 1936, the geologists John D. Boon and Claude C. Albritton Jr. revisited Bucher's studies and concluded that the craters that he studied were probably formed by impacts.
The concept of impact cratering remained more or less speculative until the 1960s. At this time a number of researchers, most notably Eugene M. Shoemaker, (co-discoverer of the comet Shoemaker-Levy 9), conducted detailed studies of a number of craters and recognized clear evidence that they had been created by impacts, specifically identifying the shock-metamorphic effects uniquely associated with impact events, of which the most familiar is shocked quartz.
Armed with the knowledge of shock-metamorphic features, Carlyle S. Beals and colleagues at the Dominion Observatory in Victoria, British Columbia, Canada and Wolf von Engelhardt of the University of Tübingen in Germany began a methodical search for impact craters. By 1970, they had tentatively identified more than 50. Although their work was controversial, the American Apollo Moon landings, which were in progress at the time, provided supportive evidence by recognizing the rate of impact cratering on the Moon. Processes of erosion on the Moon are minimal and so craters persist almost indefinitely. Since the Earth could be expected to have roughly the same cratering rate as the Moon, it became clear that the Earth had suffered far more impacts than could be seen by counting evident craters.
Crater formation.
Impact cratering involves high velocity collisions between solid objects, typically much greater than the velocity of sound in those objects. Such hyper-velocity impacts produce physical effects such as melting and vaporization that do not occur in familiar sub-sonic collisions. On Earth, ignoring the slowing effects of travel through the atmosphere, the lowest impact velocity with an object from space is equal to the gravitational escape velocity of about 11 km/s. The fastest impacts occur at more than 80 km/s in the "worst case" scenario which an object in a retrograde near-parabolic orbit hits Earth. (Because kinetic energy scales as velocity squared, Earth's gravity only contributes 1 km/s to this figure, not 11 km/s). The median impact velocity on Earth is about 20 to 25 km/s.
Impacts at these high speeds produce shock waves in solid materials, and both impactor and the material impacted are rapidly compressed to high density. Following initial compression, the high-density, over-compressed region rapidly depressurizes, exploding violently, to set in train the sequence of events that produces the impact crater. Impact-crater formation is therefore more closely analogous to cratering by high explosives than by mechanical displacement. Indeed, the energy density of some material involved in the formation of impact craters is many times higher than that generated by high explosives. Since craters are caused by explosions, they are nearly always circular – only very low-angle impacts cause significantly elliptical craters.
This describes impacts on solid surfaces. Impacts on porous surfaces, such as that of Hyperion, may produce internal compression without ejecta, punching a hole in the surface without filling in nearby craters. This may explain the 'sponge-like' appearance of that moon.
It is convenient to divide the impact process conceptually into three distinct stages: (1) initial contact and compression, (2) excavation, (3) modification and collapse. In practice, there is overlap between the three processes with, for example, the excavation of the crater continuing in some regions while modification and collapse is already underway in others.
Contact and compression.
In the absence of atmosphere, the impact process begins when the impactor first touches the target surface. This contact accelerates the target and decelerates the impactor. Because the impactor is moving so rapidly, the rear of the object moves a significant distance during the short-but-finite time taken for the deceleration to propagate across the impactor. As a result, the impactor is compressed, its density rises, and the pressure within it increases dramatically. Peak pressures in large impacts exceed 1 TPa to reach values more usually found deep in the interiors of planets, or generated artificially in nuclear explosions.
In physical terms, a supersonic shock wave initiates from the point of contact. As this shock wave expands, it decelerates and compresses the impactor, and it accelerates and compresses the target. Stress levels within the shock wave far exceed the strength of solid materials; consequently, both the impactor and the target close to the impact site are irreversibly damaged. Many crystalline minerals can be transformed into higher-density phases by shock waves; for example, the common mineral quartz can be transformed into the higher-pressure forms coesite and stishovite. Many other shock-related changes take place within both impactor and target as the shock wave passes through, and some of these changes can be used as diagnostic tools to determine whether particular geological features were produced by impact cratering.
As the shock wave decays, the shocked region decompresses towards more usual pressures and densities. The damage produced by the shock wave raises the temperature of the material. In all but the smallest impacts this increase in temperature is sufficient to melt the impactor, and in larger impacts to vaporize most of it and to melt large volumes of the target. As well as being heated, the target near the impact is accelerated by the shock wave, and it continues moving away from the impact behind the decaying shock wave.
Excavation.
Contact, compression, decompression, and the passage of the shock wave all occur within a few tenths of a second for a large impact. The subsequent excavation of the crater occurs more slowly, and during this stage the flow of material is largely sub-sonic. During excavation, the crater grows as the accelerated target material moves away from the impact point. The target's motion is initially downwards and outwards, but it becomes outwards and upwards. The flow initially produces an approximately hemispherical cavity. The cavity continues to grow, eventually producing a paraboloid (bowl-shaped) crater in which the centre has been pushed down, a significant volume of material has been ejected, and a topographically elevated crater rim has been pushed up. When this cavity has reached its maximum size, it is called the transient cavity.
The depth of the transient cavity is typically a quarter to a third of its diameter. Ejecta thrown out of the crater do not include material excavated from the full depth of the transient cavity; typically the depth of maximum excavation is only about a third of the total depth. As a result, about one third of the volume of the transient crater is formed by the ejection of material, and the remaining two thirds is formed by the displacement of material downwards, outwards and upwards, to form the elevated rim. For impacts into highly porous materials, a significant crater volume may also be formed by the permanent compaction of the pore space. Such compaction craters may be important on many asteroids, comets and small moons.
In large impacts, as well as material displaced and ejected to form the crater, significant volumes of target material may be melted and vaporized together with the original impactor. Some of this impact melt rock may be ejected, but most of it remains within the transient crater, initially forming a layer of impact melt coating the interior of the transient cavity. In contrast, the hot dense vaporized material expands rapidly out of the growing cavity, carrying some solid and molten material within it as it does so. As this hot vapor cloud expands, it rises and cools much like the archetypal mushroom cloud generated by large nuclear explosions. In large impacts, the expanding vapor cloud may rise to many times the scale height of the atmosphere, effectively expanding into free space.
Most material ejected from the crater is deposited within a few crater radii, but a small fraction may travel large distances at high velocity, and in large impacts it may exceed escape velocity and leave the impacted planet or moon entirely. The majority of the fastest material is ejected from close to the center of impact, and the slowest material is ejected close to the rim at low velocities to form an overturned coherent flap of ejecta immediately outside the rim. As ejecta escapes from the growing crater, it forms an expanding curtain in the shape of an inverted cone; the trajectory of individual particles within the curtain is thought to be largely ballistic.
Small volumes of un-melted and relatively un-shocked material may be spalled at very high relative velocities from the surface of the target and from the rear of the impactor. Spalling provides a potential mechanism whereby material may be ejected into inter-planetary space largely undamaged, and whereby small volumes of the impactor may be preserved undamaged even in large impacts. Small volumes of high-speed material may also be generated early in the impact by jetting. This occurs when two surfaces converge rapidly and obliquely at a small angle, and high-temperature highly shocked material is expelled from the convergence zone with velocities that may be several times larger than the impact velocity.
Modification and collapse.
In most circumstances, the transient cavity is not stable: it collapses under gravity. In small craters, less than about 4 km diameter on Earth, there is some limited collapse of the crater rim coupled with debris sliding down the crater walls and drainage of impact melts into the deeper cavity. The resultant structure is called a simple crater, and it remains bowl-shaped and superficially similar to the transient crater. In simple craters, the original excavation cavity is overlain by a lens of collapse breccia, ejecta and melt rock, and a portion of the central crater floor may sometimes be flat.
Above a certain threshold size, which varies with planetary gravity, the collapse and modification of the transient cavity is much more extensive, and the resulting structure is called a complex crater. The collapse of the transient cavity is driven by gravity, and involves both the uplift of the central region and the inward collapse of the rim. The central uplift is not the result of "elastic rebound", which is a process in which a material with elastic strength attempts to return to its original geometry; rather the collapse is a process in which a material with little or no strength attempts to return to a state of gravitational equilibrium.
Complex craters have uplifted centers, and they have typically broad flat shallow crater floors, and terraced walls. At the largest sizes, one or more exterior or interior rings may appear, and the structure may be labeled an "impact basin" rather than an impact crater. Complex-crater morphology on rocky planets appears to follow a regular sequence with increasing size: small complex craters with a central topographic peak are called "central peak craters", for example Tycho; intermediate-sized craters, in which the central peak is replaced by a ring of peaks, are called "peak-ring craters", for example Schrödinger; and the largest craters contain multiple concentric topographic rings, and are called "multi-ringed basins", for example Orientale. On icy as opposed to rocky bodies, other morphological forms appear which may have central pits rather than central peaks, and at the largest sizes may contain very many concentric rings – Valhalla on Callisto is the type example of the latter.
Identifying impact craters.
Some volcanic features can resemble impact craters, and brecciated rocks are associated with other geological formations besides impact craters. Non-explosive volcanic craters can usually be distinguished from impact craters by their irregular shape and the association of volcanic flows and other volcanic materials. Impact craters produce melted rocks as well, but usually in smaller volumes with different characteristics.
The distinctive mark of an impact crater is the presence of rock that has undergone shock-metamorphic effects, such as shatter cones, melted rocks, and crystal deformations. The problem is that these materials tend to be deeply buried, at least for simple craters. They tend to be revealed in the uplifted center of a complex crater, however.
Impacts produce distinctive shock-metamorphic effects that allow impact sites to be distinctively identified. Such shock-metamorphic effects can include:
Lists of craters.
Impact craters on Earth.
On Earth, the recognition of impact craters is a branch of geology, as opposed to astronomy on other worlds. Out of many proposed craters, relatively few are confirmed. The following are a sample of articles of confirmed and well-documented impact sites.
See the Earth Impact Database, a website concerned with over 170 scientifically-confirmed impact craters on Earth.
Largest named craters in the Solar System.
There are approximately twelve more impact craters/basins larger than 300 km on the Moon, five on Mercury, and four on Mars. Large basins, some unnamed but mostly smaller than 300 km, can also be found on Saturn's moons Dione, Rhea and Iapetus.

</doc>
<doc id="6417" url="http://en.wikipedia.org/wiki?curid=6417" title="Corvus">
Corvus

Corvus may refer to:

</doc>
<doc id="6420" url="http://en.wikipedia.org/wiki?curid=6420" title="Corona Borealis">
Corona Borealis

Corona Borealis is a small constellation in the northern sky. Its name is Latin for "northern crown", a name inspired by its shape; its main stars form a semicircular arc. One of the 48 constellations listed by the 2nd-century astronomer Ptolemy, it remains one of the 88 modern constellations.
The brightest star is the 2.2-magnitude Alpha Coronae Borealis. Four star systems have been found to have exoplanets to date; three of these are orange giants, while the fourth—Rho Coronae Borealis—is a solar twin, very like our own Sun. Abell 2065 is a highly concentrated galaxy cluster located one billion light-years from our Solar System containing over 400 members, the brightest of which are 16th magnitude.
Characteristics.
Covering 179 square degrees and hence 0.433% of the sky, Corona Borealis ranks 73rd of the 88 constellations in area. It is bordered by Bootes to the north and west, Serpens Caput to the south, and Hercules to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'CrB'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of eight segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between 39.71° and 25.54°. Its position in the Northern Celestial Hemisphere means that the whole constellation is visible to observers north of 50°S.
Notable features.
Stars.
Johann Bayer gave twenty stars in Corona Borealis Bayer designations from Alpha to Upsilon in his 1603 star atlas "Uranometria". The components of the double star Zeta have since been designated Zeta1 and Zeta2, and John Flamsteed equated his 20 and 21 Coronae Borealis with Nu1 and Nu2.
The seven stars that make up the constellation's figure are all 4th-magnitude stars, except for the constellation's brightest star, Alpha Coronae Borealis. This blue-white main-sequence star, also called Alphekka and Gemma, is of magnitude 2.2, though it is an Algol-type eclipsing binary. It varies by 0.1 magnitude with a period of 17.4 days. Lying 75 light-years distant from Earth, Alphekka is believed to be a member of the Ursa Major Moving Group of stars that have a common motion through space.
The other six stars are Theta, Beta, Gamma, Delta, Epsilon, and Iota Coronae Borealis.
Corona Borealis is home to several binary and double stars. Beta Coronae Borealis or Nusakan is a spectroscopic binary system located around 114 light-years away. The two components are separated by 10 astronomical units and orbit each other every 10.5 years. Zeta Coronae Borealis is a double star divisible in small telescopes. It has two blue-white components, 470 light-years from Earth. The primary is of magnitude 5.0 and the secondary is of magnitude 6.0. Another double star is Nu Coronae Borealis; both components are 550 light-years from Earth but have different radial velocities and are assumed to be unrelated. The primary, Nu1 Coronae Borealis, is a red-hued giant star of magnitude 5.2; the secondary, Nu2 Coronae Borealis is an orange-hued giant star of magnitude 5.4. Sigma Coronae Borealis, on the other hand, is a true binary star. Both components are yellow and orbit each other every 1000 years. The system, 71 light-years from Earth, has a primary of magnitude 5.6 and a secondary of magnitude 6.6. Sigma Coronae Borealis is divisible by small amateur telescopes. ADS 9731 is a system composed of six stars, two of which are spectroscopic binaries.
Corona Borealis is home to two remarkable variable stars. T Coronae Borealis is an exploding variable star also known as the Blaze Star. Normally placid around magnitude 10—it has a minimum of 10.2 and maximum of 9.9—it brightens to magnitude 2 in a period of hours, caused by a nuclear chain reaction and the subsequent explosion. T Coronae Borealis is one of a handful of stars called recurrent novae, which include RS Ophiuchi, T Pyxidis, V1017 Sagitarii, and U Scorpii. An outburst of T Coronae Borealis was first recorded in 1866; its most recent outburst was in February 1946. T Coronae Borealis is a binary star with a red-hued giant primary and a small blue secondary; its period is approximately 8 months. R Coronae Borealis is a yellow-hued variable supergiant star, over 7000 light-years from Earth, and prototype of a class of stars known as R Coronae Borealis variables. Normally of magnitude 6, its brightness periodically drops as low as magnitude 15 and then slowly increases over the next several months. Though small dips in brightness occur sporadically, extreme decreases happened most recently in 1962, 1972, and 1977. Small carbon particles building up in the stellar atmosphere may be responsible.
S Coronae Borealis is a Mira-type long period variable that ranges between magnitudes 5.8 and 14.1 over a period of 360 days. RR Coronae Borealis is a M3-type semiregular variable star that varies between magnitudes 7.3 and 8.2 over 60.8 days.
Four star systems have been found to have exoplanets to date. Kappa Coronae Borealis is an orange subgiant of spectral type K0III-IV that has a dust debris disk and one confirmed and one possible planet. Omicron Coronae Borealis is another K-type clump giant with one confirmed planet., believed to be, like HD 100655 b, one of the two least massive planets known around clump giants. Rho Coronae Borealis is a Solar twin, yellow dwarf around 57 light-years distant. It has a planet around the size and mass of Jupiter orbiting it every 40 days. HD 145457 is an orange giant of spectral type K0III found to have one planet.
Deep-sky objects.
Corona Borealis contains no bright deep-sky objects. Abell 2065 is a highly concentrated galaxy cluster containing over 400 members, the brightest of which are 16th magnitude. The cluster is more than one billion light-years from Earth. Abell 2142 is a huge, X-ray luminous galaxy cluster that is the result of a still ongoing merger between two galaxy clusters. The combined cluster is six million light years across, contains hundreds of galaxies and enough gas to make a thousand more. It has a heliocentric redshift of 0.0909 (meaning it is moving away from us at 27,250 km/s) and a visual magnitude of 16.0. It is about 1.2 billion light years (380 Mpc) away. Another galaxy cluster in the constellation, RX J1532.9+3021, is located approximately 3.9 billion light years from Earth. At the cluster's center is a large elliptical galaxy containing the supermassive black hole.
In November 2013 astronomers discovered the largest structure in the universe ever found—the Hercules–Corona Borealis Great Wall, which lies partly within this constellation's borders. The structure is a galaxy filament, or a huge group of galaxies assembled by gravity. It is about 10 billion light-years (3 Gpc) at its longest dimension, which is approximately 1/9 (10.7%) of the diameter of the observable universe, 7.2 billion light-years (2.2 Gpc; 150,000 km/s "in redshift space") wide, but only 900 million light-years (300 Mpc) thick, and is the largest known structure in the universe. It is at redshift 1.6–2.1, corresponding to a distance of approximately 10 billion light-years away from Earth.
History and mythology.
In Greek mythology, Corona Borealis was sometimes considered to represent a crown that was given by Dionysus to Ariadne, the daughter of Minos of Crete. When she wore the crown to her wedding, where she married Dionysus, he placed her crown in the heavens to commemorate the wedding. In Welsh mythology, it was called Caer Arianrhod, "the Castle of the Silver Circle", and was the heavenly abode of the Lady Arianrhod.
The Arabs called the constellation Alphecca (a name later given to Alpha Corona Borealis), which means "separated" or "broken up" ( ""), a reference to the resemblance of the stars of Corona Borealis to a loose string of jewels.
Among the Bedouins, the constellation was known as "" (), or "the dish/bowl of the poor people", since the stars form an unsymmetrical pattern with an indent in one side.
Non-western depictions.
In Chinese astronomy, the stars of Corona Borealis are located within the Heavenly Market enclosure (天市垣, "Tiān Shì Yuán").
In Australian Aboriginal astronomy, the constellation is called "womera" ("the boomerang") due to the shape of the stars. The Wailwun people of northwestern New South Wales saw Corona Borealis as "mullion wollai" "eagle's nest", with Altair and Vega—each called "mullion"—the pair of eagles accompanying it.
Polynesian peoples often recognized Corona Borealis; it was likely called "Te Hetu" in the Tuamotus, whose people called the constellation "Na Kaua-ki-tokerau". In Hawaii, the constellation was likely called "Kaua-mea"; it was called "Rangawhenua" in New Zealand. The figure of Corona Borealis was called "Te Wale-o-Awitu" in Pukapuka. Its name in Tonga was unsure; it was either called "Ao-o-Uvea" or "Kau-kupenga".
The Cheyenne nation of Native Americans called the main stars of this constellation the "Camp Circle", as they arranged their camps in a semicircle. Native Americans also used stars to make designs in the ground at the Medicine Wheel in Bighorn National Forest, Wyoming, USA.
Modern references.
The constellation of Corona Borealis was featured as a main plot ingredient in the short story "Hypnos" by H. P. Lovecraft, published in 1923.

</doc>
<doc id="6421" url="http://en.wikipedia.org/wiki?curid=6421" title="Cygnus (constellation)">
Cygnus (constellation)

Cygnus is a northern constellation lying on the plane of the Milky Way, deriving its name from the Latinized Greek word for swan. The swan is one of the most recognizable constellations of the northern summer and autumn, it features a prominent asterism known as the Northern Cross (in contrast to the Southern Cross). Cygnus was among the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains one of the 88 modern constellations. 
Cygnus contains Deneb, one of the brightest stars in the night sky and one corner of the Summer Triangle, as well as some notable X-ray sources and the giant stellar association of Cygnus OB2. One of the stars of this association, NML Cygni, is one of the largest stars currently known. The constellation is also home to Cygnus X-1, an distant X-ray binary containing a supergiant and unseen massive companion that was the first object widely held to be a black hole. Many star systems in Cygnus have known planets as a result of the Kepler Mission observing one patch of the sky, the patch is the area around Cygnus.
History and mythology.
In Greek mythology, Cygnus has been identified with several different legendary swans. Zeus disguised himself as a swan to seduce Leda, Spartan king Tyndareus's wife, who gave birth to the Gemini, Helen of Troy and Clytemnestra; Orpheus was transformed into a swan after his murder, and was said to have been placed in the sky next to his lyre (Lyra); and the King Cygnus was transformed into a swan.
The Greeks also associated this constellation with the tragic story of Phaethon, the son of Helios the sun god, who demanded to ride his father's sun chariot for a day. Phaethon, however, was unable to control the reins, forcing Zeus to destroy the chariot (and Phaethon) with a thunderbolt, causing it to plummet to the earth into the river Eridanus. According to the myth, Phaethon's brother, Cycnus, grieved bitterly and spent many days diving into the river to collect Phaethon's bones to give him a proper burial. The gods were so touched by Cycnus's devotion to his brother that they turned him into a swan and placed him among the stars.
In Ovid's "Metamorphoses", there are three people named Cygnus, all of whom are transformed into swans. Alongside Cycnus, noted above, he mentions a boy from Tempe who commits suicide when Phyllius refuses to give him a tamed bull that he demands, but is transformed into a swan and flies away. He also mentions a son of Neptune who is an invulnerable warrior in the Trojan War who is eventually defeated by Achilles, but Neptune saves him by transforming him into a swan.
Together with other avian constellations near the summer solstice, Vultur cadens and Aquila, Cygnus may be a significant part of the origin of the myth of the Stymphalian Birds, one of The Twelve Labours of Hercules.
In non-western astronomy.
In Polynesia, Cygnus was often recognized as a separate constellation. In Tonga it was called "Tuula-lupe", and in the Tuamotus it was called"Fanui-tai". Deneb was also often given a name. In New Zealand it was called "Mara-tea", in the Society Islands it was called "Pirae-tea" or "Taurua-i-te-haapa-raa-manu", and in the Tuamotus it was called "Fanui-raro". Beta Cygni was named in New Zealand; it was likely called "Whetu-kaupo". Gamma Cygni was called "Fanui-runga" in the Tuamotus.
Characteristics.
A very large constellation, Cygnus is bordered by Cepheus to the north and east, Draco to the north and west, Lyra to the west, Vulpecula to the south, Pegasus to the southeast and Lacerta to the east. The three-letter abbreviation for the constellation, as adopted by the IAU in 1922, is 'Cyg'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined as a polygon of 28 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between 27.73° and 61.36°. Covering 804 square degrees and around 1.9% of the night sky, Cygnus ranks 16th of the 88 constellations in size.
Cygnus culminates at midnight on 29 June, and is most visible in the evening from the early summer to mid-autumn in the Northern Hemisphere.
Normally, Cygnus is depicted with Delta and Epsilon Cygni as its wings, Deneb as its tail, and Albireo as the tip of its beak.
There are several asterisms in Cygnus. In the 17th-century German celestial cartographer Johann Bayer's star atlas the "Uranometria", Alpha, Beta and Gamma Cygni form the pole of a cross, while Delta and Epsilon form the cross beam. The nova P Cygni was then considered to be the body of Christ.
Notable features.
Stars.
Bayer catalogued many stars in the constellation, giving them the Bayer designations from Alpha to Omega and then using lowercase Roman letters to g. John Flamsteed added the Roman letters h,i,k,l and m (these stars were considered "informes" by Bayer as they lay outside the asterism of Cygnus), but were dropped by Francis Baily.
There are several bright stars in Cygnus. Alpha Cygni, called Deneb, is the brightest star in Cygnus. It is a white supergiant star of spectral type A2Iae that varies between magnitudes 1.21 and 1.29, one of the largest and most luminous A-class stars known. It is located about 3200 light-years away. Its traditional name means "tail" and refers to its position in the constellation. Albireo, designated Beta Cygni, is a celebrated binary star among amateur astronomers for its contrasting hues. The primary is an orange-hued giant star of magnitude 3.1 and the secondary is a blue-green hued star of magnitude 5.1. The system is 380 light-years away and is divisible in large binoculars and all amateur telescopes. Gamma Cygni, traditionally named Sadr, is a yellow-tinged supergiant star of magnitude 2.2, 1500 light-years away. Its traditional name means "breast" and refers to its position in the constellation. Delta Cygni is another bright binary star in Cygnus, 171 light-years with a period of 800 years. The primary is a blue-white hued giant star of magnitude 2.9, and the secondary is a star of magnitude 6.6. The two components are divisible in a medium-sized amateur telescope. The fifth star in Cygnus above magnitude 3 is Gienah, designated Epsilon Cygni. It is an orange-hued giant star of magnitude 2.5, 72 light-years from Earth.
There are several other dimmer double and binary stars in Cygnus. Mu Cygni is a binary star with an optical tertiary component. The binary system has a period of 790 years and is 73 light-years from Earth. The primary and secondary, both white stars, are of magnitude 4.8 and 6.2, respectively. The unrelated tertiary component is of magnitude 6.9. Though the tertiary component is divisible in binoculars, the primary and secondary currently require a medium-sized amateur telescope to split, as they will through the year 2020. The two stars will be closest between 2043 and 2050, when they will require a telescope with larger aperture to split. The stars 30 and 31 Cygni form a contrasting double star similar to the brighter Albireo. The two are divisible in binoculars. The primary, 31 Cygni, is an orange-hued star of magnitude 3.8, 1400 light-years from Earth. The secondary, 30 Cygni, appears blue-green. It is of spectral type A5IIIn and magnitude 4.83, and is around 610 light-years from Earth. 31 Cygni itself is a binary star; the tertiary component is a blue star of magnitude 7.0. Psi Cygni is a binary star divisible in small amateur telescopes, with two white components. The primary is of magnitude 5.0 and the secondary is of magnitude 7.5. 61 Cygni is a binary star divisible in large binoculars or a small amateur telescope. It is 11.4 light-years from Earth and has a period of 650 years. Both components are orange-hued dwarf (main sequence) stars; the primary is of magnitude 5.2 and the secondary is of magnitude 6.1. 61 Cygni is significant because Friedrich Wilhelm Bessel determined its parallax in 1838, the first star to have a known parallax.
Located near Eta Cygni is the X-ray source Cygnus X-1, which is now thought to be caused by a black hole accreting matter in a binary star system. This was the first x-ray source widely believed to be a black hole.
Cygnus also contains several other noteworthy X-ray sources. Cygnus X-3 is a microquasar containing a Wolf-Rayet star in orbit around a very compact object, with a period of only 4.8 hours.The system is one of the most intrinsically luminous X-ray sources observed. Interestingly, the system undergoes periodic outbursts of unknown nature, and during one such outburst, the system was found to be emitting muons, likely caused by neutrinos. While the compact object is thought to be a neutron star or possibly a black hole, it is possible that the object is instead a more exotic stellar remnant, possibly the first discovered quark star, hypothesized due to its production of cosmic rays that cannot be explained if the object is a normal neutron star. The system also emits cosmic rays and gamma rays, and has helped shed insight on to the formation of such rays. Cygnus X-2 is another X-ray binary, containing an A-type giant in orbit around a neutron star with a 9.8 day period. The system is interesting due to the rather small mass of the companion star, as most millisecond pulsars have much more massive companions. Another black hole in Cygnus is V404 Cygni, which consists of a K-type star orbiting around a black hole of around 12 solar masses. The black hole, similar to that of Cygnus X-3, has been hypothesized to be a quark star. 4U 2129+ 47 is another X-ray binary containing a neutron star which undergoes outbursts, as is EXO 2030+ 375.
Cygnus is also home to several variable stars. SS Cygni is a dwarf nova which undergoes outbursts every 7-8 days. The system's total magnitude varies from 12th magnitude at its dimmest to 8th magnitude at its brightest. The two objects in the system are incredibly close together, with an orbital period of less than 0.28 days. Chi Cygni is a red giant and the second-brightest Mira variable star at its maximum. It ranges between magnitudes 3.3 and 14.2, and spectral types S6,2e to S10,4e (MSe) over a period of 408 days; it has a diameter of 300 solar diameters and is 350 light-years from Earth. P Cygni is a luminous blue variable that brightened suddenly to 3rd magnitude in 1600 AD. Since 1715, the star has been of 5th magnitude, despite being more than 5000 light-years from Earth. The star's spectrum is unusual in that it contains very strong emission lines resulting from surrounding nebulosity. W Cygni is a semi-regular variable red giant star, 618 light-years from Earth.It has a maximum magnitude of 5.10 and a minimum magnitude 6.83; its period of 131 days. It is a red giant ranging between spectral types M4e-M6e(Tc:)III, NML Cygni, a red hypergiant semi-regular variable star and possibly the largest star currently known in the galaxy, is in Cygnus; it has the magnitude of around 16.60 and an estimated period of about 940 days; it was 5,300 light-years from Earth and has the estimated radius of about 1,650 solar radii, and mass 40 times that of the Sun.
Cygnus is one of the constellations that the Kepler satellite surveyed in its search for extrasolar planets, and as a result, there are about a hundred stars in Cygnus with known planets, the most of any constellation. One of the most notable systems is the Kepler-11 system, containing six transiting planets, all within a plane of approximately one degree. With a spectral type of G6V, the star is somewhat cooler than the Sun. The planets are very close to the star; all but the last planet are closer to Kepler-11 than Mercury is to the Sun, and all the planets are more massive than Earth. The naked-eye star 16 Cygni, a triple star approximately 70 light-years from Earth composed two Sun-like stars and a red dwarf, contains a planet orbiting one of the sun-like stars, found due to variations in the star's radial velocity. Gliese 777, another naked-eye multiple star system containing a yellow star and a red dwarf, also contains a planet. The planet is somewhat similar to Jupiter, but with slightly more mass and a more eccentric orbit. The Kepler-22 system is also notable, in that its extrasolar planet is believed to be the first "Earth-twin" planet ever discovered.
Deep-sky objects.
There is an abundance of deep-sky objects, with many open clusters, nebulae of various types and supernova remnants found in Cygnus due to its position on the Milky Way. Some open clusters can be difficult to make out from a rich background of stars.
M39 (NGC 7092) is an open cluster 950 light-years from Earth that is visible to the unaided eye under dark skies. It is loose, with about 30 stars arranged over a wide area; their conformation appears triangular. The brightest stars of M39 are of the 7th magnitude. Another open cluster in Cygnus is NGC 6910, also called the Rocking Horse Cluster, possessing 16 stars with a diameter of 5 arcminutes visible in a small amateur instrument; it is of magnitude 7.4. The brightest of these are two gold-hued stars, which represent the bottom of the toy it is named for. A larger amateur instrument reveals 8 more stars, nebulosity to the east and west of the cluster, and a diameter of 9 arcminutes. The nebulosity in this region is part of the Gamma Cygni Nebula. The other stars, approximately 3700 light-years from Earth, are mostly blue-white and very hot.
Other open clusters in Cygnus include Dolidze 9, Collinder 421, Dolidze 11, and Berkeley 90. Dolidze 9, 2800 light-years from Earth and relatively young at 20 million light-years old, is a faint open cluster with up to 22 stars visible in small and medium-sized amateur telescopes. Nebulosity is visible to the north and east of the cluster, which is 7 arcminutes in diameter. The brightest star appears in the eastern part of the cluster and is of the 7th magnitude; another bright star has a yellow hue. Dolidze 11 is an open cluster 400 million years old, farthest away of the three at 3700 light-years. More than 10 stars are visible in an amateur instrument in this cluster, of similar size to Dolidze 9 at 7 arcminutes in diameter, whose brightest star is of magnitude 7.5. It, too, has nebulosity in the east. Collinder 421 is a particularly old open cluster at an age of approximately 1 billion years; it is of magnitude 10.1. 3100 light-years from Earth, more than 30 stars are visible in a diameter of 8 arcseconds. The prominent star in the north of the cluster has a golden color, whereas the stars in the south of the cluster appear orange. Collinder 421 appears to be embedded in nebulosity, which extends past the cluster's borders to its west. Berkeley 90 is a smaller open cluster, with a diameter of 5 arcminutes. More than 16 members appear in an amateur telescope.
NGC 6826, the Blinking Planetary Nebula, is a planetary nebula with a magnitude of 8.5, 3200 light-years from Earth. It appears to "blink" in the eyepiece of a telescope because its central star is unusually bright (10th magnitude). When an observer focuses on the star, the nebula appears to fade out. Less than one degree from the Blinking Planetary is the double star 16 Cygni.
The North America Nebula (NGC 7000) is one of the most well-known nebulae in Cygnus, because it is visible to the unaided eye under dark skies, as a bright patch in the Milky Way. However, its characteristic shape is only visible in long-exposure photographs – it is difficult to observe in telescopes because of its low surface brightness. It has low surface brightness because it is so large; at its widest, the North America Nebula is 2 degrees across. Illuminated by a hot embedded star of magnitude 6, NGC 7000 is 1500 light-years from Earth.
To the south of Epsilon Cygni is the Veil Nebula (NGC 6960, 6962, 6979, 6992, and 6995), a 5,000-year-old supernova remnant covering approximately 3 degrees of the sky - it is over 50 light-years long. Because of its appearance, it is also called the Cygnus Loop. The Loop is only visible in long-exposure astrophotographs. However, the brightest portion, NGC 6992, is faintly visible in binoculars, and a dimmer portion, NGC 6960, is visible in wide-angle telescopes.
The Northern Coalsack Nebula, also called the Cygnus Rift, is a dark nebula located in the Cygnus Milky Way.
The Gamma Cygni Nebula (IC 1318) includes both bright and dark nebulae in an area of over 4 degrees. DWB 87 is another of the many bright emission nebulae in Cygnus, 7.8 by 4.3 arcminutes. It is in the Gamma Cygni area. Two other emission nebulae include Sharpless 2-112 and Sharpless 2-115. When viewed in an amateur telescope, Sharpless 2–112 appears to be in a teardrop shape. More of the nebula's eastern portion is visible with an O III (doubly ionized oxygen) filter. There is an orange star of magnitude 10 nearby and a star of magnitude 9 near the nebula's northwest edge. Further to the northwest, there is a dark rift and another bright patch. The whole nebula measures 15 arcminutes in diameter. Sharpless 2–115 is another emission nebula with a complex pattern of light and dark patches. Two pairs of stars appear in the nebula; it is larger near the southwestern pair. The open cluster Berkeley 90 is embedded in this large nebula, which measures 30 by 20 arcminutes. 
Also of note is the Crescent Nebula (NGC 6888), located between Gamma and Eta Cygni, which was formed by the Wolf-Rayet star HD 192163.
In recent years, amateur astronomers have made some notable Cygnus discoveries. The "Soap bubble nebula" (PN G75.5+1.7), near the Crescent nebula, was discovered on a digital image by Dave Jurasevich in 2007. In 2011, Austrian amateur Matthias Kronberger discovered a planetary nebula (Kronberger 61, now nicknamed "The Soccer Ball") on old survey photos, confirmed recently in images by the Gemini Observatory; both of these are likely too faint to be detected by eye in a small amateur scope.
But a much more obscure and relatively 'tiny' object—one which is readily seen in dark skies by amateur telescopes, under good conditions—is the newly discovered nebula (likely reflection type) associated with the star 4 Cygni (HD 183056): an approximately fan-shaped glowing region of several arcminutes' diameter, to the south and west of the fifth-magnitude star. It was first discovered visually near San Jose, California and publicly reported by amateur astronomer Stephen Waldee in 2007, and was confirmed photographically by Al Howard in 2010. California amateur astronomer Dana Patchick also says he detected it on the Palomar Observatory survey photos in 2005 but had not published it for others to confirm and analyze at the time of Waldee's first official notices and later 2010 paper.
Cygnus X is the largest star-forming region in the Solar neighborhood and includes not only some of the brightest and most massive stars known (such as Cygnus OB2-12), but also Cygnus OB2, a massive stellar association classified by some authors as a young globular cluster.
More supernovae have been seen in the Fireworks Galaxy (NGC 6946) than in any other galaxy.
Cygnus A is the first radio galaxy discovered; at a distance of 730 million light-years from Earth, it is the closest powerful radio galaxy. In the visible spectrum, it appears as an elliptical galaxy in a small cluster. It is classified as an active galaxy because the supermassive black hole at its nucleus is accreting matter, which produces two jets of matter from the poles. The jets' interaction with the interstellar medium creates radio lobes, one source of radio emissions.

</doc>
<doc id="6422" url="http://en.wikipedia.org/wiki?curid=6422" title="Communion">
Communion

Communion may refer to:
Communion may also refer to:

</doc>
<doc id="6423" url="http://en.wikipedia.org/wiki?curid=6423" title="Calorie">
Calorie

The name calorie is used for two units of energy.
Although these units are part of the metric system, they have been superseded in the International System of Units by the joule. One small calorie is approximately 4.2 joules (so one large calorie is about 4.2 kilojoules). The factor used to convert calories to joules at a given temperature is numerically equivalent to the specific heat capacity of water expressed in joules per kelvin per gram or per kilogram. The precise conversion factor depends on the definition adopted.
In spite of its non-official status, the large calorie is still widely used as a unit of food energy in the US, UK and some other Western countries. The small calorie is also often used for measurements in chemistry, although the amounts involved are typically recorded in kilocalories.
The calorie was first defined by Nicolas Clément in 1824 as a unit of heat, and entered French and English dictionaries between 1841 and 1867. The word comes from Latin "calor" meaning "heat".
Definitions.
The energy needed to increase the temperature of a given mass of water by 1 °C depends on the atmospheric pressure and the starting temperature. Accordingly, several different precise definitions of the calorie have been used.
The pressure is usually taken to be the standard atmospheric pressure (). The temperature increase can be expressed as one kelvin, which means the same as an increment of one degree Celsius.
Usage.
The calorie was first defined specifically to measure energy in the form of heat, especially in experimental calorimetry.
Nutrition.
In nutritional contexts, the kilojoule (kJ) is the SI unit of food energy. However, the calorie and kilocalorie are still in common use.
In these contexts, confusingly, the word "calorie" and "kilocalorie" refer to equivalent units (the former to the large calorie and the latter to small calories). Sometimes, in an attempt to avoid confusion, the large calorie is written as "Calorie" (with a capital "C"). This convention is not always followed, and not explained to the average person clearly.
These quantities are often used for the total amount of food energy (e.g., in a meal) and for the specific energy, namely amount of energy per unit of mass (e.g. "calories per gram", "calories per serving"). Nutritional requirements or intakes are often expressed in calories per day.
Chemistry.
In scientific contexts, the term "calorie" almost always refers to the small calorie. Even though it is not an SI unit, it is still used in chemistry. For example, the energy released in a chemical reaction per mole of reagent is occasionally expressed in kilocalories per mole. Traditionally, this use was largely due to the ease with which it could be calculated in laboratory reactions, especially in aqueous solution: a volume of reagent dissolved in water forming a solution, with concentration expressed in moles per liter (1 liter weighing 1 kg), will induce a temperature change in degrees Celsius in the total volume of water solvent, and these quantities (volume, molar concentration and temperature change) can then be used to calculate energy per mole. It is also occasionally used to specify energy quantities that relate to reaction energy, such as enthalpy of formation and the size of activation barriers. However, its use is being superseded by the SI unit, the joule, and multiples thereof such as the kilojoule.

</doc>
<doc id="6424" url="http://en.wikipedia.org/wiki?curid=6424" title="Corona Australis">
Corona Australis

Corona Australis or Corona Austrina is a constellation in the southern celestial hemisphere. Its Latin name means "southern crown", and it is the southern counterpart of Corona Borealis, the northern crown. One of the 48 constellations listed by the 2nd-century astronomer Ptolemy, it remains one of the 88 modern constellations. The Ancient Greeks saw Corona Australis as a wreath rather than a crown and associated it with Sagittarius or Centaurus. Other cultures have likened the pattern to a turtle, ostrich nest, a tent, or even a hut belonging to a rock hyrax.
Although fainter than its namesake, the oval- or horseshoe-shaped pattern of its brighter stars renders it distinctive. Alpha and Beta Coronae Australis are the two brightest stars with an apparent magnitude of around 4.1. Epsilon Coronae Australis is the brightest example of a W Ursae Majoris variable in the southern sky. Lying alongside the Milky Way, Corona Australis contains one of the closest star-forming regions to our Solar System—a dusty dark nebula known as the Corona Australis Molecular Cloud, lying about 430 light years away. Within it are stars at the earliest stages of their lifespan. The variable stars R and TY Coronae Australis light up parts of the nebula, which varies in brightness accordingly.
Characteristics.
Corona Australis is a small constellation bordered by Sagittarius to the north, Scorpius to the west, Telescopium to the south, and Ara to the southwest. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'CrA'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of four segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between −36.77° and −45.52°. Covering 128 square degrees, Corona Australis culminates at midnight around the 30th of June and ranks 80th in area. Only visible at latitudes south of 53° north, Corona Australis cannot be seen from the British Isles as it lies too far south, but it can be seen from southern Europe and readily from the southern United States.
Notable features.
While not a bright constellation, Corona Australis is nonetheless distinctive due to its easily identifiable pattern of stars, which has been described as horseshoe- or oval-shaped. Though it has no stars brighter than magnitude 2.4, it still has 21 stars visible to the unaided eye (brighter than magnitude 5.5), making it the second-brightest constellation. Nicolas Louis de Lacaille used the Greek letters Alpha through to Lambda to label the most prominent eleven stars in the constellation, designating two stars as Eta and omitting Iota altogether. Mu Coronae Australis, a yellow star of spectral type G5.5III and apparent magnitude 5.21, was labelled by Johann Elert Bode and retained by Benjamin Gould, who deemed it bright enough to warrant naming.
Stars.
The only star in the constellation to have received a name is Alfecca Meridiana or Alpha CrA. The name combines the Arabic name of the constellation with the Latin for "middle". In Arabic, "Alfecca" means "break", and refers to the shape of both Corona Australis and Corona Borealis. Also called simply "Meridiana", it is a white main sequence star located 130 light years away from Earth, with an apparent magnitude of 4.10 and spectral type A2Va. A rapidly rotating star, it spins at almost 200 km per second at its equator, making a complete revolution in around 14 hours. Like the star Vega, it has excess infrared radiation, which indicates it may be ringed by a disk of dust. It is currently a main-sequence star, but will eventually evolve into a white dwarf; currently, it has a luminosity 31 times greater, and a radius and mass of 2.3 times that of the Sun. Beta Coronae Australis is an orange giant 510 light years from Earth. Its spectral type is K0II, and it is of apparent magnitude 4.11. Since its formation, it has evolved from a B-type star to a K-type star. Its luminosity class places it as a bright giant; its luminosity is 730 times that of the Sun, designating it one of the highest-luminosity K0-type stars visible to the naked eye. 100 million years old, it has a radius of 43 solar radii (R☉) and a mass of between 4.5 and 5 solar masses (M☉). Alpha and Beta are so similar as to be indistinguishable in brightness to the naked eye.
Some of the more prominent double stars include Gamma Coronae Australis—a pair of yellowish white stars 58 light years away from Earth, which orbit each other every 122 years. Widening since 1990, the two stars can be seen as separate with a 100 mm aperture telescope; they are separated by 1.3 arcseconds at an angle of 61 degrees. They have a combined visual magnitude of 4.2; each component is an F8V dwarf star with a magnitude of 5.01. Epsilon Coronae Australis is an eclipsing binary belonging to a class of stars known as W Ursae Majoris variables. These star systems are known as contact binaries as the component stars are so close together they touch. Varying by a quarter of a magnitude around an average apparent magnitude of 4.83 every seven hours, the star system lies 98 light years away. Its spectral type is F4VFe-0.8+. At the southern end of the crown asterism are the stars Eta¹ and Eta² Coronae Australis, which form an optical double. Of magnitude 5.1 and 5.5, they are separable with the naked eye and are both white. Kappa Coronae Australis is an easily resolved optical double—the components are of apparent magnitudes 5.7 and 6.3 and are 1700 and 490 light years away respectively. They appear at an angle of 359 degrees, separated by 21.6 arcseconds. Kappa² is actually the brighter of the pair and is more bluish white, with a spectral type of B9V, while Kappa¹ is of spectral type A0III. Lying 202 light years away, Lambda Coronae Australis is a double splittable in small telescopes. The primary is a white star of spectral type A2Vn and magnitude of 5.1, while the companion star has a magnitude of 9.7. The two components are separated by 29.2 arcseconds at an angle of 214 degrees.
Zeta Coronae Australis is a rapidly rotating main sequence star with an apparent magnitude of 4.8, 221.7 light years from Earth. The star has blurred lines in its hydrogen spectrum due to its rotation. Its spectral type is B9V. Theta Coronae Australis lies further to the west, a yellow giant of spectral type G8III and apparent magnitude 4.62. Corona Australis harbours RX J1856.5-3754, an isolated neutron star that is thought to lie 140 (±40) parsecs, or 460 (±130) light years, away, with a diameter of 14 km. It was once suspected to be a strange star, but this has been discounted.
Deep sky objects.
In the north of the constellation is the Corona Australis Molecular Cloud, a dark molecular cloud with many embedded reflection nebulae, including NGC 6729, NGC 6726–7, and IC 4812. A star-forming region of around 7000 M☉, it contains Herbig–Haro objects (protostars) and some very young stars. About 430 light years (130 parsecs) away, it is one of the closest star-forming regions to our solar system. The related NGC 6726 and 6727, along with unrelated NGC 6729, were first recorded by Johann Friedrich Julius Schmidt in 1865.
R Coronae Australis is an irregular variable star ranging from magnitudes 9.7 to 13.9. Blue-white, it is of spectral type B5IIIpe. A very young star, it is still accumulating interstellar material. It is obscured by, and illuminates, the surrounding nebula, NGC 6729, which brightens and darkens with it. The nebula is often compared to a comet for its appearance in a telescope, as its length is five times its width. S Coronae Australis is a G-class dwarf in the same field as R and is a T Tauri star. Nearby, another young variable star, TY Coronae Australis, illuminates another nebula: reflection nebula NGC 6726–7. TY Coronae Australis ranges irregularly between magnitudes 8.7 and 12.4,and the brightness of the nebula varies with it. Blue-white, it is of spectral type B8e. The largest young stars in the region, R, S, T Coronae Australis, TY and VV Coronae Australis, are all ejecting jets of material which cause surrounding dust and gas to coalesce and form Herbig–Haro objects, many of which have been identified nearby. Lying adjacent to the nebulosity is the globular cluster known as NGC 6723, which is actually in the neighbouring constellation of Sagittarius and is much much further away.
Near Epsilon and Gamma Coronae Australis is Bernes 157, a dark nebula and star forming region. It is a large nebula, 55 by 18 arcminutes, that possesses several stars around magnitude 13. These stars have been dimmed by up to 8 magnitudes by its dust clouds.
IC 1297 is a planetary nebula of apparent magnitude 10.7, which appears as a green-hued roundish object in higher-powered amateur instruments. The nebula surrounds the variable star RU Coronae Australis, which has an average apparent magnitude of 12.9 and is a WC class Wolf–Rayet star. IC 1297 is small, at only 7 arcseconds in diameter; it has been described as "a square with rounded edges" in the eyepiece, elongated in the north-south direction. Descriptions of its color encompass blue, blue-tinged green, and green-tinged blue.
Corona Australis' location near the Milky Way means that galaxies are uncommonly seen. NGC 6768 is a magnitude 11.2 object 35′ south of IC 1297. It is made up of two galaxies merging, one of which is an elongated elliptical galaxy of classification E4 and the other a lenticular galaxy of classification S0. IC 4808 is a galaxy of apparent magnitude 12.9 located on the border of Corona Australis with the neighbouring constellation of Telescopium and 3.9 degrees west-southwest of Beta Sagittarii. However, amateur telescopes will only show a suggestion of its spiral structure. It is 1.9 arcminutes by 0.8 arcminutes. The central area of the galaxy does appear brighter in an amateur instrument, which shows it to be tilted northeast-southwest.
Southeast of Theta and southwest of Eta lies the open cluster ESO 281-SC24, which is composed of the yellow 9th magnitude star GSC 7914 178 1 and five 10th to 11th magnitude stars. Halfway between Theta Coronae Australis and Theta Scorpii is the dense globular cluster NGC 6541. Described as between magnitude 6.3 and magnitude 6.6, it is visible in binoculars and small telescopes. Around 22000 light years away, it is around 100 light years in diameter. It is estimated to be around 14 billion years old. NGC 6541 appears 13.1 arcminutes in diameter and is somewhat resolvable in large amateur instruments; a 12-inch telescope reveals approximately 100 stars but the core remains unresolved.
Meteor showers.
The Corona Australids are a meteor shower that takes place between 14 and 18 March each year, peaking around 16 March. This meteor shower does not have a high peak hourly rate. In 1953 and 1956, observers noted a maximum of 6 meteors per hour and 4 meteors per hour respectively; in 1955 the shower was "barely resolved". However, in 1992, astronomers detected a peak rate of 45 meteors per hour. The Corona Australids' rate varies from year to year. At only six days, the shower's duration is particularly short, and its meteoroids are small; the stream is devoid of large meteoroids. The Corona Australids were first seen with the unaided eye in 1935 and first observed with radar in 1955. Corona Australid meteors have an entry velocity of 45 kilometers per second. In 2006, a shower originating near Beta Coronae Australis was designated as the Beta Coronae Australids. They appear in May, the same month as a nearby shower known as the May Microscopids, but the two showers have different trajectories and are unlikely to be related.
History.
Corona Australis may have been recorded by ancient Mesopotamians in the MUL.APIN, as a constellation called MA.GUR ("The Bark"). However, this constellation, adjacent to SUHUR.MASH ("The Goat-Fish", modern Capricornus), may instead have been modern Epsilon Sagittarii. As a part of the southern sky, MA.GUR was one of the fifteen "stars of Ea".
In the 3rd century BC, the Greek didactic poet Aratus wrote of, but did not name the constellation, instead calling the two crowns Στεφάνοι ("Stephanoi"). The Greek astronomer Ptolemy described the constellation in the 2nd century AD, though with the inclusion of Alpha Telescopii, since transferred to Telescopium. Ascribing 13 stars to the constellation, he named it Στεφάνος νοτιος ("Stephanos notios"), "Southern Wreath", while other authors associated it with either Sagittarius (having fallen off his head) or Centaurus; with the former, it was called "Corona Sagittarii". Similarly, the Romans called Corona Australis the "Golden Crown of Sagittarius". It was known as "Parvum Coelum" ("Canopy", "Little Sky") in the 5th century. The 18th-century French astronomer Jérôme Lalande gave it the names "Sertum Australe" ("Southern Garland") and "Orbiculus Capitis", while German poet and author Philippus Caesius called it "Corolla" ("Little Crown") or "Spira Australis" ("Southern Coil"), and linked it with the Crown of Eternal Life from the New Testament. Seventeenth-century celestial cartographer Julius Schiller linked it to the Diadem of Solomon. Sometimes, Corona Australis was not the wreath of Sagittarius but arrows held in his hand.
Corona Australis has been associated with the myth of Bacchus and Stimula. Jupiter had impregnated Stimula, causing Juno to become jealous. Juno convinced Stimula to ask Jupiter to appear in his full splendor, which the mortal woman could not handle, causing her to burn. After Bacchus, Stimula's unborn child, became an adult and the god of wine, he honored his deceased mother by placing a wreath in the sky.
In Chinese astronomy, the stars of Corona Australis are located within the Black Tortoise of the North (北方玄武, "Běi Fāng Xuán Wǔ"). The constellation itself was known as "ti'en pieh" ("Heavenly Turtle") and during the Western Zhou period, marked the beginning of winter. However, precession over time has meant that the "Heavenly River" (Milky Way) became the more accurate marker to the ancient Chinese and hence supplanted the turtle in this role. Arabic names for Corona Australis include "Al Ķubbah" "the Tortoise", "Al Ĥibā" "the Tent" or "Al Udḥā al Na'ām" "the Ostrich Nest". It was later given the name "Al Iklīl al Janūbiyyah", which the European authors Chilmead, Riccioli and Caesius transliterated as Alachil Elgenubi, Elkleil Elgenubi and Aladil Algenubi respectively.
The ǀXam speaking San people of South Africa knew the constellation as "≠nabbe ta !nu" "house of branches"—owned originally by the Dassie (rock hyrax), and the star pattern depicting people sitting in a semicircle around a fire.
The indigenous Boorong people of northwestern Victoria saw it as "Won", a boomerang thrown by "Totyarguil" (Altair). The Aranda people of Central Australia saw Corona Australis as a coolamon carrying a baby, which was accidentally dropped to earth by a group of sky-women dancing in the Milky Way. The impact of the coolamon created Gosses Bluff crater, 175 km west of Alice Springs. The Torres Strait Islanders saw Corona Australis as part of a larger constellation encompassing part of Sagittarius and the tip of Scorpius's tail; the Pleiades and Orion were also associated. This constellation was Tagai's canoe, crewed by the Pleiades, called the "Usiam", and Orion, called the "Seg". The myth of Tagai says that he was in charge of this canoe, but his crewmen consumed all of the supplies onboard without asking permission. Enraged, Tagai bound the Usiam with a rope and tied them to the side of the boat, then threw them overboard. Scorpius's tail represents a suckerfish, while Eta Sagittarii and Theta Coronae Australis mark the bottom of the canoe. On the island of Futuna, the figure of Corona Australis was called "Tanuma" and in the Tuamotus, it was called "Na Kaua-ki-Tonga".
References.
Sources
Online sources
"SIMBAD"

</doc>
<doc id="6426" url="http://en.wikipedia.org/wiki?curid=6426" title="Corcovado">
Corcovado

Corcovado, meaning "hunchback" in Portuguese, is a mountain in central Rio de Janeiro, Brazil. The granite peak is located in the Tijuca Forest, a national park. It is sometimes confused with nearby Sugarloaf Mountain.
Corcovado hill lies just west of the city center but is wholly within the city limits and visible from great distances. It is known worldwide for the 38-metre (125 ft) statue of Jesus atop its peak, entitled "Cristo Redentor" or "Christ the Redeemer".
Access.
The peak and statue can be accessed via a narrow road or by the 3.8 kilometre (2.4 mi) Corcovado Rack Railway which was opened in 1884 and refurbished in 1980. The railway uses three electrically powered trains, with a passenger capacity of 540 passengers per hour. The rail trip takes approximately 20 minutes and departs every 20 minutes. Due to its limited passenger capacity, the wait to board at the entry station can take several hours. The year-round schedule is 8:30 to 18:30.
From the train terminus and road, the observation deck at the foot of the statue is reached by 223 steps, or by elevators and escalators. Among the most popular year-round tourist attractions in Rio, the Corcovado railway, access roads, and statue platform are commonly crowded.
Attractions.
The most popular attraction of Corcovado mountain is the statue and viewing platform at its peak, drawing over 300,000 visitors per year. From the peak's platform the panoramic view includes downtown Rio, Sugarloaf Mountain, the Lagoa Rodrigo de Freitas (lake), Copacabana and Ipanema beaches, Estádio do Maracanã (Maracanã Stadium), and several of Rio's favelas. Cloud cover is common in Rio and the view from the platform is often obscured. Sunny days are recommended for optimal viewing.
Notable past visitors to the mountain peak include Pope Pius XII, Pope John Paul II, Alberto Santos-Dumont, German Sueiro Vasquez, Albert Einstein, Diana, Princess of Wales, among others. An additional attraction of the mountain is rock climbing. The south face had 54 climbing routes in 1992. The easiest way starts from Park Lage.
The Corcovado is also a symbol of the Brazilian culture.
Geology.
The peak of Corcovado is a big granite dome, which describes a generally vertical rocky formation. It is claimed to be the highest such formation in Brazil, the second highest being Pedra Agulha, situated near to the town of Pancas in Espírito Santo.

</doc>
<doc id="6427" url="http://en.wikipedia.org/wiki?curid=6427" title="Cheddar, Somerset">
Cheddar, Somerset

Cheddar is a large village and civil parish in the Sedgemoor district of the English county of Somerset. It is situated on the southern edge of the Mendip Hills, north-west of Wells. The civil parish includes the hamlets of Nyland and Bradley Cross. The village, which has its own parish council, has a population of 5,755 and the parish has an acreage of as of 1961.
Cheddar Gorge, on the northern edge of the village, is the largest gorge in the United Kingdom and includes several show caves including Gough's Cave. The gorge has been a centre of human settlement since Neolithic times, including a Saxon palace. It has a temperate climate and provides a unique geological and biological environment that has been recognised by the designation of several Sites of Special Scientific Interest. It is also the site of several limestone quarries. The village gave its name to Cheddar cheese and has been a centre for strawberry growing, with the crop being transported on the Cheddar Valley line, which closed in the late 1960s but is now a cycle path. It is now a major tourist destination with several cultural and community facilities, including the Cheddar Show Caves Museum.
The village supports a variety of community groups including religious, sporting and cultural organisations. Several of these are based on the site of The Kings of Wessex Academy, which is the largest educational establishment.
History.
The name Cheddar comes from the Old English word "ceodor", meaning deep dark cavity or pouch.
There is evidence of occupation from the Neolithic period in Cheddar. Britain's oldest complete human skeleton, Cheddar Man, estimated to be 9,000 years old, was found in Cheddar Gorge in 1903. Older remains from the Upper Late Palaeolithic era (12,000–13,000 years ago) have been found. There is some evidence of a Bronze Age field system at the Batts Combe quarry site. There is also evidence of Bronze Age barrows at the mound in the Longwood valley, which if man-made it is likely to be a field system. The remains of a Roman villa have been excavated in the grounds of the current vicarage.
The village of Cheddar had been important during the Roman and Saxon eras. There was a royal palace at Cheddar during the Saxon period, which was used on three occasions in the 10th century to host the Witenagemot. The ruins of the palace were excavated in the 1960s. They are located on the grounds of The Kings of Wessex Academy, together with a 14th century chapel dedicated to St. Columbanus. Roman remains have also been uncovered at the site. Cheddar was listed in the Domesday Book of 1086 as "Ceder", meaning "Shear Water", from the Old English "scear" and Celtic "dwr". As early as 1130 AD, the Cheddar Gorge was recognised as one of the "Four wonders of England". Historically, Cheddar's source of wealth was farming and cheese making for which it was famous as early as 1170 AD. The parish was part of the Winterstoke Hundred.
The manor of Cheddar was deforested in 1337 and Bishop Ralph was granted a licence by the King to create a hunting forest.
As early as 1527 there are records of watermills on the river. In the 17th and 18th centuries, there were several watermills which ground corn and made paper, with 13 mills on the Yeo at the peak, declining to seven by 1791 and just three by 1915.
In the Victorian era it also became a centre for the production of clothing. The last mill, used as a shirt factory, closed in the early 1950s. William Wilberforce saw the poor conditions of the locals when he visited Cheddar in 1789. He inspired Hannah More in her work to improve the conditions of the Mendip miners and agricultural workers. In 1801, of common land were enclosed under the Inclosure Acts.
Tourism of the Cheddar gorge and caves began with the opening of the Cheddar Valley Railway in 1869.
Cheddar, its surrounding villages and specifically the gorge has been subject to flooding. In the Great Flood of 1968 the flow of water washed large boulders down the gorge, washed away cars, and damaged the cafe and the entrance to Gough's Cave.
Government.
Cheddar is recognised as a village. The adjacent settlement of Axbridge, although only about a third the population of Cheddar, is a town. This apparently illogical situation is explained by the relative importance of the two places in historic times. While Axbridge grew in importance as a centre for cloth manufacturing in the Tudor period and gained a charter from King John, Cheddar remained a more dispersed mining and dairy-farming village. Its population grew with the arrival of the railways in the Victorian era and the advent of tourism.
The parish council, which has 15 members who are elected for four years, is responsible for local issues, including setting an annual precept (local rate) to cover the council's operating costs and producing annual accounts for public scrutiny. The parish council evaluates local planning applications and works with the police, district council officers, and neighbourhood watch groups on matters of crime, security, and traffic. The parish council's role also includes initiating projects for the maintenance and repair of parish facilities, as well as consulting with the district council on the maintenance, repair, and improvement of highways, drainage, footpaths, public transport, and street cleaning. Conservation matters (including trees and listed buildings) and environmental issues are also the responsibility of the council.
The village falls within the non-metropolitan district of Sedgemoor, which was formed on 1 April 1974 under the Local Government Act 1972. It was previously part of Axbridge Rural District. Sedgemoor is responsible for local planning and building control, local roads, council housing, environmental health, markets and fairs, refuse collection and recycling, cemeteries and crematoria, leisure services, parks, and tourism. Somerset County Council is responsible for running the largest and most expensive local services such as education, social services, the library, roads, public transport, trading standards, waste disposal and strategic planning, although fire, police and ambulance services are provided jointly with other authorities through the Devon and Somerset Fire and Rescue Service, Avon and Somerset Constabulary and the South Western Ambulance Service.
It is also part of the Wells county constituency represented in the House of Commons of the Parliament of the United Kingdom. It elects one Member of Parliament (MP) by the first past the post system of election, and is part of the South West England constituency of the European Parliament which elects six MEPs using the d'Hondt method of party-list proportional representation.
Cheddar is twinned with Felsberg, Germany and Vernouillet, France, and it has an active programme of exchange visits. Initially, Cheddar twinned with Felsberg in 1984. In 2000, Cheddar twinned with Vernouillet, which had also been twinned with Felsberg. Cheddar also has a friendship link with Ocho Rios in Saint Ann Parish, Jamaica.
Geography.
The area is underlain by Black Rock slate, Burrington Oolite and Clifton Down Limestone of the Carboniferous Limestone Series, which contain ooliths and fossil debris on top of Old Red Sandstone, and by Dolomitic Conglomerate of the Keuper. Evidence for Variscan orogeny is seen in the sheared rock and cleaved shales. In many places weathering of these strata has resulted in the formation of immature calcareous soils.
Gorge and caves.
Cheddar Gorge, which is located on the edge of the village, is the largest gorge in the United Kingdom.
The gorge is the site of the Cheddar Caves, where Cheddar Man was found in 1903. Older remains from the Upper Late Palaeolithic era (12,000–13,000 years ago) have been found. The caves, produced by the activity of an underground river, contain stalactites and stalagmites. Gough's Cave, which was discovered in 1903, leads around into the rock-face, and contains a variety of large rock chambers and formations. Cox's Cave, discovered in 1837, is smaller but contains many intricate formations. A further cave houses a children's entertainment walk known as the "Crystal Quest".
Cheddar Gorge, including Cox's Cave, Gough's Cave and other attractions, has become a tourist destination, attracting about 500,000 visitors per year.
In a 2005 poll of "Radio Times" readers, following its appearance on the 2005 television programme "Seven Natural Wonders", Cheddar Gorge was named as the second greatest natural wonder in Britain, surpassed only by the Dan yr Ogof caves.
Sites of Special Scientific Interest.
There are several large and unique Sites of Special Scientific Interest (SSSI) around the village.
Cheddar Reservoir is a near-circular artificial reservoir operated by Bristol Water. Dating from the 1930s, it has a capacity of 135 million gallons (614,000 cubic metres). The reservoir is supplied with water taken from the Cheddar Yeo, which rises in Gough's Cave in Cheddar Gorge and is a tributary of the River Axe. The inlet grate for the water pipe that is used to transport the water can be seen next to the sensory garden in Cheddar Gorge. It has been designated as a Site of Special Scientific Interest (SSSI) due to its wintering waterfowl populations.
Cheddar Wood and the smaller Macall's Wood form a biological Site of Special Scientific Interest from what remains of the wood of the Bishops of Bath and Wells in the 13th century and of King Edmund the Magnificent's wood in the 10th. During the 19th century, its lower fringes were grubbed out to make strawberry fields. Most of these have been allowed to revert to woodland. The wood was coppiced until 1917. This site compromises a wide range of habitats which include ancient and secondary semi-natural broadleaved woodland, unimproved neutral grassland, and a complex mosaic of calcareous grassland and acidic dry dwarf-shrub heath. Cheddar Wood is one of only a few English stations for Starved Wood-sedge ("Carex depauperata"). Purple Gromwell ("Lithospermum purpurocaeruleum"), a nationally rare plant, also grows in the wood. Butterflies include Silver-washed Fritillary ("Argynnis paphia"), Dark Green Fritillary ("Argynnis aglaja"), Pearl-bordered Fritillary ("Boloria euphrosyne"), Holby Blue ("Celastrina argiolus") and Brown Argus ("Aricia agestis"). The slug ("Arion fasciatus"), which has a restricted distribution in the south of England, and the Soldier beetle ("Cantharis fusca") also occur.
By far the largest of the SSSIs is called Cheddar Complex and covers of the gorge, caves and the surrounding area. It is important because of both biological and geological features. It includes four SSSIs, formerly known as Cheddar Gorge SSSI, August Hole/Longwood Swallet SSSI, GB Cavern Charterhouse SSSI and Charterhouse on-Mendip SSSI. It is partly owned by the National Trust who acquired it in 1910 and partly managed by the Somerset Wildlife Trust.
Quarries.
Close to the village and gorge are Batts Combe quarry and Callow Rock quarry, two of the active Quarries of the Mendip Hills where limestone is still extracted. Operating since the early 20th century, Batts Combe is owned and operated by Hanson Aggregates. The output in 2005 was around 4,000 tonnes of limestone per day, one third of which was supplied to an on-site lime kiln, which closed in 2009; the remainder was sold as coated or dusted aggregates. The limestone at this site is close to 99 percent carbonate of calcium and magnesium (dolomite).
The Chelmscombe Quarry finished its work as a limestone quarry in the 1950s and was then used by the Central Electricity Generating Board as a tower testing station. During the 1970s and 1980s it was also used to test the ability of containers of radioactive material to withstand impacts and other accidents.
Climate.
Along with the rest of South West England, Cheddar has a temperate climate which is generally wetter and milder than the rest of the country. The annual mean temperature is approximately . Seasonal temperature variation is less extreme than most of the United Kingdom because of the adjacent sea, which moderates temperature. The summer months of July and August are the warmest with mean daily maxima of approximately . In winter mean minimum temperatures of or are common. In the summer the Azores high-pressure system affects the south-west of England. Convective cloud sometimes forms inland, reducing the number of hours of sunshine; annual sunshine rates are slightly less than the regional average of 1,600 hours. In December 1998 there were 20 days without sun recorded at Yeovilton. Most the rainfall in the south-west is caused by Atlantic depressions or by convection. Most of the rainfall in autumn and winter is caused by the Atlantic depressions, which are most active during those seasons. In summer, a large proportion of the rainfall is caused by sun heating the ground leading to convection and to showers and thunderstorms. Average rainfall is around . About 8–15 days of snowfall per year is typical. November to March have the highest mean wind speeds, and June to August have the lightest winds. The predominant wind direction is from the south-west.
Demography.
The parish has a population of 5,093, with a mean age of 43 years. Residents live in 2,209 households. The vast majority of households (2,183) give their ethnic status as white.
Economy.
The village gave its name to Cheddar cheese, which is the most popular type of cheese in the United Kingdom. The cheese is now made and consumed worldwide, and only one producer remains in the village.
Since the 1880s, Cheddar's other main produce has been the strawberry,
which is grown on the south-facing lower slopes of the Mendip hills. As a consequence of its use for transporting strawberries to market, the since-closed Cheddar Valley line became known as "The Strawberry Line" after it opened in 1869.
The line ran from Yatton to Wells. When the rest of the line was closed and all passenger services ceased, the section of the line between Cheddar and Yatton remained open for goods traffic. It provided a fast link with the main markets for the strawberries in Birmingham and London, but finally closed in 1964, becoming part of the Cheddar Valley Railway Nature Reserve.
Cheddar Ales is a small brewery based in the village, producing beer for local public houses. Tourism is a significant source of employment. Around 15 percent of employment in Sedgemoor is provided by tourism, but within Cheddar it is estimated to employ as many as 1,000 people.
The village also has a youth hostel, and a number of camping and caravan sites.
Culture and community.
Cheddar has a number of active service clubs including Cheddar Vale Lions Club, Mendip Rotary and Mendip Inner Wheel Club. The clubs raise money for projects in the local community and hold annual events such as a fireworks display, duck races in the Gorge, a dragon boat race on the reservoir and concerts on the grounds of the nearby St Michael's Cheshire Home.
Several notable people have been born or lived in Cheddar. Musician Jack Bessant, the bass guitarist with the band Reef grew up on his parents' strawberry farm, and Matt Goss and Luke Goss, former members of Bros, lived in Cheddar for nine months as children. Trina Gulliver, eight-time World Professional Darts Champion, currently lives in Cheddar.
The comedian Richard Herring grew up in Cheddar. His 2008 Edinburgh Festival Fringe show, "The Headmaster's Son" is based on his time at The Kings of Wessex School, where his father Keith was the headmaster. The final performance of this show was held at the school in November 2009. He also visited the school in March 2010 to perform his show "Hitler Moustache".
Landmarks.
The market cross in Bath Street dates from the 15th century, with the shelter having been rebuilt in 1834. It has a central octagonal pier, a socket raised on four steps, a hexagonal shelter with six arched four-centred openings, shallow two-stage buttresses at each angle, and an embattled parapet. The shaft is crowned by an abacus with figures in niches, probably from the late 19th century, although the cross is now missing. It was rebuilt by Thomas, Marquis of Bath. It is a Scheduled Ancient Monument (Somerset County No 21) and Grade II* listed building.
In January 2000, the cross was seriously damaged in a traffic accident. By 2002, the cross had been rebuilt and the area around it was redesigned to protect and enhance its appearance.
The cross was badly damaged again in March 2012, when a taxi crashed into it late at night demolishing two sides.
Repair work, which included the addition of wooden-clad steel posts to protect against future crashes, was completed in November 2012 at a cost of £60,000.
Hannah More, a philanthropist and educator, founded a school in the village in the late 18th century for the children of miners. Her first school was located in a 17th-century house. Now named "Hannah More's Cottage", the Grade II-listed building is used by the local community as a meeting place.
Transport.
The village is situated on the A371 road which runs from Wincanton, to Weston-super-Mare. It is approximately from the route of the M5 motorway with around a drive to junction 21 or 22.
It was on the Cheddar Valley line, a railway line that was opened in 1869 and closed in 1963. It became known as The Strawberry Line because of the large volume of locally-grown strawberries that it carried. It ran from Yatton railway station through to Wells (Tucker Street) railway station and joined the East Somerset Railway to make a through route via Shepton Mallet (High Street) railway station to Witham. Sections of the now-disused railway have been opened as the Strawberry Line Trail, which currently runs from Yatton to Cheddar. The Cheddar Valley line survived until the "Beeching Axe". Towards the end of its life there were so few passengers that diesel railcars were sometimes used. The Cheddar branch closed to passengers on 9 September 1963 and to goods in 1964. The line closed in the 1960s, when it became part of the Cheddar Valley Railway Nature Reserve, and part of the National Cycle Network route 26. The cycle route also intersects with the West Mendip Way and various other footpaths.
Education.
Cheddar has three schools belonging to the Cheddar Valley Group of Schools, twelve schools that provide Cheddar Valley's three-tier education system. Cheddar First School has ten classes for children between 4 and 9 years. Fairlands Middle School, a middle school categorised as a middle-deemed-secondary school, has 510 pupils between 9 and 13. Fairlands takes children moving up from Cheddar First School as well as other first schools in the Cheddar Valley. The Kings of Wessex Academy, a coeducational comprehensive school, has been rated as "outstanding" by Ofsted. It has 1,182 students aged 13 to 18, including 302 in the sixth form. Kings is a faith school linked to the Church of England. It was awarded the specialist status of Technology College in 2001, enabling it to develop its Information Technology (IT) facilities and improve courses in science, mathematics and design technology. In 2007 it became a foundation school, giving it more control over its own finances. The academy owns and runs a sports centre and swimming pool, Kings Fitness & Leisure, with facilities that are used by students as well as residents. Community education project I.T. for the Terrified, which was originally set up in Wedmore in 1999, is based in an old cow shed on the school's grounds.
Religious sites.
The Church of St Andrew dates from the 14th century. It was restored in 1873 by William Butterfield. It is a Grade I listed building and contains some 15th century stained glass and an altar table of 1631. The chest tomb in the chancel is believed to contain the remains of Sir Thomas Cheddar and is dated 1442. The tower, which rises to , contains a bell dating from 1759 made by Thomas Bilbie of the Bilbie family.
There are also churches for Roman Catholic, Methodist and other denominations, including Cheddar Valley Community Church, who not only meet at The Kings of Wessex School on Sunday, but also have their own site on Tweentown for meeting during the week. The Baptist chapel was built in 1831.
Sport.
Kings Fitness & Leisure, situated on the grounds of The Kings of Wessex School, provides a venue for various sports and includes a 20-metre swimming pool, racket sport courts, a sports hall, dance studios and a gym. A youth sports festival was held on Sharpham Road Playing Fields in 2009. In 2010 a skatepark was built in the village, funded by the Cheddar Local Action Team.
Cheddar Football Club, founded in 1892 and nicknamed "The Cheesemen", play in the Somerset County Football League Premier Division. In 2009 plans were revealed to move the club from its present home at Bowdens Park on Draycott Road to a new larger site.
Cheddar Cricket Club was formed in the late 19th century and moved to Sharpham Road Playing Fields in 1964. They now play in the West of England Premier League Somerset Division. Cheddar Rugby Club, who own part of the Sharpham playing fields, was formed in 1836. The club organises an annual Cheddar Rugby Tournament. Cheddar Lawn Tennis Club, was formed in 1924, and play in the North Somerset League and also has social tennis and coaching. Cheddar Running Club organised an annual half marathon until 2009.

</doc>
<doc id="6429" url="http://en.wikipedia.org/wiki?curid=6429" title="Compact disc">
Compact disc

Compact disc (CD) is a digital optical disc data storage format. The format was originally developed to store and play only sound recordings (CD-DA), but was later adapted for storage of data (CD-ROM). Several other formats were further derived from these, including write-once audio and data storage (CD-R), rewritable media (CD-RW), Video Compact Disc (VCD), Super Video Compact Disc (SVCD), Photo CD, PictureCD, CD-i, and Enhanced Music CD. Audio CDs and audio CD players have been commercially available since October 1982.
Standard CDs have a diameter of and can hold up to about 80 minutes of uncompressed audio or 700 MiB (actually about 703 MiB or 737 MB) of data. The Mini CD has various diameters ranging from ; they are sometimes used for CD singles, storing up to 24 minutes of audio or delivering device drivers.
At the time of the technology's introduction, it had much greater capacity than computer hard drives common at the time. The reverse is now true, with hard drives far exceeding the capacity of CDs.
In 2004, worldwide sales of CD audio, CD-ROM, and CD-R reached about 30 billion discs. By 2007, 200 billion CDs had been sold worldwide. Compact discs are increasingly being replaced or supplemented by other forms of digital distribution and storage, such as downloading and flash drives, with audio CD sales dropping nearly 50% from their peak in 2000.
History.
The Compact Disc is an evolution of LaserDisc technology. Prototypes were developed by Philips and Sony independently from the mid-to-late 1970s. The two companies then collaborated to produce a standard format and related player technology which was made commercially available in 1982.
Digital audio optical disc prototypes.
American inventor James T. Russell has been credited with inventing the first system to record digital information on an optical transparent foil which is lighted 
from behind by a high-power halogen lamp. Russell's patent application was first filed in 1966 and he was granted a patent in 1970. Following litigation, Sony and Philips licensed Russell's patents (then held by a Canadian company, Optical Recording Corp.) in the 1980s.
In 1974, an initiative was taken by L. Ottens, a director of the audio industry group within the Philips Technology Corporation in Eindhoven, the Netherlands. A seven-person project group was formed to develop an optical audio disc with a diameter of 20 cm with a sound quality superior to that of the large and fragile vinyl record. In March 1974, during a meeting of the audio group, two engineers from the Philips research laboratory recommended the use of a digital format on the 20 cm optical disc, because an error-correcting code could be added. It was not until 1977 that the directors of the group decided to establish a laboratory with the mission of creating a small optical digital audio disc and a small player. They chose the term "compact disc" in line with another Philips product, the compact cassette. Rather than the original 20 cm size, the diameter of this compact disc was set at 11.5 cm, the diagonal measurement of a compact cassette.
Meanwhile, Sony first publicly demonstrated an optical digital audio disc in September 1976. In September 1978, the company demonstrated an optical digital audio disc with a 150 minute playing time, 44,056 Hz sampling rate, 16-bit linear resolution, and cross-interleaved error correction code—specifications similar to those later settled upon for the standard Compact Disc format in 1980. Technical details of Sony's digital audio disc were presented during the 62nd AES Convention, held on March 13–16, 1979, in Brussels. Just before that, on March 8, 1979 Philips publicly demonstrated a prototype of an optical digital audio disc at a press conference called "Philips Introduce Compact Disc" in Eindhoven, Netherlands. Thirty years later, on March 6, 2009, Philips received an IEEE Milestone award with the following citation: "On 8 March 1979, N.V. Philips' Gloeilampenfabrieken demonstrated for the international press a Compact Disc Audio Player. The demonstration showed that it is possible by using digital optical recording and playback to reproduce audio signals with superb stereo quality. This research at Philips established the technical standard for digital optical recording systems."
Sony executive Norio Ohga, who later became the CEO and chairman of Sony, was convinced of the format's commercial potential and pushed further development despite widespread skepticism.
Collaboration and standardization.
Later in 1979, Sony and Philips set up a joint task force of engineers to design a new digital audio disc. Led by Kees Schouhamer Immink and Toshitada Doi, the research pushed forward laser and optical disc technology that began independently by the two companies. After a year of experimentation and discussion, the task force produced the "Red Book" CD-DA standard. First published in 1980, the standard was formally adopted by the IEC as an international standard in 1987, with various amendments becoming part of the standard in 1996.
Philips contributed the general manufacturing process, based on video LaserDisc technology. Philips also contributed eight-to-fourteen modulation (EFM), which offers a certain resilience to defects such as scratches and fingerprints, while Sony contributed the error-correction method, CIRC.
The "Compact Disc Story", told by a former member of the taskforce, gives background information on the many technical decisions made, including the choice of the sampling frequency, playing time, and disc diameter. The task force consisted of around four to eight persons, though according to Philips, the Compact Disc was "invented collectively by a large group of people working as a team."
First "Red Book" CDs and players.
Philips established the Polydor Pressing Operations plant in Langenhagen near Hannover, Germany, and quickly passed a series of milestones.
The Japanese launch was followed in March 1983 by the introduction of CD players and discs to Europe, and North America (where CBS Records released sixteen titles). This event is often seen as the "Big Bang" of the digital audio revolution. The new audio disc was enthusiastically received, especially in the early-adopting classical music and audiophile communities, and its handling quality received particular praise. As the price of players gradually came down, the CD began to gain popularity in the larger popular and rock music markets. The first artist to sell a million copies on CD was Dire Straits, with its 1985 album "Brothers in Arms". The first major artist to have his entire catalogue converted to CD was David Bowie, whose 15 studio albums were made available by RCA Records in February 1985, along with four Greatest Hits albums. In 1988, 400 million CDs were manufactured by 50 pressing plants around the world.
Further development and decline.
The CD was planned to be the successor of the gramophone record for playing music, rather than primarily as a data storage medium. From its origins as a musical format, CDs have grown to encompass other applications. In June 1985, the computer-readable CD-ROM (read-only memory) and, in 1990, CD-Recordable were introduced, also developed by both Sony and Philips. Recordable CDs are an alternative to tape for recording music and copying music albums without defects introduced in compression used in other digital recording methods. Other newer video formats such as DVD and Blu-ray use the same physical geometry as CD, and most DVD and Blu-ray players are backward compatible with Audio CD.
By the early 2000s, the CD had largely replaced the audio cassette player as standard equipment in new automobiles, with 2010 being the final model year for any car in the US to have a factory-equipped cassette player. With the increasing popularity of portable digital audio players and solid state music storage, CD players are being phased out of automobiles in favor of minijack auxiliary inputs and connections to USB devices.
Meanwhile, with the advent and popularity of Internet-based distribution of files in lossily-compressed audio formats, such as MP3, sales of CDs began dropping in the 2000s. For example, during the eight-year period ending in 2008, despite overall growth in music sales and one anomalous year of increase, major-label CD sales declined overall by 20% although independent and DIY music sales may be tracking better according to figures released March 30, 2009 and CDs still continue to sell greatly.
Physical details.
A CD is made from thick, polycarbonate plastic and weighs 15–20 grams. From the center outward, components are: the center spindle hole (15 mm), the first-transition area (clamping ring), the clamping area (stacking ring), the second-transition area (mirror band), the program (data) area, and the rim. The inner program area occupies a radius from 25 to 58 mm.
A thin layer of aluminium or, more rarely, gold is applied to the surface making it reflective. The metal is protected by a film of lacquer normally spin coated directly on the reflective layer. The label is printed on the lacquer layer, usually by screen printing or offset printing.
CD data is represented as tiny indentations known as "pits", encoded in a spiral track moulded into the top of the polycarbonate layer. The areas between pits are known as "lands". Each pit is approximately 100 nm deep by 500 nm wide, and varies from 850 nm to 3.5 µm in length. The distance between the tracks, the pitch, is 1.5 µm.
Scanning velocity is 1.2–1.4 m/s (constant linear velocity) – equivalent to approximately 500 RPM at the inside of the disc, and approximately 200 RPM at the outside edge. (A disc played from beginning to end slows its rotation rate during playback.)
The program area is 86.05 cm2 and the length of the recordable spiral is (86.05 cm2 / 1.6 µm) = 5.38 km. With a scanning speed of 1.2 m/s, the playing time is 74 minutes, or 650 MB of data on a CD-ROM. A disc with data packed slightly more densely is tolerated by most players (though some old ones fail). Using a linear velocity of 1.2 m/s and a narrower track pitch of 1.5 µm increases the playing time to 80 minutes, and data capacity to 700 MB.
A CD is read by focusing a 780 nm wavelength (near infrared) semiconductor laser through the bottom of the polycarbonate layer. The change in height between pits and lands results in a difference in the way the light is reflected. By measuring the intensity change with a photodiode, the data can be read from the disc.
The pits and lands themselves do not directly represent the zeros and ones of binary data. Instead, non-return-to-zero, inverted encoding is used: a change from pit to land or land to pit indicates a one, while no change indicates a series of zeros. There must be at least two and no more than ten zeros between each one, which is defined by the length of the pit. This in turn is decoded by reversing the eight-to-fourteen modulation used in mastering the disc, and then reversing the cross-interleaved Reed–Solomon coding, finally revealing the raw data stored on the disc. These encoding techniques (defined in the "Red Book") were originally designed for the CD Digital Audio, but they later became a standard for almost all CD formats (such as CD-ROM).
Integrity.
CDs are susceptible to damage during handling and from environmental exposure. Pits are much closer to the label side of a disc, enabling defects and contaminants on the clear side to be out of focus during playback. Consequently, CDs are more likely to suffer damage on the label side of the disc. Scratches on the clear side can be repaired by refilling them with similar refractive plastic, or by careful polishing. The edges of CDs are sometimes incompletely sealed, allowing gases and liquids to corrode the metal reflective layer and to interfere with the focus of the laser on the pits. The fungus Geotrichum candidum, found in Belize, has been found to consume the polycarbonate plastic and aluminium found in CDs.
Disc shapes and diameters.
The digital data on a CD begins at the center of the disc and proceeds toward the edge, which allows adaptation to the different size formats available. Standard CDs are available in two sizes. By far, the most common is in diameter, with a 74- or 80-minute audio capacity and a 650 or 700 MB (737,280,000 bytes) data capacity. This capacity was reportedly specified by Sony executive Norio Ohga so as to be able to contain the entirety of London Philharmonic Orchestra's recording of Beethoven's Ninth Symphony on one disc. This diameter has been adopted by subsequent formats, including Super Audio CD, DVD, HD DVD, and Blu-ray Disc. 80 mm discs ("Mini CDs") were originally designed for CD singles and can hold up to 24 minutes of music or 210 MB of data but never became popular. Today, nearly every single is released on a 120 mm CD, called a Maxi single.
Logical formats.
Audio CD.
The logical format of an audio CD (officially Compact Disc Digital Audio or CD-DA) is described in a document produced in 1980 by the format's joint creators, Sony and Philips. The document is known colloquially as the "Red Book" CD-DA after the color of its cover. The format is a two-channel 16-bit PCM encoding at a 44.1 kHz sampling rate per channel. Four-channel sound was to be an allowable option within the "Red Book" format, but has never been implemented. Monaural audio has no existing standard on a "Red Book" CD; mono-source material thus is usually presented as two identical channels in a standard "Red Book" stereo track (i.e. mirrored mono); an MP3 CD, however, can have audio file formats with mono sound.
CD-Text is an extension of the "Red Book" specification for audio CD that allows for storage of additional text information (e.g., album name, song name, artist) on a standards-compliant audio CD. The information is stored either in the lead-in area of the CD, where there is roughly five kilobytes of space available, or in the subcode channels R to W on the disc, which can store about 31 megabytes.
Compact Disc + Graphics is a special audio compact disc that contains graphics data in addition to the audio data on the disc. The disc can be played on a regular audio CD player, but when played on a special CD+G player, can output a graphics signal (typically, the CD+G player is hooked up to a television set or a computer monitor); these graphics are almost exclusively used to display lyrics on a television set for karaoke performers to sing along with. The CD+G format takes advantage of the channels R through W. These six bits store the graphics information.
CD + Extended Graphics (CD+EG, also known as CD+XG) is an improved variant of the Compact Disc + Graphics (CD+G) format. Like CD+G, CD+EG utilizes basic CD-ROM features to display text and video information in addition to the music being played. This extra data is stored in subcode channels R-W. Very few, if any, CD+EG discs have been published.
Super Audio CD.
Super Audio CD (SACD) is a high-resolution read-only optical audio disc format that was designed to provide higher fidelity digital audio reproduction than the "Red Book". Introduced in 1999, it was developed by Sony and Philips, the same companies that created the "Red Book". SACD was in a format war with DVD-Audio, but neither has replaced audio CDs. The SACD standard is referred to the "Scarlet Book" standard.
Titles in the SACD format can be issued as hybrid discs; these discs contain the SACD audio stream as well as a standard audio CD layer which is playable in standard CD players, thus making them backward compatible.
CD-MIDI.
CD-MIDI is a format used to store music-performance data which upon playback is performed by electronic instruments that synthesize the audio. Hence, unlike the original "Red Book" CD-DA, these recordings are not digitally sampled audio recordings. The CD-MIDI format is defined as an extension to the original "Red Book".
CD-ROM.
For the first few years of its existence, the CD was a medium used purely for audio. However, in 1985 the "Yellow Book" CD-ROM standard was established by Sony and Philips, which defined a non-volatile optical data computer data storage medium using the same physical format as audio compact discs, readable by a computer with a CD-ROM drive.
Video CD (VCD).
Video CD (VCD, View CD, and Compact Disc digital video) is a standard digital format for storing video media on a CD. VCDs are playable in dedicated VCD players, most modern DVD-Video players, personal computers, and some video game consoles.
The VCD standard was created in 1993 by Sony, Philips, Matsushita, and JVC and is referred to as the "White Book" standard.
Overall picture quality is intended to be comparable to VHS video. Poorly compressed VCD video can sometimes be lower quality than VHS video, but VCD exhibits block artifacts rather than analog noise, and does not deteriorate further with each use, which may be preferable.
352x240 (or SIF) resolution was chosen because it is half the vertical, and half the horizontal resolution of NTSC video. 352x288 is similarly one quarter PAL/SECAM resolution. This approximates the (overall) resolution of an analog VHS tape, which, although it has double the number of (vertical) scan lines, has a much lower horizontal resolution.
Super Video CD.
Super Video CD (Super Video Compact Disc or SVCD) is a format used for storing video media on standard compact discs. SVCD was intended as a successor to VCD and an alternative to DVD-Video, and falls somewhere between both in terms of technical capability and picture quality.
SVCD has two-thirds the resolution of DVD, and over 2.7 times the resolution of VCD. One CD-R disc can hold up to 60 minutes of standard quality SVCD-format video. While no specific limit on SVCD video length is mandated by the specification, one must lower the video bit rate, and therefore quality, to accommodate very long videos. It is usually difficult to fit much more than 100 minutes of video onto one SVCD without incurring significant quality loss, and many hardware players are unable to play video with an instantaneous bit rate lower than 300 to 600 kilobits per second.
Photo CD.
Photo CD is a system designed by Kodak for digitizing and storing photos on a CD. Launched in 1992, the discs were designed to hold nearly 100 high quality images, scanned prints and slides using special proprietary encoding. Photo CDs are defined in the "Beige Book" and conform to the CD-ROM XA and CD-i Bridge specifications as well. They are intended to play on CD-i players, Photo CD players and any computer with the suitable software irrespective of the operating system. The images can also be printed out on photographic paper with a special Kodak machine. This format is not to be confused with Kodak Picture CD, which is a consumer product in CD-ROM format.
CD-i.
The Philips "Green Book" specifies a standard for interactive multimedia compact discs designed for CD-i players (1993). CD-i discs can contain audio tracks which can be played on regular CD players, but CD-i discs are not compatible with most CD-ROM drives and software. The CD-i Ready specification was later created to improve compatibility with audio CD players, and the CD-i Bridge specification was added to create CD-i compatible discs than can be accessed by regular CD-ROM drives.
CD-i Ready.
Philips defined a format similar to CD-i called CD-i Ready, which puts CD-i software and data into the pregap of track 1. This format was supposed to be more compatible with older audio CD players.
Enhanced Music CD (CD+).
Enhanced Music CD, also known as CD Extra and CD Plus, is a format which combines audio tracks and data tracks on the same disc by putting audio tracks in a first session and data in a second session. It was developed by Philips and Sony and it is defined in the "Blue Book".
Vinyl Disc.
Vinyl Disc is the hybrid of a standard Audio CD and the vinyl record. The vinyl layer on the disc's label side can hold approximately three minutes of music.
Manufacture.
Replicated CDs are mass-produced initially using a hydraulic press. Small granules of heated raw polycarbonate plastic are fed into the press. A screw forces the liquefied plastic into the mold cavity. The mold closes with a metal stamper in contact with the disc surface. The plastic is allowed to cool and harden. Once opened, the disc substrate is removed from the mold by a robotic arm, and a 15 mm diameter center hole (called a stacking ring) is created. The time it takes to "stamp" one CD, is usually 2 to 3 seconds.
This method produces the clear plastic blank part of the disc. After a metallic reflecting layer (usually aluminium, but sometimes gold or other metal) is applied to the clear blank substrate, the disc goes under a UV light for curing and it is ready to go to press. To prepare to press a CD, a glass master is made, using a high-powered laser on a device similar to a CD writer. The glass master is a positive image of the desired CD surface (with the desired microscopic pits and lands). After testing, it is used to make a die by pressing it against a metal disc.
The die is a negative image of the glass master: typically, several are made, depending on the number of pressing mills that are to make the CD. The die then goes into a press and the physical image is transferred to the blank CD, leaving a final positive image on the disc. A small amount of lacquer is applied as a ring around the center of the disc, and rapid spinning spreads it evenly over the surface. Edge protection lacquer is applied before the disc is finished. The disc can then be printed and packed.
Manufactured CDs that are sold in stores are sealed via a process called "polywrapping" or shrink wrapping.
The most expensive part of a CD is the jewel case. In 1995, material costs were 30 cents for the jewel case and 10 to 15 cents for the CD. Wholesale cost of CDs was $0.75 to $1.15, which retailed for $16.98. On average the store received 35 percent of the retail price, the record company 27 percent, the artist 16 percent, the manufacturer 13 percent, and the distributor 9 percent. When 8-track tapes, cassette tapes, and CDs were introduced, each was marketed at a higher price than the format they succeeded, even though the cost to produce the media was reduced. This was done because the apparent value increased. This continued from vinyl to CDs but was broken when Apple marketed MP3s for $0.99, and albums for $9.99. The incremental cost, though, to produce an MP3 is infinitely small.
Writable compact discs.
Recordable CD.
Recordable Compact Discs, CD-Rs, are injection molded with a "blank" data spiral. A photosensitive dye is then applied, after which the discs are metalized and lacquer-coated. The write laser of the CD recorder changes the color of the dye to allow the read laser of a standard CD player to see the data, just as it would with a standard stamped disc. The resulting discs can be read by most CD-ROM drives and played in most audio CD players. CD-Rs follow the "Orange Book" standard.
CD-R recordings are designed to be permanent. Over time the dye's physical characteristics may change, however, causing read errors and data loss until the reading device cannot recover with error correction methods. The design life is from 20 to 100 years, depending on the quality of the discs, the quality of the writing drive, and storage conditions. However, testing has demonstrated such degradation of some discs in as little as 18 months under normal storage conditions. This failure is known as disc rot, for which there are several, mostly environmental, reasons.
The recordable audio CD is designed to be used in a consumer audio CD recorder. These consumer audio CD recorders use SCMS (Serial Copy Management System), an early form of digital rights management (DRM), to conform to the AHRA (Audio Home Recording Act). The Recordable Audio CD is typically somewhat more expensive than CD-R due to lower production volume and a 3% AHRA royalty used to compensate the music industry for the making of a copy.
"High-capacity recordable CD" is a higher density recording format that can hold 90 or 99 minutes of audio on a disc (compared to about 80 minutes for "Red Book" audio), or 30 minutes of audio on an disc (compared to about 24 minutes for "Red Book" audio). The higher capacity is incompatible with some recorders and recording software.
ReWritable CD.
CD-RW is a re-recordable medium that uses a metallic alloy instead of a dye. The write laser in this case is used to heat and alter the properties (amorphous vs. crystalline) of the alloy, and hence change its reflectivity. A CD-RW does not have as great a difference in reflectivity as a pressed CD or a CD-R, and so many earlier CD audio players "cannot" read CD-RW discs, although "most" later CD audio players and stand-alone DVD players can. CD-RWs follow the "Orange Book" standard.
The ReWritable Audio CD is designed to be used in a consumer audio CD recorder, which won't (without modification) accept standard CD-RW discs. These consumer audio CD recorders use the Serial Copy Management System (SCMS), an early form of digital rights management (DRM), to conform to the United States' Audio Home Recording Act (AHRA). The ReWritable Audio CD is typically somewhat more expensive than CD-RW due to (a) lower volume and (b) a 3% AHRA royalty used to compensate the music industry for the making of a copy.
Speed.
Due to technical limitations, the original ReWritable CD could be written no faster than 4x speed. High Speed ReWritable CD has a different design that permits writing at speeds ranging from 4x to 12x. Original CD-RW drives can only write to original ReWritable CDs. High Speed CD-RW drives can typically write to both original ReWritable CDs and High Speed ReWritable CDs. Both types of CD-RW discs can be read in most CD drives. Higher speed CD-RW discs, Ultra Speed (16x to 24x write speed) and Ultra Speed+ (32x write speed), are now available.
Copy protection.
The "Red Book" audio specification, except for a simple 'anti-copy' statement in the subcode, does not include any copy protection mechanism. Known at least as early as 2001, attempts were made by record companies to market "copy-protected" non-standard compact discs, which cannot be ripped, or copied, to hard drives or easily converted to MP3s. One major drawback to these copy-protected discs is that most will not play on either computer CD-ROM drives, or some standalone CD players that use CD-ROM mechanisms. Philips has stated that such discs are not permitted to bear the trademarked "Compact Disc Digital Audio" logo because they violate the "Red Book" specifications. Numerous copy-protection systems have been countered by readily available, often free, software.

</doc>
<doc id="6431" url="http://en.wikipedia.org/wiki?curid=6431" title="Charles Farrar Browne">
Charles Farrar Browne

Charles Farrar Browne (April 26, 1834 – March 6, 1867) was a United States humor writer, better known under his "nom de plume", Artemus Ward. At birth, his surname was "Brown." He added the "e" after he became famous.
Biography.
Browne was born in Waterford, Maine. He began life as a compositor and occasional contributor to the daily and weekly journals. In 1858, he published in "The Plain Dealer" (Cleveland, Ohio) the first of the "Artemus Ward" series, which, in a collected form, achieved great popularity in both America and England. In 1860, he became editor of "Vanity Fair", a humorous New York weekly, which proved a failure. About the same time, he began to appear as a lecturer and, by his droll and eccentric humor, attracted large audiences.
"Artemus Ward" was the favorite author of U.S. President Abraham Lincoln. Before presenting "The Emancipation Proclamation" to his Cabinet, Lincoln read to them the latest episode, "Outrage in Utiky", also known as "High-Handed Outrage at Utica". 
Ward is also said to have inspired Mark Twain when Ward performed in Virginia City, Nevada. Legend has it that, following Ward's stage performance, he, Mark Twain, and Dan De Quille were taking a drunken rooftop tour of Virginia City until a town constable threatened to blast all three of them with a shotgun loaded with rock salt.
In 1866, Ward visited England, where he became exceedingly popular both as a lecturer and as a contributor to "Punch". In the spring of the following year, Ward's health gave way and he died of tuberculosis at Southampton on March 6, 1867.
After initially being buried at Kensal Green Cemetery, Ward's remains were removed to the United States on May 20, 1868. He is buried at Elm Vale Cemetery in Waterford, Maine.

</doc>
<doc id="6432" url="http://en.wikipedia.org/wiki?curid=6432" title="Caelum">
Caelum

Caelum is a faint constellation in the southern sky, introduced in the 1750s by Nicolas Louis de Lacaille. Its name means "the chisel" in Latin, and it was formerly known as Caelum Scalptorium ("the engraver's chisel"). It is the eighth-smallest constellation, and subtends a solid angle of around 0.038 steradians, just less than that of Corona Australis.
Due to its small size and location away from the plane of the Milky Way, Caelum is a rather barren constellation, with few objects of interest. The constellation's brightest star, Alpha Caeli, is only of magnitude 4.45, and only one other star (Gamma1 Caeli) is brighter than magnitude 5. Other notable objects in Caelum are RR Caeli, a binary star with one planet approximately away; X Caeli, a Delta Scuti variable that forms an optical double with Gamma1 Caeli; and HE0450-2958, a Seyfert galaxy that at first appeared as just a jet with no host galaxy visible.
History.
Caelum was first introduced in the eighteenth century by Nicolas Louis de Lacaille, a French astronomer who introduced thirteen other southern constellations at the same time. The name Lacaille gave the constellation was originally romanized to "Caelum Scalptorium" ("The Engraver's Chisel"), and Francis Baily shortened this name to "Caelum" after a suggestion by John Herschel. In Lacaille's original chart, the constellation was shown as a burin and an échoppe, although it has come to be recognized simply as a chisel. Johann Elert Bode stated the name as plural, "Caela Scalptoris", but this did not stick.
Characteristics.
Caelum is bordered by Dorado and Pictor to the south, Horologium and Eridanus to the east, Lepus to the north, and Columba to the west. Covering 125 square degrees, it ranks 81st of the 88 modern constellations in size. It appears prominently in the southern sky during the Southern Hemisphere's summer, and the whole constellation is visible for at least part of the year to observers south of latitude 41°N. Its main asterism consists of four stars, and twenty stars in total are brighter than magnitude 6.5. The constellation's boundaries, as set by Eugène Delporte in 1930, are defined by a 12-sided polygon. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between and . The International Astronomical Union (IAU) adopted the three-letter abbreviation "Cae" for the constellation in 1922.
Notable features.
Stars.
Caelum is a faint constellation, having no star brighter than fourth magnitude and only two brighter than fifth magnitude. Lacaille gave six stars Bayer designations, labeling them Alpha to Zeta in 1756, but omitted Epsilon and designated two nearby stars as Gamma. Bode extended the designations to Rho for other stars but most have fallen out of use. Caelum is too far south for any of its stars to bear Flamsteed designations.
The brightest star, Alpha Caeli, is a double star, containing an F-type main-sequence star of magnitude 4.45 and a red dwarf of magnitude 12.5, from Earth. Beta Caeli, another F-type star of magnitude 5.05, is further away, being located from Earth. Unlike Alpha, Beta Caeli is a subgiant star, slightly evolved from the main sequence. Delta Caeli, also of magnitude 5.05, is a B-type subgiant and is much farther from Earth, at .
Gamma1 Caeli is a double star with a red giant primary of magnitude 4.58 and a secondary of magnitude 8.1. The primary is from Earth. The two components are difficult to resolve with small amateur telescopes because of their difference in visual magnitude and their close separation. This star system forms an optical double with the unrelated X Caeli (Gamma2 Caeli), a Delta Scuti variable located from Earth. These are a class of short-period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. X Caeli itself is also a binary star, specifically a contact binary, meaning that the stars are so close that they share envelopes. The only other variable star in Caelum visible to the naked eye is RV Caeli, a pulsating red giant of spectral type M1III, which varies between magnitudes 6.44 and 6.56.
Three other stars in Caelum are still occasionally referred to by their Bayer designations, although they are only on the edge of naked-eye visibility. Nu Caeli is another double star, containing a white giant of magnitude 6.07 and a star of magnitude 10.66 with unknown spectral type. The system is approximately away. Lambda Caeli, at magnitude 6.24, is much redder and farther away, being a red giant around from Earth. Zeta Caeli is even fainter, being only of magnitude 6.36. This star, located away, is a K-type subgiant of spectral type K1. The other twelve naked-eye stars in Caelum are not referred to by Bode's Bayer designations anymore, including RV Caeli.
One of the nearest stars in Caelum is the eclipsing binary star RR Caeli, at a distance of . This star system consists of a dim red dwarf and a white dwarf. Despite its closeness to the Earth, the system's apparent magnitude is only 14.40 due to the faintness of its components, and thus it cannot be easily seen with amateur equipment. In 2012, the system was found to contain a giant planet, and there is evidence for a second substellar body. The system is a post-common-envelope binary and is losing angular momentum over time, which will eventually cause mass transfer from the red dwarf to the white dwarf. In approximately 9–20 billion years, this will cause the system to become a cataclysmic variable.
Deep-sky objects.
Due to its small size and location away from the plane of the Milky Way, Caelum is rather devoid of deep-sky objects, and contains no Messier objects. The only deep-sky object in Caelum to receive much attention is HE0450-2958, an unusual Seyfert galaxy. Originally, the jet's host galaxy proved elusive to find, and this jet appeared to be emanating from nothing. Although it has been suggested that the object is an ejected supermassive black hole, the host is now agreed to be a small galaxy that is difficult to see due to light from the jet and a nearby starburst galaxy.

</doc>
<doc id="6433" url="http://en.wikipedia.org/wiki?curid=6433" title="Clarinet">
Clarinet

The clarinet is a family of woodwind instruments that have a single-reed mouthpiece, a straight cylindrical tube with an approximately cylindrical bore, and a flaring bell. A person who plays any type of clarinet is called a clarinetist or clarinettist.
The word "clarinet" may have entered the English language via the French "clarinette" (the feminine diminutive of Old French "clarin" or "clarion"), or from Provençal "", "oboe". It "is plainly a diminutive of "clarino", the Italian for trumpet", and the Italian "clarinetto" is the source of the name in many other languages. According to Johann Gottfried Walther, writing in 1732, the reason for the name is that "it sounded from far off not unlike a trumpet". The English form "clarinet" is found as early as 1733, and the now-archaic "clarionet" appears from 1784 until the early years of the 20th century.
There are some different types of clarinets of differing sizes and pitches. The unmodified word "clarinet" usually refers to the B soprano clarinet, by far the most common type, which has a large range of nearly four octaves. The clarinet family is the largest woodwind family, with more than a dozen types, ranging from the (extremely rare) BBB octo-contrabass to the A piccolo clarinet. Of these, many are rare or obsolete (there is only one BBB octo-contrabass clarinet in existence, for example), and music written for them is usually played on more common versions of the instrument.
Johann Christoph Denner invented the clarinet in Germany around the turn of the 18th century by adding a register key to the earlier chalumeau. Over time, additional keywork and airtight pads were added to improve tone and playability. 
Today, the clarinet is commonly used in classical music (such as concert bands, orchestras, chamber music, and solo repertoire), military bands, marching bands, klezmer, and jazz, as well as in folk music, Arabic pop, choro, samba, and Bulgarian wedding music.
Characteristics.
Sound.
The cylindrical bore is primarily responsible for the clarinet's distinctive timbre, which varies between its three main registers, known as the chalumeau, clarion, and altissimo. The tone quality can vary greatly with the musician, the music, the instrument, the mouthpiece, and the reed. The differences in instruments and geographical isolation of players in different countries led to the development, from the last part of the 18th century onwards, of several different schools of clarinet playing. The most prominent were the German/Viennese traditions and the French school. The latter was centered on the clarinetists of the Conservatoire de Paris. The proliferation of recorded music has made examples of different styles of clarinet playing available. The modern clarinetist has a diverse palette of "acceptable" tone qualities to choose from.
The A clarinet and B clarinet have nearly the same bore, and use the same mouthpiece. Orchestral players using the A and B instruments in the same concert could use the same mouthpiece (and often the same barrel) for both (see 'usage' below). The A and the B instruments have nearly identical tonal quality, although the A typically has a slightly warmer sound. The tone of the E clarinet is brighter than that of the lower clarinets and can be heard even through loud orchestral or concert band textures. The bass clarinet has a characteristically deep, mellow sound, while the alto clarinet is similar in tone to the bass and the basset horn has a tone quality comparable to the A clarinet.
Range.
Clarinets have the largest pitch range of common woodwinds. The intricate key organization that makes this range possible can make the playability of some passages awkward. The bottom of the clarinet’s written range is defined by the keywork on each instrument, standard keywork schemes allowing a low E on the common B clarinet. The lowest concert pitch depends on the transposition of the instrument in question.
Nearly all soprano and piccolo clarinets have keywork enabling them to play the E below middle C as their lowest written note (in scientific pitch notation that sounds D3 on a soprano clarinet or C4, i.e. concert middle C, on a piccolo clarinet), though some B clarinets go down to E3 to enable them to match the range of the A clarinet. On the B soprano clarinet, the concert pitch of the lowest note is D3, a whole tone lower than the written pitch.
Most alto and bass clarinets have an extra key to allow a (written) E3. Modern professional-quality bass clarinets generally have additional keywork to written C3. Among the less commonly encountered members of the clarinet family, contra-alto and contrabass clarinets may have keywork to written E3, D3, or C3; the basset clarinet and basset horn generally go to low C3.
Defining the top end of a clarinet’s range is difficult, since many advanced players can produce notes well above the highest notes commonly found in method books. G6 is usually the highest note clarinetists encounter in classical repertoire. The C above that (C7 i.e. resting on the fifth ledger line above the treble staff) is attainable by advanced players and is shown on many fingering charts, and fingerings as high as G7 exist.
The range of a clarinet can be divided into three distinct registers. The lowest register, consisting of the notes up to the written B above middle C (B4), is known as the "chalumeau" register (named after the instrument that was the clarinet's immediate predecessor). The middle register is termed the "clarino" (sometimes "clarion") register and spans just over an octave (from written B above middle C (B4) to the C two octaves above middle C (C6)); it is the dominant range for most members of the clarinet family. The top or "altissimo" register consists of the notes above the written C two octaves above middle C (C6). Unlike other woodwinds, all three registers have characteristically different sounds. The chalumeau register is rich and dark. The clarino register is brighter and sweet, like a trumpet ("clarino") heard from afar. The altissimo register can be piercing and sometimes shrill.
Acoustics.
Sound is a wave that propagates through the air as a result of a local variation in air pressure. The production of sound by a clarinet follows these steps:
The cycle repeats at a frequency relative to how long it takes a wave to travel to the first open hole and back twice (i.e. four times the length of the pipe). For example: when all the holes bar the very top one are open (i.e. the trill 'B' key is pressed), the note A4 (440 Hz) is produced. This represents a repeat of the cycle 440 times per second.
In addition to this primary compression wave, other waves, known as harmonics, are created. Harmonics are caused by factors including: the imperfect wobbling and shaking of the clarinet reed, the reed sealing the mouthpiece opening for part of the wave cycle (which creates a flattened section of the sound wave) and imperfections (bumps and holes) in the clarinet bore. A wide variety of compression waves are created, but only some (primarily the odd harmonics) are reinforced. These extra waves are what gives the clarinet its characteristic tone.
The bore of the soprano clarinet is cylindrical for most of the tube with an inner bore diameter between , but there is a subtle hourglass shape, with the thinnest part below the junction between the upper and lower joint. The reduction is depending on the maker. This hourglass shape, although not visible to the naked eye, helps to correct the pitch/scale discrepancy between the chalumeau and clarino registers (perfect 12th). The diameter of the bore affects characteristics such as available harmonics, timbre, and pitch stability (how far the player can bend a note in the manner required in jazz and other music). The bell at the bottom of the instrument flares out to improve the tone of the lowest notes.
Most modern clarinets have "undercut" tone holes that improve intonation and sound. Undercutting means chamfering the bottom edge of tone holes inside the bore. Acoustically, this makes the tone hole function as if it were larger, but its main function is to allow the air column to follow the curve up through the tone hole (surface tension) instead of "blowing past" it under the increasingly directional frequencies of the upper registers.
The fixed reed and fairly uniform diameter of the clarinet give the instrument an acoustical behavior approximating that of a cylindrical stopped pipe. Recorders use a tapered internal bore to overblow at the 8th (octave) when its thumb/register hole is pinched open while the clarinet, with its cylindrical bore, overblows on the 12th. Adjusting the angle of the bore taper controls the frequencies of the overblown notes (harmonics). Changing the mouthpiece's tip opening and the length of the reed changes aspects of the harmonic timbre or voice of the instrument because this changes the speed of reed vibrations. Generally, the goal of the clarinetist when producing a sound is to make as much of the reed vibrate as possible, making the sound fuller, warmer, and potentially louder.
The lip position and pressure, the shaping of the vocal tract, the choice of reed and mouthpiece, the amount of air pressure created and the evenness of the air flow, accounts for most of the player’s ability to control the tone of a clarinet. A highly skilled musician will provide the ideal lip pressure and air pressure for each frequency (note) being produced. They will have an embouchure which places an even pressure across the reed by carefully controlling their lip muscles. The air flow will also be carefully controlled by using the strong stomach muscles (as opposed to the weaker and erratic chest muscles) and they will use the diaphragm to oppose the stomach muscles to achieve a tone softer than a forte, rather than weakening the stomach muscle tension to lower air pressure. Their vocal tract will be shaped to resonate at frequencies associated with the tone being produced.
Covering or uncovering the tone holes varies the length of the pipe, changing the resonant frequencies of the enclosed air column and hence the pitch of the sound. A clarinetist moves between the chalumeau and clarino registers through use of the register key, or speaker key: clarinetists call the change from chalumeau register to clarino register "the break". The open register key stops the fundamental frequency from being reinforced and the reed is forced to vibrate at three times the speed it was originally vibrating at. This produces a note a twelfth above the original note. Most instruments overblow at two times the speed of the fundamental frequency (the octave) but as the clarinet acts as a closed pipe system, the reed cannot vibrate at twice the original speed because it would be creating a ‘puff’ of air at the time the previous ‘puff’ is returning as a rarefaction. This means that it cannot be reinforced and so would die away.
The lower or 'chalumeau' register plays fundamentals, whereas the upper or 'clarino' register, aided by the register key, plays third harmonics, a perfect twelfth higher than the fundamentals. The first several notes of the altissimo range, aided by the register key and venting with the first left-hand hole, play fifth harmonics, a major seventeenth (that is a perfect twelfth plus a major sixth) above the fundamental. The clarinet is therefore said to overblow at the twelfth, and when moving to the altissimo register, a seventeenth. By contrast, nearly all other woodwind instruments overblow at the octave, or like the ocarina and tonette, do not overblow at all (the rackett or sausage bassoon is the next most common Western instrument that overblows at the twelfth). A clarinet must have holes and keys for nineteen notes (a chromatic octave and a half, from bottom E to B) in its lowest register to play the chromatic scale. This overblowing behavior explains the clarinet's great range and complex fingering system. The fifth and seventh harmonics are also available, sounding a further sixth and fourth (a flat, diminished fifth) higher respectively; these are the notes of the altissimo register. This is also why the inner "waist" measurement is so critical to these harmonic frequencies.
The highest notes on a clarinet can have a shrill piercing quality and can be difficult to tune accurately. Different instruments often play differently in this respect due to the sensitivity of the bore and reed measurements. Using alternate fingerings and adjusting the embouchure helps correct the pitch of these higher notes.
Since approximately 1850, clarinets have been nominally tuned according to twelve-tone equal temperament. Older clarinets were nominally tuned to meantone. A skilled performer can use his or her embouchure to considerably alter the tuning of individual notes or to produce vibrato, a pulsating change of pitch often employed in jazz. Vibrato is rare in classical or concert band literature; however, certain clarinetists, such as Richard Stoltzman, do use vibrato in classical music. Special fingerings may be used to play quarter tones and other microtonal intervals.
Around 1900, Dr. Richard H. Stein, a Berlin musicologist, made a quarter-tone clarinet, which was soon abandoned. Years later, another German, Fritz Schüller of Markneukirchen, built a quarter tone clarinet, with two parallel bores of slightly different lengths whose tone holes are operated using the same keywork and a valve to switch from one bore to the other.
Construction.
Materials.
Clarinet bodies have been made from a variety of materials including wood, plastic, hard rubber, metal, resin, and ivory. The vast majority of clarinets used by professional musicians are made from African hardwood, mpingo (African Blackwood) or grenadilla, rarely (because of diminishing supplies) Honduran rosewood and sometimes even cocobolo. Historically other woods, notably boxwood, were used.
Most modern, inexpensive instruments are made of plastic resin, such as ABS. These materials are sometimes called "resonite," which is Selmer's trademark name for its type of plastic. Metal soprano clarinets were popular in the early 20th century, until plastic instruments supplanted them; metal construction is still used for the bodies of some contra-alto and contrabass clarinets, and for the necks and bells of nearly all alto and larger clarinets. Ivory was used for a few 18th-century clarinets, but it tends to crack and does not keep its shape well.
Buffet Crampon's Greenline clarinets are made from a composite of grenadilla wood powder and carbon fiber. Such instruments are less affected by humidity and temperature changes than wooden instruments but are heavier. Hard rubber, such as ebonite, has been used for clarinets since the 1860s, although few modern clarinets are made of it. Clarinet designers Alastair Hanson and Tom Ridenour are strong advocates of hard rubber. Hanson Clarinets of England manufactures clarinets using a grenadilla compound reinforced with ebonite, known as 'BTR' (bithermal reinforced) grenadilla. This material is also not affected by humidity, and the weight is the same as that of a wood clarinet.
Mouthpieces are generally made of hard rubber, although some inexpensive mouthpieces may be made of plastic. Other materials such as crystal/glass, wood, ivory, and metal have also been used. Ligatures are often made out of metal and plated in nickel, silver or gold. Other ligature materials include wire, wire mesh, plastic, naugahyde, string, or leather.
Reed.
The instrument uses a single reed made from the cane of "Arundo donax", a type of grass. Reeds may also be manufactured from synthetic materials. The ligature fastens the reed to the mouthpiece. When air is blown through the opening between the reed and the mouthpiece facing, the reed vibrates and produces the instrument's sound.
Basic reed measurements are as follows: tip, wide; lay, long (distance from the place where the reed touches the mouthpiece to the tip); gap, (distance between the underside of the reed tip and the mouthpiece). Adjustment to these measurements is one method of affecting tone color.
Most clarinetists buy manufactured reeds, although many make adjustments to these reeds and some make their own reeds from cane "blanks". Reeds come in varying degrees of hardness, generally indicated on a scale from one (soft) through five (hard). This numbering system is not standardized—reeds with the same hardness number often vary in hardness across manufacturers and models. Reed and mouthpiece characteristics work together to determine ease of playability, pitch stability, and tonal characteristics.
Components.
Note: A Boehm system soprano clarinet is shown in the photos illustrating this section. However, all modern clarinets have similar components.
The "reed" is attached to the "mouthpiece" by the "ligature", and the top half-inch or so of this assembly is held in the player’s mouth. In the past clarinetists used to wrap a string around the mouthpiece and reed instead of using a ligature. The formation of the mouth around the mouthpiece and reed is called the "embouchure".
The reed is on the underside of the mouthpiece, pressing against the player's lower lip, while the top teeth normally contact the top of the mouthpiece (some players roll the upper lip under the top teeth to form what is called a ‘double-lip’ embouchure). Adjustments in the strength and shape of the embouchure change the tone and intonation (tuning). It is not uncommon for clarinetists to employ methods to relieve the pressure on the upper teeth and inner lower lip by attaching pads to the top of the mouthpiece or putting (temporary) padding on the front lower teeth, commonly from folded paper.
Next is the short "barrel"; this part of the instrument may be extended to fine-tune the clarinet. As the pitch of the clarinet is fairly temperature-sensitive, some instruments have interchangeable barrels whose lengths vary slightly. Additional compensation for pitch variation and tuning can be made by pulling out the barrel and thus increasing the instrument's length, particularly common in group playing in which clarinets are tuned to other instruments (such as in an orchestra or concert band). Some performers use a plastic barrel with a thumbwheel that adjusts the barrel length. On basset horns and lower clarinets, the barrel is normally replaced by a curved metal neck.
The main body of most clarinets is divided into the "upper joint", the holes and most keys of which are operated by the left hand, and the "lower joint" with holes and most keys operated by the right hand. Some clarinets have a single joint: on some basset horns and larger clarinets the two joints are held together with a screw clamp and are usually not disassembled for storage. The left thumb operates both a "tone hole" and the "register key". On some models of clarinet, such as many Albert system clarinets and increasingly some higher-end Boehm system clarinets, the register key is a 'wraparound' key, with the key on the back of the clarinet and the pad on the front. Advocates of the wraparound register key say it improves sound, and it is harder for moisture to accumulate in the tube beneath the pad. Nevertheless, there is a consensus among repair techs that this type of register key is harder to keep in adjustment, i.e., it is hard to have enough spring pressure to close the hole securely.
The body of a modern soprano clarinet is equipped with numerous "tone holes" of which seven (six front, one back) are covered with the fingertips, and the rest are opened or closed using a set of keys. These tone holes let the player produce every note of the chromatic scale. On alto and larger clarinets, and a few soprano clarinets, key-covered holes replace some or all finger holes. The most common system of keys was named the Boehm system by its designer Hyacinthe Klosé in honour of flute designer Theobald Boehm, but it is not the same as the Boehm System used on flutes. The other main system of keys is called the Oehler system and is used mostly in Germany and Austria (see History). The related Albert system is used by some jazz, klezmer, and eastern European folk musicians. The Albert and Oehler systems are both based on the early Mueller system.
The cluster of keys at the bottom of the upper joint (protruding slightly beyond the cork of the joint) are known as the "trill keys" and are operated by the right hand. These give the player alternative fingerings that make it easy to play ornaments and trills. The entire weight of the smaller clarinets is supported by the right thumb behind the lower joint on what is called the "thumb-rest". Basset horns and larger clarinets are supported with a neck strap or a floor peg.
Finally, the flared end is known as the "bell". Contrary to popular belief, the bell does not amplify the sound; rather, it improves the uniformity of the instrument's tone for the lowest notes in each register. For the other notes the sound is produced almost entirely at the tone holes and the bell is irrelevant. On basset horns and larger clarinets, the bell curves up and forward and is usually made of metal.
Keywork.
Theobald Boehm did not directly invent the key system of the clarinet. Boehm was a flautist who created the key system that is now used for the transverse flute. Klosé and Buffet applied Boehm's system to the clarinet. Although the credit goes to those people, Boehm's name was given to that key system.
The current Boehm key system consists of generally 6 rings, on the thumb, 1st, 2nd, 4th, 5th and 6th holes, a register key just above the thumb hole, easily accessible with the thumb. Above the 1st hole, there is a key that lifts two covers creating the note A in the throat register (high part of low register) of the clarinet. A key at the side of the instrument at the same height as the A key lifts only one of the two covers, producing G a semitone lower. The A key can be used in conjunction solely with the register key to produce A/B.
History.
Lineage.
The clarinet has its roots in the early single-reed instruments or hornpipes used in Ancient Greece, old Egypt, Middle East and Europe since the Middle Ages, such as the albogue, alboka, and double clarinet.
The modern clarinet developed from a Baroque instrument called the chalumeau. This instrument was similar to a recorder, but with a single-reed mouthpiece and a cylindrical bore. Lacking a register key, it was played mainly in its fundamental register, with a limited range of about one and a half octaves. It had eight finger holes, like a recorder, and two keys for its two highest notes. At this time, contrary to modern practice, the reed was placed in contact with the upper lip.
Around the turn of the 18th century, the chalumeau was modified by converting one of its keys into a register key to produce the first clarinet. This development is usually attributed to German instrument maker Johann Christoph Denner, though some have suggested his son Jacob Denner was the inventor. This instrument played well in the middle register with a loud, shrill sound, so it was given the name "clarinetto" meaning "little trumpet" (from "clarino" + "-etto"). Early clarinets did not play well in the lower register, so players continued to play the chalumeaux for low notes. As clarinets improved, the chalumeau fell into disuse, and these notes became known as the "chalumeau register". Original Denner clarinets had two keys, and could play a chromatic scale, but various makers added more keys to get improved tuning, easier fingerings, and a slightly larger range. The classical clarinet of Mozart's day typically had eight finger holes and five keys.
Clarinets were soon accepted into orchestras. Later models had a mellower tone than the originals. Mozart (d. 1791) liked the sound of the clarinet (he considered its tone the closest in quality to the human voice) and wrote numerous pieces for the instrument., and by the time of Beethoven (c. 1800–1820), the clarinet was a standard fixture in the orchestra.
Pads.
The next major development in the history of clarinet was the invention of the modern pad. Because early clarinets used felt pads to cover the tone holes, they leaked air. This required pad-covered holes to be kept to a minimum, restricting the number of notes the clarinet could play with good tone. In 1812, Iwan Müller, a Russian-born clarinetist and inventor, developed a new type of pad that was covered in leather or fish bladder. It was airtight and let makers increase the number of pad-covered holes. Müller designed a new type of clarinet with seven finger holes and thirteen keys. This allowed the instrument to play in any key with near-equal ease. Over the course of the 19th-century makers made many enhancements to Mueller's clarinet, such as the Albert system and the Baermann system, all keeping the same basic design. Modern instruments may also have cork or synthetic pads.
Arrangement of keys and holes.
The final development in the modern design of the clarinet used in most of the world today was introduced by Hyacinthe Klosé in 1839. He devised a different arrangement of keys and finger holes, which allow simpler fingering. It was inspired by the Boehm System developed for flutes by Theobald Boehm. Klosé was so impressed by Boehm's invention that he named his own system for clarinets the Boehm system, although it is different from the one used on flutes. This new system was slow to gain popularity because it meant the player had to relearn how to play the instrument. To ease this transition, Klosé wrote a series of exercises for the clarinet, designed to teach his fingering system. Gradually it became the standard, and today the Boehm system is used everywhere in the world except Germany and Austria. These countries still use a direct descendant of the Mueller clarinet known as the Oehler system clarinet. Also, some contemporary Dixieland and Klezmer players continue to use Albert system clarinets, as the simpler fingering system can allow for easier slurring of notes.
Usage and repertoire.
Use of multiple clarinets.
The modern orchestral standard of using soprano clarinets in both B and A has to do partly with the history of the instrument, and partly with acoustics, aesthetics and economics. Before about 1800, due to the lack of airtight pads "(see History)", practical woodwinds could have only a few keys to control accidentals (notes outside their diatonic home scales). The low (chalumeau) register of the clarinet spans a twelfth (an octave plus a perfect fifth), so the clarinet needs keys/holes to produce all nineteen notes in that range. This involves more keywork than is necessary on instruments that "overblow" at the octave—oboes, flutes, bassoons, and saxophones, for example, which need only twelve notes before overblowing.
Clarinets with few keys cannot therefore easily play chromatically, limiting any such instrument to a few closely related key signatures. For example, an eighteenth-century clarinet in C could be played in F, C, and G (and their relative minors) with good intonation, but with progressive difficulty and poorer intonation as the key moved away from this range. In contrast, for octave-overblowing instruments, an instrument in C with few keys could much more readily be played in any key.
This problem was overcome by using three clarinets—in A, B and C—so that early 19th-century music, which rarely strayed into the remote keys (five or six sharps or flats), could be played as follows: music in 5 to 2 sharps (B major to D major concert pitch) on A clarinet (D major to F major for the player), music in 1 sharp to 1 flat (G to F) on C clarinet, and music in 2 flats to 4 flats (B to A) on the B clarinet (C to B for the player). Difficult key signatures and numerous accidentals were thus largely avoided.
With the invention of the airtight pad, and as key technology improved and more keys were added to woodwinds, the need for clarinets in multiple musical keys was reduced. However, the use of multiple instruments in different keys persisted, with the three instruments in C, B and A all used as specified by the composer.
The lower-pitched clarinets sound more "mellow" (less bright), and the C clarinet—being the highest and therefore brightest of the three—fell out of favour as the other two clarinets could cover its range and their sound was considered better. While the clarinet in C began to fall out of general use around 1850, some composers continued to write C parts after this date, e.g., Bizet's Symphony in C (1855), Tchaikovsky's Symphony No. 2 (1872), Smetana's "Má Vlast" (1874), Brahms' Symphony No. 4 (1885), and Richard Strauss deliberately reintroduced it to take advantage of its brighter tone, as in "Der Rosenkavalier" (1911).
While technical improvements and an equal-tempered scale reduced the need for two clarinets, the technical difficulty of playing in remote keys persisted and the A has thus remained a standard orchestral instrument. In addition, by the late 19th century the orchestral clarinet repertoire contained so much music for clarinet in A that the disuse of this instrument was not practical. Attempts were made to standardise to the B instrument between 1930 and 1950 (e.g., tutors recommended learning the routine transposition of orchestral A parts on the B clarinet, including solos written for A clarinet, and some manufacturers provided a low E on the B to match the range of the A), but this failed in the orchestral sphere.
Similarly there have been E and D instruments in the upper soprano range, B, A, and C instruments in the bass range, and so forth; but over time the E and B instruments have become predominant.
The B instrument remains dominant in concert bands and in jazz. Both B and C instruments are used in some ethnic traditions, such as klezmer music.
Classical music.
In classical music, clarinets are part of standard orchestral and concert band instrumentation.
The orchestra frequently includes two clarinetists playing individual parts—each player is usually equipped with a pair of standard clarinets in B and A, and clarinet parts commonly alternate between B and A instruments several times over the course of a piece or even, less commonly, of a movement (e.g., 1st movement Brahms 3rd symphony). Clarinet sections grew larger during the last few decades of the 19th century, often employing a third clarinetist, an E or a bass clarinet. In the 20th century, composers such as Igor Stravinsky, Richard Strauss, Gustav Mahler and Olivier Messiaen enlarged the clarinet section on occasion to up to nine players, employing many different clarinets including the E or D soprano clarinets, basset horn, alto clarinet, bass clarinet and/or contrabass clarinet.
In concert bands, clarinets are an important part of the instrumentation. The E clarinet, B clarinet, alto clarinet, bass clarinet, and contra-alto/contrabass clarinet are commonly used in concert bands. Concert bands generally have multiple B clarinets; there are commonly 3 B clarinet parts with 2-3 players per part. There is generally only one player per part on the other clarinets. There are not always E clarinet, alto clarinet, and contra-alto clarinets/contrabass clarinet parts in concert band music, but all three are quite common.
This practice of using a variety of clarinets to achieve coloristic variety was common in 20th-century classical music and continues today. However, many clarinetists and conductors prefer to play parts originally written for obscure instruments on B or E clarinets, which are often of better quality and more prevalent and accessible.
The clarinet is widely used as a solo instrument. The relatively late evolution of the clarinet (when compared to other orchestral woodwinds) has left solo repertoire from the Classical period and later, but few works from the Baroque era. Many clarinet concertos have been written to showcase the instrument, with the concerti by Mozart, Copland and Weber being well known.
Many works of chamber music have also been written for the clarinet. Common combinations are:
Jazz.
The clarinet was originally a central instrument in jazz, beginning with the New Orleans players in the 1910s. It remained a signature instrument of jazz music through much of the big band era into the 1940s. American players Larry Shields, Ted Lewis, Jimmie Noone and Sidney Bechet were all pioneers of the instrument in jazz. The B soprano was the most common instrument, but a few early jazz musicians such as Louis Nelson Delisle and Alcide Nunez preferred the C soprano, and many New Orleans jazz brass bands have used E soprano.
Swing clarinetists such as Benny Goodman, Artie Shaw, and Woody Herman led successful big bands and smaller groups from the 1930s onward. Duke Ellington, active from the 1920s to the 1970s, used the clarinet as lead instrument in his works, with several players of the instrument (Barney Bigard, Jimmy Hamilton and Russell Procope) spending a significant portion of their careers in his orchestra. Harry Carney, primarily Ellington's baritone saxophonist, occasionally doubled on bass clarinet. Meanwhile, Pee Wee Russell had a long and successful career in small groups.
With the decline of the big bands' popularity in the late 1940s, the clarinet faded from its prominent position in jazz. By that time, an interest in Dixieland or traditional New Orleans jazz had revived; Pete Fountain was one of the best known performers in this genre. Bob Wilber, active since the 1950s, is a more eclectic jazz clarinetist, playing in several classic jazz styles. During the 1950s and 1960s, Britain underwent a surge in the popularity of what was termed 'Trad jazz'. In 1956 the British clarinetist Acker Bilk founded his own ensemble. Several singles recorded by Bilk reached the British pop charts, including the ballad "Stranger on the Shore". 
The clarinet's place in the jazz ensemble was usurped by the saxophone, which projects a more powerful sound and uses a less complicated fingering system. The requirement for an increased speed of execution in modern jazz also did not favour the clarinet, but the clarinet did not entirely disappear. A few players such as Buddy DeFranco, Tony Scott, Jimmy Giuffre emerged during the 1950s playing bebop or other styles. A little later, Eric Dolphy (on bass clarinet), Perry Robinson, John Carter, Theo Jörgensmann and others used the clarinet in free jazz. The French composer and clarinetist Jean-Christian Michel initiated a jazz-classical cross-over on the clarinet with the drummer Kenny Clarke.
In the U.S., the prominent players on the instrument since the 1980s have included Eddie Daniels, Don Byron, and Marty Ehrlich and others playing the clarinet in more contemporary contexts.
Other genres.
The clarinet is uncommon, but not unheard of in rock music. Jerry Martini played clarinet on Sly and the Family Stone's 1968 hit, "Dance to the Music"; Don Byron, a founder of the Black Rock Coalition who was a member of hard rock guitarist Vernon Reid's band, plays clarinet on the "Mistaken Identity" album (1996). The Beatles, Pink Floyd, Radiohead, Aerosmith, Billy Joel, and Tom Waits have also all used clarinet on occasion.
Clarinets feature prominently in klezmer music, which entails a distinctive style of playing. The use of quarter-tones requires a different embouchure. Some klezmer musicians prefer Albert system clarinets.
The popular Brazilian music styles of choro and samba use the clarinet. Prominent contemporary players include Paulo Moura, Naylor 'Proveta' Azevedo, Paulo Sérgio dos Santos and Paquito D'Rivera.
The clarinet is prominent in Bulgarian wedding music, an offshoot of Roma/Romani traditional music. Ivo Papazov is a well-known clarinetist in this genre. In Moravian dulcimer bands, the clarinet is usually the only wind instrument among string instruments.
In the Republic of Macedonia, old-town folk music -called chalgija ("чалгија"), the clarinet has the most important role in wedding music; clarinet solos mark the high point of dancing euphoria. One of the most renowned Macedonian clarinet players is Tale Ognenovski, who gained worldwide fame for his virtuosity.
In Greece the clarinet (usually referred to as "κλαρίνο" - "clarino") is prominent in traditional music, especially in central, northwest and northern Greece (Thessaly, Epirus and Macedonia). The double-reed zurna was the dominant woodwind instrument before the clarinet arrived in the country, although many Greeks regard the clarinet as a native instrument. Traditional dance music, wedding music and laments include a clarinet soloist and quite often improvisations. Petroloukas Chalkias is a famous clarinetist in this genre.
The instrument is equally famous in Turkey, especially the soprano clarinet in G. The soprano clarinet crossed via Turkey to Arabic music, where it is widely used in Arabic pop, especially if the intention of the arranger is to imitate the Turkish style.
Also in Turkish folk music, a clarinet-like woodwind instrument, the sipsi, is used. However, it's far more rare than the soprano clarinet and is mainly limited to folk music of the Aegean Region.
Groups of clarinets.
Groups of clarinets playing together have become increasingly popular among clarinet enthusiasts in recent years. Common forms are:
Clarinet choirs and quartets often play arrangements of both classical and popular music, in addition to a body of literature specially written for a combination of clarinets by composers such as Arnold Cooke, Alfred Uhl, Lucien Caillet and Václav Nelhýbel.
Extended family of clarinets.
There is a family of many differently pitched clarinet types, some of which are very rare. The following are the most important sizes, from highest to lowest:
Experimental EEE and BBB octocontra-alto and octocontrabass clarinets have also been built. There have also been soprano clarinets in C, A, and B with curved barrels and bells marketed under the names saxonette, claribel, and clariphon.

</doc>
<doc id="6434" url="http://en.wikipedia.org/wiki?curid=6434" title="Chojnów">
Chojnów

Chojnów () is a small town in Legnica County, Lower Silesian Voivodeship, in south-western Poland. It is located on the Skora river, a tributary of the Kaczawa at an average altitude of above sea level. Chojnów is the administrative seat of the rural gmina called Gmina Chojnów, although the town is not part of its territory and forms a separate urban gmina. As of 2006 it had 14,389 inhabitants.
Chojnów is located west of Legnica, east from Bolesławiec and north of Złotoryja, from the A4 motorway. It has railroad connections to Bolesławiec and Legnica.
History.
The settlement of "Haynow" was mentioned in a 1272 deed. It was already called a "civitas" in a 1288 document issued by the Piast duke Henry V of Legnica, and officially received town privileges in 1333.
After World War II and the implementation of the Oder-Neisse line in 1945, the town passed to the Republic of Poland. The German population was expelled from the region.
Chojnów today.
Chojnów is an industrial and agricultural town. Among local products are: paper, agricultural machinery, chains, metal furniture for hospitals, equipment for the meat industry, beer, wine, leather clothing, and clothing for infants, children and adults. The local government-run weekly newspaper is Gazeta Chojnowska, which has been published since 1992.
Among the interesting monuments of Chojnów are the 13th-century castle of the Dukes of Legnica (currently used as a museum), two old churches, the "Baszta Tkaczy" ("Weavers' Tower") and preserved fragments of city walls.
The biggest green area in Chojnów is small forest "Park Piastowski" ("Piast's Park"), named after the Polish Piast dynasty. Wild animals that can be found in the Chojnów area are roe-deer ("sarna", Capreolus capraea ?), foxes, rabbits and wild domestic animals, especially cats.
Every year in the first days of June, the "Days of Chojnów" ("Dni Chojnowa") are celebrated. The Whole-Poland bike race "Masters" has been organized yearly in Chojnów for the past few years.
International relations.
Twin towns — sister cities.
Chojnów is twinned with:

</doc>
<doc id="6435" url="http://en.wikipedia.org/wiki?curid=6435" title="Canes Venatici">
Canes Venatici

Canes Venatici is one of the 88 official modern constellations. It is a small northern constellation that was created by Johannes Hevelius in the 17th century. Its name is Latin for "hunting dogs", and the constellation is often depicted in illustrations as representing the dogs of Boötes the Herdsman, a neighboring constellation.
History.
The stars of Canes Venatici are not bright. In classical times, they were included by Ptolemy within the constellation Ursa Major in his star catalogue. α CVn was Ptolemy's "28th of Ursa Major", and β CVn was his "29th of Ursa Major".
In medieval times, the identification of these stars with the dogs of Boötes arose through a mistranslation. Some of Boötes's stars were traditionally described as representing the club (Greek, Κολλοροβος) of Boötes. When the Greek astronomer Ptolemy's "Almagest" was translated from Greek to Arabic, the translator Johannitius (following Alberuni) did not know the Greek word and rendered it as the nearest-looking Arabic word, writing العصى ذات الكلاب in ordinary unvowelled Arabic text "al-`aşā dhāt al-kullāb", which means "the spearshaft having a hook". When the Arabic text was translated into Latin, the translator Gerard of Cremona (probably in Spain) mistook the Arabic word كلاب for "kilāb" (the plural of كلب "kalb"), meaning "dogs", writing "hastile habens canes" ("spearshaft having dogs").
In 1533, the German astronomer Peter Apian depicted Boötes as having two dogs with him.
These spurious dogs floated about the astronomical literature until Hevelius decided to specify their presence in the sky by making them a separate constellation in 1687. Hevelius chose the name "Asterion" (from the Greek 'αστέριον, meaning the "little star", the diminutive of 'αστηρ the "star", or adjective meaning "starry") for the northern dog and "Chara" (from the Greek χαρά, meaning "joy") for the southern dog, as "Canes Venatici", the Hunting Dogs, in his star atlas.
In his star catalogue, the Czech astronomer Bečvář assigned "Asterion" to β CVn and "Chara" to α CVn.
Characteristics.
Canes Venatici is bordered by Ursa Major to the north and west, Coma Berenices to the south, and Bootes to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'CVn'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of 14 sides. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between +27.84° and +52.36°. Covering 465 square degrees, it ranks 38th of the 88 constellations in size.
Notable features.
Stars.
Canes Venatici contains no bright stars, α and β CVn being only of 3rd and 4th magnitude respectively. Flamsteed catalogued 25 stars in the constellation, labelling them 1 to 25 Canum Venaticorum, however 1 turned out to be in Ursa Major, 13 was in Coma Berenices and 22 did not exist. 
Supervoid.
The Giant Void, an extremely large void (part of the universe containing very few galaxies) is within the vicinity of this constellation. It may be possibly the largest void ever discovered, rivaling the size of the Eridanus Supervoid. It was discovered in 1983 in a deep-sky survey.
Deep-sky objects.
Canes Venatici contains five Messier objects, including four galaxies. One of the more significant galaxies in Canes Venatici is the Whirlpool Galaxy (M51, NGC 5194) and NGC 5195, a small barred spiral galaxy that is seen face on. This was the first galaxy recognised as having a spiral structure, this structure being first observed by Lord Rosse in 1845. It is a face-on spiral galaxy 37 million light-years from Earth. Widely considered to be one of the most beautiful galaxies visible, M51 has many star-forming regions and nebulae in its arms, coloring them pink and blue in contrast to the older yellow core. M51 has a smaller companion, NGC 5195, that has very few star-forming regions and thus appears yellow. It is passing behind M51 and may be the cause of the larger galaxy's prodigious star formation.
Other notable spiral galaxies in Canes Venatici are the Sunflower Galaxy (M63, NGC 5055), M94 (NGC 4736), and M106 (NGC 4258). M63, the Sunflower Galaxy, was named for its appearance in large amateur telescopes. It is a spiral galaxy with an integrated magnitude of 9.0. M94 is a small face-on spiral galaxy with an approximate magnitude of 8.0, about 15 million light-years from Earth. NGC 4631 is a barred spiral galaxy, which is one of the largest and brightest edge-on galaxies in the sky.
M3 (NGC 5272) is a globular cluster 32,000 light-years from Earth. It is 18' in diameter, and at magnitude 6.3 is bright enough to be seen with binoculars. It can even be seen with the naked eye under particularly dark skies.
M94, also classified as NGC 4736, is a face-on spiral galaxy 15 million light-years from Earth. It has very tight spiral arms and a bright core. The outskirts of the galaxy are incredibly luminous in the ultraviolet because of a ring of new stars surrounding the core, 7,000 light-years in diameter. Though astronomers are not sure what has caused this ring of new stars, some hypothesize that it is from shock waves caused by a bar that is thus far invisible.

</doc>
<doc id="6436" url="http://en.wikipedia.org/wiki?curid=6436" title="Chamaeleon">
Chamaeleon

Chamaeleon () is a small constellation in the southern sky. It is named after the chamaeleon, a kind of lizard. It was first defined in the 16th century.
History.
Chamaeleon was one of twelve constellations created by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman. It first appeared on a 35-cm diameter celestial globe published in 1597 (or 1598) in Amsterdam by Plancius and Jodocus Hondius. Johann Bayer was the first uranographer to put Chamaeleon in a celestial atlas. It was one of many constellations created by European explorers in the 15th and 16th centuries out of unfamiliar Southern Hemisphere stars.
Notable features.
Stars.
There are four bright stars in Chamaeleon. Alpha Chamaeleontis is a white-hued star of magnitude 4.1, 63 light-years from Earth. Beta Chamaeleontis is a blue-white hued star of magnitude 4.2, 27 light-years from Earth. Gamma Chamaeleontis is a red-hued giant star of magnitude 4.1, 413 light-years from Earth. The other bright star in Chamaeleon is Delta Chamaeleontis, a wide double star. The brighter star is Delta2 Chamaeleontis, a blue-hued star of magnitude 4.4, 364 light-years from Earth. Delta1 Chamaeleontis, the dimmer component, is an orange-hued giant star of magnitude 5.5, 354 light-years away.
Chamaeleon is also the location of Cha 110913, a unique dwarf star or proto solar system.
Deep-sky objects.
In 1999, a nearby open cluster was discovered centered on the star η Chamaeleontis. The cluster, known as either
the Eta Chamaeleontis cluster or Mamajek 1, is 8 million years old, and lies 316 light years from Earth.
The constellation contains a number of molecular clouds (the Chamaeleon dark clouds) that are forming low-mass T Tauri stars. The cloud complex lies some 400 to 600 light years from Earth, and contains tens of thousands of solar masses of gas and dust. The most prominent cluster of T Tauri stars and young B-type stars are in the Chamaeleon I cloud, and are associated with the reflection nebula IC 2631.
Chamaeleon contains one planetary nebula, NGC 3195, which is fairly faint. It appears in a telescope at about the same apparent size as Jupiter.
Equivalents.
In Chinese astronomy, the stars that form Chamaeleon were classified as the Little Dipper (小斗, "Xiǎodǒu") among the Southern Asterisms (近南極星區, "Jìnnánjíxīngōu") by Xu Guangqi.
See also.
Chamaeleon (Chinese astronomy)

</doc>
<doc id="6437" url="http://en.wikipedia.org/wiki?curid=6437" title="Cholesterol">
Cholesterol

Cholesterol, from the Ancient Greek "chole-" (bile) and "stereos" (solid) followed by the chemical suffix "-ol" for an alcohol, is an organic molecule. It is a sterol (or modified steroid), a lipid molecule and is biosynthesized by all animal cells because it is an essential structural component of animal cell membranes that is required to maintain both membrane structural integrity and fluidity. Cholesterol enables animal cells to (a) not need a cell wall (like plants & bacteria) to protect membrane integrity/cell-viability and thus be able to (b) change shape and (c) move about (unlike bacteria and plant cells which are restricted by their cell walls).
In addition to its importance within cells, cholesterol also serves as a precursor for the biosynthesis of steroid hormones, bile acids, and vitamin D. Cholesterol is the principal sterol synthesized by animals. All kinds of cells in animals can produce it. In vertebrates the hepatic cells typically produce greater amounts than other cells. It is almost completely absent among prokaryotes (bacteria and archaea), although there are some exceptions such as Mycoplasma, which require cholesterol for growth.
François Poulletier de la Salle first identified cholesterol in solid form in gallstones in 1769. However, it was not until 1815 that chemist Michel Eugène Chevreul named the compound "cholesterine".
Physiology.
Since cholesterol is essential for all animal life, each cell synthesizes it from simpler molecules, a complex 37-step process that starts with the intracellular protein enzyme HMG-CoA reductase. However, normal and particularly high levels of fats (including cholesterol) in the blood circulation, depending on how they are transported within lipoproteins, are strongly associated with the progression of atherosclerosis.
For a man of about 68 kg (150 lb), typical total body-cholesterol synthesis is approximately 1 g (1,000 mg) per day, and total body content is approximately 35 g, primarily located within the membranes of all the cells of the body. Typical daily dietary intake of additional cholesterol, in the United States, is 200–300 mg.
Most ingested cholesterol is esterified, and esterified cholesterol is poorly absorbed. The body also compensates for any absorption of additional cholesterol by reducing cholesterol synthesis. For these reasons, seven to ten hours after ingestion of cholesterol, blood levels will show little if any effect on total body cholesterol content or concentrations of cholesterol in the blood. However, during the first seven hours after ingestion of cholesterol, the levels significantly increase.
Cholesterol is recycled. The liver excretes it in a non-esterified form (via bile) into the digestive tract. Typically about 50% of the excreted cholesterol is reabsorbed by the small bowel back into the bloodstream.
Plants make cholesterol in very small amounts. Plants manufacture phytosterols (substances chemically similar to cholesterol produced within plants), which can compete with cholesterol for reabsorption in the intestinal tract, thus potentially reducing cholesterol reabsorption. When intestinal lining cells absorb phytosterols, in place of cholesterol, they usually excrete the phytosterol molecules back into the GI tract, an important protective mechanism.
Function.
Cholesterol is required to build and maintain membranes; it modulates membrane fluidity over the range of physiological temperatures. The hydroxyl group on cholesterol interacts with the polar head groups of the membrane phospholipids and sphingolipids, while the bulky steroid and the hydrocarbon chain are embedded in the membrane, alongside the nonpolar fatty-acid chain of the other lipids. Through the interaction with the phospholipid fatty-acid chains, cholesterol increases membrane packing, which reduces membrane fluidity. The structure of the tetracyclic ring of cholesterol contributes to the decreased fluidity of the cell membrane as the molecule is in a trans conformation making all but the side chain of cholesterol rigid and planar. In this structural role, cholesterol reduces the permeability of the plasma membrane to neutral solutes, hydrogen ions, and sodium ions.
Within the cell membrane, cholesterol also functions in intracellular transport, cell signaling and nerve conduction. Cholesterol is essential for the structure and function of invaginated caveolae and clathrin-coated pits, including caveola-dependent and clathrin-dependent endocytosis. The role of cholesterol in such endocytosis can be investigated by using methyl beta cyclodextrin (MβCD) to remove cholesterol from the plasma membrane. Recently, cholesterol has also been implicated in cell signaling processes, assisting in the formation of lipid rafts in the plasma membrane. Lipid raft formation brings receptor proteins in close proximity with high concentrations of second messenger molecules. In many neurons, a myelin sheath, rich in cholesterol, since it is derived from compacted layers of Schwann cell membrane, provides insulation for more efficient conduction of impulses.
Within cells, cholesterol is the precursor molecule in several biochemical pathways. In the liver, cholesterol is converted to bile, which is then stored in the gallbladder. Bile contains bile salts, which solubilize fats in the digestive tract and aid in the intestinal absorption of fat molecules as well as the fat-soluble vitamins, A, D, E, and K. Cholesterol is an important precursor molecule for the synthesis of vitamin D and the steroid hormones, including the adrenal gland hormones cortisol and aldosterone, as well as the sex hormones progesterone, estrogens, and testosterone, and their derivatives.
Some research indicates cholesterol may act as an antioxidant.
Dietary sources.
Animal fats are complex mixtures of triglycerides, with lesser amounts of phospholipids and cholesterol. As a consequence, all foods containing animal fat contain cholesterol to varying extents. Major dietary sources of cholesterol include cheese, egg yolks, beef, pork, poultry, fish, and shrimp. Human breast milk also contains significant quantities of cholesterol.
From a dietary perspective, cholesterol is not found in significant amounts in plant sources. In addition, plant products such as flax seeds and peanuts contain cholesterol-like compounds called phytosterols, which are believed to compete with cholesterol for absorption in the intestines. Phytosterols can be supplemented through the use of phytosterol-containing functional foods or nutraceuticals that are widely recognized as having a proven LDL cholesterol-lowering efficacy. Current supplemental guidelines recommend doses of phytosterols in the 1.6-3.0 grams per day range (Health Canada, EFSA, ATP III,FDA) with a recent meta-analysis demonstrating an 8.8% reduction in LDL-cholesterol at a mean dose of 2.15 gram per day. However, the benefits of a diet supplemented with phytosterol has been questioned.
Fat intake also plays a role in blood-cholesterol levels. Isocalorically replacing dietary carbohydrates with monounsaturated and polyunsaturated fats has been shown to lower serum LDL and total cholesterol levels and increase serum HDL levels, while replacing carbohydrates with saturated fat was shown to increase HDL, LDL, and total cholesterol levels. Trans fats have been shown to reduce levels of HDL while increasing levels of LDL. Based on such evidence and evidence implicating low HDL and high LDL levels in cardiovascular disease (see Hypercholesterolemia), many health authorities advocate reducing LDL cholesterol through changes in diet in addition to other lifestyle modifications. The USDA, for example, recommends that those wishing to reduce their cholesterol through a change in diet should aim to consume less than 7% of their daily energy needs from saturated fat and fewer than 200 mg of cholesterol per day. An alternative view is that any reduction to dietary cholesterol intake could be counteracted by the organs compensating to try to keep blood cholesterol levels constant. Other research has found that an increase in the consumption of saturated fats and cholesterol decreases overall serum cholesterol.
Biosynthesis.
All animal cells manufacture cholesterol for their use, with relative production rates varying by cell type and organ function. About 20–25% of total daily cholesterol production occurs in the liver; other sites of higher synthesis rates include the intestines, adrenal glands, and reproductive organs. Synthesis within the body starts with one molecule of acetyl CoA and one molecule of acetoacetyl-CoA, which are hydrated to form 3-hydroxy-3-methylglutaryl CoA (HMG-CoA). This molecule is then reduced to mevalonate by the enzyme HMG-CoA reductase. This is the regulated, rate-limiting and irreversible step in cholesterol synthesis and is the site of action for the statin drugs (HMG-CoA reductase competitive inhibitors).
Mevalonate is then converted to 3-isopentenyl pyrophosphate in three reactions that require ATP. Mevalonate is decarboxylated to isopentenyl pyrophosphate, which is a key metabolite for various biological reactions. Three molecules of isopentenyl pyrophosphate condense to form farnesyl pyrophosphate through the action of geranyl transferase. Two molecules of farnesyl pyrophosphate then condense to form squalene by the action of squalene synthase in the endoplasmic reticulum. Oxidosqualene cyclase then cyclizes squalene to form lanosterol. Finally, lanosterol is converted to cholesterol through a 19-step process.
Konrad Bloch and Feodor Lynen shared the Nobel Prize in Physiology or Medicine in 1964 for their discoveries concerning the mechanism and regulation of cholesterol and fatty acid metabolism.
Regulation of cholesterol synthesis.
Biosynthesis of cholesterol is directly regulated by the cholesterol levels present, though the homeostatic mechanisms involved are only partly understood. A higher intake from food leads to a net decrease in endogenous production, whereas lower intake from food has the opposite effect. The main regulatory mechanism is the sensing of intracellular cholesterol in the endoplasmic reticulum by the protein SREBP (sterol regulatory element-binding protein 1 and 2). In the presence of cholesterol, SREBP is bound to two other proteins: SCAP (SREBP cleavage activating protein) and Insig1. When cholesterol levels fall, Insig-1 dissociates from the SREBP-SCAP complex, which allows the complex to migrate to the Golgi apparatus. Here SREBP is cleaved by S1P and S2P (site-1 and -2 protease), two enzymes that are activated by SCAP when cholesterol levels are low.
The cleaved SREBP then migrates to the nucleus, and acts as a transcription factor to bind to the sterol regulatory element (SRE), which stimulates the transcription of many genes. Among these are the low-density lipoprotein (LDL) receptor and HMG-CoA reductase. The LDL receptor former scavenges circulating LDL from the bloodstream, whereas HMG-CoA reductase leads to an increase of endogenous production of cholesterol. A large part of this signaling pathway was clarified by Dr. Michael S. Brown and Dr. Joseph L. Goldstein in the 1970s. In 1985, they received the Nobel Prize in Physiology or Medicine for their work. Their subsequent work shows how the SREBP pathway regulates expression of many genes that control lipid formation and metabolism and body fuel allocation.
Cholesterol synthesis can also be turned off when cholesterol levels are high. HMG-CoA reductase contains both a cytosolic domain (responsible for its catalytic function) and a membrane domain. The membrane domain senses signals for its degradation. Increasing concentrations of cholesterol (and other sterols) cause a change in this domain's oligomerization state, which makes it more susceptible to destruction by the proteosome. This enzyme's activity can also be reduced by phosphorylation by an AMP-activated protein kinase. Because this kinase is activated by AMP, which is produced when ATP is hydrolyzed, it follows that cholesterol synthesis is halted when ATP levels are low.
Plasma transport and regulation of absorption.
Cholesterol is only slightly soluble in water; it dissolves into the (water-based) bloodstream only at exceedingly small concentrations. Instead, cholesterol is transported inside lipoproteins, complex discoidal particles with exterior amphiphilic proteins and lipids, whose outward-facing surfaces are water-soluble and inward-facing surfaces are lipid-soluble. Triglycerides and cholesterol esters are carried internally. Phospholipids and cholesterol, being amphipathic, are transported in the monolayer surface of the lipoprotein particle.
There are several types of lipoproteins in the blood. In order of increasing density, they are chylomicrons, very-low-density lipoprotein (VLDL), low-density lipoprotein (LDL), intermediate-density lipoprotein (IDL), and high-density lipoprotein (HDL). Lower protein/lipid ratios make for less dense lipoproteins. Cholesterol within different lipoproteins is identical, although some is carried as "free" alcohol, while others as fatty acyl esters, known also as cholesterol esters.
Lipoproteins contain apolipoproteins, which bind to specific receptors on cell membranes, directing their lipid payload to specific tissues. Lipoprotein particles thus include these molecular addresses, which determine the start- and end points of cholesterol transport.
Chylomicrons, the least dense cholesterol transport molecules, contain apolipoprotein B-48, apolipoprotein C, and apolipoprotein E in their shells. Chylomicrons carry fats from the intestine to muscle and other tissues in need of fatty acids for energy or fat production. Unused cholesterol remains in more cholesterol-rich chylomicron remnants, and taken up from here to the bloodstream by the liver.
VLDL molecules are produced by the liver from triacylglycerol and cholesterol which was not used in the synthesis of bile acids. These molecules contain apolipoprotein B100 and apolipoprotein E in their shells.
Blood vessels cleave and absorb triacylglycerol from IDL molecules, increasing the concentration of cholesterol. IDL molecules are then consumed in two processes: half is metabolized by HTGL and taken up by the LDL receptor on the liver cell surfaces, while the other half continues to lose triacylglycerols in the bloodstream until they become LDL molecules, with the highest concentration of cholesterol within them.
LDL particles are the major blood cholesterol carriers. Each one contains approximately 1,500 molecules of cholesterol ester. LDL molecule shells contain just one molecule of apolipoprotein B100, recognized by LDL receptors in peripheral tissues. Upon binding of apolipoprotein B100, many LDL receptors concentrate in clathrin-coated pits. Both LDL and its receptor form vesicles within a cell via endocytosis. These vesicles then fuse with a lysosome, where the lysosomal acid lipase enzyme hydrolyzes the cholesterol esters. The cholesterol can then be used for membrane biosynthesis or esterified and stored within the cell, so as to not interfere with the cell membranes.
LDL receptors are used up during cholesterol absorption, and its synthesis is regulated by SREBP, the same protein that controls the synthesis of cholesterol "de novo", according to its presence inside the cell. A cell with abundant cholesterol will have its LDL receptor synthesis blocked, to prevent new cholesterol in LDL molecules from being taken up. Conversely, LDL receptor synthesis proceeds when a cell is deficient in cholesterol.
When this process becomes unregulated, LDL molecules without receptors begin to appear in the blood. These LDL molecules are oxidized and taken up by macrophages, which become engorged and form foam cells. These foam cells often become trapped in the walls of blood vessels and contribute to atherosclerotic plaque formation. Differences in cholesterol homeostasis affect the development of early atherosclerosis (carotid intima-media thickness). These plaques are the main causes of heart attacks, strokes, and other serious medical problems, leading to the association of so-called LDL cholesterol (actually a lipoprotein) with "bad" cholesterol.
HDL particles are thought to transport cholesterol back to the liver, either for excretion or for other tissues that synthesize hormones, in a process known as reverse cholesterol transport (RCT). Large numbers of HDL particles correlates with better health outcomes., whereas low numbers of HDL particles is associated with atheromatous disease progression in the arteries.
Metabolism, recycling and excretion.
Cholesterol is susceptible to oxidation and easily forms oxygenated derivatives known as oxysterols. Three different mechanisms can form these; autoxidation, secondary oxidation to lipid peroxidation, and cholesterol-metabolizing enzyme oxidation. A great interest in oxysterols arose when they were shown to exert inhibitory actions on cholesterol biosynthesis. This finding became known as the “oxysterol hypothesis”. Additional roles for oxysterols in human physiology include their: participation in bile acid biosynthesis, function as transport forms of cholesterol, and regulation of gene transcription.
In biochemical experiments radiolabelled forms of cholesterol, such as tritiated-cholesterol are used. These derivatives undergo degradation upon storage and it is essential to purify cholesterol prior to use. Cholesterol can be purified using small Sephadex LH-20 columns.
Cholesterol is oxidized by the liver into a variety of bile acids. These, in turn, are conjugated with glycine, taurine, glucuronic acid, or sulfate. A mixture of conjugated and nonconjugated bile acids, along with cholesterol itself, is excreted from the liver into the bile. Approximately 95% of the bile acids are reabsorbed from the intestines, and the remainder are lost in the feces. The excretion and reabsorption of bile acids forms the basis of the enterohepatic circulation, which is essential for the digestion and absorption of dietary fats. Under certain circumstances, when more concentrated, as in the gallbladder, cholesterol crystallises and is the major constituent of most gallstones. Although, lecithin and bilirubin gallstones also occur, but less frequently.
Every day, up to 1 g of cholesterol enters the colon. This cholesterol originates from the diet, bile, and desquamated intestinal cells, and can be metabolized by the colonic bacteria. Cholesterol is converted mainly into coprostanol, a nonabsorbable sterol that is excreted in the feces. A cholesterol-reducing bacterium origin has been isolated from human feces.
Although cholesterol is a steroid generally associated with mammals, the human pathogen "Mycobacterium tuberculosis" is able to completely degrade this molecule and contains a large number of genes that are regulated by its presence. Many of these cholesterol-regulated genes are homologues of fatty acid β-oxidation genes, but have evolved in such a way as to bind large steroid substrates like cholesterol.
Clinical significance.
Hypercholesterolemia.
According to the lipid hypothesis, abnormal cholesterol levels (hypercholesterolemia) — actually higher concentrations of LDL particles and lower concentrations of functional HDL particles  — are strongly associated with cardiovascular disease because these promote atheroma development in arteries (atherosclerosis). This disease process leads to myocardial infarction (heart attack), stroke, and peripheral vascular disease. Since higher blood LDL, especially higher LDL particle concentrations and smaller LDL particle size, contribute to this process more than the cholesterol content of the HDL particles, LDL particles are often termed "bad cholesterol" because they have been linked to atheroma formation. On the other hand, high concentrations of functional HDL, which can remove cholesterol from cells and atheroma, offer protection and are sometimes referred to as "good cholesterol". These balances are mostly genetically determined, but can be changed by body build, medications, food choices, and other factors. Resistin, a protein secreted by fat tissue, has been shown to increase the production of LDL in human liver cells and also degrades LDL receptors in the liver. As a result, the liver is less able to clear cholesterol from the bloodstream. Resistin accelerates the accumulation of LDL in arteries, increasing the risk of heart disease. Resistin also adversely impacts the effects of statins, the main cholesterol-reducing drug used in the treatment and prevention of cardiovascular disease.
Conditions with elevated concentrations of oxidized LDL particles, especially "small dense LDL" (sdLDL) particles, are associated with atheroma formation in the walls of arteries, a condition known as atherosclerosis, which is the principal cause of coronary heart disease and other forms of cardiovascular disease. In contrast, HDL particles (especially large HDL) have been identified as a mechanism by which cholesterol and inflammatory mediators can be removed from atheroma. Increased concentrations of HDL correlate with lower rates of atheroma progressions and even regression. A 2007 study pooling data on almost 900,000 subjects in 61 cohorts demonstrated that blood total cholesterol levels have an exponential effect on cardiovascular and total mortality, with the association more pronounced in younger subjects. Still, because cardiovascular disease is relatively rare in the younger population, the impact of high cholesterol on health is still larger in older people.
Elevated levels of the lipoprotein fractions, LDL, IDL and VLDL are regarded as atherogenic (prone to cause atherosclerosis). Levels of these fractions, rather than the total cholesterol level, correlate with the extent and progress of atherosclerosis. Conversely, the total cholesterol can be within normal limits, yet be made up primarily of small LDL and small HDL particles, under which conditions atheroma growth rates would still be high. Recently, a "post hoc" analysis of the IDEAL and the EPIC prospective studies found an association between high levels of HDL cholesterol (adjusted for apolipoprotein A-I and apolipoprotein B) and increased risk of cardiovascular disease, casting doubt on the cardioprotective role of "good cholesterol".
Elevated cholesterol levels are treated with a strict diet consisting of low saturated fat, trans fat-free, low cholesterol foods, often followed by one of various hypolipidemic agents, such as statins, fibrates, cholesterol absorption inhibitors, nicotinic acid derivatives or bile acid sequestrants. Extreme cases have previously been treated with partial ileal bypass surgery, which has now been superseded by medication. Apheresis-based treatments are still used for very severe hyperlipidemias that are either unresponsive to treatment or require rapid lowering of blood lipids.
Multiple human trials using HMG-CoA reductase inhibitors, known as statins, have repeatedly confirmed that changing lipoprotein transport patterns from unhealthy to healthier patterns significantly lowers cardiovascular disease event rates, even for people with cholesterol values currently considered low for adults. Studies have also found that statins reduce atheroma progression. As a result, people with a history of cardiovascular disease may derive benefit from statins irrespective of their cholesterol levels (total cholesterol below 5.0 mmol/L [193 mg/dL]), and in men without cardiovascular disease, there is benefit from lowering abnormally high cholesterol levels ("primary prevention"). Primary prevention in women was originally practiced only by extension of the findings in studies on men, since, in women, none of the large statin trials conducted prior to 2007 demonstrated a statistically significant reduction in overall mortality or in cardiovascular endpoints. In 2008, a large clinical trial reported that, in apparently healthy adults with increased levels of the inflammatory biomarker high-sensitivity C-reactive protein but with low initial LDL, 20 mg/day of rosuvastatin for 1.9 years resulted in a 44% reduction in the incidence of cardiovascular events and a 20% reduction in all-cause mortality; the effect was statistically significant for both genders. Though this result was met with some skepticism, later studies and meta-analyses likewise demonstrated statistically significant (but smaller) reductions in all-cause and cardiovascular mortality, without significant heterogeneity by gender.
The 1987 report of National Cholesterol Education Program, Adult Treatment Panels suggests the total blood cholesterol level should be: < 200 mg/dL normal blood cholesterol, 200–239 mg/dL borderline-high, > 240 mg/dL high cholesterol. The American Heart Association provides a similar set of guidelines for total (fasting) blood cholesterol levels and risk for heart disease:
However, as today's testing methods determine LDL ("bad") and HDL ("good") cholesterol separately, this simplistic view has become somewhat outdated. The desirable LDL level is considered to be less than 100 mg/dL (2.6 mmol/L), although a newer upper limit of 70 mg/dL (1.8 mmol/L) can be considered in higher-risk individuals based on some of the above-mentioned trials. A ratio of total cholesterol to HDL—another useful measure—of far less than 5:1 is thought to be healthier.
Total cholesterol is defined as the sum of HDL, LDL, and VLDL. Usually, only the total, HDL, and triglycerides are measured. For cost reasons, the VLDL is usually estimated as one-fifth of the triglycerides and the LDL is estimated using the Friedewald formula (or a variant): estimated LDL = [total cholesterol] − [total HDL] − [estimated VLDL]. VLDL can be calculated by dividing total triglycerides by five. Direct LDL measures are used when triglycerides exceed 400 mg/dL. The estimated VLDL and LDL have more error when triglycerides are above 400 mg/dL.
Given the well-recognized role of cholesterol in cardiovascular disease, some studies have shown an inverse correlation between cholesterol levels and mortality. A 2009 study of patients with acute coronary syndromes found an association of hypercholesterolemia with better mortality outcomes. In the Framingham Heart Study, in subjects over 50 years of age, they found an 11% increase overall and 14% increase in cardiovascular disease mortality per 1 mg/dL per year drop in total cholesterol levels. The researchers attributed this phenomenon to the fact that people with severe chronic diseases or cancer tend to have below-normal cholesterol levels. This explanation is not supported by the Vorarlberg Health Monitoring and Promotion Programme, in which men of all ages and women over 50 with very low cholesterol were likely to die of cancer, liver diseases, and mental diseases. This result indicates the low-cholesterol effect occurs even among younger respondents, contradicting the previous assessment among cohorts of older people that this is a proxy or marker for frailty occurring with age.
The vast majority of doctors and medical scientists consider that there is a link between cholesterol and atherosclerosis as discussed above; a small group of scientists, united in The International Network of Cholesterol Skeptics, questions the link. A 2014 meta analysis which followed over 500,000 patients, concluded there is insufficient evidence to support the recommendation of high consumption of polyunsaturated fatty acids and low consumption of total saturated fats for cardiovascular health.
Hypocholesterolemia.
Abnormally low levels of cholesterol are termed "hypocholesterolemia". Research into the causes of this state is relatively limited, but some studies suggest a link with depression, cancer, and cerebral hemorrhage. In general, the low cholesterol levels seem to be a consequence, rather than a cause, of an underlying illness. A genetic defect in cholesterol synthesis causes Smith-Lemli-Opitz syndrome, which is often associated with low plasma cholesterol levels.
Cholesterol testing.
The American Heart Association recommends testing cholesterol every five years for people aged 20 years or older. A separate set of American Heart Association guidelines issued in 2013 indicates that patients taking statin medications should have their cholesterol tested 4–12 weeks after their first dose and then every 3–12 months thereafter.
A blood sample after 12-hour fasting is taken by a doctor, or a home cholesterol-monitoring device is used to determine a lipoprotein profile. This measures total cholesterol, LDL (bad) cholesterol, HDL (good) cholesterol, and triglycerides. It is recommended to test cholesterol at least every five years if a person has total cholesterol of 5.2 mmol/L or more (200+ mg/dL), or if a man over age 45 or a woman over age 50 has HDL (good) cholesterol less than 1 mmol/L (40 mg/dL), or there are other risk factors for heart disease and stroke. Other risk factors for heart disease include Diabetes, Hypertension (or use of anti-hypertensive medications), low HDL, family history of CAD and hypercholesterolemia, and cigarette smoking.
Cholesteric liquid crystals.
Some cholesterol derivatives (among other simple cholesteric lipids) are known to generate the liquid crystalline "cholesteric phase". The cholesteric phase is, in fact, a chiral nematic phase, and it changes colour when its temperature changes. This makes cholesterol derivatives useful for indicating temperature in liquid crystal display thermometers and in temperature-sensitive paints.
Stereoisomers.
Cholesterol has 256 stereoisomers, although only two of them are of biochemical significance (nat-cholesterol and ent-cholesterol,) and only one of them occurs naturally (nat-cholesterol).

</doc>
<doc id="6438" url="http://en.wikipedia.org/wiki?curid=6438" title="Chromosome">
Chromosome

A chromosome is packaged and organized chromatin, a complex of macromolecules found in cells, consisting of DNA, protein and RNA. The main information-carrying macromolecule is a single piece of coiled double-stranded DNA, containing many genes, regulatory elements and other non-coding DNA. The DNA-bound macromolecules are proteins, which serve to package the DNA and control its functions. Chromosomes vary widely between different organisms. Some species also contain plasmids or other extrachromosomal DNA.
Compaction of the duplicated chromosomes during mitosis and meiosis results either in a four-arm structure (pictured to the right) if the centromere is located in the middle of the chromosome or a two-arm structure if the centromere is located near one of the ends. Chromosomal recombination during mitosis plays a vital role in genetic diversity. If these structures are manipulated incorrectly, through processes known as chromosomal instability and translocation, the cell may undergo mitotic catastrophe and die, or it may unexpectedly evade apoptosis leading to the progression of cancer.
In prokaryotes (see nucleoids) and viruses, the DNA is often densely packed and organized. In the case of Archaea by homologs to eukaryotic histones, in the case of Bacteria by histone-like proteins. Small circular genomes called plasmids are often found in Bacteria and also in mitochondria and chloroplasts, reflecting their bacterial origins.
History of discovery.
The word "chromosome" comes from the Greek ("chroma", colour) and ("soma", body). Chromatin and chromosomes, are both very strongly stained by particular dyes. 
Schleiden, Virchow and Bütschli were among the first scientists who recognized the structures now so familiar to everyone as chromosomes. The term was coined by von Waldeyer-Hartz, referring to the term chromatin, which was introduced by Walther Flemming.
In a series of experiments beginning in the mid-1880s, Theodor Boveri gave the definitive demonstration that chromosomes are the vectors of heredity. His two principles were the "continuity" of chromosomes and the "individuality" of chromosomes. It is the second of these principles that was so original. Wilhelm Roux suggested that each chromosome carries a different genetic load. Boveri was able to test and confirm this hypothesis. Aided by the rediscovery at the start of the 1900s of Gregor Mendel's earlier work, Boveri was able to point out the connection between the rules of inheritance and the behaviour of the chromosomes. Boveri influenced two generations of American cytologists: Edmund Beecher Wilson, Walter Sutton and Theophilus Painter were all influenced by Boveri (Wilson and Painter actually worked with him).
In his famous textbook "The Cell in Development and Heredity", Wilson linked together the independent work of Boveri and Sutton (both around 1902) by naming the chromosome theory of inheritance the Boveri–Sutton chromosome theory (the names are sometimes reversed). Ernst Mayr remarks that the theory was hotly contested by some famous geneticists: William Bateson, Wilhelm Johannsen, Richard Goldschmidt and T.H. Morgan, all of a rather dogmatic turn of mind. Eventually, complete proof came from chromosome maps in Morgan's own lab.
The number of human chromosomes was published in 1923 by Theophilus Painter. By inspection through the microscope he counted 24 pairs which would mean 48 chromosomes. His error was copied by others and it was not until 1956 that the true number, 46, was determined by Indonesia-born cytogeneticist Joe Hin Tjio.
Prokaryotes.
The prokaryotes – bacteria and archaea – typically have a single circular chromosome, but many variations exist. Most bacteria's chromosome can range in size from only 160,000 base pairs in the endosymbiotic bacterium "Candidatus Carsonella ruddii", to 12,200,000 base pairs in the soil-dwelling bacterium "Sorangium cellulosum". Spirochaetes of the genus "Borrelia" are a notable exception to this arrangement, with bacteria such as "Borrelia burgdorferi", the cause of Lyme disease, containing a single linear chromosome. Some genes, known as Orphons, aren't even in a chromosome at all.
Structure in sequences.
Prokaryotic chromosomes have less sequence-based structure than eukaryotes. Bacteria typically have a single point (the origin of replication) from which replication starts, whereas some archaea contain multiple replication origins. The genes in prokaryotes are often organized in operons, and do not usually contain introns, unlike eukaryotes.
DNA packaging.
Prokaryotes do not possess nuclei. Instead, their DNA is organized into a structure called the nucleoid. The nucleoid is a distinct structure and occupies a defined region of the bacterial cell. This structure is, however, dynamic and is maintained and remodeled by the actions of a range of histone-like proteins, which associate with the bacterial chromosome. In archaea, the DNA in chromosomes is even more organized, with the DNA packaged within structures similar to eukaryotic nucleosomes.
Bacterial chromosomes tend to be tethered to the plasma membrane of the bacteria. In molecular biology application, this allows for its isolation from plasmid DNA by centrifugation of lysed bacteria and pelleting of the membranes (and the attached DNA).
Prokaryotic chromosomes and plasmids are, like eukaryotic DNA, generally supercoiled. The DNA must first be released into its relaxed state for access for transcription, regulation, and replication.
Eukaryotes.
In eukaryotes, nuclear chromosomes are packaged by proteins into a condensed structure called chromatin. This allows the very long DNA molecules to fit into the cell nucleus. The structure of chromosomes and chromatin varies through the cell cycle. Chromosomes are even more condensed than chromatin and are an essential unit for cellular division. Chromosomes must be replicated, divided, and passed successfully to their daughter cells so as to ensure the genetic diversity and survival of their progeny. Chromosomes may exist as either duplicated or unduplicated. Unduplicated chromosomes are single linear strands, whereas duplicated chromosomes contain two identical copies (called chromatids or sister chromatids) joined by a centromere.
Eukaryotes (cells with nuclei such as those found in plants, yeast, and animals) possess multiple large linear chromosomes contained in the cell's nucleus. Each chromosome has one centromere, with one or two arms projecting from the centromere, although, under most circumstances, these arms are not visible as such. In addition, most eukaryotes have a small circular mitochondrial genome, and some eukaryotes may have additional small circular or linear cytoplasmic chromosomes.
In the nuclear chromosomes of eukaryotes, the uncondensed DNA exists in a semi-ordered structure, where it is wrapped around histones (structural proteins), forming a composite material called chromatin.
Chromatin.
Chromatin is the complex of DNA and protein found in the eukaryotic nucleus, which packages chromosomes. The structure of chromatin varies significantly between different stages of the cell cycle, according to the requirements of the DNA.
Interphase chromatin.
During interphase (the period of the cell cycle where the cell is not dividing), two types of chromatin can be distinguished:
Metaphase chromatin and division.
In the early stages of mitosis or meiosis (cell division), the chromatin strands become more and more condensed. They cease to function as accessible genetic material (transcription stops) and become a compact transportable form. This compact form makes the individual chromosomes visible, and they form the classic four arm structure, a pair of sister chromatids attached to each other at the centromere. The shorter arms are called "p arms" (from the French "petit", small) and the longer arms are called "q arms" ("q" follows "p" in the Latin alphabet; q-g "grande"; alternatively it is sometimes said q is short for "queue" meaning tail in French). This is the only natural context in which individual chromosomes are visible with an optical microscope.
During mitosis, microtubules grow from centrosomes located at opposite ends of the cell and also attach to the centromere at specialized structures called kinetochores, one of which is present on each sister chromatid. A special DNA base sequence in the region of the kinetochores provides, along with special proteins, longer-lasting attachment in this region. The microtubules then pull the chromatids apart toward the centrosomes, so that each daughter cell inherits one set of chromatids. Once the cells have divided, the chromatids are uncoiled and DNA can again be transcribed. In spite of their appearance, chromosomes are structurally highly condensed, which enables these giant DNA structures to be contained within a cell nucleus (Fig. 2).
Human chromosomes.
Chromosomes in humans can be divided into two types: autosomes and sex chromosomes. Certain genetic traits are linked to a person's sex and are passed on through the sex chromosomes. The autosomes contain the rest of the genetic hereditary information. All act in the same way during cell division. Human cells have 23 pairs of chromosomes (22 pairs of autosomes and one pair of sex chromosomes), giving a total of 46 per cell. In addition to these, human cells have many hundreds of copies of the mitochondrial genome. Sequencing of the human genome has provided a great deal of information about each of the chromosomes. Below is a table compiling statistics for the chromosomes, based on the Sanger Institute's human genome information in the Vertebrate Genome Annotation (VEGA) database. Number of genes is an estimate as it is in part based on gene predictions. Total chromosome length is an estimate as well, based on the estimated size of unsequenced heterochromatin regions.
Number of chromosomes in various organisms.
Eukaryotes.
These tables give the total number of chromosomes (including sex chromosomes) in a cell nucleus. For example, human cells are diploid and have 22 different types of autosome, each present as two copies, and two sex chromosomes. This gives 46 chromosomes in total. Other organisms have more than two copies of their chromosomes, such as bread wheat, which is "hexaploid" and has six copies of seven different chromosomes – 42 chromosomes in total.
Normal members of a particular eukaryotic species all have the same number of nuclear chromosomes (see the table). Other eukaryotic chromosomes, i.e., mitochondrial and plasmid-like small chromosomes, are much more variable in number, and there may be thousands of copies per cell.
Asexually reproducing species have one set of chromosomes, which are the same in all body cells. However, asexual species can be either haploid or diploid.
Sexually reproducing species have somatic cells (body cells), which are diploid [2n] having two sets of chromosomes (23 pairs in humans with one set of 23 chromosomes from each parent), one set from the mother and one from the father. Gametes, reproductive cells, are haploid [n]: They have one set of chromosomes. Gametes are produced by meiosis of a diploid germ line cell. During meiosis, the matching chromosomes of father and mother can exchange small parts of themselves (crossover), and thus create new chromosomes that are not inherited solely from either parent. When a male and a female gamete merge (fertilization), a new diploid organism is formed.
Some animal and plant species are polyploid [Xn]: They have more than two sets of homologous chromosomes. Plants important in agriculture such as tobacco or wheat are often polyploid, compared to their ancestral species. Wheat has a haploid number of seven chromosomes, still seen in some cultivars as well as the wild progenitors. The more-common pasta and bread wheats are polyploid, having 28 (tetraploid) and 42 (hexaploid) chromosomes, compared to the 14 (diploid) chromosomes in the wild wheat.
Prokaryotes.
Prokaryote species generally have one copy of each major chromosome, but most cells can easily survive with multiple copies. For example, "Buchnera", a symbiont of aphids has multiple copies of its chromosome, ranging from 10–400 copies per cell. However, in some large bacteria, such as "Epulopiscium fishelsoni" up to 100,000 copies of the chromosome can be present. Plasmids and plasmid-like small chromosomes are, as in eukaryotes, highly variable in copy number. The number of plasmids in the cell is almost entirely determined by the rate of division of the plasmid – fast division causes high copy number.
Karyotype.
In general, the karyotype is the characteristic chromosome complement of a eukaryote species. The preparation and study of karyotypes is part of cytogenetics.
Although the replication and transcription of DNA is highly standardized in eukaryotes, "the same cannot be said for their karyotypes", which are often highly variable. There may be variation between species in chromosome number and in detailed organization.
In some cases, there is significant variation within species. Often there is:
Also, variation in karyotype may occur during development from the fertilised egg.
The technique of determining the karyotype is usually called "karyotyping". Cells can be locked part-way through division (in metaphase) in vitro (in a reaction vial) with colchicine. These cells are then stained, photographed, and arranged into a "karyogram", with the set of chromosomes arranged, autosomes in order of length, and sex chromosomes (here X/Y) at the end: Fig. 3.
Like many sexually reproducing species, humans have special gonosomes (sex chromosomes, in contrast to autosomes). These are XX in females and XY in males. 
Historical note.
Investigation into the human karyotype took many years to settle the most basic question: "How many chromosomes does a normal diploid human cell contain?" In 1912, Hans von Winiwarter reported 47 chromosomes in spermatogonia and 48 in oogonia, concluding an XX/XO sex determination mechanism. Painter in 1922 was not certain whether the diploid number of man is 46 or 48, at first favouring 46. He revised his opinion later from 46 to 48, and he correctly insisted on humans having an XX/XY system.
New techniques were needed to definitively solve the problem:
It took until 1954 before the human diploid number was confirmed as 46. Considering the techniques of Winiwarter and Painter, their results were quite remarkable. Chimpanzees (the closest living relatives to modern humans) have 48 chromosomes (as well as the other great apes: in humans two chromosomes fused to form chromosome 2).
Aberrations.
Chromosomal aberrations are disruptions in the normal chromosomal content of a cell and are a major cause of genetic conditions in humans, such as Down syndrome, although most aberrations have little to no effect. Some chromosome abnormalities do not cause disease in carriers, such as translocations, or chromosomal inversions, although they may lead to a higher chance of bearing a child with a chromosome disorder. Abnormal numbers of chromosomes or chromosome sets, called aneuploidy, may be lethal or may give rise to genetic disorders. Genetic counseling is offered for families that may carry a chromosome rearrangement.
The gain or loss of DNA from chromosomes can lead to a variety of genetic disorders. Human examples include:

</doc>
<doc id="6439" url="http://en.wikipedia.org/wiki?curid=6439" title="Charge">
Charge

Charge or charged may refer to:

</doc>
<doc id="6440" url="http://en.wikipedia.org/wiki?curid=6440" title="Colonna family">
Colonna family

The Colonna family is an Italian noble family; it was powerful in medieval and Renaissance Rome, supplying one Pope and many other Church and political leaders. Their family is notable for their bitter feud with the Orsini family over influence in Rome until it was stopped by Papal Bull in 1511; in 1571 the Chiefs of both families married nieces of Pope Sixtus V. Thereafter, historians recorded that, "no peace had been concluded between the princes of Christendom, in which they had not been included by name".
Family history.
Early history.
According to tradition, the Colonna are a branch of the Counts of Tusculum — by Peter (1099–1151) son of Gregory III, called Peter "de Columna" from his property, the Columna Castle, in Colonna, Alban Hills.
The first cardinal from the family was appointed in 1206 when Giovanni Colonna di Carbognano was made Cardinal Deacon of SS. Cosma e Damiano. For many years, cardinal Giovanni di San Paolo (elevated in 1193) was identified as member of the Colonna family and therefore its first representative in the College of Cardinals, but modern scholars have established that this was based on the false information from the beginning of 16th century.
Giovanni Colonna (1206 c.- ), nephew of Cardinal Giovanni Colonna di Carbognano, made his solemn vows as a Dominican c. 1228 and received his theological and philosophical training at the Roman "studium" of Santa Sabina, the forerunner of the Pontifical University of Saint Thomas Aquinas, "Angelicum. He served as the Provincial of the Roman province of the Dominican Order and led the provincial chapter of 1248 at Anagni. Colonna was appointed as Archbishop of Messina in 1255.
At this time a rivalry began with the pro-papal Orsini family, leaders of the Guelph faction. This reinforced the pro-Emperor Ghibelline course that the Colonna family followed throughout the period of conflict between the Papacy and the Holy Roman Empire.
In 1297, Cardinal Jacopo (Giacomo Colonna) disinherited his brothers Ottone, Matteo, and Landolfo of their lands. The latter three appealed to Pope Boniface VIII who ordered Jacopo to return the land, and furthermore hand over the family's strongholds of Colonna, Palestrina, and other towns to the Papacy. Jacopo refused; in May, Boniface removed him from the College of Cardinals and excommunicated him and his followers for four generations.
The Colonna family (aside from the three brothers allied with the Pope) declared that Boniface had been elected illegally following the unprecedented abdication of Pope Celestine V three years previously. The dispute lead to open warfare, and in September Boniface appointed Landolfo to the command of his army, to put down the revolt of Landolfo's own Colonna relatives. This he did, and by the end of 1298 Colonna, Palestrina, and other towns had been captured and razed to the ground. The family's lands were distributed among Landolfo and his loyal brothers; the rest of the family fled Italy.
Family enmity with Pope Boniface VIII led to destruction of the fortress at Palestrina and to the seizure of the Pope at Anagni by Sciarra Colonna in 1303. Sciarra, apparently, smacked the Pope publicly in his face. It was he who, in old age, crowned Louis IV of Bavaria as Holy Roman Emperor in 1328. In honor of this event, the Colonna family was granted the privilege of using the imperial pointed crown on top of their coat of arms.
The family remained at the centre of civic and religious life throughout the late Middle Ages. In 1248, after having dedicated her entire life to serving God and the poor, Margherita Colonna died. A member of the Franciscan Order, she was beatified by Pope Pius IX in 1848.
14th century to 18th century.
In the 14th century, the family sponsored the decoration of the Church of San Giovanni, most notably the floor mosaics. In 1314, Cardinal Egidio Colonna died at Avignon, now in France, where the Popes had withdrawn. An Augustinian, he had studied theology in Paris under St. Thomas of Aquinas to become one of the most authoritative thinkers of his time, and tutor to French king Philip IV the Fair, (1268 - 29 November 1314). The celebrated poet Petrarch, was a great friend of the family, in particular of Giovanni Colonna and often lived in Rome as a guest of the family. He composed a number of sonnets for special occasions within the Colonna family, including "Colonna the Glorious, the great Latin name upon which all our hopes rest". In this period, the Colonna started claiming they were descendants of the Julio-Claudian dynasty (similar spurious claims are common among the old Roman nobility, the Massimo case probably being the best known).
Oddone Colonna (1369-20 February 1431) reigned as Pope Martin V from 14 November 1417 to 20 February 1431.
Vittoria Colonna became famous in the sixteenth century as a poet and a figure in literate circles.
In 1627 Anna Colonna, daughter of Filippo I Colonna, married Taddeo Barberini of the family Barberini; nephew of Pope Urban VIII.
In 1728, the Carbognano branch (Colonna di Sciarra) of the Colonna family added the name Barberini to its family name when Giulio Cesare Colonna di Sciarra married Cornelia Barberini, daughter of the last male Barberini to hold the name and granddaughter of Maffeo Barberini (son of Taddeo Barberini).
Later history.
The Colonna family have been Prince Assistants to the Papal Throne since 1710, though their papal princely title only dates from 1854.
The family residence in Rome, the Palazzo Colonna, is open to the public every Saturday morning.
The main 'Colonna di Paliano' family is represented today by Prince Marcantonio Colonna di Paliano, Prince and Duke of Paliano (b. 1948), whose heir is Don Giovanni Andrea Colonna di Paliano (b. 1975), and by Don Prospero Colonna di Paliano, Prince of Avella (b. 1956), whose heir is Don Filippo Colonna di Paliano (b. 1995).
The 'Colonna di Stigliano' line is represented by Don Prospero Colonna di Stigliano, Prince of Stigliano (b. 1938), whose heir is his nephew Don Stefano Colonna di Stigliano (b. 1975).

</doc>
<doc id="6443" url="http://en.wikipedia.org/wiki?curid=6443" title="Ceuta">
Ceuta

Ceuta (; , "Sibtah") is an autonomous city of Spain and an exclave located on the north coast of Africa, sharing a western border with Morocco. Separated from the Iberian peninsula by the Strait of Gibraltar, Ceuta lies along the boundary between the Mediterranean Sea and the Atlantic Ocean. Ceuta, along with the Spanish exclave Melilla, is one of two permanently inhabited Spanish territories in mainland Africa. It was part of Cádiz province until 14 March 1995, when the city's Statute of Autonomy was passed.
Ceuta, like Melilla, was a free port before Spain joined the European Union. As of 2011, it has a population of 82,376. Its population consists of Christians, Muslims (chiefly Arabic and Berber speakers), and small minorities of Jews and Indian Hindus. Spanish is the official language. The majority of the city's population are ethnic Spanish who are opposed to the idea of being ruled by Morocco. A poll conducted by "Instituto Opina" found that 87.9% of people from mainland Spain consider the two cities (Ceuta and Melilla) to be Spanish.
History.
 After being controlled by the Visigoths, it then became an outpost of the Byzantine Empire (in Greek "Abyla", ). Ceuta was an important Christian center since the fourth century (as recent discovered ruins of a Roman basilica show), and consequently is the only place in the Maghreb where the Roman heritage has survived continuously until modern times.
Around 710, as Muslim armies approached the city, its Byzantine governor, Julian (described as "King of the Ghomara") changed his allegiance, and exhorted the Muslims to invade the Iberian Peninsula. Under the leadership of the Berber general Tariq ibn Ziyad, the Muslims used Ceuta as a staging ground for an assault on Visigothic Iberian Peninsula. After Julian's death, the Berbers took direct control of the city, which the indigenous Berber tribes resented. They destroyed Ceuta during the Kharijite rebellion led by Maysara al-Matghari in 740.
Ceuta lay in ruins until it was resettled in the 9th century by Mâjakas, chief of the Majkasa Berber tribe, who started the short-lived Banu Isam dynasty. His great-grandson briefly allied his tribe with the Idrisids, but the Banu Isam rule ended in 931 when he abdicated in favor of Abd ar-Rahman III, the Umayyad Caliph of Cordoba. Ceuta reverted to Moorish Andalusian rule in 927 along with Melilla, and later Tangier, in 951.
Chaos ensued with the fall of the Umayyad caliphate in 1031. Following this Ceuta and the rest of Muslim Iberia were controlled by successive North African dynasties. Starting in 1084, the Almoravid Berbers ruled the region until 1147, when the Almohads conquered the land. Apart from Ibn Hud's rebellion of 1232, they ruled until the Tunisian Hafsids established control. The Hafsids' influence in the west rapidly waned, and Ceuta's inhabitants eventually expelled them in 1249. After this, a period of political instability persisted, under competing interests from the Kingdom of Fez and the Kingdom of Granada. The Kingdom of Fez finally conquered the region in 1387, with assistance from the Crown of Aragon.
In 1415, during the Battle of Ceuta, the city was captured by the Portuguese during the reign of John I of Portugal. The Benemerine sultan besieged the city in 1418 but was defeated. Phillip II (King of Spain 1556-1598), ascended the Portuguese throne in 1580 and Spanish kings of Portugal governed Ceuta for 60 years (Iberian Union). During this time, Ceuta attracted many residents of Spanish origin. Ceuta became the only city of the Portuguese Empire that sided with Spain when Portugal regained its independence in 1640, and war broke out between the two countries.
On 1 January 1668 by the Treaty of Lisbon, King Afonso VI of Portugal recognized the formal allegiance of Ceuta to Spain and formally ceded Ceuta to King Carlos II of Spain. However, the originally Portuguese flag and coat of arms of Ceuta remained unchanged, and the modern-day Ceuta flag features the configuration of the Portuguese shield. The flag has the same background as that of the flag of the city of Lisbon. The city was besieged by Moroccan forces under Moulay Ismail from 1694 to 1727.
In July 1936, General Francisco Franco took command of the Spanish Army of Africa and rebelled against the Spanish republican government; his military uprising led to the Spanish Civil War of 1936-1939. Franco transported troops to mainland Spain in an airlift using transport aircraft supplied by Germany and Italy. Ceuta became one of the first casualties of the uprising: General Franco's rebel nationalist forces repressed the citizens of Ceuta, while at the same time the city came under fire from the air and sea forces of the official republican government.
A monument was erected to honour Francisco Franco; the Llano Amarillo, inaugurated on 13 July 1940, still stands. The tall obelisk has been abandoned, but the shield symbols of the Falange and Imperial Eagle remain visible.
When Spain recognized the independence of Spanish Morocco in 1956, Ceuta and the other "plazas de soberanía" remained under Spanish rule. Spain considered them integral parts of the Spanish state, but Morocco has disputed this point.
Culturally, modern Ceuta is part of the Spanish region of Andalusia. It was attached to the province of Cádiz until 1925, the Spanish coast being only 20 km (12.5 miles) away. It is a cosmopolitan city, with a large ethnic Berber Muslim minority as well as Sephardic Jewish and Hindu minorities.
On 5 November 2007, King Juan Carlos I visited the city, sparking great enthusiasm from the local population and protests from the Moroccan government. It was the first time a Spanish head of state had visited Ceuta in 80 years.
Since 2010, Ceuta (and Melilla) have declared the Muslim holiday of Eid al-Adha or Feast of the Sacrifice, as an official public holiday. It is the first time a non-Christian religious festival has been officially celebrated in Spain since the Reconquista.
Ecclesiastical history.
The Catholic Diocese of Ceuta existed from 1417 to 1879. It was a suffragan of the Patriarchate of Lisbon until 1675 and the end of the Iberian Union, when Ceuta chose to remain linked to the king of Spain. Since then it has been a suffragan of the archbishopric of Seville. The Diocese of Tanger was suppressed and incorporated to that of Ceuta in 1570. In 1851, upon the signature of the concordat between the Holy See and Spain, the diocese of Ceuta was agreed to be suppressed, being combined into the diocese of Cádiz y Ceuta. Until then in the diocese of Cádiz y Algeciras, the bishop was usually the apostolic administrator of Ceuta. The agreement was not implemented until 1879.
Geography.
Ceuta is dominated by Monte Anyera, a hill along its western frontier with Morocco. The mountain is guarded by a Spanish fort.
Politics.
Since 1995, Ceuta is, along with Melilla, one of the two autonomous cities of Spain.
Ceuta is known officially in Spanish as "Ciudad Autónoma de Ceuta" (English: "Autonomous City of Ceuta"), with a rank between a standard Spanish city and an autonomous community. Ceuta is part of the territory of the European Union. The city was a free port before Spain joined the European Union in 1986. Now it has a low-tax system within the European Monetary System. As of 2006, its population was 75,861.
Ceuta has held elections every four years since 1979, for its 25-seat assembly. The leader of its government was the Mayor until the Autonomy Statute had the title changed to the Mayor-President. In the most recent election in 2011, the People's Party won 18 seats, keeping Juan Jesús Vivas as Mayor-President, which he has been since 2001. The remaining seats are held by the regionalist Caballas Coalition (4) and the Socialist Workers' Party (PSOE, 3).
Ceuta is subdivided into 63 "barriadas" (English: "neighbourhoods"), such as Barriada de Berizu, Barriada de P. Alfonso, Barriada del Sarchal, and El Hacho.
Due to its small population, Ceuta elects only one member of the Congress of Deputies, the lower house of the Spanish legislature. Since the 2011 election, this post is held by Francisco Márquez de la Rubia of the PP.
Dispute with Morocco.
The government of Morocco has repeatedly called for Spain to transfer the sovereignty of Ceuta and Melilla, along with uninhabited islets such as the islands of Alhucemas, Velez and the Perejil island, drawing comparisons with Spain's territorial claim to Gibraltar. In both cases, the national governments and local populations of the disputed territories reject these claims by a large majority. The Spanish position states that both Ceuta and Melilla are integral parts of Spain, and have been since the 16th century, centuries prior to Morocco's independence from France in 1956, whereas Gibraltar, being a British Overseas Territory, is not and never has been part of the United Kingdom. Some argue that Ceuta has been under Christian rule (Spanish or Portuguese) for a longer period than major cities in peninsular Spain such as Málaga, Granada or Almería, and has been so since before the creation of the Spanish state in 1475. Morocco denies these claims and maintains that the Spanish presence in Ceuta and the other "presidios" on its coast is a remnant of the colonial past which should be ended. However, the United Nations list of Non-Self-Governing Territories do not consider those Spanish territories to be colonies, whereas it does declare Gibraltar as a non-decolonized territory. The claims on the Spanish territories is part of the bigger nationalist movement Greater Morocco, that includes Mauritania, Western Sahara, north of Mali and several Algerian provinces. Morocco often uses the nationalistic recovery on the autonomous cities to conceal domestic problems.
Economy.
The official currency of Ceuta is the euro. It is part of a special low tax zone in Spain.
Ceuta is one of two Spanish port cities on the northern shore of Africa, along with Melilla. They are historically military strongholds, free ports, oil ports, and also fishing and smuggling centers. Today the economy of the city depends heavily on its port (now in expansion) and its industrial and retail centres. Ceuta Heliport is now used to connect the city to mainland Spain by air.
Education.
The University of Granada offers undergraduate programs at their campus in Ceuta. Like all areas of Spain, Ceuta is also served by the National University of Distance Education (UNED).
Demographics.
Due to its location, Ceuta is home to a mixed ethnic/religious population. The four main religious groups are Christian, Muslim, Jewish and Hindu. Approximately 50% of the population is Spanish/Christian, approximately 49% Arab-Berber/Muslim, 0.25% Jewish, 0.25% Hindu, and 0.10% Roma.
Transport.
The city receives high numbers of ferries each day, most from Spain. Ferries cross from Algeciras in Andalucia in the south of Spain.
Occasionally, cruise ships stop by. There is a bus service throughout the city which does not pass into neighbouring Morocco.
Ceuta has a regular helicopter service from Ceuta Heliport to mainland Spain.
The closest airport is Sania Ramel Airport.
Religion.
Christianity has been present in Ceuta (called in Roman times "Septum") continuously since the fall of the Western Roman Empire. The ruins of a basilica in downtown Ceuta confirm this reality.
In 1415, on reconquering the city from the Muslims, the Portuguese started the construction of the Cathedral of St. Mary of the Assumption. The Roman Catholic Diocese of Ceuta was established two years later, and was amalgamated with the Roman Catholic Diocese of Cadiz y Ceuta, in 1851. The present cathedral, from the late 17th century, combines baroque and neoclassical elements.
Twin towns – sister cities.
Ceuta is twinned with:

</doc>
<doc id="6444" url="http://en.wikipedia.org/wiki?curid=6444" title="Cleopatra (disambiguation)">
Cleopatra (disambiguation)

Cleopatra (69–30 BC) was the last pharaoh of Egypt, lover of Mark Antony and Julius Caesar.
Cleopatra may also refer to:

</doc>
<doc id="6445" url="http://en.wikipedia.org/wiki?curid=6445" title="Carcinogen">
Carcinogen

A carcinogen is any substance, radionuclide, or radiation that is an agent directly involved in causing cancer. This may be due to the ability to damage the genome or to the disruption of cellular metabolic processes. Several radioactive substances are considered carcinogens, but their carcinogenic activity is attributed to the radiation, for example gamma rays and alpha particles, which they emit. Common examples of non-radioactive carcinogens are inhaled asbestos, certain dioxins, and tobacco smoke. Although the public generally associates carcinogenicity with synthetic chemicals, it is equally likely to arise in both natural and synthetic substances. Carcinogens are not necessarily immediately toxic, thus their effect can be insidious.
Cancer is any disease in which normal cells are damaged and do not undergo programmed cell death as fast as they divide via mitosis. Carcinogens may increase the risk of cancer by altering cellular metabolism or damaging DNA directly in cells, which interferes with biological processes, and induces the uncontrolled, malignant division, ultimately leading to the formation of tumors. Usually, severe DNA damage leads to apoptosis, but if the programmed cell death pathway is damaged, then the cell cannot prevent itself from becoming a cancer cell.
There are many natural carcinogens. Aflatoxin B1, which is produced by the fungus "Aspergillus flavus" growing on stored grains, nuts and peanut butter, is an example of a potent, naturally occurring microbial carcinogen. Certain viruses such as hepatitis B and human papilloma virus have been found to cause cancer in humans. The first one shown to cause cancer in animals is Rous sarcoma virus, discovered in 1910 by Peyton Rous. Other infectious organisms which cause cancer in humans include some bacteria (e.g. "Helicobacter pylori" ) and helminths (e.g. "Opisthorchis viverrini" and "Clonorchis sinensis" ).
Dioxins and dioxin-like compounds, benzene, kepone, EDB, and asbestos have all been classified as carcinogenic. As far back as the 1930s, industrial smoke and tobacco smoke were identified as sources of dozens of carcinogens, including benzo["a"]pyrene, tobacco-specific nitrosamines such as nitrosonornicotine, and reactive aldehydes such as formaldehyde—which is also a hazard in embalming and making plastics. Vinyl chloride, from which PVC is manufactured, is a carcinogen and thus a hazard in PVC production.
Co-carcinogens are chemicals that do not necessarily cause cancer on their own, but promote the activity of other carcinogens in causing cancer.
After the carcinogen enters the body, the body makes an attempt to eliminate it through a process called biotransformation. The purpose of these reactions is to make the carcinogen more water-soluble so that it can be removed from the body. But these reactions can also convert a less toxic carcinogen into a more toxic carcinogen.
DNA is nucleophilic, therefore soluble carbon electrophiles are carcinogenic, because DNA attacks them. For example, some alkenes are toxicated by human enzymes to produce an electrophilic epoxide. DNA attacks the epoxide, and is bound permanently to it. This is the mechanism behind the carcinogenicity of benzo["a"]pyrene in tobacco smoke, other aromatics, aflatoxin and mustard gas.
Radiation.
CERCLA identifies all radionuclides as carcinogens, although the nature of the emitted radiation (alpha, beta, gamma, or neutron and the radioactive strength), its consequent capacity to cause ionization in tissues, and the magnitude of radiation exposure, determine the potential hazard. Carcinogenicity of radiation depends of the type of radiation, type of exposure, and penetration. For example, alpha radiation has low penetration and is not a hazard outside the body, but emitters are carcinogenic when inhaled or ingested.
For example, Thorotrast, a (incidentally radioactive) suspension previously used as a contrast medium in x-ray diagnostics, is a potent human carcinogen known because of its retention within various organs and persistent emission of alpha particles.
Not all types of electromagnetic radiation are carcinogenic. Low-energy waves on the electromagnetic spectrum including radio waves, microwave radiation, infrared radiation and visible light are thought not to be, because they have insufficient energy to break chemical bonds. Evidence for carcinogenic effects of non-ionizing radiation is generally inconclusive, though there are some documented cases of radar technicians with prolonged high exposure experiencing significantly higher cancer incidence. Higher-energy radiation, including ultraviolet radiation (present in sunlight), x-rays, and gamma radiation, generally "is" carcinogenic, if received in sufficient doses.
Low level ionizing radiation may induce irreparable DNA damage (leading to replicational and transcriptional errors needed for neoplasia or may trigger viral interactions) leading to pre-mature aging and cancer.
Substances or foods irradiated with electrons or electromagnetic radiation (such as microwave, X-ray or gamma) are not carcinogenic. In contrast, non-electromagnetic neutron radiation produced inside nuclear reactors can produce secondary radiation through nuclear transmutation.
Carcinogens in prepared food.
Cooking food at high temperatures, for example grilling or barbecuing meats, can lead to the formation of minute quantities of many potent carcinogens that are comparable to those found in cigarette smoke (i.e., benzo["a"]pyrene). Charring of food resembles coking and tobacco pyrolysis, and produces similar carcinogens. There are several carcinogenic pyrolysis products, such as polynuclear aromatic hydrocarbons, which are converted by human enzymes into epoxides, which attach permanently to DNA. Pre-cooking meats in a microwave oven for 2–3 minutes before grilling shortens the time on the hot pan, and removes heterocyclic amine (HCA) precursors, which can help minimize the formation of these carcinogens.
Reports from the Food Standards Agency have found that the known animal carcinogen acrylamide is generated in fried or overheated carbohydrate foods (such as french fries and potato chips). Studies are underway at the FDA and European regulatory agencies to assess its potential risk to humans.
Mechanisms of carcinogenicity.
Carcinogens can be classified as genotoxic or nongenotoxic. Genotoxins cause irreversible genetic damage or mutations by binding to DNA. Genotoxins include chemical agents like N-nitroso-N-methylurea (NMU) or non-chemical agents such as ultraviolet light and ionizing radiation. Certain viruses can also act as carcinogens by interacting with DNA.
Nongenotoxins do not directly affect DNA but act in other ways to promote growth. These include hormones and some organic compounds.
Classification of carcinogens.
International Agency for Research on Cancer.
The International Agency for Research on Cancer (IARC) is an intergovernmental agency established in 1965, which forms part of the World Health Organization of the United Nations. It is based in Lyon, France. Since 1971 it has published a series of "Monographs on the Evaluation of Carcinogenic Risks to Humans" that have been highly influential in the classification of possible carcinogens.
Globally Harmonized System.
The Globally Harmonized System of Classification and Labelling of Chemicals (GHS) is a United Nations initiative to attempt to harmonize the different systems of assessing chemical risk which currently exist (as of March 2009) around the world. It classifies carcinogens into two categories, of which the first may be divided again into subcategories if so desired by the competent regulatory authority:
U.S. National Toxicology Program.
The National Toxicology Program of the U.S. Department of Health and Human Services is mandated to produce a biennial "Report on Carcinogens". As of June 2011, the latest edition was the 12th report (2011). It classifies carcinogens into two groups:
American Conference of Governmental Industrial Hygienists.
The American Conference of Governmental Industrial Hygienists (ACGIH) is a private organization best known for its publication of threshold limit values (TLVs) for occupational exposure and monographs on workplace chemical hazards. It assesses carcinogenicity as part of wider assessment of the occupational hazards of chemicals.
European Union.
The European Union classification of carcinogens is contained in the Dangerous Substances Directive and the Dangerous Preparations Directive. It consists of three categories:
This assessment scheme is being phased out in favor of the GHS scheme (see above), to which it is very close in category definitions.
Safe Work Australia.
Under a previous name, the NOHSC, in 1999 Safe Work Australia published the Approved Criteria for Classifying Hazardous Substances [NOHSC:1008(1999)].
Section 4.76 of this document outlines the criteria for classifying carcinogens as approved by the Australian government. This classification consists of three categories:
Procarcinogen.
A procarcinogen is a precursor to a carcinogen. One example is nitrites when taken in by the diet. They are not carcinogenic themselves, but turn into nitrosamines in the body, which are carcinogenic.
Common carcinogens.
Occupational carcinogens.
Occupational carcinogens are agents that pose a risk of cancer in several specific work-locations:
Major carcinogens implicated in the four most common cancers worldwide.
In this section, the carcinogens implicated as the main causative agents of the four most common cancers worldwide are briefly described. These four cancers are lung, breast, colon, and stomach cancers. Together they account for about 41% of worldwide cancer incidence and 42% of cancer deaths (for more detailed information on the carcinogens implicated in these and other cancers, see references).
Lung cancer.
Lung cancer is the most common cancer in the world, both in terms of cases (1.6 million cases; 12.7% of total cancer cases) and deaths (1.4 million deaths; 18.2% of total cancer deaths). Lung cancer is largely caused by tobacco smoke. Risk estimates for lung cancer in the United States indicate that tobacco smoke is responsible for 90% of lung cancers. Other factors are implicated in lung cancer, and these factors can interact synergistically with smoking, so that total attributable risk adds up to more than 100%. These factors include occupational exposure to carcinogens (about 9-15%), radon (10%) and outdoor air pollution (1-2%). Tobacco smoke is a complex mixture of more than 5,300 identified chemicals. The most important carcinogens in tobacco smoke have been determined by a “Margin of Exposure” approach. Using this approach, the most important tumorigenic compounds in tobacco smoke were, in order of importance, acrolein, formaldehyde, acrylonitrile, 1,3-butadiene, cadmium, acetaldehyde, ethylene oxide and isoprene. Most of these compounds cause DNA damage by forming DNA adducts or by inducing other alterations in DNA. DNA damages are subject to error-prone DNA repair or can cause replication errors. Such errors in repair or replication can result in mutations in tumor suppressor genes or oncogenes leading to cancer.
Breast cancer.
Breast cancer is the second most common cancer [(1.4 million cases, 10.9%), but ranks 5th as cause of death (458,000, 6.1%)]. Increased risk of breast cancer is associated with persistently elevated blood levels of estrogen. Estrogen appears to contribute to breast carcinogenesis by three processes; (1) the metabolism of estrogen to genotoxic, mutagenic carcinogens, (2) the stimulation of tissue growth, and (3) the repression of phase II detoxification enzymes that metabolize ROS leading to increased oxidative DNA damage. The major estrogen in humans, estradiol, can be metabolized to quinone derivatives that form adducts with DNA. These derivatives can cause dupurination, the removal of bases from the phosphodiester backbone of DNA, followed by inaccurate repair or replication of the apurinic site leading to mutation and eventually cancer. This genotoxic mechanism may interact in synergy with estrogen receptor-mediated, persistent cell proliferation to ultimately cause breast cancer. Genetic background, dietary practices and environmental factors also likely contribute to the incidence of DNA damage and breast cancer risk.
Colon cancer.
Colorectal cancer is the third most common cancer [1.2 million cases (9.4%), 608,000 deaths (8.0%)]. Tobacco smoke may be responsible for up to 20% of colorectal cancers in the United States. In addition, substantial evidence implicates bile acids as an important factor in colon cancer. Twelve studies (summarized in Bernstein et al.) indicate that the bile acids deoxycholic acid (DCA) and/or lithocholic acid (LCA) induce production of DNA damaging reactive oxygen species and/or reactive nitrogen species in human or animal colon cells. Furthermore 14 studies showed that DCA and LCA induce DNA damage in colon cells. Also 27 studies reported that bile acids cause programmed cell death (apoptosis). Increased apoptosis can result in selective survival of cells that are resistant to induction of apoptosis. Colon cells with reduced ability to undergo apoptosis in response to DNA damage would tend to accumulate mutations, and such cells may give rise to colon cancer. Epidemiologic studies have found that fecal bile acid concentrations are increased in populations with a high incidence of colon cancer. Dietary increases in total fat or saturated fat result in elevated DCA and LCA in feces and elevated exposure of the colon epithelium to these bile acids. When the bile acid DCA was added to the standard diet of wild-type mice invasive colon cancer was induced in 56% of the mice after 8 to 10 months. Overall, the available evidence indicates that DCA and LCA are centrally important DNA-damaging carcinogens in colon cancer.
Stomach cancer.
Stomach cancer is the fourth most common cancer [990,000 cases (7.8%), 738,000 deaths (9.7%)]. "Helicobacter pylori" infection is the main causative factor in stomach cancer. Chronic gastritis (inflammation) caused by "H. pylori" is often long-standing if not treated. Infection of gastric epithelial cells with "H. pylori" results in increased production of reactive oxygen species (ROS). ROS cause oxidative DNA damage including the major base alteration 8-hydroxydeoxyguanosine (8-OHdG). 8-OHdG resulting from ROS is increased in chronic gastritis. The altered DNA base can cause errors during DNA replication that have mutagenic and carcinogenic potential. Thus "H. pylori"-induced ROS appear to be the major carcinogens in stomach cancer because they cause oxidative DNA damage leading to carcinogenic mutations.

</doc>
<doc id="6446" url="http://en.wikipedia.org/wiki?curid=6446" title="Camouflage">
Camouflage

Camouflage is the use of any combination of materials, coloration or illumination for concealment, either by making animals or objects hard to see (crypsis), or by disguising them as something else (mimesis). Examples include the leopard's spotted coat, the battledress of a modern soldier, and the leaf-mimic katydid's wings. A third approach, motion dazzle, confuses the observer with a conspicuous pattern, making the object visible but momentarily harder to locate. The majority of camouflage methods aim for crypsis, often through a general resemblance to the background, high contrast disruptive coloration, eliminating shadow, and countershading. In the open ocean, where there is no background, the principal methods of camouflage are transparency, silvering, and countershading, while the ability to produce light is among other things used for counter-illumination on the undersides of cephalopods such as squid. Some animals, such as chameleons and octopuses, are capable of actively changing their skin pattern and colours, whether for camouflage or for signalling.
Military camouflage was spurred by the increasing range and accuracy of firearms in the 19th century. In particular the replacement of the inaccurate musket with the rifle made personal concealment in battle a survival skill. In the 20th century, military camouflage developed rapidly, especially during the First World War. On land, artists such as André Mare designed camouflage schemes and observation posts disguised as trees. At sea, warships and troop carriers were painted in dazzle patterns that were highly visible, but designed to confuse enemy gunners as to the target's speed, range, and heading. During and after the Second World War, a variety of camouflage schemes were used for aircraft and for ground vehicles in different theatres of war. The use of radar in the Cold War period has largely made camouflage for fixed-wing military aircraft obsolete.
Non-military use of camouflage includes making cell telephone towers less obtrusive and helping hunters to approach wary game animals. Patterns derived from military camouflage are frequently used in fashion clothing, exploiting their strong designs and sometimes their symbolism. Camouflage themes recur in modern art, and both figuratively and literally in science fiction and works of literature.
History.
In zoology.
In ancient Greece, Aristotle (384 BC – 322 BC) commented on the colour-changing abilities, both for camouflage and for signalling, of cephalopods including the octopus, in his "Historia animalium":
Camouflage has been a topic of interest and research in zoology for well over a century. According to Charles Darwin's 1859 theory of natural selection, features such as camouflage evolved by providing individual animals with a reproductive advantage, enabling them to leave more offspring, on average, than other members of the same species. In his "Origin of Species", Darwin wrote:
The English zoologist Edward Bagnall Poulton studied animal coloration, especially camouflage. In his 1890 book "The Colours of Animals", he classified different types such as "special protective resemblance" (where an animal looks like another object), or "general aggressive resemblance" (where a predator blends in with the background, enabling it to approach prey). His experiments showed that swallowtailed moth pupae were camouflaged to match the backgrounds on which they were reared as larvae. Poulton's "general protective resemblance" was at that time considered to be the main method of camouflage, as when Frank Evers Beddard wrote in 1892 that "tree-frequenting animals are often green in colour. Among vertebrates numerous species of parrots, iguanas, tree-frogs, and the green tree-snake are examples". Beddard did however briefly mention other methods, including the "alluring coloration" of the flower mantis and the possibility of a different mechanism in the orange tip butterfly. He wrote that "the scattered green spots upon the under surface of the wings might have been intended for a rough sketch of the small flowerets of the plant [an umbellifer], so close is their mutual resemblance." He also explained the coloration of sea fish such as the mackerel: "Among pelagic fish it is common to find the upper surface dark-coloured and the lower surface white, so that the animal is inconspicuous when seen either from above or below."
The artist Abbott Handerson Thayer formulated what is sometimes called Thayer's Law, the principle of countershading. However, he overstated the case in the 1909 book "Concealing-Coloration in the Animal Kingdom", arguing that "All patterns and colors whatsoever of all animals that ever preyed or are preyed on are under certain normal circumstances obliterative" (that is, cryptic camouflage), and that "Not one 'mimicry' mark, not one 'warning color'... nor any 'sexually selected' color, exists anywhere in the world where there is not every reason to believe it the very best conceivable device for the concealment of its wearer", and using paintings such as "Peacock in the Woods" (1907) to reinforce his argument.
The English zoologist Hugh Cott's 1940 book "Adaptive Coloration in Animals" corrected Thayer's errors, sometimes sharply: "Thus we find Thayer straining the theory to a fantastic extreme in an endeavour to make it cover almost every type of coloration in the animal kingdom." Cott built on Thayer's discoveries, developing a comprehensive view of camouflage based on "maximum disruptive contrast", countershading and hundreds of examples. The book explained how disruptive camouflage worked, using streaks of boldly contrasting colour, paradoxically making objects less visible by breaking up their outlines. While Cott was more systematic and balanced in his view than Thayer, and did include some experimental evidence on the effectiveness of camouflage, his 500 page textbook was, like Thayer's, mainly a natural history narrative which illustrated theories with examples.
Camouflage is a soft-tissue feature that is rarely preserved in the fossil record, but rare fossilised skin samples from the Cretaceous period show that some marine reptiles were countershaded. The skins, pigmented with dark-coloured eumelanin, reveal that both leatherback turtles and mosasaurs had dark backs and light bellies.
Military.
Before 1800.
Ship camouflage was occasionally used in ancient times. Philostratus (c. 172–250 AD) wrote in his "Imagines" that Mediterranean pirate ships could be painted blue-gray for concealment. Vegetius (c. 360–400 AD) says that "Venetian blue" (sea green) was used in the Gallic Wars, when Julius Caesar sent his "speculatoria navigia" (reconnaissance boats) to gather intelligence along the coast of Britain. The ships were painted entirely in bluish-green wax, with sails, ropes and crew the same colour. There is little evidence of military use of camouflage on land before 1800, but two unusual ceramics show men in Peru's Mochica culture from before 500 AD, hunting birds with blowpipes which are fitted with a kind of shield near the mouth, perhaps to conceal the hunters' hands and faces. Another early source is a fifteenth-century French manuscript, "The Hunting Book of Gaston Phebus", showing a horse pulling a cart which contains a hunter armed with a crossbow under a cover of branches, perhaps serving as a hide for shooting game. Jamaican Maroons are said to have used plant materials as camouflage in the First Maroon War (c. 1655–1740).
19th century origins.
The development of military camouflage was driven by the increasing range and accuracy of infantry firearms in the 19th century. In particular the replacement of the inaccurate musket with weapons such as the Baker rifle made personal concealment in battle essential. For example, two Napoleonic War skirmishing units of the British Army, the 95th Rifle Regiment and the 60th Rifle Regiment, were the first to adopt camouflage in the form of a rifle green jacket, while the Line regiments continued to wear scarlet tunics. A contemporary study in 1800 by the English artist and soldier Charles Hamilton Smith provided evidence that grey uniforms were less visible than green ones at a range of 150 yards.
In the American Civil War, rifle units such as the 1st United States Sharp Shooters (in the Federal army) similarly wore green jackets while other units wore more conspicuous colours. The first British Army unit to adopt khaki uniforms was the Corps of Guides at Peshawar, when Sir Harry Lumsden and his second in command, William Hodson introduced a "drab" uniform in 1848. Hodson wrote that it would be more appropriate for the hot climate, and help make his troops "invisible in a land of dust". Later they improvised by dyeing cloth locally. Other regiments in India soon adopted the khaki uniform, and by 1896 khaki drill uniform was used everywhere outside Europe; by the Second Boer War six years later it was used throughout the British Army.
First World War.
In the First World War, the French army formed a camouflage corps, led by Lucien-Victor Guirand de Scévola, employing artists known as "camoufleurs" to create schemes such as tree observation posts and covers for guns. Other armies soon followed them. The term "camouflage" probably comes from "camoufler", a Parisian slang term meaning "to disguise", and may have been influenced by "camouflet", a French term meaning "smoke blown in someone's face". The English zoologist John Graham Kerr and artist Solomon J Solomon, and the American artist Abbott Thayer, led attempts to introduce scientific principles of countershading and disruptive patterning into military camouflage, with limited success.
Ship camouflage was introduced in the early twentieth century as the range of naval guns increased, with ships painted grey all over. In April 1917, when German U-boats were sinking many British ships with torpedoes, the marine artist Norman Wilkinson devised dazzle camouflage, which paradoxically made ships more visible but harder to target. In Wilkinson's own words, dazzle was designed "not for low visibility, but in such a way as to break up her form and thus confuse a submarine officer as to the course on which she was heading".
Second World War.
In the Second World War, the zoologist Hugh Cott, a protégé of Kerr, worked to persuade the British army to use more effective camouflage techniques, including countershading, but, like Kerr and Thayer in the First World War, with limited success. For example, he painted two rail-mounted coastal guns, one in conventional style, one countershaded. In aerial photographs, the countershaded gun was essentially invisible. The power of aerial observation and attack led every warring nation to camouflage targets of all types. The Soviet Union's Red Army created the comprehensive doctrine of "Maskirovka" for military deception, including the use of camouflage. For example, during the Battle of Kursk, General Katukov, the commander of the Soviet 1st Tank Army, remarked that the enemy "did not suspect that our well-camouflaged tanks were waiting for him. As we later learned from prisoners, we had managed to move our tanks forward unnoticed". The tanks were concealed in previously prepared defensive emplacements, with only their turrets above ground level. In the air, Second World War fighters were often painted in ground colours above and sky colours below, attempting two different camouflage schemes for observers above and below. Bombers and night fighters were often black, while maritime reconnaissance planes were usually white, to avoid appearing as dark shapes against the sky. For ships, dazzle camouflage was mainly replaced with plain grey in the Second World War, though experimentation with colour schemes continued.
As in the First World War, artists were pressed into service; for example, the surrealist painter Roland Penrose became a lecturer at the newly founded Camouflage Development and Training Centre at Farnham Castle, writing the practical "Home Guard Manual of Camouflage". The film-maker Geoffrey Barkas ran the Middle East Command Camouflage Directorate during the 1941–1942 war in the Western Desert, including the successful deception of Operation Bertram. Hugh Cott was chief instructor; the artist camouflage officers, who called themselves "camoufleurs", included Steven Sykes and Tony Ayrton. In Australia, artists were also prominent in the Sydney Camouflage Group, formed under the chairmanship of Professor William John Dakin, a zoologist from Sydney University. Max Dupain, Sydney Ure Smith and William Dobell were among the members of the group, which worked at Bankstown Airport, RAAF Base Richmond and Garden Island Dockyard.
After 1945.
Camouflage has been used to protect military equipment such as vehicles, guns, ships, aircraft and buildings as well as individual soldiers and their positions.
Vehicle camouflage techniques begin with paint, which offers at best only limited effectiveness. Other methods for stationary land vehicles include covering with improvised materials such as blankets and vegetation, and erecting nets, screens and soft covers which may suitably reflect, scatter or absorb near infrared and radar waves. Some military textiles and vehicle camouflage paints also reflect infrared to help provide concealment from night vision devices. 
After the Second World War, radar made camouflage generally less effective, though coastal boats are sometimes painted like land vehicles. Aircraft camouflage too came to be seen as less important because of radar, and aircraft of different air forces, such as the Royal Air Force's Lightning, were often uncamouflaged.
Many camouflaged textile patterns have been developed to suit the need to match combat clothing to different kinds of terrain (such as woodland, snow, and desert). The design of a pattern effective in all terrains has proved elusive. The American Universal Camouflage Pattern of 2004 attempted to suit all environments, but was withdrawn after a few years of service. Terrain-specific patterns have sometimes been developed but are ineffective in other terrains. The problem of making a pattern that works at different ranges has been solved with pixellated shapes, often designed digitally, that provide a fractal-like range of patch sizes so they appear disruptively coloured both at close range and at a distance. The first genuinely digital camouflage pattern was the Canadian CADPAT, soon followed by the American MARPAT. A pixellated appearance is not essential for this effect, though it is simpler to design and to print.
Principles.
Camouflage can be achieved by different methods, described below. Most of the methods contribute to crypsis, helping to hide against a background; but mimesis and motion dazzle protect without hiding. Methods may be applied on their own or in combination.
Crypsis.
Crypsis means blending with the background, making the animal or military equipment hard to see (or to detect in other ways, such as by sound or scent: for details, see crypsis). Visual crypsis can be achieved in many different ways, which are described below.
Resemblance to the surroundings.
Some animals' colours and patterns resemble a particular natural background. This is an important component of camouflage in all environments. For instance, tree-dwelling parakeets are mainly green; woodcocks of the forest floor are brown and speckled; reedbed bitterns are streaked brown and buff; in each case the animal's coloration matches the hues of its habitat. Similarly, desert animals are almost all desert coloured in tones of sand, buff, ochre, and brownish grey, whether they are mammals like the gerbil or fennec fox, birds such as the desert lark or sandgrouse, or reptiles like the skink or horned viper. Military uniforms, too, generally resemble their backgrounds; for example khaki uniforms are a muddy or dusty colour, originally chosen for service in South Asia. Many moths show industrial melanism, including the peppered moth which has coloration that blends in with tree bark. The coloration of these insects evolved between 1860 and 1940 to match the changing colour of the tree trunks on which they rest, from pale and mottled to almost black in polluted areas. This is taken by zoologists as evidence that camouflage is influenced by natural selection, as well as demonstrating that it changes where necessary to resemble the local background.
Disruptive coloration.
Disruptive patterns use strongly contrasting, non-repeating markings such as spots or stripes to break up the outlines of an animal or military vehicle, or to conceal telltale features, especially the eyes, as in the common frog. Disruptive patterns may use more than one method to defeat visual systems such as edge detection. Predators like the leopard use disruptive camouflage to help them approach prey, while potential prey like the Egyptian nightjar use it to avoid detection by predators. Disruptive patterning is common in military usage, both for uniforms and for military vehicles. Disruptive patterning, however, does not always achieve crypsis on its own, as an animal or a military target may be given away by factors like shape, shine, and shadow.
The presence of bold skin markings does not in itself prove that an animal relies on camouflage, as that depends on its behaviour. For example, although giraffes have a high contrast pattern that could be disruptive coloration, the adults are extremely conspicuous when in the open. Some authors have argued that adult giraffes are cryptic, since when standing among trees and bushes they are hard to see at even a few metres' distance. However, adult giraffes move about to gain the best view of an approaching predator, relying on their size and ability to defend themselves, even from lions, rather than on camouflage. A different explanation is implied by the fact that young giraffes are far more vulnerable to predation than adults: more than half of all giraffe calves die within a year, and giraffe mothers hide their calves, which spend much of the time lying down in cover while their mothers are away feeding. Since the presence of a mother nearby does not affect survival, it is argued that young giraffes must be extremely well camouflaged; this is supported by the fact that coat markings are strongly inherited.
Eliminating shadow.
Some animals, such as the Horned Lizards of North America, have evolved elaborate measures to eliminate shadow. Their bodies are flattened, with the sides thinning to an edge; the animals habitually press their bodies to the ground; and their sides are fringed with white scales which effectively hide and disrupt any remaining areas of shadow there may be under the edge of the body. The theory that the body shape of the Horned Lizards which live in open desert is adapted to minimise shadow is supported by the one species which lacks fringe scales, the roundtail horned lizard, which lives in rocky areas and resembles a rock. When this species is threatened, it makes itself look as much like a rock as possible by curving its back, emphasizing its three-dimensional shape. Some species of butterflies, such as the Speckled Wood, "Pararge aegeria", minimise their shadows when perched by closing the wings over their backs, aligning their bodies with the sun, and tilting to one side towards the sun, so that the shadow becomes a thin inconspicuous line rather than a broad patch. Similarly, some ground-nesting birds including the European nightjar select a resting position facing the sun. The elimination of shadow was identified as a principle of military camouflage during the Second World War.
Self-decoration.
Some animals actively seek to hide by decorating themselves with materials such as twigs, sand, or pieces of shell from their environment, to break up their outlines, to conceal the features of their bodies, and to match their backgrounds. For example, a caddis fly larva builds a decorated case and lives almost entirely inside it; a decorator crab covers its back with seaweed, sponges and stones. The nymph of the predatory masked bug uses its hind legs and a 'tarsal fan' to decorate its body with sand or dust. There are two layers of bristles (trichomes) over the body. On these, the nymph spreads an inner layer of fine particles and an outer layer of coarser particles. The camouflage may conceal the bug from both predators and prey.
Similar principles can be applied for military purposes, for instance when a sniper wears a ghillie suit designed to be further camouflaged by decoration with materials such as tufts of grass from the sniper's immediate environment. Such suits were used as early as 1916, the British army having adopted "coats of motley hue and stripes of paint" for snipers. Cott takes the example of the larva of the blotched emerald moth, which fixes a screen of fragments of leaves to its specially hooked bristles, to argue that military camouflage uses the same method, pointing out that the "device is ... essentially the same as one widely practised during the Great War for the concealment, not of caterpillars, but of caterpillar-tractors, [gun] battery positions, observation posts and so forth."
Cryptic behaviour.
Movement catches the eye of prey animals on the lookout for predators, and of predators hunting for prey. Most methods of crypsis therefore also require suitable cryptic behaviour, such as lying down and keeping still to avoid being detected, or in the case of stalking predators such as the tiger, moving with extreme stealth, both slowly and quietly, watching its prey for any sign they are aware of its presence. As an example of the combination of behaviours and other methods of crypsis involved, young giraffes seek cover, lie down, and keep still, often for hours until their mothers return; their skin pattern blends with the pattern of the vegetation, while the chosen cover and lying position together hide the animals' shadows. The flat-tail horned lizard similarly relies on a combination of methods: it is adapted to lie flat in the open desert, relying on stillness, its cryptic coloration, and concealment of its shadow to avoid being noticed by predators. In the ocean, the leafy sea dragon sways mimetically, like the seaweeds amongst which it rests, as if rippled by wind or water currents.
Motion camouflage.
Most forms of camouflage are ineffective when the camouflaged animal or object moves, because the motion is easily seen by the observing predator, prey or enemy. However, insects such as hoverflies and dragonflies use motion camouflage: the hoverflies to approach possible mates, and the dragonflies to approach rivals when defending territories. Motion camouflage is achieved by moving so as to stay on a straight line between the target and a fixed point in the landscape; the pursuer thus appears not to move, but only to loom larger in the target's field of vision. The same technique can be used for military purposes, for example by missiles to minimise their risk of detection by the enemy. However, missile engineers, and animals such as bats, use the technique primarily for its efficiency rather than camouflage.
Changeable skin pattern / colour.
Animals such as chameleon, frog, flatfish, squid and octopus actively change their skin patterns and colours using special chromatophore cells to resemble their current background (as well as for signalling).
Each chromatophore contains pigment of only one colour. In fish and frogs, colour change is mediated by the type of chromatophores known as melanophores that contain dark pigment. A melanophore is star-shaped; it contains many small pigmented organelles which can be dispersed throughout the cell, or aggregated near its centre. When the pigmented organelles are dispersed, the cell makes a patch of the animal's skin appear dark; when they are aggregated, most of the cell, and the animal's skin, appears light. In frogs, the change is controlled relatively slowly, mainly by hormones. In fish, the change is controlled by the brain, which sends signals directly to the chromatophores, as well as producing hormones.
The skins of cephalopods such as the octopus contain complex units, each consisting of a chromatophore with surrounding muscle and nerve cells. The cephalopod chromatophore has all its pigment grains in a small elastic sac, which can be stretched or allowed to relax under the control of the brain to vary its opacity. By controlling chromatophores of different colours, cephalopods can rapidly change their skin patterns and colours.
On a longer timescale, animals like the arctic hare, arctic fox, stoat, and rock ptarmigan change their coat colour (by moulting and growing new fur or feathers) from brown or grey in the summer to white in the winter; the arctic fox is the only species in the dog family to do so. However, arctic hares which live in the far north of Canada, where summer is very short, remain white year-round.
The principle of varying coloration either rapidly or with the changing seasons has military applications. "Active camouflage" could in theory make use of both dynamic colour change and counterillumination. Simple techniques such as changing uniforms and repainting vehicles for winter have been in use since the Second World War. In 2011, BAE Systems announced their Adaptiv infrared camouflage technology. It uses about 1000 hexagonal panels to cover the sides of a tank. The panels are heated and cooled to match either the vehicle's surroundings (crypsis), or an object such as a car (mimesis), when viewed in infrared.
Countershading.
Countershading uses graded colour to counteract the effect of self-shadowing, creating an illusion of flatness. Self-shadowing makes an animal appear darker below than on top, grading from light to dark; countershading 'paints in' tones which are darkest on top, lightest below, making the countershaded animal nearly invisible against a suitable background. Thayer observed that "Animals are painted by Nature, darkest on those parts which tend to be most lighted by the sky's light, and "vice versa"". Accordingly the principle of countershading is sometimes called "Thayer's Law". Countershading is widely used by terrestrial animals, such as gazelles and grasshoppers; marine animals, such as sharks and dolphins; and birds, such as snipe and dunlin.
Countershading is less often used for military camouflage, despite Second World War experiments that showed its effectiveness. English zoologist Hugh Cott encouraged the use of techniques including countershading, but despite his authority on the subject, failed to persuade the British authorities. Soldiers often wrongly viewed camouflage netting as a kind of invisibility cloak, and they had to be taught to look at camouflage practically, from the enemy observer's point of view. At the same time in Australia, zoologist William John Dakin advised soldiers to copy animals' methods, using their instincts for wartime camouflage.
The term countershading has a second meaning unrelated to "Thayer's Law". It is that the upper and undersides of animals such as sharks, and of some military aircraft, are different colours to match the different backgrounds when seen from above or from below. Here the camouflage consists of two surfaces, each with the simple function of providing concealment against a specific background, such as a bright water surface or the sky. The body of a shark or the fuselage of an aircraft is not gradated from light to dark to appear flat when seen from the side. The camouflage techniques used are the matching of background colour and pattern, and disruption of outlines.
Counterillumination.
Counterillumination means producing light to match a background that is brighter than an animal's body or military vehicle; it is a form of active camouflage. It is notably used by some species of squid, such as the firefly or sparkling enope squid and the midwater squid. The latter has light-producing organs (photophores) scattered all over its underside; these create a sparkling glow that prevents the animal from appearing as a dark shape when seen from below. Counterillumination camouflage is the likely function of the bioluminescence of many marine organisms, though light is also produced to attract or to detect prey and for signalling.
Counterillumination has rarely been used for military purposes. "Diffused lighting camouflage" was trialled by Canada's National Research Council during the Second World War. It involved projecting light on to the sides of ships to match the faint glow of the night sky, requiring awkward external platforms to support the lamps. The Canadian concept was refined in the American Yehudi lights project, and trialled in aircraft including B-24 Liberators and naval Avengers. The planes were fitted with forward-pointing lamps automatically adjusted to match the brightness of the night sky. This enabled them to approach much closer to a target – within 3,000 yards (2,700 metres) – before being seen. Counterillumination was made obsolete by radar, and neither diffused lighting camouflage nor Yehudi lights entered active service.
Transparency.
Many marine animals that float near the surface are highly transparent, giving them almost perfect camouflage. However, transparency is difficult for bodies made of materials that have different refractive indices from seawater. Some marine animals such as jellyfish have gelatinous bodies, composed mainly of water; their thick mesogloea is acellular and highly transparent. This conveniently makes them buoyant, but it also makes them large for their muscle mass, so they cannot swim fast, making this form of camouflage a costly trade-off with mobility. Gelatinous planktonic animals are between 50 and 90 percent transparent. A transparency of 50 percent is enough to make an animal invisible to a predator such as cod at a depth of ; better transparency is required for invisibility in shallower water, where the light is brighter and predators can see better. For example, a cod can see prey that are 98 percent transparent in optimal lighting in shallow water. Therefore, sufficient transparency for camouflage is more easily achieved in deeper waters.
Some tissues such as muscles can be made transparent, provided either they are very thin or organised as regular layers or fibrils that are small compared to the wavelength of visible light. A familiar example is the transparency of the lens of the vertebrate eye, which is made of the protein crystallin, and the vertebrate cornea which is made of the protein collagen. Other structures cannot be made transparent, notably the retinas or equivalent light-absorbing structures of eyes — they must absorb light to be able to function. The camera-type eye of vertebrates and cephalopods must be completely opaque. Finally, some structures are visible for a reason, such as to lure prey. For example, the nematocysts (stinging cells) of the transparent siphonophore "Agalma okenii" resemble small copepods. Examples of transparent marine animals include a wide variety of larvae, including coelenterates, siphonophores, salps (floating tunicates), gastropod molluscs, polychaete worms, many shrimplike crustaceans, and fish; whereas the adults of most of these are opaque and pigmented, resembling the seabed or shores where they live. Adult comb jellies and jellyfish obey the rule, often being mainly transparent. Cott suggests this follows the more general rule that animals resemble their background: in a transparent medium like seawater, that means actually being transparent. The small Amazon river fish "Microphilypnus amazonicus" and the shrimps it associates with, "Pseudopalaemon gouldingi", are so transparent as to be "almost invisible"; further, these species appear to select whether to be transparent or more conventionally mottled (disruptively patterned) according to the local background in the environment.
Silvering.
Where transparency cannot be achieved, it can be imitated effectively by silvering to make an animal's body highly reflective. At medium depths at sea, light comes from above, so a mirror oriented vertically makes animals such as fish invisible from the side. Most fish in the upper ocean such as sardine and herring are camouflaged by silvering.
The marine hatchetfish is extremely flattened laterally, leaving the body just millimetres thick, and the body is so silvery as to resemble aluminium foil. The mirrors consist of microscopic structures similar to those used to provide structural coloration: stacks of between 5 and 10 crystals of guanine spaced about ¼ of a wavelength apart to interfere constructively and achieve nearly 100 per cent reflection. In the deep waters that the hatchetfish lives in, only blue light with a wavelength of 500 nanometres percolates down and needs to be reflected, so mirrors 125 nanometres apart provide good camouflage.
In fish such as the herring which live in shallower water, the mirrors must reflect a mixture of wavelengths, and the fish accordingly has crystal stacks with a range of different spacings. A further complication for fish with bodies that are rounded in cross-section is that the mirrors would be ineffective if laid flat on the skin, as they would fail to reflect horizontally. The overall mirror effect is achieved with many small reflectors, all oriented vertically. Silvering is found in other marine animals as well as fish. The cephalopods, including squid, octopus and cuttlefish, have multi-layer mirrors made of protein rather than guanine.
Mimesis.
In mimesis (also called "masquerade"), the camouflaged object looks like something else which is of no special interest to the observer. Mimesis is common in prey animals, for example when a peppered moth caterpillar mimics a twig, or a grasshopper mimics a dry leaf.
Mimesis is also employed by some predators and parasites to lure their prey. For example, a flower mantis mimics a particular kind of flower, such as an orchid. This tactic has occasionally been used in warfare, for example with heavily armed Q-ships disguised as merchant ships.
The common cuckoo, a brood parasite, provides examples of mimesis both in the adult and in the egg. The female lays her eggs in nests of other, smaller species of bird, one per nest. The female mimics a sparrowhawk. The resemblance is sufficient to make small birds take action to avoid the apparent predator. The female cuckoo then has time to lay her egg in their nest without being seen to do so. The cuckoo's egg itself mimics the eggs of the host species, reducing its chance of being rejected.
Motion dazzle.
Most forms of camouflage are made ineffective by movement: a deer or grasshopper may be highly cryptic when motionless, but instantly seen when it moves. But one method, motion dazzle, requires rapidly moving bold patterns of contrasting stripes. Motion dazzle may degrade predators' ability to estimate the prey's speed and direction accurately, giving the prey an improved chance of escape. Motion dazzle distorts speed perception, and is most effective at high speeds; stripes can also distort perception of size (and so, perceived range to the target). As of 2011, motion dazzle had been proposed for military vehicles, but never applied. Since dazzle patterns would make animals more difficult to locate accurately when moving, but easier to see when stationary, there would be an evolutionary trade-off between dazzle and crypsis.
An animal that is commonly thought to be dazzle patterned is the zebra. The bold stripes of the zebra have been claimed to be disruptive camouflage, background blending and countershading. After many years in which the purpose of the coloration was disputed, an experimental study by Tim Caro suggested in 2012 that the pattern reduces the attractiveness of stationary models to biting flies such as horseflies and tsetse flies. However, a simulation study by Martin How and Johannes Zanker in 2014 suggests that when moving the stripes may confuse observers, such as mammalian predators and biting insects, via two visual illusions, the wagon wheel effect, where the perceived motion is inverted, and the barber pole illusion, where the perceived motion is in a wrong direction.
Civil applications.
Camouflage is occasionally used to make buildings less conspicuous: for example, in South Africa, towers carrying cell telephone antennae are sometimes camouflaged as tall trees with plastic branches, in response to "resistance from the community". Since this method is costly (a figure of three times the normal cost is mentioned), alternative forms of camouflage can include using neutral colours or familiar shapes such as cylinders and flagpoles. Conspicuousness can also be reduced by siting masts near or actually on other structures.
Hunters of game have long made use of camouflage in the form of materials such as animal skins, mud, foliage, and green or brown clothing to enable them to approach wary game animals. Field sports such as driven grouse shooting conceal hunters in hides (also called blinds or shooting butts). Modern hunting clothing makes use of fabrics that provide a disruptive camouflage pattern; for example, in 1986 the hunter Bill Jordan created cryptic clothing for hunters, printed with images of specific kinds of vegetation such as grass and branches.
Fashion, art and society.
Military camouflage patterns influenced fashion and art from the time of the First World War onwards. Gertrude Stein recalled the cubist artist Pablo Picasso's reaction in around 1915:
In 1919, the attendants of a "dazzle ball", hosted by the Chelsea Arts Club, wore dazzle-patterned black and white clothing. The ball influenced fashion and art via postcards and magazine articles. The "Illustrated London News" announced
 More recently, fashion designers have often used camouflage fabric for its striking designs, its "patterned disorder" and its symbolism. Camouflage clothing can be worn largely for its symbolic significance rather than for fashion, as when, during the late 1960s and early 1970s in the United States, anti-war protestors often ironically wore military clothing during demonstrations against the American involvement in the Vietnam War.
Modern artists such as Ian Hamilton Finlay have used camouflage to reflect on war. His 1973 screenprint of a tank camouflaged in a leaf pattern, "Arcadia", is described by the Tate as drawing "an ironic parallel between this idea of a natural paradise and the camouflage patterns on a tank". The title refers to the Utopian Arcadia of poetry and art, and the "memento mori" Latin phrase "Et in Arcadia ego" which recurs in Hamilton Finlay's work. In science fiction, "Camouflage" is a novel about shapeshifting alien beings by Joe Haldeman. The word is used more figuratively in works of literature such as Thaisa Frank's collection of stories of love and loss, "A Brief History of Camouflage".

</doc>
<doc id="6449" url="http://en.wikipedia.org/wiki?curid=6449" title="Clock">
Clock

A clock is an instrument to indicate, keep, and co-ordinate time. The word "clock" is derived ultimately (via Dutch, Northern French, and Medieval Latin) from the Celtic words "clagan" and "clocca" meaning "bell". A silent instrument missing such a mechanism has traditionally been known as a timepiece. In general usage today a "clock" refers to any device for measuring and displaying the time. Watches and other timepieces that can be carried on one's person are often distinguished from clocks.
The clock is one of the oldest human inventions, meeting the need to consistently measure intervals of time shorter than the natural units: the day, the lunar month, and the year. Devices operating on several physical processes have been used over the millennia. A sundial shows the time by displaying the position of a shadow on a flat surface. There are a range of duration timers, a well-known example being the hourglass. Water clocks, along with the sundials, are possibly the oldest time-measuring instruments. A major advance occurred in Europe around 1300 with the invention of the "escapement", which allowed construction of the first mechanical clocks, which used oscillating timekeepers like balance wheels. Spring-driven clocks appeared during the 15th century. During the 15th and 16th centuries, clockmaking flourished. The next development in accuracy occurred after 1656 with the invention of the pendulum clock. A major stimulus to improving the accuracy and reliability of clocks was the importance of precise time-keeping for navigation. The electric clock was patented in 1840. The development of electronics in the 20th century led to clocks with no clockwork parts at all. 
The timekeeping element in every modern clock is a harmonic oscillator, a physical object (resonator) that vibrates or oscillates repetitively at a precisely constant frequency.
This object can be a pendulum, a tuning fork, a quartz crystal, or the vibration of electrons in atoms as they emit microwaves. Analog clocks usually indicate time using angles. Digital clocks display a numeric representation of time. Two numeric display formats are commonly used on digital clocks: 24 hour notation and 12 hour notation. Most digital clocks use electronic mechanisms and LCD, LED, or VFD displays. For convenience, distance, telephony or blindness, auditory clocks present the time as sounds. There are also clocks for the blind that have displays that can be read by using the sense of touch. Some of these are similar to normal analog displays, but are constructed so the hands can be felt without damaging them. The evolution of the technology of clocks continues today.
The study of timekeeping is known as horology.
Time measuring devices.
Sundials.
When the Sun is shining, its apparent position in the sky moves during a day, reflecting the rotation of the Earth. Shadows cast by stationary objects move correspondingly, so their positions can be used to indicate the time of day. A sundial shows the time by displaying the position of a shadow on a (usually) flat surface, which has markings that correspond to the hours. Sundials can be horizontal, vertical, or in other orientations. Sundials were widely used in ancient times. With the knowledge of latitude, a well-constructed sundial can measure local solar time with reasonable accuracy, within a minute or two. Sundials continued to be used to monitor the performance of clocks until the modern era. However, practical limitations, such as that sundials work only when the Sun shines, and never during the night, encouraged the use of other techniques for measuring and displaying time.
Devices that measure duration, elapsed time and/or intervals.
Many devices can be used to mark passage of time without respect to reference time (time of day, minutes, etc...) and can be useful for measuring duration and/or intervals. Examples of such duration timers are, candle clocks, incense clocks and the hourglass. Both the candle clock and the incense clock work on the same principle wherein the consumption of resources is more or less constant allowing reasonably precise, and repeatable, estimates of time passages. In the hourglass, fine sand pouring through a tiny hole at a constant rate indicates an arbitrary, predetermined, passage of time, the resource is not consumed but re-used.
Water clocks.
Water clocks, also known as clepsydrae (sg: "clepsydra"), along with the sundials, are possibly the oldest time-measuring instruments, with the only exceptions being the vertical gnomon and the day counting tally stick. Given their great antiquity, where and when they first existed is not known and perhaps unknowable. The bowl-shaped outflow is the simplest form of a water clock and is known to have existed in Babylon and in Egypt around the 16th century BC. Other regions of the world, including India and China, also have early evidence of water clocks, but the earliest dates are less certain. Some authors, however, write about water clocks appearing as early as 4000 BC in these regions of the world.
Greek astronomer Andronicus of Cyrrhus supervised the construction of the Tower of the Winds in Athens in the 1st century B.C.
The Greek and Roman civilizations are credited for initially advancing water clock design to include complex gearing, which was connected to fanciful automata and also resulted in improved accuracy. These advances were passed on through Byzantium and Islamic times, eventually making their way back to Europe. Independently, the Chinese developed their own advanced water clocks（水鐘）in 725 A.D., passing their ideas on to Korea and Japan.
Some water clock designs were developed independently and some knowledge was transferred through the spread of trade. Pre-modern societies do not have the same precise timekeeping requirements that exist in modern industrial societies, where every hour of work or rest is monitored, and work may start or finish at any time regardless of external conditions. Instead, water clocks in ancient societies were used mainly for astrological reasons. These early water clocks were calibrated with a sundial. While never reaching the level of accuracy of a modern timepiece, the water clock was the most accurate and commonly used timekeeping device for millennia, until it was replaced by the more accurate pendulum clock in 17th-century Europe.
Islamic civilization is credited with further advancing the accuracy of clocks with elaborate engineering. In 797 (or possibly 801), the Abbasid caliph of Baghdad, Harun al-Rashid, presented Charlemagne with an Asian Elephant named Abul-Abbas together with a "particularly elaborate example" of a water clock.
Pope Sylvester II introduced clocks to northern and western Europe around 1000 C.E.
In the 13th century, Al-Jazari, an engineer from Mesopotamia (lived 1136-1206) who worked for Artuqid king of Diyar-Bakr, Nasir al-Din, made numerous clocks of all shapes and sizes. The book described 50 mechanical devices in 6 categories, including water clocks. The most reputed clocks included the Elephant, Scribe and Castle clocks, all of which have been successfully reconstructed. As well as telling the time, these grand clocks were symbols of status, grandeur and wealth of the Urtuq State.
Early mechanical clocks.
The word "horologia" (from the Greek ὡρα, hour, and λέγειν, to tell) was used to describe early mechanical clocks, but the use of this word (still used in several Romance languages) for all timekeepers conceals the true nature of the mechanisms. For example, there is a record that in 1176 Sens Cathedral installed a ‘horologe’ but the mechanism used is unknown. According to Jocelin of Brakelond, in 1198 during a fire at the abbey of St Edmundsbury (now Bury St Edmunds), the monks 'ran to the clock' to fetch water, indicating that their water clock had a reservoir large enough to help extinguish the occasional fire.
The word "clock" (from the Celtic words "clocca" and "clogan", both meaning "bell"), which gradually supersedes "horologe", suggests that it was the sound of bells which also characterized the prototype mechanical clocks that appeared during the 13th century in Europe.
Outside Europe, the first mechanical clock was completed in China in AD 725 by Yi Xing and Liang Lingzan. The escapement mechanism had been known and used in medieval China, as the Song Dynasty horologist and engineer Su Song (1020–1101) incorporated it into his astronomical clock-tower of Kaifeng in 1088. His astronomical clock and rotating armillary sphere still relied on the use of flowing water (i.e. hydraulics), while European clockworks of the following centuries shed this method for a more efficient driving power of weights, in addition to the escapement mechanism.
A mercury clock, described in the "Libros del saber", a Spanish work from 1277 consisting of translations and paraphrases of Arabic works, is sometimes quoted as evidence for Muslim knowledge of a mechanical clock. The first mercury powered automatic clock was invented by Ibn Khalaf al-Muradi
Between 1280 and 1320, there is an increase in the number of references to clocks and horologes in church records, and this probably indicates that a new type of clock mechanism had been devised. Existing clock mechanisms that used water power were being adapted to take their driving power from falling weights. This power was controlled by some form of oscillating mechanism, probably derived from existing bell-ringing or alarm devices. This controlled release of power—the escapement—marks the beginning of the true mechanical clock.
These mechanical clocks were intended for two main purposes: for signalling and notification (e.g. the timing of services and public events), and for modeling the solar system. The former purpose is administrative, the latter arises naturally given the scholarly interest in astronomy, science, astrology, and how these subjects integrated with the religious philosophy of the time. The astrolabe was used both by astronomers and astrologers, and it was natural to apply a clockwork drive to the rotating plate to produce a working model of the solar system.
Simple clocks intended mainly for notification were installed in towers, and did not always require faces or hands. They would have announced the canonical hours or intervals between set times of prayer. Canonical hours varied in length as the times of sunrise and sunset shifted. The more sophisticated astronomical clocks would have had moving dials or hands, and would have shown the time in various time systems, including Italian hours, canonical hours, and time as measured by astronomers at the time. Both styles of clock started acquiring extravagant features such as automata.
In 1283, a large clock was installed at Dunstable Priory; its location above the rood screen suggests that it was not a water clock. In 1292, Canterbury Cathedral installed a 'great horloge'. Over the next 30 years there are mentions of clocks at a number of ecclesiastical institutions in England, Italy, and France. In 1322, a new clock was installed in Norwich, an expensive replacement for an earlier clock installed in 1273. This had a large (2 metre) astronomical dial with automata and bells. The costs of the installation included the full-time employment of two clockkeepers for two years.
Astronomical clocks.
Besides the Chinese astronomical clock of Su Song in 1088 mentioned above, in Europe there were the clocks constructed by Richard of Wallingford in St Albans by 1336, and by Giovanni de Dondi in Padua from 1348 to 1364. They no longer exist, but detailed descriptions of their design and construction survive, 
 and modern reproductions have been made. They illustrate how quickly the theory of the mechanical clock had been translated into practical constructions, and also that one of the many impulses to their development had been the desire of astronomers to investigate celestial phenomena.
Wallingford's clock had a large astrolabe-type dial, showing the sun, the moon's age, phase, and node, a star map, and possibly the planets. In addition, it had a wheel of fortune and an indicator of the state of the tide at London Bridge. Bells rang every hour, the number of strokes indicating the time.
Dondi's clock was a seven-sided construction, 1 metre high, with dials showing the time of day, including minutes, the motions of all the known planets, an automatic calendar of fixed and movable feasts, and an eclipse prediction hand rotating once every 18 years.
It is not known how accurate or reliable these clocks would have been. They were probably adjusted manually every day to compensate for errors caused by wear and imprecise manufacture.
Water clocks are sometimes still used today, and can be examined in places such as ancient castles and museums.
The Salisbury Cathedral clock, built in 1386, is considered to be the world's oldest surviving mechanical clock that strikes the hours.
Spring-driven Clocks.
Clockmakers developed their art in various ways. Building smaller clocks was a technical challenge, as was improving accuracy and reliability. Clocks could be impressive showpieces to demonstrate skilled craftsmanship, or less expensive, mass-produced items for domestic use. The escapement in particular was an important factor affecting the clock's accuracy, so many different mechanisms were tried.
Spring-driven clocks appeared during the 15th century, although they are often erroneously credited to Nuremberg watchmaker Peter Henlein (or Henle, or Hele) around 1511. The earliest existing spring driven clock is the chamber clock given to Phillip the Good, Duke of Burgundy, around 1430, now in the Germanisches Nationalmuseum. Spring power presented clockmakers with a new problem: how to keep the clock movement running at a constant rate as the spring ran down. This resulted in the invention of the "stackfreed" and the fusee in the 15th century, and many other innovations, down to the invention of the modern "going barrel" in 1760.
Early clock dials did not indicate minutes and seconds. A clock with a dial indicating minutes was illustrated in a 1475 manuscript by Paulus Almanus, and some 15th-century clocks in Germany indicated minutes and seconds.
An early record of a seconds hand on a clock dates back to about 1560 on a clock now in the Fremersdorf collection. However, this clock could not have been accurate, and the seconds hand was probably for indicating that the clock was working.
During the 15th and 16th centuries, clockmaking flourished, particularly in the metalworking towns of Nuremberg and Augsburg, and in Blois, France. Some of the more basic table clocks have only one time-keeping hand, with the dial between the hour markers being divided into four equal parts making the clocks readable to the nearest 15 minutes. Other clocks were exhibitions of craftsmanship and skill, incorporating astronomical indicators and musical movements. The cross-beat escapement was invented in 1584 by Jost Bürgi, who also developed the remontoire. Bürgi's clocks were a great improvement in accuracy as they were correct to within a minute a day.
These clocks helped the 16th-century astronomer Tycho Brahe to observe astronomical events with much greater precision than before.
Pendulum Clock.
The next development in accuracy occurred after 1656 with the invention of the pendulum clock. Galileo had the idea to use a swinging bob to regulate the motion of a time-telling device earlier in the 17th century. Christiaan Huygens, however, is usually credited as the inventor. He determined the mathematical formula that related pendulum length to time (99.38 cm or 39.13 inches for the one second movement) and had the first pendulum-driven clock made. The first model clock was built in 1657 in the Hague, but it was in England that the idea was taken up. The longcase clock (also known as the "grandfather clock") was created to house the pendulum and works by the English clockmaker William Clement in 1670 or 1671. It was also at this time that clock cases began to be made of wood and clock faces to utilize enamel as well as hand-painted ceramics.
In 1670, William Clement created the anchor escapement, an improvement over Huygens' crown escapement. Clement also introduced the pendulum suspension spring in 1671. The concentric minute hand was added to the clock by Daniel Quare, a London clock-maker and others, and the Second Hand was first introduced.
The Hairspring.
In 1675, Huygens and Robert Hooke invented the spiral balance, or the hairspring, designed to control the oscillating speed of the balance wheel. This crucial advance finally made accurate pocket watches possible. The great English clockmaker, Thomas Tompion, was one of the first to use this mechanism successfully in his pocket watches, and he adopted the minute hand which, after a variety of designs were trialled, eventually stabilised into the modern-day configuration.
The Rev. Edward Barlow invented the rack and snail striking mechanism for striking clocks, which was a great improvement over the previous mechanism. The repeating clock, that chimes the number of hours (or even minutes) was invented by either Quare or Barlow in 1676. George Graham invented the deadbeat escapement for clocks in 1720.
Marine Chronometer.
A major stimulus to improving the accuracy and reliability of clocks was the importance of precise time-keeping for navigation. The position of a ship at sea could be determined with reasonable accuracy if a navigator could refer to a clock that lost or gained less than about 10 seconds per day. This clock could not contain a pendulum, which would be virtually useless on a rocking ship. The British government offered a large prize to the value of 20,000 pounds, for anyone who could determine longitude accurately after the Scilly naval disaster of 1707. The reward was eventually claimed in 1761 by John Harrison, who dedicated his life to improving the accuracy of his clocks.
In 1735 Harrison built his first chronometer, which he steadily improved on over the next thirty years before submitting it for examination. The clock had many innovations, including the use of bearings to reduce friction, weighted balances to compensate for the ship's pitch and roll in the sea and the use of two different metals to reduce the problem of expansion from heat.
The chronometer was tested in 1761 by Harrison's son and by the end of 10 weeks the clock was in error by less than 5 seconds.
Mass production.
The British had predominated in watch manufacture for much of the 17th and 18th centuries, but maintained a system of production that was geared towards high quality products for the elite. Although there was an attempt to modernise clock manufacture with mass production techniques and the application of duplicating tools and machinery by the British Watch Company in 1843, it was in the United States that this system took off. Aaron Lufkin Dennison started a factory in 1851 in Massachusetts that used interchangeable parts, and by 1861 was running a successful enterprise incorporated as the Waltham Watch Company.
Electric Clocks.
Alexander Bain, Scottish clockmaker, patented the electric clock in 1840. The electric clock's mainspring is wound either with an electric motor or with an electromagnet and armature. In 1841, he first patented the electromagnetic pendulum.
By the end of the nineteenth century, the advent of the dry cell battery made it feasible to use electric power in clocks. Spring or weight driven clocks that use electricity, either alternating current (AC) or direct current (DC), to rewind the spring or raise the weight of a mechanical clock would be classified as an electromechanical clock. This classification would also apply to clocks that employ an electrical impulse to propel the pendulum. In electromechanical clocks the electricity serves no time keeping function. These types of clocks were made as individual timepieces but more commonly used in synchronized time installations in schools, businesses, factories, railroads and government facilities as a master clock and slave clocks.
Electric clocks that are powered from the AC supply often use synchronous motors. The supply current alternates with a frequency of exactly 50 hertz in many countries, and 60 hertz in others. The rotor of the motor rotates at a speed that is exactly related to the alternation frequency. Appropriate gearing converts this rotation speed to the correct ones for the hands of the analog clock.
The development of electronics in the 20th century led to clocks with no clockwork parts at all. Time in these cases is measured in several ways, such as by the alternation of the AC supply, vibration of a tuning fork, the behaviour of quartz crystals, or the quantum vibrations of atoms. Electronic circuits divide these high-frequency oscillations to slower ones that drive the time display. Even mechanical clocks have since come to be largely powered by batteries, removing the need for winding.
How clocks work.
The invention of the mechanical clock in the 13th century initiated a change in timekeeping methods from continuous processes, such as the motion of the gnomon's shadow on a sundial or the flow of liquid in a water clock, to periodic oscillatory processes, such as the swing of a pendulum or the vibration of a quartz crystal, which had the potential for more accuracy. All modern clocks use oscillation.
Although the methods they use vary, all oscillating clocks, mechanical and digital and atomic, work similarly and can be divided into analogous parts. They consist of an object that repeats the same motion over and over again, an "oscillator", with a precisely constant time interval between each repetition, or 'beat'. Attached to the oscillator is a "controller" device, which sustains the oscillator's motion by replacing the energy it loses to friction, and converts its oscillations into a series of pulses. The pulses are then counted by some type of "counter", and the number of counts is converted into convenient units, usually seconds, minutes, hours, etc. Finally some kind of "indicator" displays the result in human readable form.
Power source.
This provides power to keep the clock going.
Oscillator.
The timekeeping element in every modern clock is a harmonic oscillator, a physical object (resonator) that vibrates or oscillates repetitively at a precisely constant frequency.
The advantage of a harmonic oscillator over other forms of oscillator is that it employs resonance to vibrate at a precise natural resonant frequency or 'beat' dependent only on its physical characteristics, and resists vibrating at other rates. The possible precision achievable by a harmonic oscillator is measured by a parameter called its Q, or quality factor, which increases (other things being equal) with its resonant frequency. This is why there has been a long term trend toward higher frequency oscillators in clocks. Balance wheels and pendulums always include a means of adjusting the rate of the timepiece. Quartz timepieces sometimes include a rate screw that adjusts a capacitor for that purpose. Atomic clocks are primary standards, and their rate cannot be adjusted.
Synchronized or slave clocks.
Some clocks rely for their accuracy on an external oscillator; that is, they are automatically synchronized to a more accurate clock:
Controller.
This has the dual function of keeping the oscillator running by giving it 'pushes' to replace the energy lost to friction, and converting its vibrations into a series of pulses that serve to measure the time.
In mechanical clocks, the low Q of the balance wheel or pendulum oscillator made them very sensitive to the disturbing effect of the impulses of the escapement, so the escapement had a great effect on the accuracy of the clock, and many escapement designs were tried. The higher Q of resonators in electronic clocks makes them relatively insensitive to the disturbing effects of the drive power, so the driving oscillator circuit is a much less critical component.
Counter chain.
This counts the pulses and adds them up to get traditional time units of seconds, minutes, hours, etc. It usually has a provision for "setting" the clock by manually entering the correct time into the counter.
Indicator.
This displays the count of seconds, minutes, hours, etc. in a human readable form.
Types.
Clocks can be classified by the type of time display, as well as by the method of timekeeping.
Time display methods.
Analog clocks.
Analog clocks usually indicate time using angles. The most common clock face uses a fixed numbered dial or dials and moving hand or hands. It usually has a circular scale of 12 hours, which can also serve as a scale of 60 minutes, and 60 seconds if the clock has a second hand. Many other styles and designs have been used throughout the years, including dials divided into 6, 8, 10, and 24 hours. The only other widely used clock face today is the 24 hour analog dial, because of the use of 24 hour time in military organizations and timetables. The 10-hour clock was briefly popular during the French Revolution, when the metric system was applied to time measurement, and an Italian 6 hour clock was developed in the 18th century, presumably to save power (a clock or watch striking 24 times uses more power).
Another type of analog clock is the sundial, which tracks the sun continuously, registering the time by the shadow position of its gnomon. Because the sun does not adjust to daylight savings times, users must add an hour during that time. Corrections must also be made for the equation of time, and for the difference between the longitudes of the sundial and of the central meridian of the time zone that is being used (i.e. 15 degrees east of the prime meridian for each hour that the time zone is ahead of GMT). Sundials use some or part of the 24 hour analog dial. There also exist clocks which use a digital display despite having an analog mechanism—these are commonly referred to as flip clocks.
Alternative systems have been proposed. For example, the Twelv clock indicates the current hour using one of twelve colors, and indicates the minute by showing a proportion of a circular disk, similar to a moon phase.
Digital clocks.
Click on any image to enlarge it.
Digital clocks display a numeric representation of time. Two numeric display formats are commonly used on digital clocks:
Most digital clocks use electronic mechanisms and LCD, LED, or VFD displays; many other display technologies are used as well (cathode ray tubes, nixie tubes, etc.). After a reset, battery change or power failure, these clocks without a backup battery or capacitor either start counting from 12:00, or stay at 12:00, often with blinking digits indicating that the time needs to be set. Some newer clocks will reset themselves based on radio or Internet time servers that are tuned to national atomic clocks. Since the advent of digital clocks in the 1960s, the use of analog clocks has declined significantly.
Some clocks, called 'flip clocks', have digital displays that work mechanically. The digits are painted on sheets of material which are mounted like the pages of a book. Once a minute, a page is turned over to reveal the next digit. These displays are usually easier to read in brightly lit conditions than LCDs or LEDs. Also, they do not go back to 12:00 after a power interruption. Flip clocks generally do not have electronic mechanisms. Usually, they are driven by AC-synchronous motors.
Auditory clocks.
For convenience, distance, telephony or blindness, auditory clocks present the time as sounds. The sound is either spoken natural language, (e.g. "The time is twelve thirty-five"), or as auditory codes (e.g. number of sequential bell rings on the hour represents the number of the hour like the bell Big Ben). Most telecommunication companies also provide a speaking clock service as well.
Word clocks.
Word clocks are clocks that display the time visually using sentences. E.g.: "It’s about three o’clock." These clocks can be implemented in hardware or software.
Projection clocks.
Some clocks, usually digital ones, include an optical projector that shines a magnified image of the time display onto a screen or onto a surface such as an indoor ceiling or wall. The digits are large enough to be easily read, without using glasses, by persons with moderately imperfect vision, so the clocks are convenient for use in their bedrooms. Usually, the timekeeping circuitry has a battery as a backup source for an uninterrupted power supply to keep the clock on time, while the projection light only works when the unit is connected to an A.C. supply. Completely battery-powered portable versions resembling flashlights are also available.
Tactile clocks.
Auditory and projection clocks can be used by people who are blind or have limited vision. There are also clocks for the blind that have displays that can be read by using the sense of touch. Some of these are similar to normal analog displays, but are constructed so the hands can be felt without damaging them. Another type is essentially digital, and uses devices that use a code such as Braille to show the digits so that they can be felt with the fingertips.
Multi-display clocks.
Some clocks have several displays driven by a single mechanism, and some others have several completely separate mechanisms in a single case. Clocks in public places often have several faces visible from different directions, so that the clock can be read from anywhere in the vicinity. Of course, all the faces show the same time. Other clocks show the current time in several time-zones. Watches that are intended to be carried by travellers often have two displays, one for the local time and the other for the time at home, which is useful for making pre-arranged phone calls. Some equation clocks have two displays, one showing mean time and the other solar time, as would be shown by a sundial. Some clocks have both analog and digital displays. Clocks with Braille displays usually also have conventional digits so they can be read by sighted people.
Purposes.
Clocks are in homes, offices and many other places; smaller ones (watches) are carried on the wrist or in a pocket; larger ones are in public places, e.g. a railway station or church. A small clock is often shown in a corner of computer displays, mobile phones and many MP3 players.
The primary purpose of a clock is to "display" the time. Clocks may also have the facility to make a loud alert signal at a specified time, typically to waken a sleeper at a preset time; they are referred to as "alarm clocks". The alarm may start at a low volume and become louder, or have the facility to be switched off for a few minutes then resume. Alarm clocks with visible indicators are sometimes used to indicate to children too young to read the time that the time for sleep has finished; they are sometimes called "training clocks".
A clock mechanism may be used to "control" a device according to time, e.g. a central heating system, a VCR, or a time bomb (see: counter). Such mechanisms are usually called timers. Clock mechanisms are also used to drive devices such as solar trackers and astronomical telescopes, which have to turn at accurately controlled speeds to counteract the rotation of the Earth.
Most digital computers depend on an internal signal at constant frequency to synchronize processing; this is referred to as a clock signal. (A few research projects are developing CPUs based on asynchronous circuits.) Some equipment, including computers, also maintains time and date for use as required; this is referred to as time-of-day clock, and is distinct from the system clock signal, although possibly based on counting its cycles.
Time standards.
For some scientific work timing of the utmost accuracy is essential. It is also necessary to have a standard of the maximum accuracy against which working clocks can be calibrated. An ideal clock would give the time to unlimited accuracy, but this is of course not realisable.
Many physical processes, in particular including some transitions between atomic energy levels, occur at exceedingly stable frequency; counting cycles of such a process can give a very accurate and consistent time—clocks which work this way are usually called atomic clocks. Such clocks are typically large, very expensive, require a controlled environment, and are far more accurate than required for most purposes; they are typically used in a standards laboratory.
Navigation.
Until advances in the late twentieth century, navigation depended on the ability to measure latitude and longitude. Latitude can be determined through celestial navigation; the measurement of longitude requires accurate knowledge of time. This need was a major motivation for the development of accurate mechanical clocks. John Harrison created the first highly accurate marine chronometer in the mid-18th century. The Noon gun in Cape Town still fires an accurate signal to allow ships to check their chronometers. Many buildings near major ports used to have (some still do) a large ball mounted on a tower or mast arranged to drop at a pre-determined time, for the same purpose.
While satellite navigation systems such as the Global Positioning System (GPS) require unprecedentedly accurate knowledge of time, this is supplied by equipment on the satellites; vehicles no longer need timekeeping equipment.
Seismology.
In determining the location of an earthquake, the arrival time of several types of seismic wave at a minimum of four dispersed observers is dependent upon each observer recording wave arrival times according to a common clock.

</doc>
<doc id="6451" url="http://en.wikipedia.org/wiki?curid=6451" title="Charles Proteus Steinmetz">
Charles Proteus Steinmetz

Charles Proteus Steinmetz (April 9, 1865 – October 26, 1923) was a German-born American mathematician and electrical engineer. He fostered the development of alternating current that made possible the expansion of the electric power industry in the United States, formulating mathematical theories for engineers. He made ground-breaking discoveries in the understanding of hysteresis that enabled engineers to design better electromagnetic apparatus equipment including especially electric motors for use in industry.
Biography.
Steinmetz was born on April 9, 1865 as Karl August Rudolph Steinmetz into a Jewish family in Breslau, Province of Silesia. Steinmetz suffered from dwarfism, hunchback, and hip dysplasia, as did his father and grandfather. Steinmetz attended Johannes Gymnasium and astonished his teachers with his proficiency in mathematics and physics.
Following the Gymnasium, Steinmetz went on to the University of Breslau to begin work on his undergraduate degree in 1883. He was on the verge of finishing his doctorate in 1888 when he came under investigation by the German police for activities on behalf of a socialist university group and articles he had written for a local socialist newspaper.
Steinmetz died on October 26, 1923 and was buried in Vale Cemetery, Schenectady.
Socialism.
As socialist meetings and press had been banned in Germany, Steinmetz fled to Zürich in 1888 to escape possible arrest. Faced with an expiring visa, he emigrated to the United States in 1889. He changed his first name to Charles in order to sound more American and chose the middle name Proteus after a childhood taunt given to him by classmates. Proteus was a wise hunchbacked character from the Odyssey who knew many secrets and he felt it suited him.
Cornell University Professor Ronald R. Kline, the author of "Steinmetz: Engineer and Socialist", contended that other factors were more directly involved in Steinmetz's decision to leave his homeland, such as the fact that he was in arrears with his tuition at the University of Breslau and that life at home with his father, stepmother, and their daughters was full of tension.
Despite his earlier efforts and interest in socialism, by 1922 Steinmetz concluded that socialism would never work in the U.S. because the country lacked a "powerful, centralized government of competent men, remaining continuously in office" and because "only a small percentage of Americans accept this viewpoint today."
Engineering wizard.
Steinmetz is known for his contribution in three major fields of alternating current (AC) systems theory: hysteresis, steady-state analysis, and transients.
AC hysteresis theory.
Shortly after arriving in the U.S., Steinmetz went to work for Rudolf Eickemeyer in Yonkers, New York, and published in the field of magnetic hysteresis, which gave him world-wide professional recognition. Eickemeyer's firm developed transformers for use in the transmission of electrical power among many other mechanical and electrical devices. In 1893 Eickemeyer's company, along with all of its patents and designs, was bought by the newly formed General Electric Company, where he quickly became known as the engineering wizard in GE's engineering community.
AC steady state circuit theory.
Steinmetz's work revolutionized AC circuit theory and analysis, which had been carried out using complex, time-consuming calculus-based methods. In the groundbreaking paper, "Complex Quantities and Their Use in Electrical Engineering", presented at a July 1893 meeting published in the American Institute of Electrical Engineers (AIEE), Steinmetz simplified these complicated methods to "a simple problem of algebra". He systematized the use of complex number phasor representation in electrical engineering education texts, whereby the letter j is used to designate the 90 degree rotation operator in AC system analysis. His seminal books and many other AIEE papers "taught a whole generation of engineers how to deal with AC phenomena".
AC transient theory.
Steinmetz also made greater strides to the understanding of lightning phenomena. He undertook a systematic study of it, resulting in experiments of man-made lightning in the laboratory; this work was published. Steinmetz was called the "forger of thunderbolts", being the first to create artificial lightning in his football field-sized laboratory and high towers built at General Electric, using 120,000 volt generators. He erected a lightning tower to attract lightning and studied the patterns and effects of lightning resulting in several theories and ideas.
Professional and personal aspects.
Steinmetz served as president of the Board of Education of Schenectady, and as president of the Schenectady City Council. He was president of the American Institute of Electrical Engineers (AIEE) from 1901 to 1902, as well as the first vice-president of the International Association of Municipal Electricians (IAME)—which later became the International Municipal Signal Association (IMSA)—from 1913 until his death. Steinmetz wrote 13 books and 60 articles, not all about engineering. He was an honorary member and advisor to the fraternity Phi Gamma Delta at Union (whose chapter house there was one of the first electrified houses ever).
Steinmetz was a lifelong agnostic. 
Legacy.
Based on Steinmetz experiments, "Steinmetz's formula" defines the approximate heat energy due to magnetic hysteresis released per cycle per unit area of magnetic material. "Steinmetz equivalent circuit" theory is still widely used for the design and testing of induction motors.
One of the highest technical awards given by the Institute of Electrical and Electronics Engineers, for major contributions to standardization within the field of electrical and electronics engineering, is named in his honor as the IEEE Charles Proteus Steinmetz Award.
His connection to Union College is celebrated with the annual Steinmetz Symposium, a day-long event in which Union undergraduates give presentations on research they have done. Steinmetz Hall, which houses the Union College computer center, is named after him.
Steinmetz was portrayed in 1959 by the actor Rod Steiger in the CBS anthology series, "The Joseph Cotten Show". The episode centered on his socialist activities in Germany.
A Chicago Public High School is named for him.
A public park in north Schenectady, New York was named for him in 1931.
Patents.
At the time of his death, Steinmetz held over 200 patents:
In popular culture.
Steinmetz is featured in John Dos Passos's "USA Trilogy" in one of the biographies.
He also serves as a major character in Starling Lawrence's "The Lightning Keeper".
In the animated television show "The Simpsons", his name was used as a kind of expletive by the industrialist character Mr. Burns ("Oh, quit cogitating, Steinmetz!") in reference to someone who was overthinking a decision.
Novelist John Ball grew up in Steinmetz's house. His parents were graduate students paid by GE to live with and take care of the man Ball called "Uncle Steinie". Ball used to tell Steinmetz stories to the Southern California Mystery Writers Association meetings.

</doc>
